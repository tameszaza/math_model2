{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully.\n",
      "\n",
      "Columns in the dataset:\n",
      "Index(['Unnamed: 0', 'Sport', 'drug_1896', 'Female_1896', 'Male_1896',\n",
      "       'total_1896', 'equity_1896', 'country_1896', '10.0_1896', '17.0_1896',\n",
      "       ...\n",
      "       'CV_1980', 'CV_1984', 'CV_1988', 'CV_1992', 'CV_1996', 'CV_2000',\n",
      "       'CV_2004', 'CV_2008', 'CV_2012', 'CV_2016'],\n",
      "      dtype='object', length=1757)\n",
      "\n",
      "Preview of the dataset:\n",
      "   Unnamed: 0             Sport  drug_1896  Female_1896  Male_1896  \\\n",
      "0           0     Alpine Skiing        0.0          NaN        NaN   \n",
      "1           1          Alpinism        0.0          NaN        NaN   \n",
      "2           2           Archery        0.0          NaN        NaN   \n",
      "3           3  Art Competitions        0.0          NaN        NaN   \n",
      "4           4         Athletics        0.0          NaN      106.0   \n",
      "\n",
      "   total_1896  equity_1896  country_1896  10.0_1896  17.0_1896  ...   CV_1980  \\\n",
      "0         0.0          NaN           NaN        NaN        NaN  ...  0.941454   \n",
      "1         0.0          NaN           NaN        NaN        NaN  ...  0.000000   \n",
      "2         0.0          NaN           NaN        NaN        NaN  ...  0.518674   \n",
      "3         0.0          NaN           NaN        NaN        NaN  ...  0.000000   \n",
      "4       106.0          0.0           9.0        NaN        1.0  ...  1.012697   \n",
      "\n",
      "    CV_1984   CV_1988   CV_1992   CV_1996   CV_2000   CV_2004   CV_2008  \\\n",
      "0  0.810152  0.975410  1.038671  0.000000  0.000000  0.000000  0.000000   \n",
      "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "2  0.486000  0.736622  0.877037  0.872777  0.840279  0.893923  0.819216   \n",
      "3  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "4  1.053289  1.032190  0.986700  1.016212  0.982383  0.984688  1.058562   \n",
      "\n",
      "    CV_2012   CV_2016  \n",
      "0  0.000000  0.000000  \n",
      "1  0.000000  0.000000  \n",
      "2  0.751548  0.849326  \n",
      "3  0.000000  0.000000  \n",
      "4  0.964608  0.974802  \n",
      "\n",
      "[5 rows x 1757 columns]\n",
      "\n",
      "Data types of each column:\n",
      "Unnamed: 0       int64\n",
      "Sport           object\n",
      "drug_1896      float64\n",
      "Female_1896    float64\n",
      "Male_1896      float64\n",
      "                ...   \n",
      "CV_2000        float64\n",
      "CV_2004        float64\n",
      "CV_2008        float64\n",
      "CV_2012        float64\n",
      "CV_2016        float64\n",
      "Length: 1757, dtype: object\n",
      "\n",
      "Missing values summary:\n",
      "Unnamed: 0      0\n",
      "Sport           0\n",
      "drug_1896       3\n",
      "Female_1896    67\n",
      "Male_1896      59\n",
      "               ..\n",
      "CV_2000         0\n",
      "CV_2004         0\n",
      "CV_2008         0\n",
      "CV_2012         0\n",
      "CV_2016         0\n",
      "Length: 1757, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"not_final3.csv\")\n",
    "\n",
    "# Rename 'Sport_-1' for clarity\n",
    "df = df.rename(columns={'Sport_-1': 'Sport'})\n",
    "\n",
    "# Show dataset structure and preview\n",
    "print(\"Dataset loaded successfully.\\n\")\n",
    "print(\"Columns in the dataset:\")\n",
    "print(df.columns)\n",
    "\n",
    "print(\"\\nPreview of the dataset:\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\nData types of each column:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing values summary:\")\n",
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Raw data for Athletics (drug):\n",
      "    Year  Value\n",
      "0   1896    0.0\n",
      "1   1900    NaN\n",
      "2   1904    NaN\n",
      "3   1906    NaN\n",
      "4   1908    NaN\n",
      "5   1912    NaN\n",
      "6   1920    NaN\n",
      "7   1924    NaN\n",
      "8   1928    NaN\n",
      "9   1932    NaN\n",
      "10  1936    NaN\n",
      "11  1948    NaN\n",
      "12  1952    NaN\n",
      "13  1956    NaN\n",
      "14  1960    NaN\n",
      "15  1964    NaN\n",
      "16  1968    NaN\n",
      "17  1972    NaN\n",
      "18  1976    1.0\n",
      "19  1980    NaN\n",
      "20  1984    4.0\n",
      "21  1988    1.0\n",
      "22  1992    5.0\n",
      "23  1996    7.0\n",
      "24  2000    4.0\n",
      "25  2004   17.0\n",
      "26  2008   46.0\n",
      "27  2012   86.0\n",
      "28  2016    2.0\n",
      "29  2020    7.0\n",
      "30  2024    2.0\n",
      "\n",
      "Rechecked time series data for Athletics (drug):\n",
      "Year\n",
      "1896     0.0\n",
      "1900     0.0\n",
      "1904     0.0\n",
      "1906     0.0\n",
      "1908     0.0\n",
      "1912     0.0\n",
      "1920     0.0\n",
      "1924     0.0\n",
      "1928     0.0\n",
      "1932     0.0\n",
      "1936     0.0\n",
      "1948     0.0\n",
      "1952     0.0\n",
      "1956     0.0\n",
      "1960     0.0\n",
      "1964     0.0\n",
      "1968     0.0\n",
      "1972     0.0\n",
      "1976     1.0\n",
      "1980     0.0\n",
      "1984     4.0\n",
      "1988     1.0\n",
      "1992     5.0\n",
      "1996     7.0\n",
      "2000     4.0\n",
      "2004    17.0\n",
      "2008    46.0\n",
      "2012    86.0\n",
      "2016     2.0\n",
      "2020     7.0\n",
      "2024     2.0\n",
      "Name: Value, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:5: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:9: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:5: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:9: SyntaxWarning: invalid escape sequence '\\d'\n",
      "/tmp/ipykernel_641144/1984988609.py:5: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  raw_data = df[df['Sport'] == 'Athletics'].filter(regex=f'{parameter}_\\d+')\n",
      "/tmp/ipykernel_641144/1984988609.py:9: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  raw_melted['Year'] = raw_melted['Year'].str.extract('(\\d+)').astype(int)\n"
     ]
    }
   ],
   "source": [
    "# Example for one parameter and sport (you can loop through all sports later)\n",
    "parameter = 'drug'\n",
    "sport_name = 'Athletics'  # Example sport\n",
    "# Filter raw data for Athletics and drug parameter\n",
    "raw_data = df[df['Sport'] == 'Athletics'].filter(regex=f'{parameter}_\\d+')\n",
    "\n",
    "# Melt raw data for better visualization\n",
    "raw_melted = raw_data.melt(var_name='Year', value_name='Value')\n",
    "raw_melted['Year'] = raw_melted['Year'].str.extract('(\\d+)').astype(int)\n",
    "\n",
    "print(\"\\nRaw data for Athletics (drug):\")\n",
    "print(raw_melted.sort_values('Year'))\n",
    "\n",
    "# Re-prepare the series and compare\n",
    "ts_data_check = raw_melted.set_index('Year')['Value'].sort_index()\n",
    "# Replace NaN with 0 specifically for 'drug' parameter\n",
    "ts_data_check = ts_data_check.fillna(0)\n",
    "\n",
    "\n",
    "print(\"\\nRechecked time series data for Athletics (drug):\")\n",
    "print(ts_data_check)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw data for Athletics (equity):\n",
      "          Sport  Year     Value\n",
      "4     Athletics  1896  0.000000\n",
      "72    Athletics  1900  0.000000\n",
      "140   Athletics  1904  0.000000\n",
      "208   Athletics  1906  0.000000\n",
      "276   Athletics  1908  0.000000\n",
      "344   Athletics  1912  0.000000\n",
      "412   Athletics  1920  0.000000\n",
      "480   Athletics  1924  0.000000\n",
      "548   Athletics  1928  0.130040\n",
      "616   Athletics  1932  0.153257\n",
      "684   Athletics  1936  0.133069\n",
      "752   Athletics  1948  0.224548\n",
      "820   Athletics  1952  0.223214\n",
      "888   Athletics  1956  0.213228\n",
      "956   Athletics  1960  0.205793\n",
      "1024  Athletics  1964  0.256929\n",
      "1092  Athletics  1968  0.263197\n",
      "1160  Athletics  1972  0.300119\n",
      "1228  Athletics  1976  0.323053\n",
      "1296  Athletics  1980  0.294953\n",
      "1364  Athletics  1984  0.302867\n",
      "1432  Athletics  1988  0.357905\n",
      "1500  Athletics  1992  0.369523\n",
      "1568  Athletics  1996  0.375524\n",
      "1636  Athletics  2000  0.417747\n",
      "1704  Athletics  2004  0.460230\n",
      "1772  Athletics  2008  0.475936\n",
      "1840  Athletics  2012  0.481563\n",
      "1908  Athletics  2016  0.481659\n",
      "1976  Athletics  2020  0.480000\n",
      "2044  Athletics  2024  0.500000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:12: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:12: SyntaxWarning: invalid escape sequence '\\d'\n",
      "/tmp/ipykernel_641144/3914523016.py:12: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  melted_data_equity['Year'] = melted_data_equity['Year'].str.extract('(\\d+)').astype(int)\n"
     ]
    }
   ],
   "source": [
    "# Example for parameter and sport\n",
    "parameter = 'equity'\n",
    "sport_name = 'Athletics'\n",
    "\n",
    "# Filter columns that match the parameter\n",
    "param_columns = [col for col in df.columns if col.startswith(f\"{parameter}_\")]\n",
    "\n",
    "# Melt the data for 'equity'\n",
    "melted_data_equity = df[['Sport'] + param_columns].melt(id_vars='Sport', var_name='Year', value_name='Value')\n",
    "\n",
    "# Extract the year from column names\n",
    "melted_data_equity['Year'] = melted_data_equity['Year'].str.extract('(\\d+)').astype(int)\n",
    "\n",
    "# Filter data for the specified sport\n",
    "sport_data_equity = melted_data_equity[melted_data_equity['Sport'] == sport_name].sort_values('Year')\n",
    "\n",
    "print(f\"Raw data for {sport_name} ({parameter}):\")\n",
    "print(sport_data_equity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing parameter: drug\n",
      "\n",
      "Processing sport: Alpine Skiing (drug)\n",
      "Raw data for Alpine Skiing (drug):\n",
      "               Sport  Year  Value\n",
      "0     Alpine Skiing  1896    0.0\n",
      "65    Alpine Skiing  1900    0.0\n",
      "130   Alpine Skiing  1904    0.0\n",
      "195   Alpine Skiing  1906    0.0\n",
      "260   Alpine Skiing  1908    0.0\n",
      "325   Alpine Skiing  1912    0.0\n",
      "390   Alpine Skiing  1920    0.0\n",
      "455   Alpine Skiing  1924    0.0\n",
      "520   Alpine Skiing  1928    0.0\n",
      "585   Alpine Skiing  1932    0.0\n",
      "650   Alpine Skiing  1936    0.0\n",
      "715   Alpine Skiing  1948    0.0\n",
      "780   Alpine Skiing  1952    0.0\n",
      "845   Alpine Skiing  1956    0.0\n",
      "910   Alpine Skiing  1960    0.0\n",
      "975   Alpine Skiing  1964    0.0\n",
      "1040  Alpine Skiing  1968    0.0\n",
      "1105  Alpine Skiing  1972    0.0\n",
      "1170  Alpine Skiing  1976    0.0\n",
      "1235  Alpine Skiing  1980    0.0\n",
      "1300  Alpine Skiing  1984    0.0\n",
      "1365  Alpine Skiing  1988    0.0\n",
      "1430  Alpine Skiing  1992    0.0\n",
      "1495  Alpine Skiing  1996    0.0\n",
      "1560  Alpine Skiing  2000    0.0\n",
      "1625  Alpine Skiing  2004    0.0\n",
      "1690  Alpine Skiing  2008    0.0\n",
      "1755  Alpine Skiing  2012    0.0\n",
      "1820  Alpine Skiing  2016    0.0\n",
      "1885  Alpine Skiing  2020    0.0\n",
      "1950  Alpine Skiing  2024    0.0\n",
      "\n",
      "Prepared time series data for Alpine Skiing (drug):\n",
      " Year\n",
      "1896    0.0\n",
      "1900    0.0\n",
      "1904    0.0\n",
      "1906    0.0\n",
      "1908    0.0\n",
      "1912    0.0\n",
      "1920    0.0\n",
      "1924    0.0\n",
      "1928    0.0\n",
      "1932    0.0\n",
      "1936    0.0\n",
      "1948    0.0\n",
      "1952    0.0\n",
      "1956    0.0\n",
      "1960    0.0\n",
      "1964    0.0\n",
      "1968    0.0\n",
      "1972    0.0\n",
      "1976    0.0\n",
      "1980    0.0\n",
      "1984    0.0\n",
      "1988    0.0\n",
      "1992    0.0\n",
      "1996    0.0\n",
      "2000    0.0\n",
      "2004    0.0\n",
      "2008    0.0\n",
      "2012    0.0\n",
      "2016    0.0\n",
      "2020    0.0\n",
      "2024    0.0\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Alpinism (drug)\n",
      "Raw data for Alpinism (drug):\n",
      "          Sport  Year  Value\n",
      "1     Alpinism  1896    0.0\n",
      "66    Alpinism  1900    0.0\n",
      "131   Alpinism  1904    0.0\n",
      "196   Alpinism  1906    0.0\n",
      "261   Alpinism  1908    0.0\n",
      "326   Alpinism  1912    0.0\n",
      "391   Alpinism  1920    0.0\n",
      "456   Alpinism  1924    0.0\n",
      "521   Alpinism  1928    0.0\n",
      "586   Alpinism  1932    0.0\n",
      "651   Alpinism  1936    0.0\n",
      "716   Alpinism  1948    0.0\n",
      "781   Alpinism  1952    0.0\n",
      "846   Alpinism  1956    0.0\n",
      "911   Alpinism  1960    0.0\n",
      "976   Alpinism  1964    0.0\n",
      "1041  Alpinism  1968    0.0\n",
      "1106  Alpinism  1972    0.0\n",
      "1171  Alpinism  1976    0.0\n",
      "1236  Alpinism  1980    0.0\n",
      "1301  Alpinism  1984    0.0\n",
      "1366  Alpinism  1988    0.0\n",
      "1431  Alpinism  1992    0.0\n",
      "1496  Alpinism  1996    0.0\n",
      "1561  Alpinism  2000    0.0\n",
      "1626  Alpinism  2004    0.0\n",
      "1691  Alpinism  2008    0.0\n",
      "1756  Alpinism  2012    0.0\n",
      "1821  Alpinism  2016    0.0\n",
      "1886  Alpinism  2020    0.0\n",
      "1951  Alpinism  2024    0.0\n",
      "\n",
      "Prepared time series data for Alpinism (drug):\n",
      " Year\n",
      "1896    0.0\n",
      "1900    0.0\n",
      "1904    0.0\n",
      "1906    0.0\n",
      "1908    0.0\n",
      "1912    0.0\n",
      "1920    0.0\n",
      "1924    0.0\n",
      "1928    0.0\n",
      "1932    0.0\n",
      "1936    0.0\n",
      "1948    0.0\n",
      "1952    0.0\n",
      "1956    0.0\n",
      "1960    0.0\n",
      "1964    0.0\n",
      "1968    0.0\n",
      "1972    0.0\n",
      "1976    0.0\n",
      "1980    0.0\n",
      "1984    0.0\n",
      "1988    0.0\n",
      "1992    0.0\n",
      "1996    0.0\n",
      "2000    0.0\n",
      "2004    0.0\n",
      "2008    0.0\n",
      "2012    0.0\n",
      "2016    0.0\n",
      "2020    0.0\n",
      "2024    0.0\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Archery (drug)\n",
      "Raw data for Archery (drug):\n",
      "         Sport  Year  Value\n",
      "2     Archery  1896    0.0\n",
      "67    Archery  1900    0.0\n",
      "132   Archery  1904    0.0\n",
      "197   Archery  1906    0.0\n",
      "262   Archery  1908    0.0\n",
      "327   Archery  1912    0.0\n",
      "392   Archery  1920    0.0\n",
      "457   Archery  1924    0.0\n",
      "522   Archery  1928    0.0\n",
      "587   Archery  1932    0.0\n",
      "652   Archery  1936    0.0\n",
      "717   Archery  1948    0.0\n",
      "782   Archery  1952    0.0\n",
      "847   Archery  1956    0.0\n",
      "912   Archery  1960    0.0\n",
      "977   Archery  1964    0.0\n",
      "1042  Archery  1968    0.0\n",
      "1107  Archery  1972    0.0\n",
      "1172  Archery  1976    0.0\n",
      "1237  Archery  1980    0.0\n",
      "1302  Archery  1984    0.0\n",
      "1367  Archery  1988    0.0\n",
      "1432  Archery  1992    0.0\n",
      "1497  Archery  1996    0.0\n",
      "1562  Archery  2000    0.0\n",
      "1627  Archery  2004    0.0\n",
      "1692  Archery  2008    0.0\n",
      "1757  Archery  2012    0.0\n",
      "1822  Archery  2016    0.0\n",
      "1887  Archery  2020    0.0\n",
      "1952  Archery  2024    0.0\n",
      "\n",
      "Prepared time series data for Archery (drug):\n",
      " Year\n",
      "1896    0.0\n",
      "1900    0.0\n",
      "1904    0.0\n",
      "1906    0.0\n",
      "1908    0.0\n",
      "1912    0.0\n",
      "1920    0.0\n",
      "1924    0.0\n",
      "1928    0.0\n",
      "1932    0.0\n",
      "1936    0.0\n",
      "1948    0.0\n",
      "1952    0.0\n",
      "1956    0.0\n",
      "1960    0.0\n",
      "1964    0.0\n",
      "1968    0.0\n",
      "1972    0.0\n",
      "1976    0.0\n",
      "1980    0.0\n",
      "1984    0.0\n",
      "1988    0.0\n",
      "1992    0.0\n",
      "1996    0.0\n",
      "2000    0.0\n",
      "2004    0.0\n",
      "2008    0.0\n",
      "2012    0.0\n",
      "2016    0.0\n",
      "2020    0.0\n",
      "2024    0.0\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Art Competitions (drug)\n",
      "Raw data for Art Competitions (drug):\n",
      "                  Sport  Year  Value\n",
      "3     Art Competitions  1896    0.0\n",
      "68    Art Competitions  1900    0.0\n",
      "133   Art Competitions  1904    0.0\n",
      "198   Art Competitions  1906    0.0\n",
      "263   Art Competitions  1908    0.0\n",
      "328   Art Competitions  1912    0.0\n",
      "393   Art Competitions  1920    0.0\n",
      "458   Art Competitions  1924    0.0\n",
      "523   Art Competitions  1928    0.0\n",
      "588   Art Competitions  1932    0.0\n",
      "653   Art Competitions  1936    0.0\n",
      "718   Art Competitions  1948    0.0\n",
      "783   Art Competitions  1952    0.0\n",
      "848   Art Competitions  1956    0.0\n",
      "913   Art Competitions  1960    0.0\n",
      "978   Art Competitions  1964    0.0\n",
      "1043  Art Competitions  1968    0.0\n",
      "1108  Art Competitions  1972    0.0\n",
      "1173  Art Competitions  1976    0.0\n",
      "1238  Art Competitions  1980    0.0\n",
      "1303  Art Competitions  1984    0.0\n",
      "1368  Art Competitions  1988    0.0\n",
      "1433  Art Competitions  1992    0.0\n",
      "1498  Art Competitions  1996    0.0\n",
      "1563  Art Competitions  2000    0.0\n",
      "1628  Art Competitions  2004    0.0\n",
      "1693  Art Competitions  2008    0.0\n",
      "1758  Art Competitions  2012    0.0\n",
      "1823  Art Competitions  2016    0.0\n",
      "1888  Art Competitions  2020    0.0\n",
      "1953  Art Competitions  2024    0.0\n",
      "\n",
      "Prepared time series data for Art Competitions (drug):\n",
      " Year\n",
      "1896    0.0\n",
      "1900    0.0\n",
      "1904    0.0\n",
      "1906    0.0\n",
      "1908    0.0\n",
      "1912    0.0\n",
      "1920    0.0\n",
      "1924    0.0\n",
      "1928    0.0\n",
      "1932    0.0\n",
      "1936    0.0\n",
      "1948    0.0\n",
      "1952    0.0\n",
      "1956    0.0\n",
      "1960    0.0\n",
      "1964    0.0\n",
      "1968    0.0\n",
      "1972    0.0\n",
      "1976    0.0\n",
      "1980    0.0\n",
      "1984    0.0\n",
      "1988    0.0\n",
      "1992    0.0\n",
      "1996    0.0\n",
      "2000    0.0\n",
      "2004    0.0\n",
      "2008    0.0\n",
      "2012    0.0\n",
      "2016    0.0\n",
      "2020    0.0\n",
      "2024    0.0\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Athletics (drug)\n",
      "Raw data for Athletics (drug):\n",
      "           Sport  Year  Value\n",
      "4     Athletics  1896    0.0\n",
      "69    Athletics  1900    0.0\n",
      "134   Athletics  1904    0.0\n",
      "199   Athletics  1906    0.0\n",
      "264   Athletics  1908    0.0\n",
      "329   Athletics  1912    0.0\n",
      "394   Athletics  1920    0.0\n",
      "459   Athletics  1924    0.0\n",
      "524   Athletics  1928    0.0\n",
      "589   Athletics  1932    0.0\n",
      "654   Athletics  1936    0.0\n",
      "719   Athletics  1948    0.0\n",
      "784   Athletics  1952    0.0\n",
      "849   Athletics  1956    0.0\n",
      "914   Athletics  1960    0.0\n",
      "979   Athletics  1964    0.0\n",
      "1044  Athletics  1968    0.0\n",
      "1109  Athletics  1972    0.0\n",
      "1174  Athletics  1976    1.0\n",
      "1239  Athletics  1980    0.0\n",
      "1304  Athletics  1984    4.0\n",
      "1369  Athletics  1988    1.0\n",
      "1434  Athletics  1992    5.0\n",
      "1499  Athletics  1996    7.0\n",
      "1564  Athletics  2000    4.0\n",
      "1629  Athletics  2004   17.0\n",
      "1694  Athletics  2008   46.0\n",
      "1759  Athletics  2012   86.0\n",
      "1824  Athletics  2016    2.0\n",
      "1889  Athletics  2020    7.0\n",
      "1954  Athletics  2024    2.0\n",
      "\n",
      "Prepared time series data for Athletics (drug):\n",
      " Year\n",
      "1896     0.0\n",
      "1900     0.0\n",
      "1904     0.0\n",
      "1906     0.0\n",
      "1908     0.0\n",
      "1912     0.0\n",
      "1920     0.0\n",
      "1924     0.0\n",
      "1928     0.0\n",
      "1932     0.0\n",
      "1936     0.0\n",
      "1948     0.0\n",
      "1952     0.0\n",
      "1956     0.0\n",
      "1960     0.0\n",
      "1964     0.0\n",
      "1968     0.0\n",
      "1972     0.0\n",
      "1976     1.0\n",
      "1980     0.0\n",
      "1984     4.0\n",
      "1988     1.0\n",
      "1992     5.0\n",
      "1996     7.0\n",
      "2000     4.0\n",
      "2004    17.0\n",
      "2008    46.0\n",
      "2012    86.0\n",
      "2016     2.0\n",
      "2020     7.0\n",
      "2024     2.0\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Badminton (drug)\n",
      "Raw data for Badminton (drug):\n",
      "           Sport  Year  Value\n",
      "5     Badminton  1896    0.0\n",
      "70    Badminton  1900    0.0\n",
      "135   Badminton  1904    0.0\n",
      "200   Badminton  1906    0.0\n",
      "265   Badminton  1908    0.0\n",
      "330   Badminton  1912    0.0\n",
      "395   Badminton  1920    0.0\n",
      "460   Badminton  1924    0.0\n",
      "525   Badminton  1928    0.0\n",
      "590   Badminton  1932    0.0\n",
      "655   Badminton  1936    0.0\n",
      "720   Badminton  1948    0.0\n",
      "785   Badminton  1952    0.0\n",
      "850   Badminton  1956    0.0\n",
      "915   Badminton  1960    0.0\n",
      "980   Badminton  1964    0.0\n",
      "1045  Badminton  1968    0.0\n",
      "1110  Badminton  1972    0.0\n",
      "1175  Badminton  1976    0.0\n",
      "1240  Badminton  1980    0.0\n",
      "1305  Badminton  1984    0.0\n",
      "1370  Badminton  1988    0.0\n",
      "1435  Badminton  1992    0.0\n",
      "1500  Badminton  1996    0.0\n",
      "1565  Badminton  2000    0.0\n",
      "1630  Badminton  2004    0.0\n",
      "1695  Badminton  2008    0.0\n",
      "1760  Badminton  2012    0.0\n",
      "1825  Badminton  2016    0.0\n",
      "1890  Badminton  2020    0.0\n",
      "1955  Badminton  2024    0.0\n",
      "\n",
      "Prepared time series data for Badminton (drug):\n",
      " Year\n",
      "1896    0.0\n",
      "1900    0.0\n",
      "1904    0.0\n",
      "1906    0.0\n",
      "1908    0.0\n",
      "1912    0.0\n",
      "1920    0.0\n",
      "1924    0.0\n",
      "1928    0.0\n",
      "1932    0.0\n",
      "1936    0.0\n",
      "1948    0.0\n",
      "1952    0.0\n",
      "1956    0.0\n",
      "1960    0.0\n",
      "1964    0.0\n",
      "1968    0.0\n",
      "1972    0.0\n",
      "1976    0.0\n",
      "1980    0.0\n",
      "1984    0.0\n",
      "1988    0.0\n",
      "1992    0.0\n",
      "1996    0.0\n",
      "2000    0.0\n",
      "2004    0.0\n",
      "2008    0.0\n",
      "2012    0.0\n",
      "2016    0.0\n",
      "2020    0.0\n",
      "2024    0.0\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Baseball (drug)\n",
      "Raw data for Baseball (drug):\n",
      "          Sport  Year  Value\n",
      "6     Baseball  1896    0.0\n",
      "71    Baseball  1900    0.0\n",
      "136   Baseball  1904    0.0\n",
      "201   Baseball  1906    0.0\n",
      "266   Baseball  1908    0.0\n",
      "331   Baseball  1912    0.0\n",
      "396   Baseball  1920    0.0\n",
      "461   Baseball  1924    0.0\n",
      "526   Baseball  1928    0.0\n",
      "591   Baseball  1932    0.0\n",
      "656   Baseball  1936    0.0\n",
      "721   Baseball  1948    0.0\n",
      "786   Baseball  1952    0.0\n",
      "851   Baseball  1956    0.0\n",
      "916   Baseball  1960    0.0\n",
      "981   Baseball  1964    0.0\n",
      "1046  Baseball  1968    0.0\n",
      "1111  Baseball  1972    0.0\n",
      "1176  Baseball  1976    0.0\n",
      "1241  Baseball  1980    0.0\n",
      "1306  Baseball  1984    0.0\n",
      "1371  Baseball  1988    0.0\n",
      "1436  Baseball  1992    0.0\n",
      "1501  Baseball  1996    0.0\n",
      "1566  Baseball  2000    0.0\n",
      "1631  Baseball  2004    2.0\n",
      "1696  Baseball  2008    0.0\n",
      "1761  Baseball  2012    0.0\n",
      "1826  Baseball  2016    0.0\n",
      "1891  Baseball  2020    0.0\n",
      "1956  Baseball  2024    0.0\n",
      "\n",
      "Prepared time series data for Baseball (drug):\n",
      " Year\n",
      "1896    0.0\n",
      "1900    0.0\n",
      "1904    0.0\n",
      "1906    0.0\n",
      "1908    0.0\n",
      "1912    0.0\n",
      "1920    0.0\n",
      "1924    0.0\n",
      "1928    0.0\n",
      "1932    0.0\n",
      "1936    0.0\n",
      "1948    0.0\n",
      "1952    0.0\n",
      "1956    0.0\n",
      "1960    0.0\n",
      "1964    0.0\n",
      "1968    0.0\n",
      "1972    0.0\n",
      "1976    0.0\n",
      "1980    0.0\n",
      "1984    0.0\n",
      "1988    0.0\n",
      "1992    0.0\n",
      "1996    0.0\n",
      "2000    0.0\n",
      "2004    2.0\n",
      "2008    0.0\n",
      "2012    0.0\n",
      "2016    0.0\n",
      "2020    0.0\n",
      "2024    0.0\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Basketball (drug)\n",
      "Raw data for Basketball (drug):\n",
      "            Sport  Year  Value\n",
      "7     Basketball  1896    0.0\n",
      "72    Basketball  1900    0.0\n",
      "137   Basketball  1904    0.0\n",
      "202   Basketball  1906    0.0\n",
      "267   Basketball  1908    0.0\n",
      "332   Basketball  1912    0.0\n",
      "397   Basketball  1920    0.0\n",
      "462   Basketball  1924    0.0\n",
      "527   Basketball  1928    0.0\n",
      "592   Basketball  1932    0.0\n",
      "657   Basketball  1936    0.0\n",
      "722   Basketball  1948    0.0\n",
      "787   Basketball  1952    0.0\n",
      "852   Basketball  1956    0.0\n",
      "917   Basketball  1960    0.0\n",
      "982   Basketball  1964    0.0\n",
      "1047  Basketball  1968    0.0\n",
      "1112  Basketball  1972    1.0\n",
      "1177  Basketball  1976    0.0\n",
      "1242  Basketball  1980    0.0\n",
      "1307  Basketball  1984    0.0\n",
      "1372  Basketball  1988    0.0\n",
      "1437  Basketball  1992    0.0\n",
      "1502  Basketball  1996    0.0\n",
      "1567  Basketball  2000    0.0\n",
      "1632  Basketball  2004    0.0\n",
      "1697  Basketball  2008    0.0\n",
      "1762  Basketball  2012    0.0\n",
      "1827  Basketball  2016    0.0\n",
      "1892  Basketball  2020    0.0\n",
      "1957  Basketball  2024    0.0\n",
      "\n",
      "Prepared time series data for Basketball (drug):\n",
      " Year\n",
      "1896    0.0\n",
      "1900    0.0\n",
      "1904    0.0\n",
      "1906    0.0\n",
      "1908    0.0\n",
      "1912    0.0\n",
      "1920    0.0\n",
      "1924    0.0\n",
      "1928    0.0\n",
      "1932    0.0\n",
      "1936    0.0\n",
      "1948    0.0\n",
      "1952    0.0\n",
      "1956    0.0\n",
      "1960    0.0\n",
      "1964    0.0\n",
      "1968    0.0\n",
      "1972    1.0\n",
      "1976    0.0\n",
      "1980    0.0\n",
      "1984    0.0\n",
      "1988    0.0\n",
      "1992    0.0\n",
      "1996    0.0\n",
      "2000    0.0\n",
      "2004    0.0\n",
      "2008    0.0\n",
      "2012    0.0\n",
      "2016    0.0\n",
      "2020    0.0\n",
      "2024    0.0\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Basque Pelota (drug)\n",
      "Raw data for Basque Pelota (drug):\n",
      "               Sport  Year  Value\n",
      "8     Basque Pelota  1896    0.0\n",
      "73    Basque Pelota  1900    0.0\n",
      "138   Basque Pelota  1904    0.0\n",
      "203   Basque Pelota  1906    0.0\n",
      "268   Basque Pelota  1908    0.0\n",
      "333   Basque Pelota  1912    0.0\n",
      "398   Basque Pelota  1920    0.0\n",
      "463   Basque Pelota  1924    0.0\n",
      "528   Basque Pelota  1928    0.0\n",
      "593   Basque Pelota  1932    0.0\n",
      "658   Basque Pelota  1936    0.0\n",
      "723   Basque Pelota  1948    0.0\n",
      "788   Basque Pelota  1952    0.0\n",
      "853   Basque Pelota  1956    0.0\n",
      "918   Basque Pelota  1960    0.0\n",
      "983   Basque Pelota  1964    0.0\n",
      "1048  Basque Pelota  1968    0.0\n",
      "1113  Basque Pelota  1972    0.0\n",
      "1178  Basque Pelota  1976    0.0\n",
      "1243  Basque Pelota  1980    0.0\n",
      "1308  Basque Pelota  1984    0.0\n",
      "1373  Basque Pelota  1988    0.0\n",
      "1438  Basque Pelota  1992    0.0\n",
      "1503  Basque Pelota  1996    0.0\n",
      "1568  Basque Pelota  2000    0.0\n",
      "1633  Basque Pelota  2004    0.0\n",
      "1698  Basque Pelota  2008    0.0\n",
      "1763  Basque Pelota  2012    0.0\n",
      "1828  Basque Pelota  2016    0.0\n",
      "1893  Basque Pelota  2020    0.0\n",
      "1958  Basque Pelota  2024    0.0\n",
      "\n",
      "Prepared time series data for Basque Pelota (drug):\n",
      " Year\n",
      "1896    0.0\n",
      "1900    0.0\n",
      "1904    0.0\n",
      "1906    0.0\n",
      "1908    0.0\n",
      "1912    0.0\n",
      "1920    0.0\n",
      "1924    0.0\n",
      "1928    0.0\n",
      "1932    0.0\n",
      "1936    0.0\n",
      "1948    0.0\n",
      "1952    0.0\n",
      "1956    0.0\n",
      "1960    0.0\n",
      "1964    0.0\n",
      "1968    0.0\n",
      "1972    0.0\n",
      "1976    0.0\n",
      "1980    0.0\n",
      "1984    0.0\n",
      "1988    0.0\n",
      "1992    0.0\n",
      "1996    0.0\n",
      "2000    0.0\n",
      "2004    0.0\n",
      "2008    0.0\n",
      "2012    0.0\n",
      "2016    0.0\n",
      "2020    0.0\n",
      "2024    0.0\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Beach Volleyball (drug)\n",
      "Raw data for Beach Volleyball (drug):\n",
      "                  Sport  Year  Value\n",
      "9     Beach Volleyball  1896    0.0\n",
      "74    Beach Volleyball  1900    0.0\n",
      "139   Beach Volleyball  1904    0.0\n",
      "204   Beach Volleyball  1906    0.0\n",
      "269   Beach Volleyball  1908    0.0\n",
      "334   Beach Volleyball  1912    0.0\n",
      "399   Beach Volleyball  1920    0.0\n",
      "464   Beach Volleyball  1924    0.0\n",
      "529   Beach Volleyball  1928    0.0\n",
      "594   Beach Volleyball  1932    0.0\n",
      "659   Beach Volleyball  1936    0.0\n",
      "724   Beach Volleyball  1948    0.0\n",
      "789   Beach Volleyball  1952    0.0\n",
      "854   Beach Volleyball  1956    0.0\n",
      "919   Beach Volleyball  1960    0.0\n",
      "984   Beach Volleyball  1964    0.0\n",
      "1049  Beach Volleyball  1968    0.0\n",
      "1114  Beach Volleyball  1972    0.0\n",
      "1179  Beach Volleyball  1976    0.0\n",
      "1244  Beach Volleyball  1980    0.0\n",
      "1309  Beach Volleyball  1984    0.0\n",
      "1374  Beach Volleyball  1988    0.0\n",
      "1439  Beach Volleyball  1992    0.0\n",
      "1504  Beach Volleyball  1996    0.0\n",
      "1569  Beach Volleyball  2000    0.0\n",
      "1634  Beach Volleyball  2004    0.0\n",
      "1699  Beach Volleyball  2008    0.0\n",
      "1764  Beach Volleyball  2012    0.0\n",
      "1829  Beach Volleyball  2016    0.0\n",
      "1894  Beach Volleyball  2020    0.0\n",
      "1959  Beach Volleyball  2024    0.0\n",
      "\n",
      "Prepared time series data for Beach Volleyball (drug):\n",
      " Year\n",
      "1896    0.0\n",
      "1900    0.0\n",
      "1904    0.0\n",
      "1906    0.0\n",
      "1908    0.0\n",
      "1912    0.0\n",
      "1920    0.0\n",
      "1924    0.0\n",
      "1928    0.0\n",
      "1932    0.0\n",
      "1936    0.0\n",
      "1948    0.0\n",
      "1952    0.0\n",
      "1956    0.0\n",
      "1960    0.0\n",
      "1964    0.0\n",
      "1968    0.0\n",
      "1972    0.0\n",
      "1976    0.0\n",
      "1980    0.0\n",
      "1984    0.0\n",
      "1988    0.0\n",
      "1992    0.0\n",
      "1996    0.0\n",
      "2000    0.0\n",
      "2004    0.0\n",
      "2008    0.0\n",
      "2012    0.0\n",
      "2016    0.0\n",
      "2020    0.0\n",
      "2024    0.0\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Biathlon (drug)\n",
      "Raw data for Biathlon (drug):\n",
      "          Sport  Year  Value\n",
      "10    Biathlon  1896    0.0\n",
      "75    Biathlon  1900    0.0\n",
      "140   Biathlon  1904    0.0\n",
      "205   Biathlon  1906    0.0\n",
      "270   Biathlon  1908    0.0\n",
      "335   Biathlon  1912    0.0\n",
      "400   Biathlon  1920    0.0\n",
      "465   Biathlon  1924    0.0\n",
      "530   Biathlon  1928    0.0\n",
      "595   Biathlon  1932    0.0\n",
      "660   Biathlon  1936    0.0\n",
      "725   Biathlon  1948    0.0\n",
      "790   Biathlon  1952    0.0\n",
      "855   Biathlon  1956    0.0\n",
      "920   Biathlon  1960    0.0\n",
      "985   Biathlon  1964    0.0\n",
      "1050  Biathlon  1968    0.0\n",
      "1115  Biathlon  1972    0.0\n",
      "1180  Biathlon  1976    0.0\n",
      "1245  Biathlon  1980    0.0\n",
      "1310  Biathlon  1984    0.0\n",
      "1375  Biathlon  1988    0.0\n",
      "1440  Biathlon  1992    0.0\n",
      "1505  Biathlon  1996    0.0\n",
      "1570  Biathlon  2000    0.0\n",
      "1635  Biathlon  2004    0.0\n",
      "1700  Biathlon  2008    0.0\n",
      "1765  Biathlon  2012    0.0\n",
      "1830  Biathlon  2016    0.0\n",
      "1895  Biathlon  2020    0.0\n",
      "1960  Biathlon  2024    0.0\n",
      "\n",
      "Prepared time series data for Biathlon (drug):\n",
      " Year\n",
      "1896    0.0\n",
      "1900    0.0\n",
      "1904    0.0\n",
      "1906    0.0\n",
      "1908    0.0\n",
      "1912    0.0\n",
      "1920    0.0\n",
      "1924    0.0\n",
      "1928    0.0\n",
      "1932    0.0\n",
      "1936    0.0\n",
      "1948    0.0\n",
      "1952    0.0\n",
      "1956    0.0\n",
      "1960    0.0\n",
      "1964    0.0\n",
      "1968    0.0\n",
      "1972    0.0\n",
      "1976    0.0\n",
      "1980    0.0\n",
      "1984    0.0\n",
      "1988    0.0\n",
      "1992    0.0\n",
      "1996    0.0\n",
      "2000    0.0\n",
      "2004    0.0\n",
      "2008    0.0\n",
      "2012    0.0\n",
      "2016    0.0\n",
      "2020    0.0\n",
      "2024    0.0\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Bobsleigh (drug)\n",
      "Raw data for Bobsleigh (drug):\n",
      "           Sport  Year  Value\n",
      "11    Bobsleigh  1896    0.0\n",
      "76    Bobsleigh  1900    0.0\n",
      "141   Bobsleigh  1904    0.0\n",
      "206   Bobsleigh  1906    0.0\n",
      "271   Bobsleigh  1908    0.0\n",
      "336   Bobsleigh  1912    0.0\n",
      "401   Bobsleigh  1920    0.0\n",
      "466   Bobsleigh  1924    0.0\n",
      "531   Bobsleigh  1928    0.0\n",
      "596   Bobsleigh  1932    0.0\n",
      "661   Bobsleigh  1936    0.0\n",
      "726   Bobsleigh  1948    0.0\n",
      "791   Bobsleigh  1952    0.0\n",
      "856   Bobsleigh  1956    0.0\n",
      "921   Bobsleigh  1960    0.0\n",
      "986   Bobsleigh  1964    0.0\n",
      "1051  Bobsleigh  1968    0.0\n",
      "1116  Bobsleigh  1972    0.0\n",
      "1181  Bobsleigh  1976    0.0\n",
      "1246  Bobsleigh  1980    0.0\n",
      "1311  Bobsleigh  1984    0.0\n",
      "1376  Bobsleigh  1988    0.0\n",
      "1441  Bobsleigh  1992    0.0\n",
      "1506  Bobsleigh  1996    0.0\n",
      "1571  Bobsleigh  2000    0.0\n",
      "1636  Bobsleigh  2004    0.0\n",
      "1701  Bobsleigh  2008    0.0\n",
      "1766  Bobsleigh  2012    0.0\n",
      "1831  Bobsleigh  2016    0.0\n",
      "1896  Bobsleigh  2020    0.0\n",
      "1961  Bobsleigh  2024    0.0\n",
      "\n",
      "Prepared time series data for Bobsleigh (drug):\n",
      " Year\n",
      "1896    0.0\n",
      "1900    0.0\n",
      "1904    0.0\n",
      "1906    0.0\n",
      "1908    0.0\n",
      "1912    0.0\n",
      "1920    0.0\n",
      "1924    0.0\n",
      "1928    0.0\n",
      "1932    0.0\n",
      "1936    0.0\n",
      "1948    0.0\n",
      "1952    0.0\n",
      "1956    0.0\n",
      "1960    0.0\n",
      "1964    0.0\n",
      "1968    0.0\n",
      "1972    0.0\n",
      "1976    0.0\n",
      "1980    0.0\n",
      "1984    0.0\n",
      "1988    0.0\n",
      "1992    0.0\n",
      "1996    0.0\n",
      "2000    0.0\n",
      "2004    0.0\n",
      "2008    0.0\n",
      "2012    0.0\n",
      "2016    0.0\n",
      "2020    0.0\n",
      "2024    0.0\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Boxing (drug)\n",
      "Raw data for Boxing (drug):\n",
      "        Sport  Year  Value\n",
      "12    Boxing  1896    0.0\n",
      "77    Boxing  1900    0.0\n",
      "142   Boxing  1904    0.0\n",
      "207   Boxing  1906    0.0\n",
      "272   Boxing  1908    0.0\n",
      "337   Boxing  1912    0.0\n",
      "402   Boxing  1920    0.0\n",
      "467   Boxing  1924    0.0\n",
      "532   Boxing  1928    0.0\n",
      "597   Boxing  1932    0.0\n",
      "662   Boxing  1936    0.0\n",
      "727   Boxing  1948    0.0\n",
      "792   Boxing  1952    0.0\n",
      "857   Boxing  1956    0.0\n",
      "922   Boxing  1960    0.0\n",
      "987   Boxing  1964    0.0\n",
      "1052  Boxing  1968    0.0\n",
      "1117  Boxing  1972    0.0\n",
      "1182  Boxing  1976    0.0\n",
      "1247  Boxing  1980    0.0\n",
      "1312  Boxing  1984    0.0\n",
      "1377  Boxing  1988    0.0\n",
      "1442  Boxing  1992    0.0\n",
      "1507  Boxing  1996    0.0\n",
      "1572  Boxing  2000    0.0\n",
      "1637  Boxing  2004    1.0\n",
      "1702  Boxing  2008    0.0\n",
      "1767  Boxing  2012    0.0\n",
      "1832  Boxing  2016    2.0\n",
      "1897  Boxing  2020    0.0\n",
      "1962  Boxing  2024    1.0\n",
      "\n",
      "Prepared time series data for Boxing (drug):\n",
      " Year\n",
      "1896    0.0\n",
      "1900    0.0\n",
      "1904    0.0\n",
      "1906    0.0\n",
      "1908    0.0\n",
      "1912    0.0\n",
      "1920    0.0\n",
      "1924    0.0\n",
      "1928    0.0\n",
      "1932    0.0\n",
      "1936    0.0\n",
      "1948    0.0\n",
      "1952    0.0\n",
      "1956    0.0\n",
      "1960    0.0\n",
      "1964    0.0\n",
      "1968    0.0\n",
      "1972    0.0\n",
      "1976    0.0\n",
      "1980    0.0\n",
      "1984    0.0\n",
      "1988    0.0\n",
      "1992    0.0\n",
      "1996    0.0\n",
      "2000    0.0\n",
      "2004    1.0\n",
      "2008    0.0\n",
      "2012    0.0\n",
      "2016    2.0\n",
      "2020    0.0\n",
      "2024    1.0\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Canoeing (drug)\n",
      "Raw data for Canoeing (drug):\n",
      "          Sport  Year  Value\n",
      "13    Canoeing  1896    0.0\n",
      "78    Canoeing  1900    0.0\n",
      "143   Canoeing  1904    0.0\n",
      "208   Canoeing  1906    0.0\n",
      "273   Canoeing  1908    0.0\n",
      "338   Canoeing  1912    0.0\n",
      "403   Canoeing  1920    0.0\n",
      "468   Canoeing  1924    0.0\n",
      "533   Canoeing  1928    0.0\n",
      "598   Canoeing  1932    0.0\n",
      "663   Canoeing  1936    0.0\n",
      "728   Canoeing  1948    0.0\n",
      "793   Canoeing  1952    0.0\n",
      "858   Canoeing  1956    0.0\n",
      "923   Canoeing  1960    0.0\n",
      "988   Canoeing  1964    0.0\n",
      "1053  Canoeing  1968    0.0\n",
      "1118  Canoeing  1972    0.0\n",
      "1183  Canoeing  1976    0.0\n",
      "1248  Canoeing  1980    0.0\n",
      "1313  Canoeing  1984    0.0\n",
      "1378  Canoeing  1988    0.0\n",
      "1443  Canoeing  1992    0.0\n",
      "1508  Canoeing  1996    0.0\n",
      "1573  Canoeing  2000    0.0\n",
      "1638  Canoeing  2004    0.0\n",
      "1703  Canoeing  2008    1.0\n",
      "1768  Canoeing  2012    1.0\n",
      "1833  Canoeing  2016    1.0\n",
      "1898  Canoeing  2020    0.0\n",
      "1963  Canoeing  2024    0.0\n",
      "\n",
      "Prepared time series data for Canoeing (drug):\n",
      " Year\n",
      "1896    0.0\n",
      "1900    0.0\n",
      "1904    0.0\n",
      "1906    0.0\n",
      "1908    0.0\n",
      "1912    0.0\n",
      "1920    0.0\n",
      "1924    0.0\n",
      "1928    0.0\n",
      "1932    0.0\n",
      "1936    0.0\n",
      "1948    0.0\n",
      "1952    0.0\n",
      "1956    0.0\n",
      "1960    0.0\n",
      "1964    0.0\n",
      "1968    0.0\n",
      "1972    0.0\n",
      "1976    0.0\n",
      "1980    0.0\n",
      "1984    0.0\n",
      "1988    0.0\n",
      "1992    0.0\n",
      "1996    0.0\n",
      "2000    0.0\n",
      "2004    0.0\n",
      "2008    1.0\n",
      "2012    1.0\n",
      "2016    1.0\n",
      "2020    0.0\n",
      "2024    0.0\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Cricket (drug)\n",
      "Raw data for Cricket (drug):\n",
      "         Sport  Year  Value\n",
      "14    Cricket  1896    0.0\n",
      "79    Cricket  1900    0.0\n",
      "144   Cricket  1904    0.0\n",
      "209   Cricket  1906    0.0\n",
      "274   Cricket  1908    0.0\n",
      "339   Cricket  1912    0.0\n",
      "404   Cricket  1920    0.0\n",
      "469   Cricket  1924    0.0\n",
      "534   Cricket  1928    0.0\n",
      "599   Cricket  1932    0.0\n",
      "664   Cricket  1936    0.0\n",
      "729   Cricket  1948    0.0\n",
      "794   Cricket  1952    0.0\n",
      "859   Cricket  1956    0.0\n",
      "924   Cricket  1960    0.0\n",
      "989   Cricket  1964    0.0\n",
      "1054  Cricket  1968    0.0\n",
      "1119  Cricket  1972    0.0\n",
      "1184  Cricket  1976    0.0\n",
      "1249  Cricket  1980    0.0\n",
      "1314  Cricket  1984    0.0\n",
      "1379  Cricket  1988    0.0\n",
      "1444  Cricket  1992    0.0\n",
      "1509  Cricket  1996    0.0\n",
      "1574  Cricket  2000    0.0\n",
      "1639  Cricket  2004    0.0\n",
      "1704  Cricket  2008    0.0\n",
      "1769  Cricket  2012    0.0\n",
      "1834  Cricket  2016    0.0\n",
      "1899  Cricket  2020    0.0\n",
      "1964  Cricket  2024    0.0\n",
      "\n",
      "Prepared time series data for Cricket (drug):\n",
      " Year\n",
      "1896    0.0\n",
      "1900    0.0\n",
      "1904    0.0\n",
      "1906    0.0\n",
      "1908    0.0\n",
      "1912    0.0\n",
      "1920    0.0\n",
      "1924    0.0\n",
      "1928    0.0\n",
      "1932    0.0\n",
      "1936    0.0\n",
      "1948    0.0\n",
      "1952    0.0\n",
      "1956    0.0\n",
      "1960    0.0\n",
      "1964    0.0\n",
      "1968    0.0\n",
      "1972    0.0\n",
      "1976    0.0\n",
      "1980    0.0\n",
      "1984    0.0\n",
      "1988    0.0\n",
      "1992    0.0\n",
      "1996    0.0\n",
      "2000    0.0\n",
      "2004    0.0\n",
      "2008    0.0\n",
      "2012    0.0\n",
      "2016    0.0\n",
      "2020    0.0\n",
      "2024    0.0\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Croquet (drug)\n",
      "Raw data for Croquet (drug):\n",
      "         Sport  Year  Value\n",
      "15    Croquet  1896    0.0\n",
      "80    Croquet  1900    0.0\n",
      "145   Croquet  1904    0.0\n",
      "210   Croquet  1906    0.0\n",
      "275   Croquet  1908    0.0\n",
      "340   Croquet  1912    0.0\n",
      "405   Croquet  1920    0.0\n",
      "470   Croquet  1924    0.0\n",
      "535   Croquet  1928    0.0\n",
      "600   Croquet  1932    0.0\n",
      "665   Croquet  1936    0.0\n",
      "730   Croquet  1948    0.0\n",
      "795   Croquet  1952    0.0\n",
      "860   Croquet  1956    0.0\n",
      "925   Croquet  1960    0.0\n",
      "990   Croquet  1964    0.0\n",
      "1055  Croquet  1968    0.0\n",
      "1120  Croquet  1972    0.0\n",
      "1185  Croquet  1976    0.0\n",
      "1250  Croquet  1980    0.0\n",
      "1315  Croquet  1984    0.0\n",
      "1380  Croquet  1988    0.0\n",
      "1445  Croquet  1992    0.0\n",
      "1510  Croquet  1996    0.0\n",
      "1575  Croquet  2000    0.0\n",
      "1640  Croquet  2004    0.0\n",
      "1705  Croquet  2008    0.0\n",
      "1770  Croquet  2012    0.0\n",
      "1835  Croquet  2016    0.0\n",
      "1900  Croquet  2020    0.0\n",
      "1965  Croquet  2024    0.0\n",
      "\n",
      "Prepared time series data for Croquet (drug):\n",
      " Year\n",
      "1896    0.0\n",
      "1900    0.0\n",
      "1904    0.0\n",
      "1906    0.0\n",
      "1908    0.0\n",
      "1912    0.0\n",
      "1920    0.0\n",
      "1924    0.0\n",
      "1928    0.0\n",
      "1932    0.0\n",
      "1936    0.0\n",
      "1948    0.0\n",
      "1952    0.0\n",
      "1956    0.0\n",
      "1960    0.0\n",
      "1964    0.0\n",
      "1968    0.0\n",
      "1972    0.0\n",
      "1976    0.0\n",
      "1980    0.0\n",
      "1984    0.0\n",
      "1988    0.0\n",
      "1992    0.0\n",
      "1996    0.0\n",
      "2000    0.0\n",
      "2004    0.0\n",
      "2008    0.0\n",
      "2012    0.0\n",
      "2016    0.0\n",
      "2020    0.0\n",
      "2024    0.0\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Cross Country Skiing (drug)\n",
      "Raw data for Cross Country Skiing (drug):\n",
      "                      Sport  Year  Value\n",
      "16    Cross Country Skiing  1896    0.0\n",
      "81    Cross Country Skiing  1900    0.0\n",
      "146   Cross Country Skiing  1904    0.0\n",
      "211   Cross Country Skiing  1906    0.0\n",
      "276   Cross Country Skiing  1908    0.0\n",
      "341   Cross Country Skiing  1912    0.0\n",
      "406   Cross Country Skiing  1920    0.0\n",
      "471   Cross Country Skiing  1924    0.0\n",
      "536   Cross Country Skiing  1928    0.0\n",
      "601   Cross Country Skiing  1932    0.0\n",
      "666   Cross Country Skiing  1936    0.0\n",
      "731   Cross Country Skiing  1948    0.0\n",
      "796   Cross Country Skiing  1952    0.0\n",
      "861   Cross Country Skiing  1956    0.0\n",
      "926   Cross Country Skiing  1960    0.0\n",
      "991   Cross Country Skiing  1964    0.0\n",
      "1056  Cross Country Skiing  1968    0.0\n",
      "1121  Cross Country Skiing  1972    0.0\n",
      "1186  Cross Country Skiing  1976    0.0\n",
      "1251  Cross Country Skiing  1980    0.0\n",
      "1316  Cross Country Skiing  1984    0.0\n",
      "1381  Cross Country Skiing  1988    0.0\n",
      "1446  Cross Country Skiing  1992    0.0\n",
      "1511  Cross Country Skiing  1996    0.0\n",
      "1576  Cross Country Skiing  2000    0.0\n",
      "1641  Cross Country Skiing  2004    0.0\n",
      "1706  Cross Country Skiing  2008    0.0\n",
      "1771  Cross Country Skiing  2012    0.0\n",
      "1836  Cross Country Skiing  2016    0.0\n",
      "1901  Cross Country Skiing  2020    0.0\n",
      "1966  Cross Country Skiing  2024    0.0\n",
      "\n",
      "Prepared time series data for Cross Country Skiing (drug):\n",
      " Year\n",
      "1896    0.0\n",
      "1900    0.0\n",
      "1904    0.0\n",
      "1906    0.0\n",
      "1908    0.0\n",
      "1912    0.0\n",
      "1920    0.0\n",
      "1924    0.0\n",
      "1928    0.0\n",
      "1932    0.0\n",
      "1936    0.0\n",
      "1948    0.0\n",
      "1952    0.0\n",
      "1956    0.0\n",
      "1960    0.0\n",
      "1964    0.0\n",
      "1968    0.0\n",
      "1972    0.0\n",
      "1976    0.0\n",
      "1980    0.0\n",
      "1984    0.0\n",
      "1988    0.0\n",
      "1992    0.0\n",
      "1996    0.0\n",
      "2000    0.0\n",
      "2004    0.0\n",
      "2008    0.0\n",
      "2012    0.0\n",
      "2016    0.0\n",
      "2020    0.0\n",
      "2024    0.0\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Curling (drug)\n",
      "Raw data for Curling (drug):\n",
      "         Sport  Year  Value\n",
      "17    Curling  1896    0.0\n",
      "82    Curling  1900    0.0\n",
      "147   Curling  1904    0.0\n",
      "212   Curling  1906    0.0\n",
      "277   Curling  1908    0.0\n",
      "342   Curling  1912    0.0\n",
      "407   Curling  1920    0.0\n",
      "472   Curling  1924    0.0\n",
      "537   Curling  1928    0.0\n",
      "602   Curling  1932    0.0\n",
      "667   Curling  1936    0.0\n",
      "732   Curling  1948    0.0\n",
      "797   Curling  1952    0.0\n",
      "862   Curling  1956    0.0\n",
      "927   Curling  1960    0.0\n",
      "992   Curling  1964    0.0\n",
      "1057  Curling  1968    0.0\n",
      "1122  Curling  1972    0.0\n",
      "1187  Curling  1976    0.0\n",
      "1252  Curling  1980    0.0\n",
      "1317  Curling  1984    0.0\n",
      "1382  Curling  1988    0.0\n",
      "1447  Curling  1992    0.0\n",
      "1512  Curling  1996    0.0\n",
      "1577  Curling  2000    0.0\n",
      "1642  Curling  2004    0.0\n",
      "1707  Curling  2008    0.0\n",
      "1772  Curling  2012    0.0\n",
      "1837  Curling  2016    0.0\n",
      "1902  Curling  2020    0.0\n",
      "1967  Curling  2024    0.0\n",
      "\n",
      "Prepared time series data for Curling (drug):\n",
      " Year\n",
      "1896    0.0\n",
      "1900    0.0\n",
      "1904    0.0\n",
      "1906    0.0\n",
      "1908    0.0\n",
      "1912    0.0\n",
      "1920    0.0\n",
      "1924    0.0\n",
      "1928    0.0\n",
      "1932    0.0\n",
      "1936    0.0\n",
      "1948    0.0\n",
      "1952    0.0\n",
      "1956    0.0\n",
      "1960    0.0\n",
      "1964    0.0\n",
      "1968    0.0\n",
      "1972    0.0\n",
      "1976    0.0\n",
      "1980    0.0\n",
      "1984    0.0\n",
      "1988    0.0\n",
      "1992    0.0\n",
      "1996    0.0\n",
      "2000    0.0\n",
      "2004    0.0\n",
      "2008    0.0\n",
      "2012    0.0\n",
      "2016    0.0\n",
      "2020    0.0\n",
      "2024    0.0\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Cycling (drug)\n",
      "Raw data for Cycling (drug):\n",
      "         Sport  Year  Value\n",
      "18    Cycling  1896    0.0\n",
      "83    Cycling  1900    0.0\n",
      "148   Cycling  1904    0.0\n",
      "213   Cycling  1906    0.0\n",
      "278   Cycling  1908    0.0\n",
      "343   Cycling  1912    0.0\n",
      "408   Cycling  1920    0.0\n",
      "473   Cycling  1924    0.0\n",
      "538   Cycling  1928    0.0\n",
      "603   Cycling  1932    0.0\n",
      "668   Cycling  1936    0.0\n",
      "733   Cycling  1948    0.0\n",
      "798   Cycling  1952    0.0\n",
      "863   Cycling  1956    0.0\n",
      "928   Cycling  1960    0.0\n",
      "993   Cycling  1964    0.0\n",
      "1058  Cycling  1968    0.0\n",
      "1123  Cycling  1972    2.0\n",
      "1188  Cycling  1976    0.0\n",
      "1253  Cycling  1980    0.0\n",
      "1318  Cycling  1984    0.0\n",
      "1383  Cycling  1988    0.0\n",
      "1448  Cycling  1992    0.0\n",
      "1513  Cycling  1996    0.0\n",
      "1578  Cycling  2000    1.0\n",
      "1643  Cycling  2004    1.0\n",
      "1708  Cycling  2008    4.0\n",
      "1773  Cycling  2012    3.0\n",
      "1838  Cycling  2016    1.0\n",
      "1903  Cycling  2020    0.0\n",
      "1968  Cycling  2024    0.0\n",
      "\n",
      "Prepared time series data for Cycling (drug):\n",
      " Year\n",
      "1896    0.0\n",
      "1900    0.0\n",
      "1904    0.0\n",
      "1906    0.0\n",
      "1908    0.0\n",
      "1912    0.0\n",
      "1920    0.0\n",
      "1924    0.0\n",
      "1928    0.0\n",
      "1932    0.0\n",
      "1936    0.0\n",
      "1948    0.0\n",
      "1952    0.0\n",
      "1956    0.0\n",
      "1960    0.0\n",
      "1964    0.0\n",
      "1968    0.0\n",
      "1972    2.0\n",
      "1976    0.0\n",
      "1980    0.0\n",
      "1984    0.0\n",
      "1988    0.0\n",
      "1992    0.0\n",
      "1996    0.0\n",
      "2000    1.0\n",
      "2004    1.0\n",
      "2008    4.0\n",
      "2012    3.0\n",
      "2016    1.0\n",
      "2020    0.0\n",
      "2024    0.0\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Diving (drug)\n",
      "Raw data for Diving (drug):\n",
      "        Sport  Year  Value\n",
      "19    Diving  1896    0.0\n",
      "84    Diving  1900    0.0\n",
      "149   Diving  1904    0.0\n",
      "214   Diving  1906    0.0\n",
      "279   Diving  1908    0.0\n",
      "344   Diving  1912    0.0\n",
      "409   Diving  1920    0.0\n",
      "474   Diving  1924    0.0\n",
      "539   Diving  1928    0.0\n",
      "604   Diving  1932    0.0\n",
      "669   Diving  1936    0.0\n",
      "734   Diving  1948    0.0\n",
      "799   Diving  1952    0.0\n",
      "864   Diving  1956    0.0\n",
      "929   Diving  1960    0.0\n",
      "994   Diving  1964    0.0\n",
      "1059  Diving  1968    0.0\n",
      "1124  Diving  1972    0.0\n",
      "1189  Diving  1976    0.0\n",
      "1254  Diving  1980    0.0\n",
      "1319  Diving  1984    0.0\n",
      "1384  Diving  1988    0.0\n",
      "1449  Diving  1992    0.0\n",
      "1514  Diving  1996    0.0\n",
      "1579  Diving  2000    0.0\n",
      "1644  Diving  2004    0.0\n",
      "1709  Diving  2008    0.0\n",
      "1774  Diving  2012    0.0\n",
      "1839  Diving  2016    0.0\n",
      "1904  Diving  2020    0.0\n",
      "1969  Diving  2024    0.0\n",
      "\n",
      "Prepared time series data for Diving (drug):\n",
      " Year\n",
      "1896    0.0\n",
      "1900    0.0\n",
      "1904    0.0\n",
      "1906    0.0\n",
      "1908    0.0\n",
      "1912    0.0\n",
      "1920    0.0\n",
      "1924    0.0\n",
      "1928    0.0\n",
      "1932    0.0\n",
      "1936    0.0\n",
      "1948    0.0\n",
      "1952    0.0\n",
      "1956    0.0\n",
      "1960    0.0\n",
      "1964    0.0\n",
      "1968    0.0\n",
      "1972    0.0\n",
      "1976    0.0\n",
      "1980    0.0\n",
      "1984    0.0\n",
      "1988    0.0\n",
      "1992    0.0\n",
      "1996    0.0\n",
      "2000    0.0\n",
      "2004    0.0\n",
      "2008    0.0\n",
      "2012    0.0\n",
      "2016    0.0\n",
      "2020    0.0\n",
      "2024    0.0\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Equestrianism (drug)\n",
      "Raw data for Equestrianism (drug):\n",
      "               Sport  Year  Value\n",
      "20    Equestrianism  1896    0.0\n",
      "85    Equestrianism  1900    0.0\n",
      "150   Equestrianism  1904    0.0\n",
      "215   Equestrianism  1906    0.0\n",
      "280   Equestrianism  1908    0.0\n",
      "345   Equestrianism  1912    0.0\n",
      "410   Equestrianism  1920    0.0\n",
      "475   Equestrianism  1924    0.0\n",
      "540   Equestrianism  1928    0.0\n",
      "605   Equestrianism  1932    0.0\n",
      "670   Equestrianism  1936    0.0\n",
      "735   Equestrianism  1948    0.0\n",
      "800   Equestrianism  1952    0.0\n",
      "865   Equestrianism  1956    0.0\n",
      "930   Equestrianism  1960    0.0\n",
      "995   Equestrianism  1964    0.0\n",
      "1060  Equestrianism  1968    0.0\n",
      "1125  Equestrianism  1972    0.0\n",
      "1190  Equestrianism  1976    0.0\n",
      "1255  Equestrianism  1980    0.0\n",
      "1320  Equestrianism  1984    0.0\n",
      "1385  Equestrianism  1988    0.0\n",
      "1450  Equestrianism  1992    0.0\n",
      "1515  Equestrianism  1996    0.0\n",
      "1580  Equestrianism  2000    0.0\n",
      "1645  Equestrianism  2004    2.0\n",
      "1710  Equestrianism  2008    6.0\n",
      "1775  Equestrianism  2012    0.0\n",
      "1840  Equestrianism  2016    0.0\n",
      "1905  Equestrianism  2020    1.0\n",
      "1970  Equestrianism  2024    0.0\n",
      "\n",
      "Prepared time series data for Equestrianism (drug):\n",
      " Year\n",
      "1896    0.0\n",
      "1900    0.0\n",
      "1904    0.0\n",
      "1906    0.0\n",
      "1908    0.0\n",
      "1912    0.0\n",
      "1920    0.0\n",
      "1924    0.0\n",
      "1928    0.0\n",
      "1932    0.0\n",
      "1936    0.0\n",
      "1948    0.0\n",
      "1952    0.0\n",
      "1956    0.0\n",
      "1960    0.0\n",
      "1964    0.0\n",
      "1968    0.0\n",
      "1972    0.0\n",
      "1976    0.0\n",
      "1980    0.0\n",
      "1984    0.0\n",
      "1988    0.0\n",
      "1992    0.0\n",
      "1996    0.0\n",
      "2000    0.0\n",
      "2004    2.0\n",
      "2008    6.0\n",
      "2012    0.0\n",
      "2016    0.0\n",
      "2020    1.0\n",
      "2024    0.0\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Fencing (drug)\n",
      "Raw data for Fencing (drug):\n",
      "         Sport  Year  Value\n",
      "21    Fencing  1896    0.0\n",
      "86    Fencing  1900    0.0\n",
      "151   Fencing  1904    0.0\n",
      "216   Fencing  1906    0.0\n",
      "281   Fencing  1908    0.0\n",
      "346   Fencing  1912    0.0\n",
      "411   Fencing  1920    0.0\n",
      "476   Fencing  1924    0.0\n",
      "541   Fencing  1928    0.0\n",
      "606   Fencing  1932    0.0\n",
      "671   Fencing  1936    0.0\n",
      "736   Fencing  1948    0.0\n",
      "801   Fencing  1952    0.0\n",
      "866   Fencing  1956    0.0\n",
      "931   Fencing  1960    0.0\n",
      "996   Fencing  1964    0.0\n",
      "1061  Fencing  1968    0.0\n",
      "1126  Fencing  1972    0.0\n",
      "1191  Fencing  1976    0.0\n",
      "1256  Fencing  1980    0.0\n",
      "1321  Fencing  1984    0.0\n",
      "1386  Fencing  1988    0.0\n",
      "1451  Fencing  1992    0.0\n",
      "1516  Fencing  1996    0.0\n",
      "1581  Fencing  2000    0.0\n",
      "1646  Fencing  2004    0.0\n",
      "1711  Fencing  2008    0.0\n",
      "1776  Fencing  2012    0.0\n",
      "1841  Fencing  2016    0.0\n",
      "1906  Fencing  2020    0.0\n",
      "1971  Fencing  2024    0.0\n",
      "\n",
      "Prepared time series data for Fencing (drug):\n",
      " Year\n",
      "1896    0.0\n",
      "1900    0.0\n",
      "1904    0.0\n",
      "1906    0.0\n",
      "1908    0.0\n",
      "1912    0.0\n",
      "1920    0.0\n",
      "1924    0.0\n",
      "1928    0.0\n",
      "1932    0.0\n",
      "1936    0.0\n",
      "1948    0.0\n",
      "1952    0.0\n",
      "1956    0.0\n",
      "1960    0.0\n",
      "1964    0.0\n",
      "1968    0.0\n",
      "1972    0.0\n",
      "1976    0.0\n",
      "1980    0.0\n",
      "1984    0.0\n",
      "1988    0.0\n",
      "1992    0.0\n",
      "1996    0.0\n",
      "2000    0.0\n",
      "2004    0.0\n",
      "2008    0.0\n",
      "2012    0.0\n",
      "2016    0.0\n",
      "2020    0.0\n",
      "2024    0.0\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Figure Skating (drug)\n",
      "Raw data for Figure Skating (drug):\n",
      "                Sport  Year  Value\n",
      "22    Figure Skating  1896    0.0\n",
      "87    Figure Skating  1900    0.0\n",
      "152   Figure Skating  1904    0.0\n",
      "217   Figure Skating  1906    0.0\n",
      "282   Figure Skating  1908    0.0\n",
      "347   Figure Skating  1912    0.0\n",
      "412   Figure Skating  1920    0.0\n",
      "477   Figure Skating  1924    0.0\n",
      "542   Figure Skating  1928    0.0\n",
      "607   Figure Skating  1932    0.0\n",
      "672   Figure Skating  1936    0.0\n",
      "737   Figure Skating  1948    0.0\n",
      "802   Figure Skating  1952    0.0\n",
      "867   Figure Skating  1956    0.0\n",
      "932   Figure Skating  1960    0.0\n",
      "997   Figure Skating  1964    0.0\n",
      "1062  Figure Skating  1968    0.0\n",
      "1127  Figure Skating  1972    0.0\n",
      "1192  Figure Skating  1976    0.0\n",
      "1257  Figure Skating  1980    0.0\n",
      "1322  Figure Skating  1984    0.0\n",
      "1387  Figure Skating  1988    0.0\n",
      "1452  Figure Skating  1992    0.0\n",
      "1517  Figure Skating  1996    0.0\n",
      "1582  Figure Skating  2000    0.0\n",
      "1647  Figure Skating  2004    0.0\n",
      "1712  Figure Skating  2008    0.0\n",
      "1777  Figure Skating  2012    0.0\n",
      "1842  Figure Skating  2016    0.0\n",
      "1907  Figure Skating  2020    0.0\n",
      "1972  Figure Skating  2024    0.0\n",
      "\n",
      "Prepared time series data for Figure Skating (drug):\n",
      " Year\n",
      "1896    0.0\n",
      "1900    0.0\n",
      "1904    0.0\n",
      "1906    0.0\n",
      "1908    0.0\n",
      "1912    0.0\n",
      "1920    0.0\n",
      "1924    0.0\n",
      "1928    0.0\n",
      "1932    0.0\n",
      "1936    0.0\n",
      "1948    0.0\n",
      "1952    0.0\n",
      "1956    0.0\n",
      "1960    0.0\n",
      "1964    0.0\n",
      "1968    0.0\n",
      "1972    0.0\n",
      "1976    0.0\n",
      "1980    0.0\n",
      "1984    0.0\n",
      "1988    0.0\n",
      "1992    0.0\n",
      "1996    0.0\n",
      "2000    0.0\n",
      "2004    0.0\n",
      "2008    0.0\n",
      "2012    0.0\n",
      "2016    0.0\n",
      "2020    0.0\n",
      "2024    0.0\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Football (drug)\n",
      "Raw data for Football (drug):\n",
      "          Sport  Year  Value\n",
      "23    Football  1896    0.0\n",
      "88    Football  1900    0.0\n",
      "153   Football  1904    0.0\n",
      "218   Football  1906    0.0\n",
      "283   Football  1908    0.0\n",
      "348   Football  1912    0.0\n",
      "413   Football  1920    0.0\n",
      "478   Football  1924    0.0\n",
      "543   Football  1928    0.0\n",
      "608   Football  1932    0.0\n",
      "673   Football  1936    0.0\n",
      "738   Football  1948    0.0\n",
      "803   Football  1952    0.0\n",
      "868   Football  1956    0.0\n",
      "933   Football  1960    0.0\n",
      "998   Football  1964    0.0\n",
      "1063  Football  1968    0.0\n",
      "1128  Football  1972    0.0\n",
      "1193  Football  1976    0.0\n",
      "1258  Football  1980    0.0\n",
      "1323  Football  1984    0.0\n",
      "1388  Football  1988    0.0\n",
      "1453  Football  1992    0.0\n",
      "1518  Football  1996    0.0\n",
      "1583  Football  2000    0.0\n",
      "1648  Football  2004    0.0\n",
      "1713  Football  2008    0.0\n",
      "1778  Football  2012    0.0\n",
      "1843  Football  2016    0.0\n",
      "1908  Football  2020    0.0\n",
      "1973  Football  2024    0.0\n",
      "\n",
      "Prepared time series data for Football (drug):\n",
      " Year\n",
      "1896    0.0\n",
      "1900    0.0\n",
      "1904    0.0\n",
      "1906    0.0\n",
      "1908    0.0\n",
      "1912    0.0\n",
      "1920    0.0\n",
      "1924    0.0\n",
      "1928    0.0\n",
      "1932    0.0\n",
      "1936    0.0\n",
      "1948    0.0\n",
      "1952    0.0\n",
      "1956    0.0\n",
      "1960    0.0\n",
      "1964    0.0\n",
      "1968    0.0\n",
      "1972    0.0\n",
      "1976    0.0\n",
      "1980    0.0\n",
      "1984    0.0\n",
      "1988    0.0\n",
      "1992    0.0\n",
      "1996    0.0\n",
      "2000    0.0\n",
      "2004    0.0\n",
      "2008    0.0\n",
      "2012    0.0\n",
      "2016    0.0\n",
      "2020    0.0\n",
      "2024    0.0\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Freestyle Skiing (drug)\n",
      "Raw data for Freestyle Skiing (drug):\n",
      "                  Sport  Year  Value\n",
      "24    Freestyle Skiing  1896    0.0\n",
      "89    Freestyle Skiing  1900    0.0\n",
      "154   Freestyle Skiing  1904    0.0\n",
      "219   Freestyle Skiing  1906    0.0\n",
      "284   Freestyle Skiing  1908    0.0\n",
      "349   Freestyle Skiing  1912    0.0\n",
      "414   Freestyle Skiing  1920    0.0\n",
      "479   Freestyle Skiing  1924    0.0\n",
      "544   Freestyle Skiing  1928    0.0\n",
      "609   Freestyle Skiing  1932    0.0\n",
      "674   Freestyle Skiing  1936    0.0\n",
      "739   Freestyle Skiing  1948    0.0\n",
      "804   Freestyle Skiing  1952    0.0\n",
      "869   Freestyle Skiing  1956    0.0\n",
      "934   Freestyle Skiing  1960    0.0\n",
      "999   Freestyle Skiing  1964    0.0\n",
      "1064  Freestyle Skiing  1968    0.0\n",
      "1129  Freestyle Skiing  1972    0.0\n",
      "1194  Freestyle Skiing  1976    0.0\n",
      "1259  Freestyle Skiing  1980    0.0\n",
      "1324  Freestyle Skiing  1984    0.0\n",
      "1389  Freestyle Skiing  1988    0.0\n",
      "1454  Freestyle Skiing  1992    0.0\n",
      "1519  Freestyle Skiing  1996    0.0\n",
      "1584  Freestyle Skiing  2000    0.0\n",
      "1649  Freestyle Skiing  2004    0.0\n",
      "1714  Freestyle Skiing  2008    0.0\n",
      "1779  Freestyle Skiing  2012    0.0\n",
      "1844  Freestyle Skiing  2016    0.0\n",
      "1909  Freestyle Skiing  2020    0.0\n",
      "1974  Freestyle Skiing  2024    0.0\n",
      "\n",
      "Prepared time series data for Freestyle Skiing (drug):\n",
      " Year\n",
      "1896    0.0\n",
      "1900    0.0\n",
      "1904    0.0\n",
      "1906    0.0\n",
      "1908    0.0\n",
      "1912    0.0\n",
      "1920    0.0\n",
      "1924    0.0\n",
      "1928    0.0\n",
      "1932    0.0\n",
      "1936    0.0\n",
      "1948    0.0\n",
      "1952    0.0\n",
      "1956    0.0\n",
      "1960    0.0\n",
      "1964    0.0\n",
      "1968    0.0\n",
      "1972    0.0\n",
      "1976    0.0\n",
      "1980    0.0\n",
      "1984    0.0\n",
      "1988    0.0\n",
      "1992    0.0\n",
      "1996    0.0\n",
      "2000    0.0\n",
      "2004    0.0\n",
      "2008    0.0\n",
      "2012    0.0\n",
      "2016    0.0\n",
      "2020    0.0\n",
      "2024    0.0\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Golf (drug)\n",
      "Raw data for Golf (drug):\n",
      "      Sport  Year  Value\n",
      "25    Golf  1896    0.0\n",
      "90    Golf  1900    0.0\n",
      "155   Golf  1904    0.0\n",
      "220   Golf  1906    0.0\n",
      "285   Golf  1908    0.0\n",
      "350   Golf  1912    0.0\n",
      "415   Golf  1920    0.0\n",
      "480   Golf  1924    0.0\n",
      "545   Golf  1928    0.0\n",
      "610   Golf  1932    0.0\n",
      "675   Golf  1936    0.0\n",
      "740   Golf  1948    0.0\n",
      "805   Golf  1952    0.0\n",
      "870   Golf  1956    0.0\n",
      "935   Golf  1960    0.0\n",
      "1000  Golf  1964    0.0\n",
      "1065  Golf  1968    0.0\n",
      "1130  Golf  1972    0.0\n",
      "1195  Golf  1976    0.0\n",
      "1260  Golf  1980    0.0\n",
      "1325  Golf  1984    0.0\n",
      "1390  Golf  1988    0.0\n",
      "1455  Golf  1992    0.0\n",
      "1520  Golf  1996    0.0\n",
      "1585  Golf  2000    0.0\n",
      "1650  Golf  2004    0.0\n",
      "1715  Golf  2008    0.0\n",
      "1780  Golf  2012    0.0\n",
      "1845  Golf  2016    0.0\n",
      "1910  Golf  2020    0.0\n",
      "1975  Golf  2024    0.0\n",
      "\n",
      "Prepared time series data for Golf (drug):\n",
      " Year\n",
      "1896    0.0\n",
      "1900    0.0\n",
      "1904    0.0\n",
      "1906    0.0\n",
      "1908    0.0\n",
      "1912    0.0\n",
      "1920    0.0\n",
      "1924    0.0\n",
      "1928    0.0\n",
      "1932    0.0\n",
      "1936    0.0\n",
      "1948    0.0\n",
      "1952    0.0\n",
      "1956    0.0\n",
      "1960    0.0\n",
      "1964    0.0\n",
      "1968    0.0\n",
      "1972    0.0\n",
      "1976    0.0\n",
      "1980    0.0\n",
      "1984    0.0\n",
      "1988    0.0\n",
      "1992    0.0\n",
      "1996    0.0\n",
      "2000    0.0\n",
      "2004    0.0\n",
      "2008    0.0\n",
      "2012    0.0\n",
      "2016    0.0\n",
      "2020    0.0\n",
      "2024    0.0\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Gymnastics (drug)\n",
      "Raw data for Gymnastics (drug):\n",
      "            Sport  Year  Value\n",
      "26    Gymnastics  1896    0.0\n",
      "91    Gymnastics  1900    0.0\n",
      "156   Gymnastics  1904    0.0\n",
      "221   Gymnastics  1906    0.0\n",
      "286   Gymnastics  1908    0.0\n",
      "351   Gymnastics  1912    0.0\n",
      "416   Gymnastics  1920    0.0\n",
      "481   Gymnastics  1924    0.0\n",
      "546   Gymnastics  1928    0.0\n",
      "611   Gymnastics  1932    0.0\n",
      "676   Gymnastics  1936    0.0\n",
      "741   Gymnastics  1948    0.0\n",
      "806   Gymnastics  1952    0.0\n",
      "871   Gymnastics  1956    0.0\n",
      "936   Gymnastics  1960    0.0\n",
      "1001  Gymnastics  1964    0.0\n",
      "1066  Gymnastics  1968    0.0\n",
      "1131  Gymnastics  1972    0.0\n",
      "1196  Gymnastics  1976    0.0\n",
      "1261  Gymnastics  1980    0.0\n",
      "1326  Gymnastics  1984    0.0\n",
      "1391  Gymnastics  1988    0.0\n",
      "1456  Gymnastics  1992    0.0\n",
      "1521  Gymnastics  1996    0.0\n",
      "1586  Gymnastics  2000    1.0\n",
      "1651  Gymnastics  2004    0.0\n",
      "1716  Gymnastics  2008    1.0\n",
      "1781  Gymnastics  2012    1.0\n",
      "1846  Gymnastics  2016    0.0\n",
      "1911  Gymnastics  2020    0.0\n",
      "1976  Gymnastics  2024    0.0\n",
      "\n",
      "Prepared time series data for Gymnastics (drug):\n",
      " Year\n",
      "1896    0.0\n",
      "1900    0.0\n",
      "1904    0.0\n",
      "1906    0.0\n",
      "1908    0.0\n",
      "1912    0.0\n",
      "1920    0.0\n",
      "1924    0.0\n",
      "1928    0.0\n",
      "1932    0.0\n",
      "1936    0.0\n",
      "1948    0.0\n",
      "1952    0.0\n",
      "1956    0.0\n",
      "1960    0.0\n",
      "1964    0.0\n",
      "1968    0.0\n",
      "1972    0.0\n",
      "1976    0.0\n",
      "1980    0.0\n",
      "1984    0.0\n",
      "1988    0.0\n",
      "1992    0.0\n",
      "1996    0.0\n",
      "2000    1.0\n",
      "2004    0.0\n",
      "2008    1.0\n",
      "2012    1.0\n",
      "2016    0.0\n",
      "2020    0.0\n",
      "2024    0.0\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Handball (drug)\n",
      "Raw data for Handball (drug):\n",
      "          Sport  Year  Value\n",
      "27    Handball  1896    0.0\n",
      "92    Handball  1900    0.0\n",
      "157   Handball  1904    0.0\n",
      "222   Handball  1906    0.0\n",
      "287   Handball  1908    0.0\n",
      "352   Handball  1912    0.0\n",
      "417   Handball  1920    0.0\n",
      "482   Handball  1924    0.0\n",
      "547   Handball  1928    0.0\n",
      "612   Handball  1932    0.0\n",
      "677   Handball  1936    0.0\n",
      "742   Handball  1948    0.0\n",
      "807   Handball  1952    0.0\n",
      "872   Handball  1956    0.0\n",
      "937   Handball  1960    0.0\n",
      "1002  Handball  1964    0.0\n",
      "1067  Handball  1968    0.0\n",
      "1132  Handball  1972    0.0\n",
      "1197  Handball  1976    0.0\n",
      "1262  Handball  1980    0.0\n",
      "1327  Handball  1984    0.0\n",
      "1392  Handball  1988    0.0\n",
      "1457  Handball  1992    0.0\n",
      "1522  Handball  1996    0.0\n",
      "1587  Handball  2000    0.0\n",
      "1652  Handball  2004    0.0\n",
      "1717  Handball  2008    0.0\n",
      "1782  Handball  2012    0.0\n",
      "1847  Handball  2016    0.0\n",
      "1912  Handball  2020    0.0\n",
      "1977  Handball  2024    0.0\n",
      "\n",
      "Prepared time series data for Handball (drug):\n",
      " Year\n",
      "1896    0.0\n",
      "1900    0.0\n",
      "1904    0.0\n",
      "1906    0.0\n",
      "1908    0.0\n",
      "1912    0.0\n",
      "1920    0.0\n",
      "1924    0.0\n",
      "1928    0.0\n",
      "1932    0.0\n",
      "1936    0.0\n",
      "1948    0.0\n",
      "1952    0.0\n",
      "1956    0.0\n",
      "1960    0.0\n",
      "1964    0.0\n",
      "1968    0.0\n",
      "1972    0.0\n",
      "1976    0.0\n",
      "1980    0.0\n",
      "1984    0.0\n",
      "1988    0.0\n",
      "1992    0.0\n",
      "1996    0.0\n",
      "2000    0.0\n",
      "2004    0.0\n",
      "2008    0.0\n",
      "2012    0.0\n",
      "2016    0.0\n",
      "2020    0.0\n",
      "2024    0.0\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Hockey (drug)\n",
      "Raw data for Hockey (drug):\n",
      "        Sport  Year  Value\n",
      "28    Hockey  1896    0.0\n",
      "93    Hockey  1900    0.0\n",
      "158   Hockey  1904    0.0\n",
      "223   Hockey  1906    0.0\n",
      "288   Hockey  1908    0.0\n",
      "353   Hockey  1912    0.0\n",
      "418   Hockey  1920    0.0\n",
      "483   Hockey  1924    0.0\n",
      "548   Hockey  1928    0.0\n",
      "613   Hockey  1932    0.0\n",
      "678   Hockey  1936    0.0\n",
      "743   Hockey  1948    0.0\n",
      "808   Hockey  1952    0.0\n",
      "873   Hockey  1956    0.0\n",
      "938   Hockey  1960    0.0\n",
      "1003  Hockey  1964    0.0\n",
      "1068  Hockey  1968    0.0\n",
      "1133  Hockey  1972    0.0\n",
      "1198  Hockey  1976    0.0\n",
      "1263  Hockey  1980    0.0\n",
      "1328  Hockey  1984    0.0\n",
      "1393  Hockey  1988    0.0\n",
      "1458  Hockey  1992    0.0\n",
      "1523  Hockey  1996    0.0\n",
      "1588  Hockey  2000    0.0\n",
      "1653  Hockey  2004    0.0\n",
      "1718  Hockey  2008    0.0\n",
      "1783  Hockey  2012    0.0\n",
      "1848  Hockey  2016    0.0\n",
      "1913  Hockey  2020    0.0\n",
      "1978  Hockey  2024    0.0\n",
      "\n",
      "Prepared time series data for Hockey (drug):\n",
      " Year\n",
      "1896    0.0\n",
      "1900    0.0\n",
      "1904    0.0\n",
      "1906    0.0\n",
      "1908    0.0\n",
      "1912    0.0\n",
      "1920    0.0\n",
      "1924    0.0\n",
      "1928    0.0\n",
      "1932    0.0\n",
      "1936    0.0\n",
      "1948    0.0\n",
      "1952    0.0\n",
      "1956    0.0\n",
      "1960    0.0\n",
      "1964    0.0\n",
      "1968    0.0\n",
      "1972    0.0\n",
      "1976    0.0\n",
      "1980    0.0\n",
      "1984    0.0\n",
      "1988    0.0\n",
      "1992    0.0\n",
      "1996    0.0\n",
      "2000    0.0\n",
      "2004    0.0\n",
      "2008    0.0\n",
      "2012    0.0\n",
      "2016    0.0\n",
      "2020    0.0\n",
      "2024    0.0\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Ice Hockey (drug)\n",
      "Raw data for Ice Hockey (drug):\n",
      "            Sport  Year  Value\n",
      "29    Ice Hockey  1896    0.0\n",
      "94    Ice Hockey  1900    0.0\n",
      "159   Ice Hockey  1904    0.0\n",
      "224   Ice Hockey  1906    0.0\n",
      "289   Ice Hockey  1908    0.0\n",
      "354   Ice Hockey  1912    0.0\n",
      "419   Ice Hockey  1920    0.0\n",
      "484   Ice Hockey  1924    0.0\n",
      "549   Ice Hockey  1928    0.0\n",
      "614   Ice Hockey  1932    0.0\n",
      "679   Ice Hockey  1936    0.0\n",
      "744   Ice Hockey  1948    0.0\n",
      "809   Ice Hockey  1952    0.0\n",
      "874   Ice Hockey  1956    0.0\n",
      "939   Ice Hockey  1960    0.0\n",
      "1004  Ice Hockey  1964    0.0\n",
      "1069  Ice Hockey  1968    0.0\n",
      "1134  Ice Hockey  1972    0.0\n",
      "1199  Ice Hockey  1976    0.0\n",
      "1264  Ice Hockey  1980    0.0\n",
      "1329  Ice Hockey  1984    0.0\n",
      "1394  Ice Hockey  1988    0.0\n",
      "1459  Ice Hockey  1992    0.0\n",
      "1524  Ice Hockey  1996    0.0\n",
      "1589  Ice Hockey  2000    0.0\n",
      "1654  Ice Hockey  2004    0.0\n",
      "1719  Ice Hockey  2008    0.0\n",
      "1784  Ice Hockey  2012    0.0\n",
      "1849  Ice Hockey  2016    0.0\n",
      "1914  Ice Hockey  2020    0.0\n",
      "1979  Ice Hockey  2024    0.0\n",
      "\n",
      "Prepared time series data for Ice Hockey (drug):\n",
      " Year\n",
      "1896    0.0\n",
      "1900    0.0\n",
      "1904    0.0\n",
      "1906    0.0\n",
      "1908    0.0\n",
      "1912    0.0\n",
      "1920    0.0\n",
      "1924    0.0\n",
      "1928    0.0\n",
      "1932    0.0\n",
      "1936    0.0\n",
      "1948    0.0\n",
      "1952    0.0\n",
      "1956    0.0\n",
      "1960    0.0\n",
      "1964    0.0\n",
      "1968    0.0\n",
      "1972    0.0\n",
      "1976    0.0\n",
      "1980    0.0\n",
      "1984    0.0\n",
      "1988    0.0\n",
      "1992    0.0\n",
      "1996    0.0\n",
      "2000    0.0\n",
      "2004    0.0\n",
      "2008    0.0\n",
      "2012    0.0\n",
      "2016    0.0\n",
      "2020    0.0\n",
      "2024    0.0\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Jeu De Paume (drug)\n",
      "Raw data for Jeu De Paume (drug):\n",
      "              Sport  Year  Value\n",
      "30    Jeu De Paume  1896    0.0\n",
      "95    Jeu De Paume  1900    0.0\n",
      "160   Jeu De Paume  1904    0.0\n",
      "225   Jeu De Paume  1906    0.0\n",
      "290   Jeu De Paume  1908    0.0\n",
      "355   Jeu De Paume  1912    0.0\n",
      "420   Jeu De Paume  1920    0.0\n",
      "485   Jeu De Paume  1924    0.0\n",
      "550   Jeu De Paume  1928    0.0\n",
      "615   Jeu De Paume  1932    0.0\n",
      "680   Jeu De Paume  1936    0.0\n",
      "745   Jeu De Paume  1948    0.0\n",
      "810   Jeu De Paume  1952    0.0\n",
      "875   Jeu De Paume  1956    0.0\n",
      "940   Jeu De Paume  1960    0.0\n",
      "1005  Jeu De Paume  1964    0.0\n",
      "1070  Jeu De Paume  1968    0.0\n",
      "1135  Jeu De Paume  1972    0.0\n",
      "1200  Jeu De Paume  1976    0.0\n",
      "1265  Jeu De Paume  1980    0.0\n",
      "1330  Jeu De Paume  1984    0.0\n",
      "1395  Jeu De Paume  1988    0.0\n",
      "1460  Jeu De Paume  1992    0.0\n",
      "1525  Jeu De Paume  1996    0.0\n",
      "1590  Jeu De Paume  2000    0.0\n",
      "1655  Jeu De Paume  2004    0.0\n",
      "1720  Jeu De Paume  2008    0.0\n",
      "1785  Jeu De Paume  2012    0.0\n",
      "1850  Jeu De Paume  2016    0.0\n",
      "1915  Jeu De Paume  2020    0.0\n",
      "1980  Jeu De Paume  2024    0.0\n",
      "\n",
      "Prepared time series data for Jeu De Paume (drug):\n",
      " Year\n",
      "1896    0.0\n",
      "1900    0.0\n",
      "1904    0.0\n",
      "1906    0.0\n",
      "1908    0.0\n",
      "1912    0.0\n",
      "1920    0.0\n",
      "1924    0.0\n",
      "1928    0.0\n",
      "1932    0.0\n",
      "1936    0.0\n",
      "1948    0.0\n",
      "1952    0.0\n",
      "1956    0.0\n",
      "1960    0.0\n",
      "1964    0.0\n",
      "1968    0.0\n",
      "1972    0.0\n",
      "1976    0.0\n",
      "1980    0.0\n",
      "1984    0.0\n",
      "1988    0.0\n",
      "1992    0.0\n",
      "1996    0.0\n",
      "2000    0.0\n",
      "2004    0.0\n",
      "2008    0.0\n",
      "2012    0.0\n",
      "2016    0.0\n",
      "2020    0.0\n",
      "2024    0.0\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Judo (drug)\n",
      "Raw data for Judo (drug):\n",
      "      Sport  Year  Value\n",
      "31    Judo  1896    0.0\n",
      "96    Judo  1900    0.0\n",
      "161   Judo  1904    0.0\n",
      "226   Judo  1906    0.0\n",
      "291   Judo  1908    0.0\n",
      "356   Judo  1912    0.0\n",
      "421   Judo  1920    0.0\n",
      "486   Judo  1924    0.0\n",
      "551   Judo  1928    0.0\n",
      "616   Judo  1932    0.0\n",
      "681   Judo  1936    0.0\n",
      "746   Judo  1948    0.0\n",
      "811   Judo  1952    0.0\n",
      "876   Judo  1956    0.0\n",
      "941   Judo  1960    0.0\n",
      "1006  Judo  1964    0.0\n",
      "1071  Judo  1968    0.0\n",
      "1136  Judo  1972    1.0\n",
      "1201  Judo  1976    0.0\n",
      "1266  Judo  1980    0.0\n",
      "1331  Judo  1984    0.0\n",
      "1396  Judo  1988    1.0\n",
      "1461  Judo  1992    0.0\n",
      "1526  Judo  1996    0.0\n",
      "1591  Judo  2000    0.0\n",
      "1656  Judo  2004    0.0\n",
      "1721  Judo  2008    0.0\n",
      "1786  Judo  2012    1.0\n",
      "1851  Judo  2016    0.0\n",
      "1916  Judo  2020    0.0\n",
      "1981  Judo  2024    2.0\n",
      "\n",
      "Prepared time series data for Judo (drug):\n",
      " Year\n",
      "1896    0.0\n",
      "1900    0.0\n",
      "1904    0.0\n",
      "1906    0.0\n",
      "1908    0.0\n",
      "1912    0.0\n",
      "1920    0.0\n",
      "1924    0.0\n",
      "1928    0.0\n",
      "1932    0.0\n",
      "1936    0.0\n",
      "1948    0.0\n",
      "1952    0.0\n",
      "1956    0.0\n",
      "1960    0.0\n",
      "1964    0.0\n",
      "1968    0.0\n",
      "1972    1.0\n",
      "1976    0.0\n",
      "1980    0.0\n",
      "1984    0.0\n",
      "1988    1.0\n",
      "1992    0.0\n",
      "1996    0.0\n",
      "2000    0.0\n",
      "2004    0.0\n",
      "2008    0.0\n",
      "2012    1.0\n",
      "2016    0.0\n",
      "2020    0.0\n",
      "2024    2.0\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Lacrosse (drug)\n",
      "Raw data for Lacrosse (drug):\n",
      "          Sport  Year  Value\n",
      "32    Lacrosse  1896    0.0\n",
      "97    Lacrosse  1900    0.0\n",
      "162   Lacrosse  1904    0.0\n",
      "227   Lacrosse  1906    0.0\n",
      "292   Lacrosse  1908    0.0\n",
      "357   Lacrosse  1912    0.0\n",
      "422   Lacrosse  1920    0.0\n",
      "487   Lacrosse  1924    0.0\n",
      "552   Lacrosse  1928    0.0\n",
      "617   Lacrosse  1932    0.0\n",
      "682   Lacrosse  1936    0.0\n",
      "747   Lacrosse  1948    0.0\n",
      "812   Lacrosse  1952    0.0\n",
      "877   Lacrosse  1956    0.0\n",
      "942   Lacrosse  1960    0.0\n",
      "1007  Lacrosse  1964    0.0\n",
      "1072  Lacrosse  1968    0.0\n",
      "1137  Lacrosse  1972    0.0\n",
      "1202  Lacrosse  1976    0.0\n",
      "1267  Lacrosse  1980    0.0\n",
      "1332  Lacrosse  1984    0.0\n",
      "1397  Lacrosse  1988    0.0\n",
      "1462  Lacrosse  1992    0.0\n",
      "1527  Lacrosse  1996    0.0\n",
      "1592  Lacrosse  2000    0.0\n",
      "1657  Lacrosse  2004    0.0\n",
      "1722  Lacrosse  2008    0.0\n",
      "1787  Lacrosse  2012    0.0\n",
      "1852  Lacrosse  2016    0.0\n",
      "1917  Lacrosse  2020    0.0\n",
      "1982  Lacrosse  2024    0.0\n",
      "\n",
      "Prepared time series data for Lacrosse (drug):\n",
      " Year\n",
      "1896    0.0\n",
      "1900    0.0\n",
      "1904    0.0\n",
      "1906    0.0\n",
      "1908    0.0\n",
      "1912    0.0\n",
      "1920    0.0\n",
      "1924    0.0\n",
      "1928    0.0\n",
      "1932    0.0\n",
      "1936    0.0\n",
      "1948    0.0\n",
      "1952    0.0\n",
      "1956    0.0\n",
      "1960    0.0\n",
      "1964    0.0\n",
      "1968    0.0\n",
      "1972    0.0\n",
      "1976    0.0\n",
      "1980    0.0\n",
      "1984    0.0\n",
      "1988    0.0\n",
      "1992    0.0\n",
      "1996    0.0\n",
      "2000    0.0\n",
      "2004    0.0\n",
      "2008    0.0\n",
      "2012    0.0\n",
      "2016    0.0\n",
      "2020    0.0\n",
      "2024    0.0\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Luge (drug)\n",
      "Raw data for Luge (drug):\n",
      "      Sport  Year  Value\n",
      "33    Luge  1896    0.0\n",
      "98    Luge  1900    0.0\n",
      "163   Luge  1904    0.0\n",
      "228   Luge  1906    0.0\n",
      "293   Luge  1908    0.0\n",
      "358   Luge  1912    0.0\n",
      "423   Luge  1920    0.0\n",
      "488   Luge  1924    0.0\n",
      "553   Luge  1928    0.0\n",
      "618   Luge  1932    0.0\n",
      "683   Luge  1936    0.0\n",
      "748   Luge  1948    0.0\n",
      "813   Luge  1952    0.0\n",
      "878   Luge  1956    0.0\n",
      "943   Luge  1960    0.0\n",
      "1008  Luge  1964    0.0\n",
      "1073  Luge  1968    0.0\n",
      "1138  Luge  1972    0.0\n",
      "1203  Luge  1976    0.0\n",
      "1268  Luge  1980    0.0\n",
      "1333  Luge  1984    0.0\n",
      "1398  Luge  1988    0.0\n",
      "1463  Luge  1992    0.0\n",
      "1528  Luge  1996    0.0\n",
      "1593  Luge  2000    0.0\n",
      "1658  Luge  2004    0.0\n",
      "1723  Luge  2008    0.0\n",
      "1788  Luge  2012    0.0\n",
      "1853  Luge  2016    0.0\n",
      "1918  Luge  2020    0.0\n",
      "1983  Luge  2024    0.0\n",
      "\n",
      "Prepared time series data for Luge (drug):\n",
      " Year\n",
      "1896    0.0\n",
      "1900    0.0\n",
      "1904    0.0\n",
      "1906    0.0\n",
      "1908    0.0\n",
      "1912    0.0\n",
      "1920    0.0\n",
      "1924    0.0\n",
      "1928    0.0\n",
      "1932    0.0\n",
      "1936    0.0\n",
      "1948    0.0\n",
      "1952    0.0\n",
      "1956    0.0\n",
      "1960    0.0\n",
      "1964    0.0\n",
      "1968    0.0\n",
      "1972    0.0\n",
      "1976    0.0\n",
      "1980    0.0\n",
      "1984    0.0\n",
      "1988    0.0\n",
      "1992    0.0\n",
      "1996    0.0\n",
      "2000    0.0\n",
      "2004    0.0\n",
      "2008    0.0\n",
      "2012    0.0\n",
      "2016    0.0\n",
      "2020    0.0\n",
      "2024    0.0\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Military Ski Patrol (drug)\n",
      "Raw data for Military Ski Patrol (drug):\n",
      "                     Sport  Year  Value\n",
      "34    Military Ski Patrol  1896    0.0\n",
      "99    Military Ski Patrol  1900    0.0\n",
      "164   Military Ski Patrol  1904    0.0\n",
      "229   Military Ski Patrol  1906    0.0\n",
      "294   Military Ski Patrol  1908    0.0\n",
      "359   Military Ski Patrol  1912    0.0\n",
      "424   Military Ski Patrol  1920    0.0\n",
      "489   Military Ski Patrol  1924    0.0\n",
      "554   Military Ski Patrol  1928    0.0\n",
      "619   Military Ski Patrol  1932    0.0\n",
      "684   Military Ski Patrol  1936    0.0\n",
      "749   Military Ski Patrol  1948    0.0\n",
      "814   Military Ski Patrol  1952    0.0\n",
      "879   Military Ski Patrol  1956    0.0\n",
      "944   Military Ski Patrol  1960    0.0\n",
      "1009  Military Ski Patrol  1964    0.0\n",
      "1074  Military Ski Patrol  1968    0.0\n",
      "1139  Military Ski Patrol  1972    0.0\n",
      "1204  Military Ski Patrol  1976    0.0\n",
      "1269  Military Ski Patrol  1980    0.0\n",
      "1334  Military Ski Patrol  1984    0.0\n",
      "1399  Military Ski Patrol  1988    0.0\n",
      "1464  Military Ski Patrol  1992    0.0\n",
      "1529  Military Ski Patrol  1996    0.0\n",
      "1594  Military Ski Patrol  2000    0.0\n",
      "1659  Military Ski Patrol  2004    0.0\n",
      "1724  Military Ski Patrol  2008    0.0\n",
      "1789  Military Ski Patrol  2012    0.0\n",
      "1854  Military Ski Patrol  2016    0.0\n",
      "1919  Military Ski Patrol  2020    0.0\n",
      "1984  Military Ski Patrol  2024    0.0\n",
      "\n",
      "Prepared time series data for Military Ski Patrol (drug):\n",
      " Year\n",
      "1896    0.0\n",
      "1900    0.0\n",
      "1904    0.0\n",
      "1906    0.0\n",
      "1908    0.0\n",
      "1912    0.0\n",
      "1920    0.0\n",
      "1924    0.0\n",
      "1928    0.0\n",
      "1932    0.0\n",
      "1936    0.0\n",
      "1948    0.0\n",
      "1952    0.0\n",
      "1956    0.0\n",
      "1960    0.0\n",
      "1964    0.0\n",
      "1968    0.0\n",
      "1972    0.0\n",
      "1976    0.0\n",
      "1980    0.0\n",
      "1984    0.0\n",
      "1988    0.0\n",
      "1992    0.0\n",
      "1996    0.0\n",
      "2000    0.0\n",
      "2004    0.0\n",
      "2008    0.0\n",
      "2012    0.0\n",
      "2016    0.0\n",
      "2020    0.0\n",
      "2024    0.0\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Modern Pentathlon (drug)\n",
      "Raw data for Modern Pentathlon (drug):\n",
      "                   Sport  Year  Value\n",
      "35    Modern Pentathlon  1896    0.0\n",
      "100   Modern Pentathlon  1900    0.0\n",
      "165   Modern Pentathlon  1904    0.0\n",
      "230   Modern Pentathlon  1906    0.0\n",
      "295   Modern Pentathlon  1908    0.0\n",
      "360   Modern Pentathlon  1912    0.0\n",
      "425   Modern Pentathlon  1920    0.0\n",
      "490   Modern Pentathlon  1924    0.0\n",
      "555   Modern Pentathlon  1928    0.0\n",
      "620   Modern Pentathlon  1932    0.0\n",
      "685   Modern Pentathlon  1936    0.0\n",
      "750   Modern Pentathlon  1948    0.0\n",
      "815   Modern Pentathlon  1952    0.0\n",
      "880   Modern Pentathlon  1956    0.0\n",
      "945   Modern Pentathlon  1960    0.0\n",
      "1010  Modern Pentathlon  1964    0.0\n",
      "1075  Modern Pentathlon  1968    1.0\n",
      "1140  Modern Pentathlon  1972    0.0\n",
      "1205  Modern Pentathlon  1976    0.0\n",
      "1270  Modern Pentathlon  1980    0.0\n",
      "1335  Modern Pentathlon  1984    0.0\n",
      "1400  Modern Pentathlon  1988    2.0\n",
      "1465  Modern Pentathlon  1992    0.0\n",
      "1530  Modern Pentathlon  1996    0.0\n",
      "1595  Modern Pentathlon  2000    0.0\n",
      "1660  Modern Pentathlon  2004    0.0\n",
      "1725  Modern Pentathlon  2008    1.0\n",
      "1790  Modern Pentathlon  2012    0.0\n",
      "1855  Modern Pentathlon  2016    0.0\n",
      "1920  Modern Pentathlon  2020    0.0\n",
      "1985  Modern Pentathlon  2024    0.0\n",
      "\n",
      "Prepared time series data for Modern Pentathlon (drug):\n",
      " Year\n",
      "1896    0.0\n",
      "1900    0.0\n",
      "1904    0.0\n",
      "1906    0.0\n",
      "1908    0.0\n",
      "1912    0.0\n",
      "1920    0.0\n",
      "1924    0.0\n",
      "1928    0.0\n",
      "1932    0.0\n",
      "1936    0.0\n",
      "1948    0.0\n",
      "1952    0.0\n",
      "1956    0.0\n",
      "1960    0.0\n",
      "1964    0.0\n",
      "1968    1.0\n",
      "1972    0.0\n",
      "1976    0.0\n",
      "1980    0.0\n",
      "1984    0.0\n",
      "1988    2.0\n",
      "1992    0.0\n",
      "1996    0.0\n",
      "2000    0.0\n",
      "2004    0.0\n",
      "2008    1.0\n",
      "2012    0.0\n",
      "2016    0.0\n",
      "2020    0.0\n",
      "2024    0.0\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Motorboating (drug)\n",
      "Raw data for Motorboating (drug):\n",
      "              Sport  Year  Value\n",
      "36    Motorboating  1896    0.0\n",
      "101   Motorboating  1900    0.0\n",
      "166   Motorboating  1904    0.0\n",
      "231   Motorboating  1906    0.0\n",
      "296   Motorboating  1908    0.0\n",
      "361   Motorboating  1912    0.0\n",
      "426   Motorboating  1920    0.0\n",
      "491   Motorboating  1924    0.0\n",
      "556   Motorboating  1928    0.0\n",
      "621   Motorboating  1932    0.0\n",
      "686   Motorboating  1936    0.0\n",
      "751   Motorboating  1948    0.0\n",
      "816   Motorboating  1952    0.0\n",
      "881   Motorboating  1956    0.0\n",
      "946   Motorboating  1960    0.0\n",
      "1011  Motorboating  1964    0.0\n",
      "1076  Motorboating  1968    0.0\n",
      "1141  Motorboating  1972    0.0\n",
      "1206  Motorboating  1976    0.0\n",
      "1271  Motorboating  1980    0.0\n",
      "1336  Motorboating  1984    0.0\n",
      "1401  Motorboating  1988    0.0\n",
      "1466  Motorboating  1992    0.0\n",
      "1531  Motorboating  1996    0.0\n",
      "1596  Motorboating  2000    0.0\n",
      "1661  Motorboating  2004    0.0\n",
      "1726  Motorboating  2008    0.0\n",
      "1791  Motorboating  2012    0.0\n",
      "1856  Motorboating  2016    0.0\n",
      "1921  Motorboating  2020    0.0\n",
      "1986  Motorboating  2024    0.0\n",
      "\n",
      "Prepared time series data for Motorboating (drug):\n",
      " Year\n",
      "1896    0.0\n",
      "1900    0.0\n",
      "1904    0.0\n",
      "1906    0.0\n",
      "1908    0.0\n",
      "1912    0.0\n",
      "1920    0.0\n",
      "1924    0.0\n",
      "1928    0.0\n",
      "1932    0.0\n",
      "1936    0.0\n",
      "1948    0.0\n",
      "1952    0.0\n",
      "1956    0.0\n",
      "1960    0.0\n",
      "1964    0.0\n",
      "1968    0.0\n",
      "1972    0.0\n",
      "1976    0.0\n",
      "1980    0.0\n",
      "1984    0.0\n",
      "1988    0.0\n",
      "1992    0.0\n",
      "1996    0.0\n",
      "2000    0.0\n",
      "2004    0.0\n",
      "2008    0.0\n",
      "2012    0.0\n",
      "2016    0.0\n",
      "2020    0.0\n",
      "2024    0.0\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Nordic Combined (drug)\n",
      "Raw data for Nordic Combined (drug):\n",
      "                 Sport  Year  Value\n",
      "37    Nordic Combined  1896    0.0\n",
      "102   Nordic Combined  1900    0.0\n",
      "167   Nordic Combined  1904    0.0\n",
      "232   Nordic Combined  1906    0.0\n",
      "297   Nordic Combined  1908    0.0\n",
      "362   Nordic Combined  1912    0.0\n",
      "427   Nordic Combined  1920    0.0\n",
      "492   Nordic Combined  1924    0.0\n",
      "557   Nordic Combined  1928    0.0\n",
      "622   Nordic Combined  1932    0.0\n",
      "687   Nordic Combined  1936    0.0\n",
      "752   Nordic Combined  1948    0.0\n",
      "817   Nordic Combined  1952    0.0\n",
      "882   Nordic Combined  1956    0.0\n",
      "947   Nordic Combined  1960    0.0\n",
      "1012  Nordic Combined  1964    0.0\n",
      "1077  Nordic Combined  1968    0.0\n",
      "1142  Nordic Combined  1972    0.0\n",
      "1207  Nordic Combined  1976    0.0\n",
      "1272  Nordic Combined  1980    0.0\n",
      "1337  Nordic Combined  1984    0.0\n",
      "1402  Nordic Combined  1988    0.0\n",
      "1467  Nordic Combined  1992    0.0\n",
      "1532  Nordic Combined  1996    0.0\n",
      "1597  Nordic Combined  2000    0.0\n",
      "1662  Nordic Combined  2004    0.0\n",
      "1727  Nordic Combined  2008    0.0\n",
      "1792  Nordic Combined  2012    0.0\n",
      "1857  Nordic Combined  2016    0.0\n",
      "1922  Nordic Combined  2020    0.0\n",
      "1987  Nordic Combined  2024    0.0\n",
      "\n",
      "Prepared time series data for Nordic Combined (drug):\n",
      " Year\n",
      "1896    0.0\n",
      "1900    0.0\n",
      "1904    0.0\n",
      "1906    0.0\n",
      "1908    0.0\n",
      "1912    0.0\n",
      "1920    0.0\n",
      "1924    0.0\n",
      "1928    0.0\n",
      "1932    0.0\n",
      "1936    0.0\n",
      "1948    0.0\n",
      "1952    0.0\n",
      "1956    0.0\n",
      "1960    0.0\n",
      "1964    0.0\n",
      "1968    0.0\n",
      "1972    0.0\n",
      "1976    0.0\n",
      "1980    0.0\n",
      "1984    0.0\n",
      "1988    0.0\n",
      "1992    0.0\n",
      "1996    0.0\n",
      "2000    0.0\n",
      "2004    0.0\n",
      "2008    0.0\n",
      "2012    0.0\n",
      "2016    0.0\n",
      "2020    0.0\n",
      "2024    0.0\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Polo (drug)\n",
      "Raw data for Polo (drug):\n",
      "      Sport  Year  Value\n",
      "38    Polo  1896    0.0\n",
      "103   Polo  1900    0.0\n",
      "168   Polo  1904    0.0\n",
      "233   Polo  1906    0.0\n",
      "298   Polo  1908    0.0\n",
      "363   Polo  1912    0.0\n",
      "428   Polo  1920    0.0\n",
      "493   Polo  1924    0.0\n",
      "558   Polo  1928    0.0\n",
      "623   Polo  1932    0.0\n",
      "688   Polo  1936    0.0\n",
      "753   Polo  1948    0.0\n",
      "818   Polo  1952    0.0\n",
      "883   Polo  1956    0.0\n",
      "948   Polo  1960    0.0\n",
      "1013  Polo  1964    0.0\n",
      "1078  Polo  1968    0.0\n",
      "1143  Polo  1972    0.0\n",
      "1208  Polo  1976    0.0\n",
      "1273  Polo  1980    0.0\n",
      "1338  Polo  1984    0.0\n",
      "1403  Polo  1988    0.0\n",
      "1468  Polo  1992    0.0\n",
      "1533  Polo  1996    0.0\n",
      "1598  Polo  2000    0.0\n",
      "1663  Polo  2004    0.0\n",
      "1728  Polo  2008    0.0\n",
      "1793  Polo  2012    0.0\n",
      "1858  Polo  2016    0.0\n",
      "1923  Polo  2020    0.0\n",
      "1988  Polo  2024    0.0\n",
      "\n",
      "Prepared time series data for Polo (drug):\n",
      " Year\n",
      "1896    0.0\n",
      "1900    0.0\n",
      "1904    0.0\n",
      "1906    0.0\n",
      "1908    0.0\n",
      "1912    0.0\n",
      "1920    0.0\n",
      "1924    0.0\n",
      "1928    0.0\n",
      "1932    0.0\n",
      "1936    0.0\n",
      "1948    0.0\n",
      "1952    0.0\n",
      "1956    0.0\n",
      "1960    0.0\n",
      "1964    0.0\n",
      "1968    0.0\n",
      "1972    0.0\n",
      "1976    0.0\n",
      "1980    0.0\n",
      "1984    0.0\n",
      "1988    0.0\n",
      "1992    0.0\n",
      "1996    0.0\n",
      "2000    0.0\n",
      "2004    0.0\n",
      "2008    0.0\n",
      "2012    0.0\n",
      "2016    0.0\n",
      "2020    0.0\n",
      "2024    0.0\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Racquets (drug)\n",
      "Raw data for Racquets (drug):\n",
      "          Sport  Year  Value\n",
      "39    Racquets  1896    0.0\n",
      "104   Racquets  1900    0.0\n",
      "169   Racquets  1904    0.0\n",
      "234   Racquets  1906    0.0\n",
      "299   Racquets  1908    0.0\n",
      "364   Racquets  1912    0.0\n",
      "429   Racquets  1920    0.0\n",
      "494   Racquets  1924    0.0\n",
      "559   Racquets  1928    0.0\n",
      "624   Racquets  1932    0.0\n",
      "689   Racquets  1936    0.0\n",
      "754   Racquets  1948    0.0\n",
      "819   Racquets  1952    0.0\n",
      "884   Racquets  1956    0.0\n",
      "949   Racquets  1960    0.0\n",
      "1014  Racquets  1964    0.0\n",
      "1079  Racquets  1968    0.0\n",
      "1144  Racquets  1972    0.0\n",
      "1209  Racquets  1976    0.0\n",
      "1274  Racquets  1980    0.0\n",
      "1339  Racquets  1984    0.0\n",
      "1404  Racquets  1988    0.0\n",
      "1469  Racquets  1992    0.0\n",
      "1534  Racquets  1996    0.0\n",
      "1599  Racquets  2000    0.0\n",
      "1664  Racquets  2004    0.0\n",
      "1729  Racquets  2008    0.0\n",
      "1794  Racquets  2012    0.0\n",
      "1859  Racquets  2016    0.0\n",
      "1924  Racquets  2020    0.0\n",
      "1989  Racquets  2024    0.0\n",
      "\n",
      "Prepared time series data for Racquets (drug):\n",
      " Year\n",
      "1896    0.0\n",
      "1900    0.0\n",
      "1904    0.0\n",
      "1906    0.0\n",
      "1908    0.0\n",
      "1912    0.0\n",
      "1920    0.0\n",
      "1924    0.0\n",
      "1928    0.0\n",
      "1932    0.0\n",
      "1936    0.0\n",
      "1948    0.0\n",
      "1952    0.0\n",
      "1956    0.0\n",
      "1960    0.0\n",
      "1964    0.0\n",
      "1968    0.0\n",
      "1972    0.0\n",
      "1976    0.0\n",
      "1980    0.0\n",
      "1984    0.0\n",
      "1988    0.0\n",
      "1992    0.0\n",
      "1996    0.0\n",
      "2000    0.0\n",
      "2004    0.0\n",
      "2008    0.0\n",
      "2012    0.0\n",
      "2016    0.0\n",
      "2020    0.0\n",
      "2024    0.0\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Rhythmic Gymnastics (drug)\n",
      "Raw data for Rhythmic Gymnastics (drug):\n",
      "                     Sport  Year  Value\n",
      "40    Rhythmic Gymnastics  1896    0.0\n",
      "105   Rhythmic Gymnastics  1900    0.0\n",
      "170   Rhythmic Gymnastics  1904    0.0\n",
      "235   Rhythmic Gymnastics  1906    0.0\n",
      "300   Rhythmic Gymnastics  1908    0.0\n",
      "365   Rhythmic Gymnastics  1912    0.0\n",
      "430   Rhythmic Gymnastics  1920    0.0\n",
      "495   Rhythmic Gymnastics  1924    0.0\n",
      "560   Rhythmic Gymnastics  1928    0.0\n",
      "625   Rhythmic Gymnastics  1932    0.0\n",
      "690   Rhythmic Gymnastics  1936    0.0\n",
      "755   Rhythmic Gymnastics  1948    0.0\n",
      "820   Rhythmic Gymnastics  1952    0.0\n",
      "885   Rhythmic Gymnastics  1956    0.0\n",
      "950   Rhythmic Gymnastics  1960    0.0\n",
      "1015  Rhythmic Gymnastics  1964    0.0\n",
      "1080  Rhythmic Gymnastics  1968    0.0\n",
      "1145  Rhythmic Gymnastics  1972    0.0\n",
      "1210  Rhythmic Gymnastics  1976    0.0\n",
      "1275  Rhythmic Gymnastics  1980    0.0\n",
      "1340  Rhythmic Gymnastics  1984    0.0\n",
      "1405  Rhythmic Gymnastics  1988    0.0\n",
      "1470  Rhythmic Gymnastics  1992    0.0\n",
      "1535  Rhythmic Gymnastics  1996    0.0\n",
      "1600  Rhythmic Gymnastics  2000    0.0\n",
      "1665  Rhythmic Gymnastics  2004    0.0\n",
      "1730  Rhythmic Gymnastics  2008    0.0\n",
      "1795  Rhythmic Gymnastics  2012    0.0\n",
      "1860  Rhythmic Gymnastics  2016    0.0\n",
      "1925  Rhythmic Gymnastics  2020    0.0\n",
      "1990  Rhythmic Gymnastics  2024    0.0\n",
      "\n",
      "Prepared time series data for Rhythmic Gymnastics (drug):\n",
      " Year\n",
      "1896    0.0\n",
      "1900    0.0\n",
      "1904    0.0\n",
      "1906    0.0\n",
      "1908    0.0\n",
      "1912    0.0\n",
      "1920    0.0\n",
      "1924    0.0\n",
      "1928    0.0\n",
      "1932    0.0\n",
      "1936    0.0\n",
      "1948    0.0\n",
      "1952    0.0\n",
      "1956    0.0\n",
      "1960    0.0\n",
      "1964    0.0\n",
      "1968    0.0\n",
      "1972    0.0\n",
      "1976    0.0\n",
      "1980    0.0\n",
      "1984    0.0\n",
      "1988    0.0\n",
      "1992    0.0\n",
      "1996    0.0\n",
      "2000    0.0\n",
      "2004    0.0\n",
      "2008    0.0\n",
      "2012    0.0\n",
      "2016    0.0\n",
      "2020    0.0\n",
      "2024    0.0\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Roque (drug)\n",
      "Raw data for Roque (drug):\n",
      "       Sport  Year  Value\n",
      "41    Roque  1896    0.0\n",
      "106   Roque  1900    0.0\n",
      "171   Roque  1904    0.0\n",
      "236   Roque  1906    0.0\n",
      "301   Roque  1908    0.0\n",
      "366   Roque  1912    0.0\n",
      "431   Roque  1920    0.0\n",
      "496   Roque  1924    0.0\n",
      "561   Roque  1928    0.0\n",
      "626   Roque  1932    0.0\n",
      "691   Roque  1936    0.0\n",
      "756   Roque  1948    0.0\n",
      "821   Roque  1952    0.0\n",
      "886   Roque  1956    0.0\n",
      "951   Roque  1960    0.0\n",
      "1016  Roque  1964    0.0\n",
      "1081  Roque  1968    0.0\n",
      "1146  Roque  1972    0.0\n",
      "1211  Roque  1976    0.0\n",
      "1276  Roque  1980    0.0\n",
      "1341  Roque  1984    0.0\n",
      "1406  Roque  1988    0.0\n",
      "1471  Roque  1992    0.0\n",
      "1536  Roque  1996    0.0\n",
      "1601  Roque  2000    0.0\n",
      "1666  Roque  2004    0.0\n",
      "1731  Roque  2008    0.0\n",
      "1796  Roque  2012    0.0\n",
      "1861  Roque  2016    0.0\n",
      "1926  Roque  2020    0.0\n",
      "1991  Roque  2024    0.0\n",
      "\n",
      "Prepared time series data for Roque (drug):\n",
      " Year\n",
      "1896    0.0\n",
      "1900    0.0\n",
      "1904    0.0\n",
      "1906    0.0\n",
      "1908    0.0\n",
      "1912    0.0\n",
      "1920    0.0\n",
      "1924    0.0\n",
      "1928    0.0\n",
      "1932    0.0\n",
      "1936    0.0\n",
      "1948    0.0\n",
      "1952    0.0\n",
      "1956    0.0\n",
      "1960    0.0\n",
      "1964    0.0\n",
      "1968    0.0\n",
      "1972    0.0\n",
      "1976    0.0\n",
      "1980    0.0\n",
      "1984    0.0\n",
      "1988    0.0\n",
      "1992    0.0\n",
      "1996    0.0\n",
      "2000    0.0\n",
      "2004    0.0\n",
      "2008    0.0\n",
      "2012    0.0\n",
      "2016    0.0\n",
      "2020    0.0\n",
      "2024    0.0\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Rowing (drug)\n",
      "Raw data for Rowing (drug):\n",
      "        Sport  Year  Value\n",
      "42    Rowing  1896    0.0\n",
      "107   Rowing  1900    0.0\n",
      "172   Rowing  1904    0.0\n",
      "237   Rowing  1906    0.0\n",
      "302   Rowing  1908    0.0\n",
      "367   Rowing  1912    0.0\n",
      "432   Rowing  1920    0.0\n",
      "497   Rowing  1924    0.0\n",
      "562   Rowing  1928    0.0\n",
      "627   Rowing  1932    0.0\n",
      "692   Rowing  1936    0.0\n",
      "757   Rowing  1948    0.0\n",
      "822   Rowing  1952    0.0\n",
      "887   Rowing  1956    0.0\n",
      "952   Rowing  1960    0.0\n",
      "1017  Rowing  1964    0.0\n",
      "1082  Rowing  1968    0.0\n",
      "1147  Rowing  1972    0.0\n",
      "1212  Rowing  1976    0.0\n",
      "1277  Rowing  1980    0.0\n",
      "1342  Rowing  1984    0.0\n",
      "1407  Rowing  1988    0.0\n",
      "1472  Rowing  1992    0.0\n",
      "1537  Rowing  1996    0.0\n",
      "1602  Rowing  2000    1.0\n",
      "1667  Rowing  2004    1.0\n",
      "1732  Rowing  2008    0.0\n",
      "1797  Rowing  2012    1.0\n",
      "1862  Rowing  2016    1.0\n",
      "1927  Rowing  2020    0.0\n",
      "1992  Rowing  2024    0.0\n",
      "\n",
      "Prepared time series data for Rowing (drug):\n",
      " Year\n",
      "1896    0.0\n",
      "1900    0.0\n",
      "1904    0.0\n",
      "1906    0.0\n",
      "1908    0.0\n",
      "1912    0.0\n",
      "1920    0.0\n",
      "1924    0.0\n",
      "1928    0.0\n",
      "1932    0.0\n",
      "1936    0.0\n",
      "1948    0.0\n",
      "1952    0.0\n",
      "1956    0.0\n",
      "1960    0.0\n",
      "1964    0.0\n",
      "1968    0.0\n",
      "1972    0.0\n",
      "1976    0.0\n",
      "1980    0.0\n",
      "1984    0.0\n",
      "1988    0.0\n",
      "1992    0.0\n",
      "1996    0.0\n",
      "2000    1.0\n",
      "2004    1.0\n",
      "2008    0.0\n",
      "2012    1.0\n",
      "2016    1.0\n",
      "2020    0.0\n",
      "2024    0.0\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Rugby (drug)\n",
      "Raw data for Rugby (drug):\n",
      "       Sport  Year  Value\n",
      "43    Rugby  1896    0.0\n",
      "108   Rugby  1900    0.0\n",
      "173   Rugby  1904    0.0\n",
      "238   Rugby  1906    0.0\n",
      "303   Rugby  1908    0.0\n",
      "368   Rugby  1912    0.0\n",
      "433   Rugby  1920    0.0\n",
      "498   Rugby  1924    0.0\n",
      "563   Rugby  1928    0.0\n",
      "628   Rugby  1932    0.0\n",
      "693   Rugby  1936    0.0\n",
      "758   Rugby  1948    0.0\n",
      "823   Rugby  1952    0.0\n",
      "888   Rugby  1956    0.0\n",
      "953   Rugby  1960    0.0\n",
      "1018  Rugby  1964    0.0\n",
      "1083  Rugby  1968    0.0\n",
      "1148  Rugby  1972    0.0\n",
      "1213  Rugby  1976    0.0\n",
      "1278  Rugby  1980    0.0\n",
      "1343  Rugby  1984    0.0\n",
      "1408  Rugby  1988    0.0\n",
      "1473  Rugby  1992    0.0\n",
      "1538  Rugby  1996    0.0\n",
      "1603  Rugby  2000    0.0\n",
      "1668  Rugby  2004    0.0\n",
      "1733  Rugby  2008    0.0\n",
      "1798  Rugby  2012    0.0\n",
      "1863  Rugby  2016    0.0\n",
      "1928  Rugby  2020    0.0\n",
      "1993  Rugby  2024    0.0\n",
      "\n",
      "Prepared time series data for Rugby (drug):\n",
      " Year\n",
      "1896    0.0\n",
      "1900    0.0\n",
      "1904    0.0\n",
      "1906    0.0\n",
      "1908    0.0\n",
      "1912    0.0\n",
      "1920    0.0\n",
      "1924    0.0\n",
      "1928    0.0\n",
      "1932    0.0\n",
      "1936    0.0\n",
      "1948    0.0\n",
      "1952    0.0\n",
      "1956    0.0\n",
      "1960    0.0\n",
      "1964    0.0\n",
      "1968    0.0\n",
      "1972    0.0\n",
      "1976    0.0\n",
      "1980    0.0\n",
      "1984    0.0\n",
      "1988    0.0\n",
      "1992    0.0\n",
      "1996    0.0\n",
      "2000    0.0\n",
      "2004    0.0\n",
      "2008    0.0\n",
      "2012    0.0\n",
      "2016    0.0\n",
      "2020    0.0\n",
      "2024    0.0\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Rugby Sevens (drug)\n",
      "Raw data for Rugby Sevens (drug):\n",
      "              Sport  Year  Value\n",
      "44    Rugby Sevens  1896    0.0\n",
      "109   Rugby Sevens  1900    0.0\n",
      "174   Rugby Sevens  1904    0.0\n",
      "239   Rugby Sevens  1906    0.0\n",
      "304   Rugby Sevens  1908    0.0\n",
      "369   Rugby Sevens  1912    0.0\n",
      "434   Rugby Sevens  1920    0.0\n",
      "499   Rugby Sevens  1924    0.0\n",
      "564   Rugby Sevens  1928    0.0\n",
      "629   Rugby Sevens  1932    0.0\n",
      "694   Rugby Sevens  1936    0.0\n",
      "759   Rugby Sevens  1948    0.0\n",
      "824   Rugby Sevens  1952    0.0\n",
      "889   Rugby Sevens  1956    0.0\n",
      "954   Rugby Sevens  1960    0.0\n",
      "1019  Rugby Sevens  1964    0.0\n",
      "1084  Rugby Sevens  1968    0.0\n",
      "1149  Rugby Sevens  1972    0.0\n",
      "1214  Rugby Sevens  1976    0.0\n",
      "1279  Rugby Sevens  1980    0.0\n",
      "1344  Rugby Sevens  1984    0.0\n",
      "1409  Rugby Sevens  1988    0.0\n",
      "1474  Rugby Sevens  1992    0.0\n",
      "1539  Rugby Sevens  1996    0.0\n",
      "1604  Rugby Sevens  2000    0.0\n",
      "1669  Rugby Sevens  2004    0.0\n",
      "1734  Rugby Sevens  2008    0.0\n",
      "1799  Rugby Sevens  2012    0.0\n",
      "1864  Rugby Sevens  2016    0.0\n",
      "1929  Rugby Sevens  2020    0.0\n",
      "1994  Rugby Sevens  2024    0.0\n",
      "\n",
      "Prepared time series data for Rugby Sevens (drug):\n",
      " Year\n",
      "1896    0.0\n",
      "1900    0.0\n",
      "1904    0.0\n",
      "1906    0.0\n",
      "1908    0.0\n",
      "1912    0.0\n",
      "1920    0.0\n",
      "1924    0.0\n",
      "1928    0.0\n",
      "1932    0.0\n",
      "1936    0.0\n",
      "1948    0.0\n",
      "1952    0.0\n",
      "1956    0.0\n",
      "1960    0.0\n",
      "1964    0.0\n",
      "1968    0.0\n",
      "1972    0.0\n",
      "1976    0.0\n",
      "1980    0.0\n",
      "1984    0.0\n",
      "1988    0.0\n",
      "1992    0.0\n",
      "1996    0.0\n",
      "2000    0.0\n",
      "2004    0.0\n",
      "2008    0.0\n",
      "2012    0.0\n",
      "2016    0.0\n",
      "2020    0.0\n",
      "2024    0.0\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Sailing (drug)\n",
      "Raw data for Sailing (drug):\n",
      "         Sport  Year  Value\n",
      "45    Sailing  1896    0.0\n",
      "110   Sailing  1900    0.0\n",
      "175   Sailing  1904    0.0\n",
      "240   Sailing  1906    0.0\n",
      "305   Sailing  1908    0.0\n",
      "370   Sailing  1912    0.0\n",
      "435   Sailing  1920    0.0\n",
      "500   Sailing  1924    0.0\n",
      "565   Sailing  1928    0.0\n",
      "630   Sailing  1932    0.0\n",
      "695   Sailing  1936    0.0\n",
      "760   Sailing  1948    0.0\n",
      "825   Sailing  1952    0.0\n",
      "890   Sailing  1956    0.0\n",
      "955   Sailing  1960    0.0\n",
      "1020  Sailing  1964    0.0\n",
      "1085  Sailing  1968    0.0\n",
      "1150  Sailing  1972    0.0\n",
      "1215  Sailing  1976    1.0\n",
      "1280  Sailing  1980    0.0\n",
      "1345  Sailing  1984    0.0\n",
      "1410  Sailing  1988    0.0\n",
      "1475  Sailing  1992    0.0\n",
      "1540  Sailing  1996    0.0\n",
      "1605  Sailing  2000    0.0\n",
      "1670  Sailing  2004    0.0\n",
      "1735  Sailing  2008    0.0\n",
      "1800  Sailing  2012    0.0\n",
      "1865  Sailing  2016    0.0\n",
      "1930  Sailing  2020    0.0\n",
      "1995  Sailing  2024    0.0\n",
      "\n",
      "Prepared time series data for Sailing (drug):\n",
      " Year\n",
      "1896    0.0\n",
      "1900    0.0\n",
      "1904    0.0\n",
      "1906    0.0\n",
      "1908    0.0\n",
      "1912    0.0\n",
      "1920    0.0\n",
      "1924    0.0\n",
      "1928    0.0\n",
      "1932    0.0\n",
      "1936    0.0\n",
      "1948    0.0\n",
      "1952    0.0\n",
      "1956    0.0\n",
      "1960    0.0\n",
      "1964    0.0\n",
      "1968    0.0\n",
      "1972    0.0\n",
      "1976    1.0\n",
      "1980    0.0\n",
      "1984    0.0\n",
      "1988    0.0\n",
      "1992    0.0\n",
      "1996    0.0\n",
      "2000    0.0\n",
      "2004    0.0\n",
      "2008    0.0\n",
      "2012    0.0\n",
      "2016    0.0\n",
      "2020    0.0\n",
      "2024    0.0\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Shooting (drug)\n",
      "Raw data for Shooting (drug):\n",
      "          Sport  Year  Value\n",
      "46    Shooting  1896    0.0\n",
      "111   Shooting  1900    0.0\n",
      "176   Shooting  1904    0.0\n",
      "241   Shooting  1906    0.0\n",
      "306   Shooting  1908    0.0\n",
      "371   Shooting  1912    0.0\n",
      "436   Shooting  1920    0.0\n",
      "501   Shooting  1924    0.0\n",
      "566   Shooting  1928    0.0\n",
      "631   Shooting  1932    0.0\n",
      "696   Shooting  1936    0.0\n",
      "761   Shooting  1948    0.0\n",
      "826   Shooting  1952    0.0\n",
      "891   Shooting  1956    0.0\n",
      "956   Shooting  1960    0.0\n",
      "1021  Shooting  1964    0.0\n",
      "1086  Shooting  1968    0.0\n",
      "1151  Shooting  1972    0.0\n",
      "1216  Shooting  1976    1.0\n",
      "1281  Shooting  1980    0.0\n",
      "1346  Shooting  1984    0.0\n",
      "1411  Shooting  1988    0.0\n",
      "1476  Shooting  1992    0.0\n",
      "1541  Shooting  1996    0.0\n",
      "1606  Shooting  2000    0.0\n",
      "1671  Shooting  2004    0.0\n",
      "1736  Shooting  2008    1.0\n",
      "1801  Shooting  2012    0.0\n",
      "1866  Shooting  2016    0.0\n",
      "1931  Shooting  2020    0.0\n",
      "1996  Shooting  2024    0.0\n",
      "\n",
      "Prepared time series data for Shooting (drug):\n",
      " Year\n",
      "1896    0.0\n",
      "1900    0.0\n",
      "1904    0.0\n",
      "1906    0.0\n",
      "1908    0.0\n",
      "1912    0.0\n",
      "1920    0.0\n",
      "1924    0.0\n",
      "1928    0.0\n",
      "1932    0.0\n",
      "1936    0.0\n",
      "1948    0.0\n",
      "1952    0.0\n",
      "1956    0.0\n",
      "1960    0.0\n",
      "1964    0.0\n",
      "1968    0.0\n",
      "1972    0.0\n",
      "1976    1.0\n",
      "1980    0.0\n",
      "1984    0.0\n",
      "1988    0.0\n",
      "1992    0.0\n",
      "1996    0.0\n",
      "2000    0.0\n",
      "2004    0.0\n",
      "2008    1.0\n",
      "2012    0.0\n",
      "2016    0.0\n",
      "2020    0.0\n",
      "2024    0.0\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Short Track Speed Skating (drug)\n",
      "Raw data for Short Track Speed Skating (drug):\n",
      "                           Sport  Year  Value\n",
      "47    Short Track Speed Skating  1896    0.0\n",
      "112   Short Track Speed Skating  1900    0.0\n",
      "177   Short Track Speed Skating  1904    0.0\n",
      "242   Short Track Speed Skating  1906    0.0\n",
      "307   Short Track Speed Skating  1908    0.0\n",
      "372   Short Track Speed Skating  1912    0.0\n",
      "437   Short Track Speed Skating  1920    0.0\n",
      "502   Short Track Speed Skating  1924    0.0\n",
      "567   Short Track Speed Skating  1928    0.0\n",
      "632   Short Track Speed Skating  1932    0.0\n",
      "697   Short Track Speed Skating  1936    0.0\n",
      "762   Short Track Speed Skating  1948    0.0\n",
      "827   Short Track Speed Skating  1952    0.0\n",
      "892   Short Track Speed Skating  1956    0.0\n",
      "957   Short Track Speed Skating  1960    0.0\n",
      "1022  Short Track Speed Skating  1964    0.0\n",
      "1087  Short Track Speed Skating  1968    0.0\n",
      "1152  Short Track Speed Skating  1972    0.0\n",
      "1217  Short Track Speed Skating  1976    0.0\n",
      "1282  Short Track Speed Skating  1980    0.0\n",
      "1347  Short Track Speed Skating  1984    0.0\n",
      "1412  Short Track Speed Skating  1988    0.0\n",
      "1477  Short Track Speed Skating  1992    0.0\n",
      "1542  Short Track Speed Skating  1996    0.0\n",
      "1607  Short Track Speed Skating  2000    0.0\n",
      "1672  Short Track Speed Skating  2004    0.0\n",
      "1737  Short Track Speed Skating  2008    0.0\n",
      "1802  Short Track Speed Skating  2012    0.0\n",
      "1867  Short Track Speed Skating  2016    0.0\n",
      "1932  Short Track Speed Skating  2020    0.0\n",
      "1997  Short Track Speed Skating  2024    0.0\n",
      "\n",
      "Prepared time series data for Short Track Speed Skating (drug):\n",
      " Year\n",
      "1896    0.0\n",
      "1900    0.0\n",
      "1904    0.0\n",
      "1906    0.0\n",
      "1908    0.0\n",
      "1912    0.0\n",
      "1920    0.0\n",
      "1924    0.0\n",
      "1928    0.0\n",
      "1932    0.0\n",
      "1936    0.0\n",
      "1948    0.0\n",
      "1952    0.0\n",
      "1956    0.0\n",
      "1960    0.0\n",
      "1964    0.0\n",
      "1968    0.0\n",
      "1972    0.0\n",
      "1976    0.0\n",
      "1980    0.0\n",
      "1984    0.0\n",
      "1988    0.0\n",
      "1992    0.0\n",
      "1996    0.0\n",
      "2000    0.0\n",
      "2004    0.0\n",
      "2008    0.0\n",
      "2012    0.0\n",
      "2016    0.0\n",
      "2020    0.0\n",
      "2024    0.0\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Skeleton (drug)\n",
      "Raw data for Skeleton (drug):\n",
      "          Sport  Year  Value\n",
      "48    Skeleton  1896    0.0\n",
      "113   Skeleton  1900    0.0\n",
      "178   Skeleton  1904    0.0\n",
      "243   Skeleton  1906    0.0\n",
      "308   Skeleton  1908    0.0\n",
      "373   Skeleton  1912    0.0\n",
      "438   Skeleton  1920    0.0\n",
      "503   Skeleton  1924    0.0\n",
      "568   Skeleton  1928    0.0\n",
      "633   Skeleton  1932    0.0\n",
      "698   Skeleton  1936    0.0\n",
      "763   Skeleton  1948    0.0\n",
      "828   Skeleton  1952    0.0\n",
      "893   Skeleton  1956    0.0\n",
      "958   Skeleton  1960    0.0\n",
      "1023  Skeleton  1964    0.0\n",
      "1088  Skeleton  1968    0.0\n",
      "1153  Skeleton  1972    0.0\n",
      "1218  Skeleton  1976    0.0\n",
      "1283  Skeleton  1980    0.0\n",
      "1348  Skeleton  1984    0.0\n",
      "1413  Skeleton  1988    0.0\n",
      "1478  Skeleton  1992    0.0\n",
      "1543  Skeleton  1996    0.0\n",
      "1608  Skeleton  2000    0.0\n",
      "1673  Skeleton  2004    0.0\n",
      "1738  Skeleton  2008    0.0\n",
      "1803  Skeleton  2012    0.0\n",
      "1868  Skeleton  2016    0.0\n",
      "1933  Skeleton  2020    0.0\n",
      "1998  Skeleton  2024    0.0\n",
      "\n",
      "Prepared time series data for Skeleton (drug):\n",
      " Year\n",
      "1896    0.0\n",
      "1900    0.0\n",
      "1904    0.0\n",
      "1906    0.0\n",
      "1908    0.0\n",
      "1912    0.0\n",
      "1920    0.0\n",
      "1924    0.0\n",
      "1928    0.0\n",
      "1932    0.0\n",
      "1936    0.0\n",
      "1948    0.0\n",
      "1952    0.0\n",
      "1956    0.0\n",
      "1960    0.0\n",
      "1964    0.0\n",
      "1968    0.0\n",
      "1972    0.0\n",
      "1976    0.0\n",
      "1980    0.0\n",
      "1984    0.0\n",
      "1988    0.0\n",
      "1992    0.0\n",
      "1996    0.0\n",
      "2000    0.0\n",
      "2004    0.0\n",
      "2008    0.0\n",
      "2012    0.0\n",
      "2016    0.0\n",
      "2020    0.0\n",
      "2024    0.0\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Ski Jumping (drug)\n",
      "Raw data for Ski Jumping (drug):\n",
      "             Sport  Year  Value\n",
      "49    Ski Jumping  1896    0.0\n",
      "114   Ski Jumping  1900    0.0\n",
      "179   Ski Jumping  1904    0.0\n",
      "244   Ski Jumping  1906    0.0\n",
      "309   Ski Jumping  1908    0.0\n",
      "374   Ski Jumping  1912    0.0\n",
      "439   Ski Jumping  1920    0.0\n",
      "504   Ski Jumping  1924    0.0\n",
      "569   Ski Jumping  1928    0.0\n",
      "634   Ski Jumping  1932    0.0\n",
      "699   Ski Jumping  1936    0.0\n",
      "764   Ski Jumping  1948    0.0\n",
      "829   Ski Jumping  1952    0.0\n",
      "894   Ski Jumping  1956    0.0\n",
      "959   Ski Jumping  1960    0.0\n",
      "1024  Ski Jumping  1964    0.0\n",
      "1089  Ski Jumping  1968    0.0\n",
      "1154  Ski Jumping  1972    0.0\n",
      "1219  Ski Jumping  1976    0.0\n",
      "1284  Ski Jumping  1980    0.0\n",
      "1349  Ski Jumping  1984    0.0\n",
      "1414  Ski Jumping  1988    0.0\n",
      "1479  Ski Jumping  1992    0.0\n",
      "1544  Ski Jumping  1996    0.0\n",
      "1609  Ski Jumping  2000    0.0\n",
      "1674  Ski Jumping  2004    0.0\n",
      "1739  Ski Jumping  2008    0.0\n",
      "1804  Ski Jumping  2012    0.0\n",
      "1869  Ski Jumping  2016    0.0\n",
      "1934  Ski Jumping  2020    0.0\n",
      "1999  Ski Jumping  2024    0.0\n",
      "\n",
      "Prepared time series data for Ski Jumping (drug):\n",
      " Year\n",
      "1896    0.0\n",
      "1900    0.0\n",
      "1904    0.0\n",
      "1906    0.0\n",
      "1908    0.0\n",
      "1912    0.0\n",
      "1920    0.0\n",
      "1924    0.0\n",
      "1928    0.0\n",
      "1932    0.0\n",
      "1936    0.0\n",
      "1948    0.0\n",
      "1952    0.0\n",
      "1956    0.0\n",
      "1960    0.0\n",
      "1964    0.0\n",
      "1968    0.0\n",
      "1972    0.0\n",
      "1976    0.0\n",
      "1980    0.0\n",
      "1984    0.0\n",
      "1988    0.0\n",
      "1992    0.0\n",
      "1996    0.0\n",
      "2000    0.0\n",
      "2004    0.0\n",
      "2008    0.0\n",
      "2012    0.0\n",
      "2016    0.0\n",
      "2020    0.0\n",
      "2024    0.0\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Snowboarding (drug)\n",
      "Raw data for Snowboarding (drug):\n",
      "              Sport  Year  Value\n",
      "50    Snowboarding  1896    0.0\n",
      "115   Snowboarding  1900    0.0\n",
      "180   Snowboarding  1904    0.0\n",
      "245   Snowboarding  1906    0.0\n",
      "310   Snowboarding  1908    0.0\n",
      "375   Snowboarding  1912    0.0\n",
      "440   Snowboarding  1920    0.0\n",
      "505   Snowboarding  1924    0.0\n",
      "570   Snowboarding  1928    0.0\n",
      "635   Snowboarding  1932    0.0\n",
      "700   Snowboarding  1936    0.0\n",
      "765   Snowboarding  1948    0.0\n",
      "830   Snowboarding  1952    0.0\n",
      "895   Snowboarding  1956    0.0\n",
      "960   Snowboarding  1960    0.0\n",
      "1025  Snowboarding  1964    0.0\n",
      "1090  Snowboarding  1968    0.0\n",
      "1155  Snowboarding  1972    0.0\n",
      "1220  Snowboarding  1976    0.0\n",
      "1285  Snowboarding  1980    0.0\n",
      "1350  Snowboarding  1984    0.0\n",
      "1415  Snowboarding  1988    0.0\n",
      "1480  Snowboarding  1992    0.0\n",
      "1545  Snowboarding  1996    0.0\n",
      "1610  Snowboarding  2000    0.0\n",
      "1675  Snowboarding  2004    0.0\n",
      "1740  Snowboarding  2008    0.0\n",
      "1805  Snowboarding  2012    0.0\n",
      "1870  Snowboarding  2016    0.0\n",
      "1935  Snowboarding  2020    0.0\n",
      "2000  Snowboarding  2024    0.0\n",
      "\n",
      "Prepared time series data for Snowboarding (drug):\n",
      " Year\n",
      "1896    0.0\n",
      "1900    0.0\n",
      "1904    0.0\n",
      "1906    0.0\n",
      "1908    0.0\n",
      "1912    0.0\n",
      "1920    0.0\n",
      "1924    0.0\n",
      "1928    0.0\n",
      "1932    0.0\n",
      "1936    0.0\n",
      "1948    0.0\n",
      "1952    0.0\n",
      "1956    0.0\n",
      "1960    0.0\n",
      "1964    0.0\n",
      "1968    0.0\n",
      "1972    0.0\n",
      "1976    0.0\n",
      "1980    0.0\n",
      "1984    0.0\n",
      "1988    0.0\n",
      "1992    0.0\n",
      "1996    0.0\n",
      "2000    0.0\n",
      "2004    0.0\n",
      "2008    0.0\n",
      "2012    0.0\n",
      "2016    0.0\n",
      "2020    0.0\n",
      "2024    0.0\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Softball (drug)\n",
      "Raw data for Softball (drug):\n",
      "          Sport  Year  Value\n",
      "51    Softball  1896    0.0\n",
      "116   Softball  1900    0.0\n",
      "181   Softball  1904    0.0\n",
      "246   Softball  1906    0.0\n",
      "311   Softball  1908    0.0\n",
      "376   Softball  1912    0.0\n",
      "441   Softball  1920    0.0\n",
      "506   Softball  1924    0.0\n",
      "571   Softball  1928    0.0\n",
      "636   Softball  1932    0.0\n",
      "701   Softball  1936    0.0\n",
      "766   Softball  1948    0.0\n",
      "831   Softball  1952    0.0\n",
      "896   Softball  1956    0.0\n",
      "961   Softball  1960    0.0\n",
      "1026  Softball  1964    0.0\n",
      "1091  Softball  1968    0.0\n",
      "1156  Softball  1972    0.0\n",
      "1221  Softball  1976    0.0\n",
      "1286  Softball  1980    0.0\n",
      "1351  Softball  1984    0.0\n",
      "1416  Softball  1988    0.0\n",
      "1481  Softball  1992    0.0\n",
      "1546  Softball  1996    0.0\n",
      "1611  Softball  2000    0.0\n",
      "1676  Softball  2004    0.0\n",
      "1741  Softball  2008    0.0\n",
      "1806  Softball  2012    0.0\n",
      "1871  Softball  2016    0.0\n",
      "1936  Softball  2020    0.0\n",
      "2001  Softball  2024    0.0\n",
      "\n",
      "Prepared time series data for Softball (drug):\n",
      " Year\n",
      "1896    0.0\n",
      "1900    0.0\n",
      "1904    0.0\n",
      "1906    0.0\n",
      "1908    0.0\n",
      "1912    0.0\n",
      "1920    0.0\n",
      "1924    0.0\n",
      "1928    0.0\n",
      "1932    0.0\n",
      "1936    0.0\n",
      "1948    0.0\n",
      "1952    0.0\n",
      "1956    0.0\n",
      "1960    0.0\n",
      "1964    0.0\n",
      "1968    0.0\n",
      "1972    0.0\n",
      "1976    0.0\n",
      "1980    0.0\n",
      "1984    0.0\n",
      "1988    0.0\n",
      "1992    0.0\n",
      "1996    0.0\n",
      "2000    0.0\n",
      "2004    0.0\n",
      "2008    0.0\n",
      "2012    0.0\n",
      "2016    0.0\n",
      "2020    0.0\n",
      "2024    0.0\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Speed Skating (drug)\n",
      "Raw data for Speed Skating (drug):\n",
      "               Sport  Year  Value\n",
      "52    Speed Skating  1896    0.0\n",
      "117   Speed Skating  1900    0.0\n",
      "182   Speed Skating  1904    0.0\n",
      "247   Speed Skating  1906    0.0\n",
      "312   Speed Skating  1908    0.0\n",
      "377   Speed Skating  1912    0.0\n",
      "442   Speed Skating  1920    0.0\n",
      "507   Speed Skating  1924    0.0\n",
      "572   Speed Skating  1928    0.0\n",
      "637   Speed Skating  1932    0.0\n",
      "702   Speed Skating  1936    0.0\n",
      "767   Speed Skating  1948    0.0\n",
      "832   Speed Skating  1952    0.0\n",
      "897   Speed Skating  1956    0.0\n",
      "962   Speed Skating  1960    0.0\n",
      "1027  Speed Skating  1964    0.0\n",
      "1092  Speed Skating  1968    0.0\n",
      "1157  Speed Skating  1972    0.0\n",
      "1222  Speed Skating  1976    0.0\n",
      "1287  Speed Skating  1980    0.0\n",
      "1352  Speed Skating  1984    0.0\n",
      "1417  Speed Skating  1988    0.0\n",
      "1482  Speed Skating  1992    0.0\n",
      "1547  Speed Skating  1996    0.0\n",
      "1612  Speed Skating  2000    0.0\n",
      "1677  Speed Skating  2004    0.0\n",
      "1742  Speed Skating  2008    0.0\n",
      "1807  Speed Skating  2012    0.0\n",
      "1872  Speed Skating  2016    0.0\n",
      "1937  Speed Skating  2020    0.0\n",
      "2002  Speed Skating  2024    0.0\n",
      "\n",
      "Prepared time series data for Speed Skating (drug):\n",
      " Year\n",
      "1896    0.0\n",
      "1900    0.0\n",
      "1904    0.0\n",
      "1906    0.0\n",
      "1908    0.0\n",
      "1912    0.0\n",
      "1920    0.0\n",
      "1924    0.0\n",
      "1928    0.0\n",
      "1932    0.0\n",
      "1936    0.0\n",
      "1948    0.0\n",
      "1952    0.0\n",
      "1956    0.0\n",
      "1960    0.0\n",
      "1964    0.0\n",
      "1968    0.0\n",
      "1972    0.0\n",
      "1976    0.0\n",
      "1980    0.0\n",
      "1984    0.0\n",
      "1988    0.0\n",
      "1992    0.0\n",
      "1996    0.0\n",
      "2000    0.0\n",
      "2004    0.0\n",
      "2008    0.0\n",
      "2012    0.0\n",
      "2016    0.0\n",
      "2020    0.0\n",
      "2024    0.0\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Swimming (drug)\n",
      "Raw data for Swimming (drug):\n",
      "          Sport  Year  Value\n",
      "53    Swimming  1896    0.0\n",
      "118   Swimming  1900    0.0\n",
      "183   Swimming  1904    0.0\n",
      "248   Swimming  1906    0.0\n",
      "313   Swimming  1908    0.0\n",
      "378   Swimming  1912    0.0\n",
      "443   Swimming  1920    0.0\n",
      "508   Swimming  1924    0.0\n",
      "573   Swimming  1928    0.0\n",
      "638   Swimming  1932    0.0\n",
      "703   Swimming  1936    0.0\n",
      "768   Swimming  1948    0.0\n",
      "833   Swimming  1952    0.0\n",
      "898   Swimming  1956    0.0\n",
      "963   Swimming  1960    0.0\n",
      "1028  Swimming  1964    0.0\n",
      "1093  Swimming  1968    0.0\n",
      "1158  Swimming  1972    1.0\n",
      "1223  Swimming  1976    0.0\n",
      "1288  Swimming  1980    0.0\n",
      "1353  Swimming  1984    0.0\n",
      "1418  Swimming  1988    0.0\n",
      "1483  Swimming  1992    0.0\n",
      "1548  Swimming  1996    0.0\n",
      "1613  Swimming  2000    0.0\n",
      "1678  Swimming  2004    0.0\n",
      "1743  Swimming  2008    0.0\n",
      "1808  Swimming  2012    1.0\n",
      "1873  Swimming  2016    2.0\n",
      "1938  Swimming  2020    0.0\n",
      "2003  Swimming  2024    1.0\n",
      "\n",
      "Prepared time series data for Swimming (drug):\n",
      " Year\n",
      "1896    0.0\n",
      "1900    0.0\n",
      "1904    0.0\n",
      "1906    0.0\n",
      "1908    0.0\n",
      "1912    0.0\n",
      "1920    0.0\n",
      "1924    0.0\n",
      "1928    0.0\n",
      "1932    0.0\n",
      "1936    0.0\n",
      "1948    0.0\n",
      "1952    0.0\n",
      "1956    0.0\n",
      "1960    0.0\n",
      "1964    0.0\n",
      "1968    0.0\n",
      "1972    1.0\n",
      "1976    0.0\n",
      "1980    0.0\n",
      "1984    0.0\n",
      "1988    0.0\n",
      "1992    0.0\n",
      "1996    0.0\n",
      "2000    0.0\n",
      "2004    0.0\n",
      "2008    0.0\n",
      "2012    1.0\n",
      "2016    2.0\n",
      "2020    0.0\n",
      "2024    1.0\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Synchronized Swimming (drug)\n",
      "Raw data for Synchronized Swimming (drug):\n",
      "                       Sport  Year  Value\n",
      "54    Synchronized Swimming  1896    0.0\n",
      "119   Synchronized Swimming  1900    0.0\n",
      "184   Synchronized Swimming  1904    0.0\n",
      "249   Synchronized Swimming  1906    0.0\n",
      "314   Synchronized Swimming  1908    0.0\n",
      "379   Synchronized Swimming  1912    0.0\n",
      "444   Synchronized Swimming  1920    0.0\n",
      "509   Synchronized Swimming  1924    0.0\n",
      "574   Synchronized Swimming  1928    0.0\n",
      "639   Synchronized Swimming  1932    0.0\n",
      "704   Synchronized Swimming  1936    0.0\n",
      "769   Synchronized Swimming  1948    0.0\n",
      "834   Synchronized Swimming  1952    0.0\n",
      "899   Synchronized Swimming  1956    0.0\n",
      "964   Synchronized Swimming  1960    0.0\n",
      "1029  Synchronized Swimming  1964    0.0\n",
      "1094  Synchronized Swimming  1968    0.0\n",
      "1159  Synchronized Swimming  1972    0.0\n",
      "1224  Synchronized Swimming  1976    0.0\n",
      "1289  Synchronized Swimming  1980    0.0\n",
      "1354  Synchronized Swimming  1984    0.0\n",
      "1419  Synchronized Swimming  1988    0.0\n",
      "1484  Synchronized Swimming  1992    0.0\n",
      "1549  Synchronized Swimming  1996    0.0\n",
      "1614  Synchronized Swimming  2000    0.0\n",
      "1679  Synchronized Swimming  2004    0.0\n",
      "1744  Synchronized Swimming  2008    0.0\n",
      "1809  Synchronized Swimming  2012    0.0\n",
      "1874  Synchronized Swimming  2016    0.0\n",
      "1939  Synchronized Swimming  2020    0.0\n",
      "2004  Synchronized Swimming  2024    0.0\n",
      "\n",
      "Prepared time series data for Synchronized Swimming (drug):\n",
      " Year\n",
      "1896    0.0\n",
      "1900    0.0\n",
      "1904    0.0\n",
      "1906    0.0\n",
      "1908    0.0\n",
      "1912    0.0\n",
      "1920    0.0\n",
      "1924    0.0\n",
      "1928    0.0\n",
      "1932    0.0\n",
      "1936    0.0\n",
      "1948    0.0\n",
      "1952    0.0\n",
      "1956    0.0\n",
      "1960    0.0\n",
      "1964    0.0\n",
      "1968    0.0\n",
      "1972    0.0\n",
      "1976    0.0\n",
      "1980    0.0\n",
      "1984    0.0\n",
      "1988    0.0\n",
      "1992    0.0\n",
      "1996    0.0\n",
      "2000    0.0\n",
      "2004    0.0\n",
      "2008    0.0\n",
      "2012    0.0\n",
      "2016    0.0\n",
      "2020    0.0\n",
      "2024    0.0\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Table Tennis (drug)\n",
      "Raw data for Table Tennis (drug):\n",
      "              Sport  Year  Value\n",
      "55    Table Tennis  1896    0.0\n",
      "120   Table Tennis  1900    0.0\n",
      "185   Table Tennis  1904    0.0\n",
      "250   Table Tennis  1906    0.0\n",
      "315   Table Tennis  1908    0.0\n",
      "380   Table Tennis  1912    0.0\n",
      "445   Table Tennis  1920    0.0\n",
      "510   Table Tennis  1924    0.0\n",
      "575   Table Tennis  1928    0.0\n",
      "640   Table Tennis  1932    0.0\n",
      "705   Table Tennis  1936    0.0\n",
      "770   Table Tennis  1948    0.0\n",
      "835   Table Tennis  1952    0.0\n",
      "900   Table Tennis  1956    0.0\n",
      "965   Table Tennis  1960    0.0\n",
      "1030  Table Tennis  1964    0.0\n",
      "1095  Table Tennis  1968    0.0\n",
      "1160  Table Tennis  1972    0.0\n",
      "1225  Table Tennis  1976    0.0\n",
      "1290  Table Tennis  1980    0.0\n",
      "1355  Table Tennis  1984    0.0\n",
      "1420  Table Tennis  1988    0.0\n",
      "1485  Table Tennis  1992    0.0\n",
      "1550  Table Tennis  1996    0.0\n",
      "1615  Table Tennis  2000    0.0\n",
      "1680  Table Tennis  2004    0.0\n",
      "1745  Table Tennis  2008    0.0\n",
      "1810  Table Tennis  2012    0.0\n",
      "1875  Table Tennis  2016    0.0\n",
      "1940  Table Tennis  2020    0.0\n",
      "2005  Table Tennis  2024    0.0\n",
      "\n",
      "Prepared time series data for Table Tennis (drug):\n",
      " Year\n",
      "1896    0.0\n",
      "1900    0.0\n",
      "1904    0.0\n",
      "1906    0.0\n",
      "1908    0.0\n",
      "1912    0.0\n",
      "1920    0.0\n",
      "1924    0.0\n",
      "1928    0.0\n",
      "1932    0.0\n",
      "1936    0.0\n",
      "1948    0.0\n",
      "1952    0.0\n",
      "1956    0.0\n",
      "1960    0.0\n",
      "1964    0.0\n",
      "1968    0.0\n",
      "1972    0.0\n",
      "1976    0.0\n",
      "1980    0.0\n",
      "1984    0.0\n",
      "1988    0.0\n",
      "1992    0.0\n",
      "1996    0.0\n",
      "2000    0.0\n",
      "2004    0.0\n",
      "2008    0.0\n",
      "2012    0.0\n",
      "2016    0.0\n",
      "2020    0.0\n",
      "2024    0.0\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Taekwondo (drug)\n",
      "Raw data for Taekwondo (drug):\n",
      "           Sport  Year  Value\n",
      "56    Taekwondo  1896    0.0\n",
      "121   Taekwondo  1900    0.0\n",
      "186   Taekwondo  1904    0.0\n",
      "251   Taekwondo  1906    0.0\n",
      "316   Taekwondo  1908    0.0\n",
      "381   Taekwondo  1912    0.0\n",
      "446   Taekwondo  1920    0.0\n",
      "511   Taekwondo  1924    0.0\n",
      "576   Taekwondo  1928    0.0\n",
      "641   Taekwondo  1932    0.0\n",
      "706   Taekwondo  1936    0.0\n",
      "771   Taekwondo  1948    0.0\n",
      "836   Taekwondo  1952    0.0\n",
      "901   Taekwondo  1956    0.0\n",
      "966   Taekwondo  1960    0.0\n",
      "1031  Taekwondo  1964    0.0\n",
      "1096  Taekwondo  1968    0.0\n",
      "1161  Taekwondo  1972    0.0\n",
      "1226  Taekwondo  1976    0.0\n",
      "1291  Taekwondo  1980    0.0\n",
      "1356  Taekwondo  1984    0.0\n",
      "1421  Taekwondo  1988    0.0\n",
      "1486  Taekwondo  1992    0.0\n",
      "1551  Taekwondo  1996    0.0\n",
      "1616  Taekwondo  2000    0.0\n",
      "1681  Taekwondo  2004    0.0\n",
      "1746  Taekwondo  2008    0.0\n",
      "1811  Taekwondo  2012    0.0\n",
      "1876  Taekwondo  2016    0.0\n",
      "1941  Taekwondo  2020    0.0\n",
      "2006  Taekwondo  2024    0.0\n",
      "\n",
      "Prepared time series data for Taekwondo (drug):\n",
      " Year\n",
      "1896    0.0\n",
      "1900    0.0\n",
      "1904    0.0\n",
      "1906    0.0\n",
      "1908    0.0\n",
      "1912    0.0\n",
      "1920    0.0\n",
      "1924    0.0\n",
      "1928    0.0\n",
      "1932    0.0\n",
      "1936    0.0\n",
      "1948    0.0\n",
      "1952    0.0\n",
      "1956    0.0\n",
      "1960    0.0\n",
      "1964    0.0\n",
      "1968    0.0\n",
      "1972    0.0\n",
      "1976    0.0\n",
      "1980    0.0\n",
      "1984    0.0\n",
      "1988    0.0\n",
      "1992    0.0\n",
      "1996    0.0\n",
      "2000    0.0\n",
      "2004    0.0\n",
      "2008    0.0\n",
      "2012    0.0\n",
      "2016    0.0\n",
      "2020    0.0\n",
      "2024    0.0\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Tennis (drug)\n",
      "Raw data for Tennis (drug):\n",
      "        Sport  Year  Value\n",
      "57    Tennis  1896    0.0\n",
      "122   Tennis  1900    0.0\n",
      "187   Tennis  1904    0.0\n",
      "252   Tennis  1906    0.0\n",
      "317   Tennis  1908    0.0\n",
      "382   Tennis  1912    0.0\n",
      "447   Tennis  1920    0.0\n",
      "512   Tennis  1924    0.0\n",
      "577   Tennis  1928    0.0\n",
      "642   Tennis  1932    0.0\n",
      "707   Tennis  1936    0.0\n",
      "772   Tennis  1948    0.0\n",
      "837   Tennis  1952    0.0\n",
      "902   Tennis  1956    0.0\n",
      "967   Tennis  1960    0.0\n",
      "1032  Tennis  1964    0.0\n",
      "1097  Tennis  1968    0.0\n",
      "1162  Tennis  1972    0.0\n",
      "1227  Tennis  1976    0.0\n",
      "1292  Tennis  1980    0.0\n",
      "1357  Tennis  1984    0.0\n",
      "1422  Tennis  1988    0.0\n",
      "1487  Tennis  1992    0.0\n",
      "1552  Tennis  1996    0.0\n",
      "1617  Tennis  2000    0.0\n",
      "1682  Tennis  2004    0.0\n",
      "1747  Tennis  2008    0.0\n",
      "1812  Tennis  2012    0.0\n",
      "1877  Tennis  2016    0.0\n",
      "1942  Tennis  2020    0.0\n",
      "2007  Tennis  2024    0.0\n",
      "\n",
      "Prepared time series data for Tennis (drug):\n",
      " Year\n",
      "1896    0.0\n",
      "1900    0.0\n",
      "1904    0.0\n",
      "1906    0.0\n",
      "1908    0.0\n",
      "1912    0.0\n",
      "1920    0.0\n",
      "1924    0.0\n",
      "1928    0.0\n",
      "1932    0.0\n",
      "1936    0.0\n",
      "1948    0.0\n",
      "1952    0.0\n",
      "1956    0.0\n",
      "1960    0.0\n",
      "1964    0.0\n",
      "1968    0.0\n",
      "1972    0.0\n",
      "1976    0.0\n",
      "1980    0.0\n",
      "1984    0.0\n",
      "1988    0.0\n",
      "1992    0.0\n",
      "1996    0.0\n",
      "2000    0.0\n",
      "2004    0.0\n",
      "2008    0.0\n",
      "2012    0.0\n",
      "2016    0.0\n",
      "2020    0.0\n",
      "2024    0.0\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Trampolining (drug)\n",
      "Raw data for Trampolining (drug):\n",
      "              Sport  Year  Value\n",
      "58    Trampolining  1896    0.0\n",
      "123   Trampolining  1900    0.0\n",
      "188   Trampolining  1904    0.0\n",
      "253   Trampolining  1906    0.0\n",
      "318   Trampolining  1908    0.0\n",
      "383   Trampolining  1912    0.0\n",
      "448   Trampolining  1920    0.0\n",
      "513   Trampolining  1924    0.0\n",
      "578   Trampolining  1928    0.0\n",
      "643   Trampolining  1932    0.0\n",
      "708   Trampolining  1936    0.0\n",
      "773   Trampolining  1948    0.0\n",
      "838   Trampolining  1952    0.0\n",
      "903   Trampolining  1956    0.0\n",
      "968   Trampolining  1960    0.0\n",
      "1033  Trampolining  1964    0.0\n",
      "1098  Trampolining  1968    0.0\n",
      "1163  Trampolining  1972    0.0\n",
      "1228  Trampolining  1976    0.0\n",
      "1293  Trampolining  1980    0.0\n",
      "1358  Trampolining  1984    0.0\n",
      "1423  Trampolining  1988    0.0\n",
      "1488  Trampolining  1992    0.0\n",
      "1553  Trampolining  1996    0.0\n",
      "1618  Trampolining  2000    0.0\n",
      "1683  Trampolining  2004    0.0\n",
      "1748  Trampolining  2008    0.0\n",
      "1813  Trampolining  2012    0.0\n",
      "1878  Trampolining  2016    0.0\n",
      "1943  Trampolining  2020    0.0\n",
      "2008  Trampolining  2024    0.0\n",
      "\n",
      "Prepared time series data for Trampolining (drug):\n",
      " Year\n",
      "1896    0.0\n",
      "1900    0.0\n",
      "1904    0.0\n",
      "1906    0.0\n",
      "1908    0.0\n",
      "1912    0.0\n",
      "1920    0.0\n",
      "1924    0.0\n",
      "1928    0.0\n",
      "1932    0.0\n",
      "1936    0.0\n",
      "1948    0.0\n",
      "1952    0.0\n",
      "1956    0.0\n",
      "1960    0.0\n",
      "1964    0.0\n",
      "1968    0.0\n",
      "1972    0.0\n",
      "1976    0.0\n",
      "1980    0.0\n",
      "1984    0.0\n",
      "1988    0.0\n",
      "1992    0.0\n",
      "1996    0.0\n",
      "2000    0.0\n",
      "2004    0.0\n",
      "2008    0.0\n",
      "2012    0.0\n",
      "2016    0.0\n",
      "2020    0.0\n",
      "2024    0.0\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Triathlon (drug)\n",
      "Raw data for Triathlon (drug):\n",
      "           Sport  Year  Value\n",
      "59    Triathlon  1896    0.0\n",
      "124   Triathlon  1900    0.0\n",
      "189   Triathlon  1904    0.0\n",
      "254   Triathlon  1906    0.0\n",
      "319   Triathlon  1908    0.0\n",
      "384   Triathlon  1912    0.0\n",
      "449   Triathlon  1920    0.0\n",
      "514   Triathlon  1924    0.0\n",
      "579   Triathlon  1928    0.0\n",
      "644   Triathlon  1932    0.0\n",
      "709   Triathlon  1936    0.0\n",
      "774   Triathlon  1948    0.0\n",
      "839   Triathlon  1952    0.0\n",
      "904   Triathlon  1956    0.0\n",
      "969   Triathlon  1960    0.0\n",
      "1034  Triathlon  1964    0.0\n",
      "1099  Triathlon  1968    0.0\n",
      "1164  Triathlon  1972    0.0\n",
      "1229  Triathlon  1976    0.0\n",
      "1294  Triathlon  1980    0.0\n",
      "1359  Triathlon  1984    0.0\n",
      "1424  Triathlon  1988    0.0\n",
      "1489  Triathlon  1992    0.0\n",
      "1554  Triathlon  1996    0.0\n",
      "1619  Triathlon  2000    0.0\n",
      "1684  Triathlon  2004    0.0\n",
      "1749  Triathlon  2008    0.0\n",
      "1814  Triathlon  2012    0.0\n",
      "1879  Triathlon  2016    0.0\n",
      "1944  Triathlon  2020    2.0\n",
      "2009  Triathlon  2024    0.0\n",
      "\n",
      "Prepared time series data for Triathlon (drug):\n",
      " Year\n",
      "1896    0.0\n",
      "1900    0.0\n",
      "1904    0.0\n",
      "1906    0.0\n",
      "1908    0.0\n",
      "1912    0.0\n",
      "1920    0.0\n",
      "1924    0.0\n",
      "1928    0.0\n",
      "1932    0.0\n",
      "1936    0.0\n",
      "1948    0.0\n",
      "1952    0.0\n",
      "1956    0.0\n",
      "1960    0.0\n",
      "1964    0.0\n",
      "1968    0.0\n",
      "1972    0.0\n",
      "1976    0.0\n",
      "1980    0.0\n",
      "1984    0.0\n",
      "1988    0.0\n",
      "1992    0.0\n",
      "1996    0.0\n",
      "2000    0.0\n",
      "2004    0.0\n",
      "2008    0.0\n",
      "2012    0.0\n",
      "2016    0.0\n",
      "2020    2.0\n",
      "2024    0.0\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Tug-Of-War (drug)\n",
      "Raw data for Tug-Of-War (drug):\n",
      "            Sport  Year  Value\n",
      "60    Tug-Of-War  1896    0.0\n",
      "125   Tug-Of-War  1900    0.0\n",
      "190   Tug-Of-War  1904    0.0\n",
      "255   Tug-Of-War  1906    0.0\n",
      "320   Tug-Of-War  1908    0.0\n",
      "385   Tug-Of-War  1912    0.0\n",
      "450   Tug-Of-War  1920    0.0\n",
      "515   Tug-Of-War  1924    0.0\n",
      "580   Tug-Of-War  1928    0.0\n",
      "645   Tug-Of-War  1932    0.0\n",
      "710   Tug-Of-War  1936    0.0\n",
      "775   Tug-Of-War  1948    0.0\n",
      "840   Tug-Of-War  1952    0.0\n",
      "905   Tug-Of-War  1956    0.0\n",
      "970   Tug-Of-War  1960    0.0\n",
      "1035  Tug-Of-War  1964    0.0\n",
      "1100  Tug-Of-War  1968    0.0\n",
      "1165  Tug-Of-War  1972    0.0\n",
      "1230  Tug-Of-War  1976    0.0\n",
      "1295  Tug-Of-War  1980    0.0\n",
      "1360  Tug-Of-War  1984    0.0\n",
      "1425  Tug-Of-War  1988    0.0\n",
      "1490  Tug-Of-War  1992    0.0\n",
      "1555  Tug-Of-War  1996    0.0\n",
      "1620  Tug-Of-War  2000    0.0\n",
      "1685  Tug-Of-War  2004    0.0\n",
      "1750  Tug-Of-War  2008    0.0\n",
      "1815  Tug-Of-War  2012    0.0\n",
      "1880  Tug-Of-War  2016    0.0\n",
      "1945  Tug-Of-War  2020    0.0\n",
      "2010  Tug-Of-War  2024    0.0\n",
      "\n",
      "Prepared time series data for Tug-Of-War (drug):\n",
      " Year\n",
      "1896    0.0\n",
      "1900    0.0\n",
      "1904    0.0\n",
      "1906    0.0\n",
      "1908    0.0\n",
      "1912    0.0\n",
      "1920    0.0\n",
      "1924    0.0\n",
      "1928    0.0\n",
      "1932    0.0\n",
      "1936    0.0\n",
      "1948    0.0\n",
      "1952    0.0\n",
      "1956    0.0\n",
      "1960    0.0\n",
      "1964    0.0\n",
      "1968    0.0\n",
      "1972    0.0\n",
      "1976    0.0\n",
      "1980    0.0\n",
      "1984    0.0\n",
      "1988    0.0\n",
      "1992    0.0\n",
      "1996    0.0\n",
      "2000    0.0\n",
      "2004    0.0\n",
      "2008    0.0\n",
      "2012    0.0\n",
      "2016    0.0\n",
      "2020    0.0\n",
      "2024    0.0\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Volleyball (drug)\n",
      "Raw data for Volleyball (drug):\n",
      "            Sport  Year  Value\n",
      "61    Volleyball  1896    0.0\n",
      "126   Volleyball  1900    0.0\n",
      "191   Volleyball  1904    0.0\n",
      "256   Volleyball  1906    0.0\n",
      "321   Volleyball  1908    0.0\n",
      "386   Volleyball  1912    0.0\n",
      "451   Volleyball  1920    0.0\n",
      "516   Volleyball  1924    0.0\n",
      "581   Volleyball  1928    0.0\n",
      "646   Volleyball  1932    0.0\n",
      "711   Volleyball  1936    0.0\n",
      "776   Volleyball  1948    0.0\n",
      "841   Volleyball  1952    0.0\n",
      "906   Volleyball  1956    0.0\n",
      "971   Volleyball  1960    0.0\n",
      "1036  Volleyball  1964    0.0\n",
      "1101  Volleyball  1968    0.0\n",
      "1166  Volleyball  1972    0.0\n",
      "1231  Volleyball  1976    0.0\n",
      "1296  Volleyball  1980    0.0\n",
      "1361  Volleyball  1984    2.0\n",
      "1426  Volleyball  1988    0.0\n",
      "1491  Volleyball  1992    1.0\n",
      "1556  Volleyball  1996    0.0\n",
      "1621  Volleyball  2000    0.0\n",
      "1686  Volleyball  2004    0.0\n",
      "1751  Volleyball  2008    0.0\n",
      "1816  Volleyball  2012    0.0\n",
      "1881  Volleyball  2016    0.0\n",
      "1946  Volleyball  2020    1.0\n",
      "2011  Volleyball  2024    0.0\n",
      "\n",
      "Prepared time series data for Volleyball (drug):\n",
      " Year\n",
      "1896    0.0\n",
      "1900    0.0\n",
      "1904    0.0\n",
      "1906    0.0\n",
      "1908    0.0\n",
      "1912    0.0\n",
      "1920    0.0\n",
      "1924    0.0\n",
      "1928    0.0\n",
      "1932    0.0\n",
      "1936    0.0\n",
      "1948    0.0\n",
      "1952    0.0\n",
      "1956    0.0\n",
      "1960    0.0\n",
      "1964    0.0\n",
      "1968    0.0\n",
      "1972    0.0\n",
      "1976    0.0\n",
      "1980    0.0\n",
      "1984    2.0\n",
      "1988    0.0\n",
      "1992    1.0\n",
      "1996    0.0\n",
      "2000    0.0\n",
      "2004    0.0\n",
      "2008    0.0\n",
      "2012    0.0\n",
      "2016    0.0\n",
      "2020    1.0\n",
      "2024    0.0\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Water Polo (drug)\n",
      "Raw data for Water Polo (drug):\n",
      "            Sport  Year  Value\n",
      "62    Water Polo  1896    0.0\n",
      "127   Water Polo  1900    0.0\n",
      "192   Water Polo  1904    0.0\n",
      "257   Water Polo  1906    0.0\n",
      "322   Water Polo  1908    0.0\n",
      "387   Water Polo  1912    0.0\n",
      "452   Water Polo  1920    0.0\n",
      "517   Water Polo  1924    0.0\n",
      "582   Water Polo  1928    0.0\n",
      "647   Water Polo  1932    0.0\n",
      "712   Water Polo  1936    0.0\n",
      "777   Water Polo  1948    0.0\n",
      "842   Water Polo  1952    0.0\n",
      "907   Water Polo  1956    0.0\n",
      "972   Water Polo  1960    0.0\n",
      "1037  Water Polo  1964    0.0\n",
      "1102  Water Polo  1968    0.0\n",
      "1167  Water Polo  1972    0.0\n",
      "1232  Water Polo  1976    0.0\n",
      "1297  Water Polo  1980    0.0\n",
      "1362  Water Polo  1984    0.0\n",
      "1427  Water Polo  1988    0.0\n",
      "1492  Water Polo  1992    0.0\n",
      "1557  Water Polo  1996    0.0\n",
      "1622  Water Polo  2000    0.0\n",
      "1687  Water Polo  2004    0.0\n",
      "1752  Water Polo  2008    0.0\n",
      "1817  Water Polo  2012    0.0\n",
      "1882  Water Polo  2016    0.0\n",
      "1947  Water Polo  2020    0.0\n",
      "2012  Water Polo  2024    0.0\n",
      "\n",
      "Prepared time series data for Water Polo (drug):\n",
      " Year\n",
      "1896    0.0\n",
      "1900    0.0\n",
      "1904    0.0\n",
      "1906    0.0\n",
      "1908    0.0\n",
      "1912    0.0\n",
      "1920    0.0\n",
      "1924    0.0\n",
      "1928    0.0\n",
      "1932    0.0\n",
      "1936    0.0\n",
      "1948    0.0\n",
      "1952    0.0\n",
      "1956    0.0\n",
      "1960    0.0\n",
      "1964    0.0\n",
      "1968    0.0\n",
      "1972    0.0\n",
      "1976    0.0\n",
      "1980    0.0\n",
      "1984    0.0\n",
      "1988    0.0\n",
      "1992    0.0\n",
      "1996    0.0\n",
      "2000    0.0\n",
      "2004    0.0\n",
      "2008    0.0\n",
      "2012    0.0\n",
      "2016    0.0\n",
      "2020    0.0\n",
      "2024    0.0\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Weightlifting (drug)\n",
      "Raw data for Weightlifting (drug):\n",
      "               Sport  Year  Value\n",
      "63    Weightlifting  1896    0.0\n",
      "128   Weightlifting  1900    0.0\n",
      "193   Weightlifting  1904    0.0\n",
      "258   Weightlifting  1906    0.0\n",
      "323   Weightlifting  1908    0.0\n",
      "388   Weightlifting  1912    0.0\n",
      "453   Weightlifting  1920    0.0\n",
      "518   Weightlifting  1924    0.0\n",
      "583   Weightlifting  1928    0.0\n",
      "648   Weightlifting  1932    0.0\n",
      "713   Weightlifting  1936    0.0\n",
      "778   Weightlifting  1948    0.0\n",
      "843   Weightlifting  1952    0.0\n",
      "908   Weightlifting  1956    0.0\n",
      "973   Weightlifting  1960    0.0\n",
      "1038  Weightlifting  1964    0.0\n",
      "1103  Weightlifting  1968    0.0\n",
      "1168  Weightlifting  1972    2.0\n",
      "1233  Weightlifting  1976    8.0\n",
      "1298  Weightlifting  1980    0.0\n",
      "1363  Weightlifting  1984    5.0\n",
      "1428  Weightlifting  1988    5.0\n",
      "1493  Weightlifting  1992    2.0\n",
      "1558  Weightlifting  1996    0.0\n",
      "1623  Weightlifting  2000    5.0\n",
      "1688  Weightlifting  2004   13.0\n",
      "1753  Weightlifting  2008   26.0\n",
      "1818  Weightlifting  2012   37.0\n",
      "1883  Weightlifting  2016    7.0\n",
      "1948  Weightlifting  2020    0.0\n",
      "2013  Weightlifting  2024    0.0\n",
      "\n",
      "Prepared time series data for Weightlifting (drug):\n",
      " Year\n",
      "1896     0.0\n",
      "1900     0.0\n",
      "1904     0.0\n",
      "1906     0.0\n",
      "1908     0.0\n",
      "1912     0.0\n",
      "1920     0.0\n",
      "1924     0.0\n",
      "1928     0.0\n",
      "1932     0.0\n",
      "1936     0.0\n",
      "1948     0.0\n",
      "1952     0.0\n",
      "1956     0.0\n",
      "1960     0.0\n",
      "1964     0.0\n",
      "1968     0.0\n",
      "1972     2.0\n",
      "1976     8.0\n",
      "1980     0.0\n",
      "1984     5.0\n",
      "1988     5.0\n",
      "1992     2.0\n",
      "1996     0.0\n",
      "2000     5.0\n",
      "2004    13.0\n",
      "2008    26.0\n",
      "2012    37.0\n",
      "2016     7.0\n",
      "2020     0.0\n",
      "2024     0.0\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Wrestling (drug)\n",
      "Raw data for Wrestling (drug):\n",
      "           Sport  Year  Value\n",
      "64    Wrestling  1896    0.0\n",
      "129   Wrestling  1900    0.0\n",
      "194   Wrestling  1904    0.0\n",
      "259   Wrestling  1906    0.0\n",
      "324   Wrestling  1908    0.0\n",
      "389   Wrestling  1912    0.0\n",
      "454   Wrestling  1920    0.0\n",
      "519   Wrestling  1924    0.0\n",
      "584   Wrestling  1928    0.0\n",
      "649   Wrestling  1932    0.0\n",
      "714   Wrestling  1936    0.0\n",
      "779   Wrestling  1948    0.0\n",
      "844   Wrestling  1952    0.0\n",
      "909   Wrestling  1956    0.0\n",
      "974   Wrestling  1960    0.0\n",
      "1039  Wrestling  1964    0.0\n",
      "1104  Wrestling  1968    0.0\n",
      "1169  Wrestling  1972    0.0\n",
      "1234  Wrestling  1976    0.0\n",
      "1299  Wrestling  1980    0.0\n",
      "1364  Wrestling  1984    1.0\n",
      "1429  Wrestling  1988    1.0\n",
      "1494  Wrestling  1992    0.0\n",
      "1559  Wrestling  1996    0.0\n",
      "1624  Wrestling  2000    2.0\n",
      "1689  Wrestling  2004    1.0\n",
      "1754  Wrestling  2008    7.0\n",
      "1819  Wrestling  2012    4.0\n",
      "1884  Wrestling  2016    1.0\n",
      "1949  Wrestling  2020    0.0\n",
      "2014  Wrestling  2024    0.0\n",
      "\n",
      "Prepared time series data for Wrestling (drug):\n",
      " Year\n",
      "1896    0.0\n",
      "1900    0.0\n",
      "1904    0.0\n",
      "1906    0.0\n",
      "1908    0.0\n",
      "1912    0.0\n",
      "1920    0.0\n",
      "1924    0.0\n",
      "1928    0.0\n",
      "1932    0.0\n",
      "1936    0.0\n",
      "1948    0.0\n",
      "1952    0.0\n",
      "1956    0.0\n",
      "1960    0.0\n",
      "1964    0.0\n",
      "1968    0.0\n",
      "1972    0.0\n",
      "1976    0.0\n",
      "1980    0.0\n",
      "1984    1.0\n",
      "1988    1.0\n",
      "1992    0.0\n",
      "1996    0.0\n",
      "2000    2.0\n",
      "2004    1.0\n",
      "2008    7.0\n",
      "2012    4.0\n",
      "2016    1.0\n",
      "2020    0.0\n",
      "2024    0.0\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing parameter: equity\n",
      "\n",
      "Processing sport: Alpine Skiing (equity)\n",
      "Raw data for Alpine Skiing (equity):\n",
      "               Sport  Year     Value\n",
      "650   Alpine Skiing  1936  0.359223\n",
      "715   Alpine Skiing  1948  0.258333\n",
      "780   Alpine Skiing  1952  0.335979\n",
      "845   Alpine Skiing  1956  0.357320\n",
      "910   Alpine Skiing  1960  0.403125\n",
      "975   Alpine Skiing  1964  0.328467\n",
      "1040  Alpine Skiing  1968  0.319905\n",
      "1105  Alpine Skiing  1972  0.384615\n",
      "1170  Alpine Skiing  1976  0.320513\n",
      "1235  Alpine Skiing  1980  0.376147\n",
      "1300  Alpine Skiing  1984  0.326683\n",
      "1365  Alpine Skiing  1988  0.360778\n",
      "1430  Alpine Skiing  1992  0.348000\n",
      "\n",
      "Prepared time series data for Alpine Skiing (equity):\n",
      " Year\n",
      "1936    0.359223\n",
      "1948    0.258333\n",
      "1952    0.335979\n",
      "1956    0.357320\n",
      "1960    0.403125\n",
      "1964    0.328467\n",
      "1968    0.319905\n",
      "1972    0.384615\n",
      "1976    0.320513\n",
      "1980    0.376147\n",
      "1984    0.326683\n",
      "1988    0.360778\n",
      "1992    0.348000\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Alpinism (equity)\n",
      "Raw data for Alpinism (equity):\n",
      "         Sport  Year  Value\n",
      "456  Alpinism  1924    0.0\n",
      "586  Alpinism  1932    0.0\n",
      "651  Alpinism  1936    0.5\n",
      "\n",
      "Prepared time series data for Alpinism (equity):\n",
      " Year\n",
      "1924    0.0\n",
      "1932    0.0\n",
      "1936    0.5\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Archery (equity)\n",
      "Raw data for Archery (equity):\n",
      "         Sport  Year     Value\n",
      "67    Archery  1900  0.000000\n",
      "132   Archery  1904  0.228571\n",
      "262   Archery  1908  0.324675\n",
      "392   Archery  1920  0.000000\n",
      "1107  Archery  1972  0.421053\n",
      "1172  Archery  1976  0.421875\n",
      "1237  Archery  1980  0.432836\n",
      "1302  Archery  1984  0.431193\n",
      "1367  Archery  1988  0.416342\n",
      "1432  Archery  1992  0.453441\n",
      "1497  Archery  1996  0.500000\n",
      "1562  Archery  2000  0.485437\n",
      "1627  Archery  2004  0.514151\n",
      "1692  Archery  2008  0.484536\n",
      "1757  Archery  2012  0.500000\n",
      "1822  Archery  2016  0.500000\n",
      "1887  Archery  2020  0.500000\n",
      "1952  Archery  2024  0.500000\n",
      "\n",
      "Prepared time series data for Archery (equity):\n",
      " Year\n",
      "1900    0.000000\n",
      "1904    0.228571\n",
      "1908    0.324675\n",
      "1920    0.000000\n",
      "1972    0.421053\n",
      "1976    0.421875\n",
      "1980    0.432836\n",
      "1984    0.431193\n",
      "1988    0.416342\n",
      "1992    0.453441\n",
      "1996    0.500000\n",
      "2000    0.485437\n",
      "2004    0.514151\n",
      "2008    0.484536\n",
      "2012    0.500000\n",
      "2016    0.500000\n",
      "2020    0.500000\n",
      "2024    0.500000\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Art Competitions (equity)\n",
      "Raw data for Art Competitions (equity):\n",
      "                 Sport  Year     Value\n",
      "328  Art Competitions  1912  0.000000\n",
      "393  Art Competitions  1920  0.090909\n",
      "458  Art Competitions  1924  0.103774\n",
      "523  Art Competitions  1928  0.068069\n",
      "588  Art Competitions  1932  0.140569\n",
      "653  Art Competitions  1936  0.063961\n",
      "718  Art Competitions  1948  0.165605\n",
      "\n",
      "Prepared time series data for Art Competitions (equity):\n",
      " Year\n",
      "1912    0.000000\n",
      "1920    0.090909\n",
      "1924    0.103774\n",
      "1928    0.068069\n",
      "1932    0.140569\n",
      "1936    0.063961\n",
      "1948    0.165605\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Athletics (equity)\n",
      "Raw data for Athletics (equity):\n",
      "           Sport  Year     Value\n",
      "4     Athletics  1896  0.000000\n",
      "69    Athletics  1900  0.000000\n",
      "134   Athletics  1904  0.000000\n",
      "199   Athletics  1906  0.000000\n",
      "264   Athletics  1908  0.000000\n",
      "329   Athletics  1912  0.000000\n",
      "394   Athletics  1920  0.000000\n",
      "459   Athletics  1924  0.000000\n",
      "524   Athletics  1928  0.130040\n",
      "589   Athletics  1932  0.153257\n",
      "654   Athletics  1936  0.133069\n",
      "719   Athletics  1948  0.224548\n",
      "784   Athletics  1952  0.223214\n",
      "849   Athletics  1956  0.213228\n",
      "914   Athletics  1960  0.205793\n",
      "979   Athletics  1964  0.256929\n",
      "1044  Athletics  1968  0.263197\n",
      "1109  Athletics  1972  0.300119\n",
      "1174  Athletics  1976  0.323053\n",
      "1239  Athletics  1980  0.294953\n",
      "1304  Athletics  1984  0.302867\n",
      "1369  Athletics  1988  0.357905\n",
      "1434  Athletics  1992  0.369523\n",
      "1499  Athletics  1996  0.375524\n",
      "1564  Athletics  2000  0.417747\n",
      "1629  Athletics  2004  0.460230\n",
      "1694  Athletics  2008  0.475936\n",
      "1759  Athletics  2012  0.481563\n",
      "1824  Athletics  2016  0.481659\n",
      "1889  Athletics  2020  0.480000\n",
      "1954  Athletics  2024  0.500000\n",
      "\n",
      "Prepared time series data for Athletics (equity):\n",
      " Year\n",
      "1896    0.000000\n",
      "1900    0.000000\n",
      "1904    0.000000\n",
      "1906    0.000000\n",
      "1908    0.000000\n",
      "1912    0.000000\n",
      "1920    0.000000\n",
      "1924    0.000000\n",
      "1928    0.130040\n",
      "1932    0.153257\n",
      "1936    0.133069\n",
      "1948    0.224548\n",
      "1952    0.223214\n",
      "1956    0.213228\n",
      "1960    0.205793\n",
      "1964    0.256929\n",
      "1968    0.263197\n",
      "1972    0.300119\n",
      "1976    0.323053\n",
      "1980    0.294953\n",
      "1984    0.302867\n",
      "1988    0.357905\n",
      "1992    0.369523\n",
      "1996    0.375524\n",
      "2000    0.417747\n",
      "2004    0.460230\n",
      "2008    0.475936\n",
      "2012    0.481563\n",
      "2016    0.481659\n",
      "2020    0.480000\n",
      "2024    0.500000\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Badminton (equity)\n",
      "Raw data for Badminton (equity):\n",
      "           Sport  Year     Value\n",
      "1435  Badminton  1992  0.486726\n",
      "1500  Badminton  1996  0.505703\n",
      "1565  Badminton  2000  0.528889\n",
      "1630  Badminton  2004  0.505000\n",
      "1695  Badminton  2008  0.516304\n",
      "1760  Badminton  2012  0.516484\n",
      "1825  Badminton  2016  0.497175\n",
      "1890  Badminton  2020  0.500000\n",
      "1955  Badminton  2024  0.500000\n",
      "\n",
      "Prepared time series data for Badminton (equity):\n",
      " Year\n",
      "1992    0.486726\n",
      "1996    0.505703\n",
      "2000    0.528889\n",
      "2004    0.505000\n",
      "2008    0.516304\n",
      "2012    0.516484\n",
      "2016    0.497175\n",
      "2020    0.500000\n",
      "2024    0.500000\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Baseball (equity)\n",
      "Raw data for Baseball (equity):\n",
      "          Sport  Year  Value\n",
      "1436  Baseball  1992    0.0\n",
      "1501  Baseball  1996    0.0\n",
      "1566  Baseball  2000    0.0\n",
      "1631  Baseball  2004    0.0\n",
      "1696  Baseball  2008    0.0\n",
      "\n",
      "Prepared time series data for Baseball (equity):\n",
      " Year\n",
      "1992    0.0\n",
      "1996    0.0\n",
      "2000    0.0\n",
      "2004    0.0\n",
      "2008    0.0\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Basketball (equity)\n",
      "Raw data for Basketball (equity):\n",
      "            Sport  Year     Value\n",
      "657   Basketball  1936  0.000000\n",
      "722   Basketball  1948  0.000000\n",
      "787   Basketball  1952  0.000000\n",
      "852   Basketball  1956  0.000000\n",
      "917   Basketball  1960  0.000000\n",
      "982   Basketball  1964  0.000000\n",
      "1047  Basketball  1968  0.000000\n",
      "1112  Basketball  1972  0.000000\n",
      "1177  Basketball  1976  0.338028\n",
      "1242  Basketball  1980  0.334884\n",
      "1307  Basketball  1984  0.333333\n",
      "1372  Basketball  1988  0.394068\n",
      "1437  Basketball  1992  0.398305\n",
      "1502  Basketball  1996  0.503521\n",
      "1567  Basketball  2000  0.496503\n",
      "1632  Basketball  2004  0.498258\n",
      "1697  Basketball  2008  0.498258\n",
      "1762  Basketball  2012  0.498258\n",
      "1827  Basketball  2016  0.498221\n",
      "1892  Basketball  2020  0.500000\n",
      "1957  Basketball  2024  0.500000\n",
      "\n",
      "Prepared time series data for Basketball (equity):\n",
      " Year\n",
      "1936    0.000000\n",
      "1948    0.000000\n",
      "1952    0.000000\n",
      "1956    0.000000\n",
      "1960    0.000000\n",
      "1964    0.000000\n",
      "1968    0.000000\n",
      "1972    0.000000\n",
      "1976    0.338028\n",
      "1980    0.334884\n",
      "1984    0.333333\n",
      "1988    0.394068\n",
      "1992    0.398305\n",
      "1996    0.503521\n",
      "2000    0.496503\n",
      "2004    0.498258\n",
      "2008    0.498258\n",
      "2012    0.498258\n",
      "2016    0.498221\n",
      "2020    0.500000\n",
      "2024    0.500000\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Basque Pelota (equity)\n",
      "Raw data for Basque Pelota (equity):\n",
      "             Sport  Year  Value\n",
      "73  Basque Pelota  1900    0.0\n",
      "\n",
      "Prepared time series data for Basque Pelota (equity):\n",
      " Year\n",
      "1900    0.0\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Beach Volleyball (equity)\n",
      "Raw data for Beach Volleyball (equity):\n",
      "                  Sport  Year     Value\n",
      "1504  Beach Volleyball  1996  0.428571\n",
      "1569  Beach Volleyball  2000  0.500000\n",
      "1634  Beach Volleyball  2004  0.500000\n",
      "1699  Beach Volleyball  2008  0.500000\n",
      "1764  Beach Volleyball  2012  0.500000\n",
      "1829  Beach Volleyball  2016  0.500000\n",
      "1959  Beach Volleyball  2024  0.500000\n",
      "\n",
      "Prepared time series data for Beach Volleyball (equity):\n",
      " Year\n",
      "1996    0.428571\n",
      "2000    0.500000\n",
      "2004    0.500000\n",
      "2008    0.500000\n",
      "2012    0.500000\n",
      "2016    0.500000\n",
      "2024    0.500000\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Biathlon (equity)\n",
      "Raw data for Biathlon (equity):\n",
      "          Sport  Year     Value\n",
      "920   Biathlon  1960  0.000000\n",
      "985   Biathlon  1964  0.000000\n",
      "1050  Biathlon  1968  0.000000\n",
      "1115  Biathlon  1972  0.000000\n",
      "1180  Biathlon  1976  0.000000\n",
      "1245  Biathlon  1980  0.000000\n",
      "1310  Biathlon  1984  0.000000\n",
      "1375  Biathlon  1988  0.000000\n",
      "1440  Biathlon  1992  0.404814\n",
      "\n",
      "Prepared time series data for Biathlon (equity):\n",
      " Year\n",
      "1960    0.000000\n",
      "1964    0.000000\n",
      "1968    0.000000\n",
      "1972    0.000000\n",
      "1976    0.000000\n",
      "1980    0.000000\n",
      "1984    0.000000\n",
      "1988    0.000000\n",
      "1992    0.404814\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Bobsleigh (equity)\n",
      "Raw data for Bobsleigh (equity):\n",
      "           Sport  Year  Value\n",
      "466   Bobsleigh  1924    0.0\n",
      "531   Bobsleigh  1928    0.0\n",
      "596   Bobsleigh  1932    0.0\n",
      "661   Bobsleigh  1936    0.0\n",
      "726   Bobsleigh  1948    0.0\n",
      "791   Bobsleigh  1952    0.0\n",
      "856   Bobsleigh  1956    0.0\n",
      "986   Bobsleigh  1964    0.0\n",
      "1051  Bobsleigh  1968    0.0\n",
      "1116  Bobsleigh  1972    0.0\n",
      "1181  Bobsleigh  1976    0.0\n",
      "1246  Bobsleigh  1980    0.0\n",
      "1311  Bobsleigh  1984    0.0\n",
      "1376  Bobsleigh  1988    0.0\n",
      "1441  Bobsleigh  1992    0.0\n",
      "\n",
      "Prepared time series data for Bobsleigh (equity):\n",
      " Year\n",
      "1924    0.0\n",
      "1928    0.0\n",
      "1932    0.0\n",
      "1936    0.0\n",
      "1948    0.0\n",
      "1952    0.0\n",
      "1956    0.0\n",
      "1964    0.0\n",
      "1968    0.0\n",
      "1972    0.0\n",
      "1976    0.0\n",
      "1980    0.0\n",
      "1984    0.0\n",
      "1988    0.0\n",
      "1992    0.0\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Boxing (equity)\n",
      "Raw data for Boxing (equity):\n",
      "        Sport  Year     Value\n",
      "142   Boxing  1904  0.000000\n",
      "272   Boxing  1908  0.000000\n",
      "402   Boxing  1920  0.000000\n",
      "467   Boxing  1924  0.000000\n",
      "532   Boxing  1928  0.000000\n",
      "597   Boxing  1932  0.000000\n",
      "662   Boxing  1936  0.000000\n",
      "727   Boxing  1948  0.000000\n",
      "792   Boxing  1952  0.000000\n",
      "857   Boxing  1956  0.000000\n",
      "922   Boxing  1960  0.000000\n",
      "987   Boxing  1964  0.000000\n",
      "1052  Boxing  1968  0.000000\n",
      "1117  Boxing  1972  0.000000\n",
      "1182  Boxing  1976  0.000000\n",
      "1247  Boxing  1980  0.000000\n",
      "1312  Boxing  1984  0.000000\n",
      "1377  Boxing  1988  0.000000\n",
      "1442  Boxing  1992  0.000000\n",
      "1507  Boxing  1996  0.000000\n",
      "1572  Boxing  2000  0.000000\n",
      "1637  Boxing  2004  0.000000\n",
      "1702  Boxing  2008  0.000000\n",
      "1767  Boxing  2012  0.127208\n",
      "1832  Boxing  2016  0.127208\n",
      "1897  Boxing  2020  0.349650\n",
      "1962  Boxing  2024  0.500000\n",
      "\n",
      "Prepared time series data for Boxing (equity):\n",
      " Year\n",
      "1904    0.000000\n",
      "1908    0.000000\n",
      "1920    0.000000\n",
      "1924    0.000000\n",
      "1928    0.000000\n",
      "1932    0.000000\n",
      "1936    0.000000\n",
      "1948    0.000000\n",
      "1952    0.000000\n",
      "1956    0.000000\n",
      "1960    0.000000\n",
      "1964    0.000000\n",
      "1968    0.000000\n",
      "1972    0.000000\n",
      "1976    0.000000\n",
      "1980    0.000000\n",
      "1984    0.000000\n",
      "1988    0.000000\n",
      "1992    0.000000\n",
      "1996    0.000000\n",
      "2000    0.000000\n",
      "2004    0.000000\n",
      "2008    0.000000\n",
      "2012    0.127208\n",
      "2016    0.127208\n",
      "2020    0.349650\n",
      "2024    0.500000\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Canoeing (equity)\n",
      "Raw data for Canoeing (equity):\n",
      "          Sport  Year     Value\n",
      "663   Canoeing  1936  0.000000\n",
      "728   Canoeing  1948  0.071942\n",
      "793   Canoeing  1952  0.070652\n",
      "858   Canoeing  1956  0.068493\n",
      "923   Canoeing  1960  0.165877\n",
      "988   Canoeing  1964  0.197605\n",
      "1053  Canoeing  1968  0.172414\n",
      "1118  Canoeing  1972  0.169916\n",
      "1183  Canoeing  1976  0.126471\n",
      "1248  Canoeing  1980  0.138340\n",
      "1313  Canoeing  1984  0.197324\n",
      "1378  Canoeing  1988  0.250000\n",
      "1443  Canoeing  1992  0.241908\n",
      "1508  Canoeing  1996  0.273043\n",
      "1573  Canoeing  2000  0.229911\n",
      "1638  Canoeing  2004  0.258065\n",
      "1703  Canoeing  2008  0.275229\n",
      "1768  Canoeing  2012  0.366029\n",
      "1833  Canoeing  2016  0.367347\n",
      "1898  Canoeing  2020  0.500000\n",
      "1963  Canoeing  2024  0.500000\n",
      "\n",
      "Prepared time series data for Canoeing (equity):\n",
      " Year\n",
      "1936    0.000000\n",
      "1948    0.071942\n",
      "1952    0.070652\n",
      "1956    0.068493\n",
      "1960    0.165877\n",
      "1964    0.197605\n",
      "1968    0.172414\n",
      "1972    0.169916\n",
      "1976    0.126471\n",
      "1980    0.138340\n",
      "1984    0.197324\n",
      "1988    0.250000\n",
      "1992    0.241908\n",
      "1996    0.273043\n",
      "2000    0.229911\n",
      "2004    0.258065\n",
      "2008    0.275229\n",
      "2012    0.366029\n",
      "2016    0.367347\n",
      "2020    0.500000\n",
      "2024    0.500000\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Cricket (equity)\n",
      "Raw data for Cricket (equity):\n",
      "       Sport  Year  Value\n",
      "79  Cricket  1900    0.0\n",
      "\n",
      "Prepared time series data for Cricket (equity):\n",
      " Year\n",
      "1900    0.0\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Croquet (equity)\n",
      "Raw data for Croquet (equity):\n",
      "       Sport  Year     Value\n",
      "80  Croquet  1900  0.315789\n",
      "\n",
      "Prepared time series data for Croquet (equity):\n",
      " Year\n",
      "1900    0.315789\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Cross Country Skiing (equity)\n",
      "Raw data for Cross Country Skiing (equity):\n",
      "                      Sport  Year     Value\n",
      "471   Cross Country Skiing  1924  0.000000\n",
      "536   Cross Country Skiing  1928  0.000000\n",
      "601   Cross Country Skiing  1932  0.000000\n",
      "666   Cross Country Skiing  1936  0.000000\n",
      "731   Cross Country Skiing  1948  0.000000\n",
      "796   Cross Country Skiing  1952  0.106383\n",
      "861   Cross Country Skiing  1956  0.254545\n",
      "926   Cross Country Skiing  1960  0.180556\n",
      "991   Cross Country Skiing  1964  0.274096\n",
      "1056  Cross Country Skiing  1968  0.267442\n",
      "1121  Cross Country Skiing  1972  0.352239\n",
      "1186  Cross Country Skiing  1976  0.313924\n",
      "1251  Cross Country Skiing  1980  0.349515\n",
      "1316  Cross Country Skiing  1984  0.402516\n",
      "1381  Cross Country Skiing  1988  0.397727\n",
      "1446  Cross Country Skiing  1992  0.393305\n",
      "\n",
      "Prepared time series data for Cross Country Skiing (equity):\n",
      " Year\n",
      "1924    0.000000\n",
      "1928    0.000000\n",
      "1932    0.000000\n",
      "1936    0.000000\n",
      "1948    0.000000\n",
      "1952    0.106383\n",
      "1956    0.254545\n",
      "1960    0.180556\n",
      "1964    0.274096\n",
      "1968    0.267442\n",
      "1972    0.352239\n",
      "1976    0.313924\n",
      "1980    0.349515\n",
      "1984    0.402516\n",
      "1988    0.397727\n",
      "1992    0.393305\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Curling (equity)\n",
      "Raw data for Curling (equity):\n",
      "        Sport  Year  Value\n",
      "472  Curling  1924    0.0\n",
      "\n",
      "Prepared time series data for Curling (equity):\n",
      " Year\n",
      "1924    0.0\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Cycling (equity)\n",
      "Raw data for Cycling (equity):\n",
      "         Sport  Year     Value\n",
      "18    Cycling  1896  0.000000\n",
      "83    Cycling  1900  0.000000\n",
      "148   Cycling  1904  0.000000\n",
      "213   Cycling  1906  0.000000\n",
      "278   Cycling  1908  0.000000\n",
      "343   Cycling  1912  0.000000\n",
      "408   Cycling  1920  0.000000\n",
      "473   Cycling  1924  0.000000\n",
      "538   Cycling  1928  0.000000\n",
      "603   Cycling  1932  0.000000\n",
      "668   Cycling  1936  0.000000\n",
      "733   Cycling  1948  0.000000\n",
      "798   Cycling  1952  0.000000\n",
      "863   Cycling  1956  0.000000\n",
      "928   Cycling  1960  0.000000\n",
      "993   Cycling  1964  0.000000\n",
      "1058  Cycling  1968  0.000000\n",
      "1123  Cycling  1972  0.000000\n",
      "1188  Cycling  1976  0.000000\n",
      "1253  Cycling  1980  0.000000\n",
      "1318  Cycling  1984  0.094737\n",
      "1383  Cycling  1988  0.125483\n",
      "1448  Cycling  1992  0.151943\n",
      "1513  Cycling  1996  0.273973\n",
      "1578  Cycling  2000  0.270531\n",
      "1643  Cycling  2004  0.284109\n",
      "1708  Cycling  2008  0.282209\n",
      "1773  Cycling  2012  0.384738\n",
      "1838  Cycling  2016  0.400300\n",
      "1903  Cycling  2020  0.431818\n",
      "1968  Cycling  2024  0.500000\n",
      "\n",
      "Prepared time series data for Cycling (equity):\n",
      " Year\n",
      "1896    0.000000\n",
      "1900    0.000000\n",
      "1904    0.000000\n",
      "1906    0.000000\n",
      "1908    0.000000\n",
      "1912    0.000000\n",
      "1920    0.000000\n",
      "1924    0.000000\n",
      "1928    0.000000\n",
      "1932    0.000000\n",
      "1936    0.000000\n",
      "1948    0.000000\n",
      "1952    0.000000\n",
      "1956    0.000000\n",
      "1960    0.000000\n",
      "1964    0.000000\n",
      "1968    0.000000\n",
      "1972    0.000000\n",
      "1976    0.000000\n",
      "1980    0.000000\n",
      "1984    0.094737\n",
      "1988    0.125483\n",
      "1992    0.151943\n",
      "1996    0.273973\n",
      "2000    0.270531\n",
      "2004    0.284109\n",
      "2008    0.282209\n",
      "2012    0.384738\n",
      "2016    0.400300\n",
      "2020    0.431818\n",
      "2024    0.500000\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Diving (equity)\n",
      "Raw data for Diving (equity):\n",
      "        Sport  Year     Value\n",
      "149   Diving  1904  0.000000\n",
      "214   Diving  1906  0.000000\n",
      "279   Diving  1908  0.000000\n",
      "344   Diving  1912  0.162791\n",
      "409   Diving  1920  0.271429\n",
      "474   Diving  1924  0.311111\n",
      "539   Diving  1928  0.364865\n",
      "604   Diving  1932  0.416667\n",
      "669   Diving  1936  0.431818\n",
      "734   Diving  1948  0.380952\n",
      "799   Diving  1952  0.309278\n",
      "864   Diving  1956  0.439024\n",
      "929   Diving  1960  0.375000\n",
      "994   Diving  1964  0.441176\n",
      "1059  Diving  1968  0.422018\n",
      "1124  Diving  1972  0.459677\n",
      "1189  Diving  1976  0.495238\n",
      "1254  Diving  1980  0.465909\n",
      "1319  Diving  1984  0.445545\n",
      "1384  Diving  1988  0.435185\n",
      "1449  Diving  1992  0.508929\n",
      "1514  Diving  1996  0.453237\n",
      "1579  Diving  2000  0.483193\n",
      "1644  Diving  2004  0.505102\n",
      "1709  Diving  2008  0.500000\n",
      "1774  Diving  2012  0.486188\n",
      "1839  Diving  2016  0.500000\n",
      "1904  Diving  2020  0.500000\n",
      "1969  Diving  2024  0.500000\n",
      "\n",
      "Prepared time series data for Diving (equity):\n",
      " Year\n",
      "1904    0.000000\n",
      "1906    0.000000\n",
      "1908    0.000000\n",
      "1912    0.162791\n",
      "1920    0.271429\n",
      "1924    0.311111\n",
      "1928    0.364865\n",
      "1932    0.416667\n",
      "1936    0.431818\n",
      "1948    0.380952\n",
      "1952    0.309278\n",
      "1956    0.439024\n",
      "1960    0.375000\n",
      "1964    0.441176\n",
      "1968    0.422018\n",
      "1972    0.459677\n",
      "1976    0.495238\n",
      "1980    0.465909\n",
      "1984    0.445545\n",
      "1988    0.435185\n",
      "1992    0.508929\n",
      "1996    0.453237\n",
      "2000    0.483193\n",
      "2004    0.505102\n",
      "2008    0.500000\n",
      "2012    0.486188\n",
      "2016    0.500000\n",
      "2020    0.500000\n",
      "2024    0.500000\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Equestrianism (equity)\n",
      "Raw data for Equestrianism (equity):\n",
      "               Sport  Year     Value\n",
      "85    Equestrianism  1900  0.025316\n",
      "345   Equestrianism  1912  0.000000\n",
      "410   Equestrianism  1920  0.000000\n",
      "475   Equestrianism  1924  0.000000\n",
      "540   Equestrianism  1928  0.000000\n",
      "605   Equestrianism  1932  0.000000\n",
      "670   Equestrianism  1936  0.000000\n",
      "735   Equestrianism  1948  0.000000\n",
      "800   Equestrianism  1952  0.022814\n",
      "865   Equestrianism  1956  0.077181\n",
      "930   Equestrianism  1960  0.032609\n",
      "995   Equestrianism  1964  0.102679\n",
      "1060  Equestrianism  1968  0.180258\n",
      "1125  Equestrianism  1972  0.174847\n",
      "1190  Equestrianism  1976  0.182927\n",
      "1255  Equestrianism  1980  0.122951\n",
      "1320  Equestrianism  1984  0.313167\n",
      "1385  Equestrianism  1988  0.305556\n",
      "1450  Equestrianism  1992  0.304455\n",
      "1515  Equestrianism  1996  0.297376\n",
      "1580  Equestrianism  2000  0.338983\n",
      "1645  Equestrianism  2004  0.318059\n",
      "1710  Equestrianism  2008  0.385294\n",
      "1775  Equestrianism  2012  0.377143\n",
      "1840  Equestrianism  2016  0.369014\n",
      "1905  Equestrianism  2020  0.500000\n",
      "1970  Equestrianism  2024  0.500000\n",
      "\n",
      "Prepared time series data for Equestrianism (equity):\n",
      " Year\n",
      "1900    0.025316\n",
      "1912    0.000000\n",
      "1920    0.000000\n",
      "1924    0.000000\n",
      "1928    0.000000\n",
      "1932    0.000000\n",
      "1936    0.000000\n",
      "1948    0.000000\n",
      "1952    0.022814\n",
      "1956    0.077181\n",
      "1960    0.032609\n",
      "1964    0.102679\n",
      "1968    0.180258\n",
      "1972    0.174847\n",
      "1976    0.182927\n",
      "1980    0.122951\n",
      "1984    0.313167\n",
      "1988    0.305556\n",
      "1992    0.304455\n",
      "1996    0.297376\n",
      "2000    0.338983\n",
      "2004    0.318059\n",
      "2008    0.385294\n",
      "2012    0.377143\n",
      "2016    0.369014\n",
      "2020    0.500000\n",
      "2024    0.500000\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Fencing (equity)\n",
      "Raw data for Fencing (equity):\n",
      "         Sport  Year     Value\n",
      "21    Fencing  1896  0.000000\n",
      "86    Fencing  1900  0.000000\n",
      "151   Fencing  1904  0.000000\n",
      "216   Fencing  1906  0.000000\n",
      "281   Fencing  1908  0.000000\n",
      "346   Fencing  1912  0.000000\n",
      "411   Fencing  1920  0.000000\n",
      "476   Fencing  1924  0.058962\n",
      "541   Fencing  1928  0.062791\n",
      "606   Fencing  1932  0.088542\n",
      "671   Fencing  1936  0.073741\n",
      "736   Fencing  1948  0.076772\n",
      "801   Fencing  1952  0.072692\n",
      "866   Fencing  1956  0.082734\n",
      "931   Fencing  1960  0.188020\n",
      "996   Fencing  1964  0.178794\n",
      "1061  Fencing  1968  0.179592\n",
      "1126  Fencing  1972  0.194389\n",
      "1191  Fencing  1976  0.224742\n",
      "1256  Fencing  1980  0.242991\n",
      "1321  Fencing  1984  0.212264\n",
      "1386  Fencing  1988  0.207510\n",
      "1451  Fencing  1992  0.231441\n",
      "1516  Fencing  1996  0.396907\n",
      "1581  Fencing  2000  0.383954\n",
      "1646  Fencing  2004  0.368421\n",
      "1711  Fencing  2008  0.493976\n",
      "1776  Fencing  2012  0.504348\n",
      "1841  Fencing  2016  0.502890\n",
      "1906  Fencing  2020  0.500000\n",
      "1971  Fencing  2024  0.500000\n",
      "\n",
      "Prepared time series data for Fencing (equity):\n",
      " Year\n",
      "1896    0.000000\n",
      "1900    0.000000\n",
      "1904    0.000000\n",
      "1906    0.000000\n",
      "1908    0.000000\n",
      "1912    0.000000\n",
      "1920    0.000000\n",
      "1924    0.058962\n",
      "1928    0.062791\n",
      "1932    0.088542\n",
      "1936    0.073741\n",
      "1948    0.076772\n",
      "1952    0.072692\n",
      "1956    0.082734\n",
      "1960    0.188020\n",
      "1964    0.178794\n",
      "1968    0.179592\n",
      "1972    0.194389\n",
      "1976    0.224742\n",
      "1980    0.242991\n",
      "1984    0.212264\n",
      "1988    0.207510\n",
      "1992    0.231441\n",
      "1996    0.396907\n",
      "2000    0.383954\n",
      "2004    0.368421\n",
      "2008    0.493976\n",
      "2012    0.504348\n",
      "2016    0.502890\n",
      "2020    0.500000\n",
      "2024    0.500000\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Figure Skating (equity)\n",
      "Raw data for Figure Skating (equity):\n",
      "                Sport  Year     Value\n",
      "282   Figure Skating  1908  0.347826\n",
      "412   Figure Skating  1920  0.451613\n",
      "477   Figure Skating  1924  0.459459\n",
      "542   Figure Skating  1928  0.523810\n",
      "607   Figure Skating  1932  0.536585\n",
      "672   Figure Skating  1936  0.505747\n",
      "737   Figure Skating  1948  0.563380\n",
      "802   Figure Skating  1952  0.584615\n",
      "867   Figure Skating  1956  0.542373\n",
      "932   Figure Skating  1960  0.549296\n",
      "997   Figure Skating  1964  0.534091\n",
      "1062  Figure Skating  1968  0.520833\n",
      "1127  Figure Skating  1972  0.514706\n",
      "1192  Figure Skating  1976  0.504762\n",
      "1257  Figure Skating  1980  0.529412\n",
      "1322  Figure Skating  1984  0.500000\n",
      "1387  Figure Skating  1988  0.511628\n",
      "1452  Figure Skating  1992  0.496241\n",
      "\n",
      "Prepared time series data for Figure Skating (equity):\n",
      " Year\n",
      "1908    0.347826\n",
      "1920    0.451613\n",
      "1924    0.459459\n",
      "1928    0.523810\n",
      "1932    0.536585\n",
      "1936    0.505747\n",
      "1948    0.563380\n",
      "1952    0.584615\n",
      "1956    0.542373\n",
      "1960    0.549296\n",
      "1964    0.534091\n",
      "1968    0.520833\n",
      "1972    0.514706\n",
      "1976    0.504762\n",
      "1980    0.529412\n",
      "1984    0.500000\n",
      "1988    0.511628\n",
      "1992    0.496241\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Football (equity)\n",
      "Raw data for Football (equity):\n",
      "          Sport  Year     Value\n",
      "88    Football  1900  0.000000\n",
      "153   Football  1904  0.000000\n",
      "218   Football  1906  0.000000\n",
      "283   Football  1908  0.000000\n",
      "348   Football  1912  0.000000\n",
      "413   Football  1920  0.000000\n",
      "478   Football  1924  0.000000\n",
      "543   Football  1928  0.000000\n",
      "673   Football  1936  0.000000\n",
      "738   Football  1948  0.000000\n",
      "803   Football  1952  0.000000\n",
      "868   Football  1956  0.000000\n",
      "933   Football  1960  0.000000\n",
      "998   Football  1964  0.000000\n",
      "1063  Football  1968  0.000000\n",
      "1128  Football  1972  0.000000\n",
      "1193  Football  1976  0.000000\n",
      "1258  Football  1980  0.000000\n",
      "1323  Football  1984  0.000000\n",
      "1388  Football  1988  0.000000\n",
      "1453  Football  1992  0.000000\n",
      "1518  Football  1996  0.319588\n",
      "1583  Football  2000  0.317136\n",
      "1648  Football  2004  0.390588\n",
      "1713  Football  2008  0.415778\n",
      "1778  Football  2012  0.428266\n",
      "1843  Football  2016  0.429175\n",
      "1908  Football  2020  0.428571\n",
      "1973  Football  2024  0.500000\n",
      "\n",
      "Prepared time series data for Football (equity):\n",
      " Year\n",
      "1900    0.000000\n",
      "1904    0.000000\n",
      "1906    0.000000\n",
      "1908    0.000000\n",
      "1912    0.000000\n",
      "1920    0.000000\n",
      "1924    0.000000\n",
      "1928    0.000000\n",
      "1936    0.000000\n",
      "1948    0.000000\n",
      "1952    0.000000\n",
      "1956    0.000000\n",
      "1960    0.000000\n",
      "1964    0.000000\n",
      "1968    0.000000\n",
      "1972    0.000000\n",
      "1976    0.000000\n",
      "1980    0.000000\n",
      "1984    0.000000\n",
      "1988    0.000000\n",
      "1992    0.000000\n",
      "1996    0.319588\n",
      "2000    0.317136\n",
      "2004    0.390588\n",
      "2008    0.415778\n",
      "2012    0.428266\n",
      "2016    0.429175\n",
      "2020    0.428571\n",
      "2024    0.500000\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Freestyle Skiing (equity)\n",
      "Raw data for Freestyle Skiing (equity):\n",
      "                  Sport  Year     Value\n",
      "1454  Freestyle Skiing  1992  0.338028\n",
      "\n",
      "Prepared time series data for Freestyle Skiing (equity):\n",
      " Year\n",
      "1992    0.338028\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Golf (equity)\n",
      "Raw data for Golf (equity):\n",
      "      Sport  Year     Value\n",
      "90    Golf  1900  0.454545\n",
      "155   Golf  1904  0.000000\n",
      "1845  Golf  2016  0.500000\n",
      "1910  Golf  2020  0.500000\n",
      "1975  Golf  2024  0.500000\n",
      "\n",
      "Prepared time series data for Golf (equity):\n",
      " Year\n",
      "1900    0.454545\n",
      "1904    0.000000\n",
      "2016    0.500000\n",
      "2020    0.500000\n",
      "2024    0.500000\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Gymnastics (equity)\n",
      "Raw data for Gymnastics (equity):\n",
      "            Sport  Year     Value\n",
      "26    Gymnastics  1896  0.000000\n",
      "91    Gymnastics  1900  0.000000\n",
      "156   Gymnastics  1904  0.000000\n",
      "221   Gymnastics  1906  0.000000\n",
      "286   Gymnastics  1908  0.000000\n",
      "351   Gymnastics  1912  0.000000\n",
      "416   Gymnastics  1920  0.000000\n",
      "481   Gymnastics  1924  0.000000\n",
      "546   Gymnastics  1928  0.084337\n",
      "611   Gymnastics  1932  0.000000\n",
      "676   Gymnastics  1936  0.067582\n",
      "741   Gymnastics  1948  0.083019\n",
      "806   Gymnastics  1952  0.387286\n",
      "871   Gymnastics  1956  0.470975\n",
      "936   Gymnastics  1960  0.413517\n",
      "1001  Gymnastics  1964  0.319407\n",
      "1066  Gymnastics  1968  0.392380\n",
      "1131  Gymnastics  1972  0.444444\n",
      "1196  Gymnastics  1976  0.416944\n",
      "1261  Gymnastics  1980  0.413395\n",
      "1326  Gymnastics  1984  0.407527\n",
      "1391  Gymnastics  1988  0.428924\n",
      "1456  Gymnastics  1992  0.423904\n",
      "1521  Gymnastics  1996  0.412312\n",
      "1586  Gymnastics  2000  0.438811\n",
      "1651  Gymnastics  2004  0.440487\n",
      "1716  Gymnastics  2008  0.436747\n",
      "1781  Gymnastics  2012  0.450472\n",
      "1846  Gymnastics  2016  0.444832\n",
      "1911  Gymnastics  2020  0.648148\n",
      "1976  Gymnastics  2024  0.352201\n",
      "\n",
      "Prepared time series data for Gymnastics (equity):\n",
      " Year\n",
      "1896    0.000000\n",
      "1900    0.000000\n",
      "1904    0.000000\n",
      "1906    0.000000\n",
      "1908    0.000000\n",
      "1912    0.000000\n",
      "1920    0.000000\n",
      "1924    0.000000\n",
      "1928    0.084337\n",
      "1932    0.000000\n",
      "1936    0.067582\n",
      "1948    0.083019\n",
      "1952    0.387286\n",
      "1956    0.470975\n",
      "1960    0.413517\n",
      "1964    0.319407\n",
      "1968    0.392380\n",
      "1972    0.444444\n",
      "1976    0.416944\n",
      "1980    0.413395\n",
      "1984    0.407527\n",
      "1988    0.428924\n",
      "1992    0.423904\n",
      "1996    0.412312\n",
      "2000    0.438811\n",
      "2004    0.440487\n",
      "2008    0.436747\n",
      "2012    0.450472\n",
      "2016    0.444832\n",
      "2020    0.648148\n",
      "2024    0.352201\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Handball (equity)\n",
      "Raw data for Handball (equity):\n",
      "          Sport  Year     Value\n",
      "677   Handball  1936  0.000000\n",
      "1132  Handball  1972  0.000000\n",
      "1197  Handball  1976  0.337449\n",
      "1262  Handball  1980  0.330645\n",
      "1327  Handball  1984  0.316602\n",
      "1392  Handball  1988  0.395018\n",
      "1457  Handball  1992  0.386986\n",
      "1522  Handball  1996  0.393333\n",
      "1587  Handball  2000  0.452012\n",
      "1652  Handball  2004  0.454268\n",
      "1717  Handball  2008  0.498542\n",
      "1782  Handball  2012  0.492795\n",
      "1847  Handball  2016  0.498584\n",
      "1912  Handball  2020  0.500000\n",
      "1977  Handball  2024  0.500000\n",
      "\n",
      "Prepared time series data for Handball (equity):\n",
      " Year\n",
      "1936    0.000000\n",
      "1972    0.000000\n",
      "1976    0.337449\n",
      "1980    0.330645\n",
      "1984    0.316602\n",
      "1988    0.395018\n",
      "1992    0.386986\n",
      "1996    0.393333\n",
      "2000    0.452012\n",
      "2004    0.454268\n",
      "2008    0.498542\n",
      "2012    0.492795\n",
      "2016    0.498584\n",
      "2020    0.500000\n",
      "2024    0.500000\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Hockey (equity)\n",
      "Raw data for Hockey (equity):\n",
      "        Sport  Year     Value\n",
      "288   Hockey  1908  0.000000\n",
      "418   Hockey  1920  0.000000\n",
      "548   Hockey  1928  0.000000\n",
      "613   Hockey  1932  0.000000\n",
      "678   Hockey  1936  0.000000\n",
      "743   Hockey  1948  0.000000\n",
      "808   Hockey  1952  0.000000\n",
      "873   Hockey  1956  0.000000\n",
      "938   Hockey  1960  0.000000\n",
      "1003  Hockey  1964  0.000000\n",
      "1068  Hockey  1968  0.000000\n",
      "1133  Hockey  1972  0.000000\n",
      "1198  Hockey  1976  0.000000\n",
      "1263  Hockey  1980  0.486631\n",
      "1328  Hockey  1984  0.335664\n",
      "1393  Hockey  1988  0.394904\n",
      "1458  Hockey  1992  0.398089\n",
      "1523  Hockey  1996  0.400000\n",
      "1588  Hockey  2000  0.454286\n",
      "1653  Hockey  2004  0.454545\n",
      "1718  Hockey  2008  0.493540\n",
      "1783  Hockey  2012  0.493540\n",
      "1848  Hockey  2016  0.497436\n",
      "1913  Hockey  2020  0.500000\n",
      "1978  Hockey  2024  0.500000\n",
      "\n",
      "Prepared time series data for Hockey (equity):\n",
      " Year\n",
      "1908    0.000000\n",
      "1920    0.000000\n",
      "1928    0.000000\n",
      "1932    0.000000\n",
      "1936    0.000000\n",
      "1948    0.000000\n",
      "1952    0.000000\n",
      "1956    0.000000\n",
      "1960    0.000000\n",
      "1964    0.000000\n",
      "1968    0.000000\n",
      "1972    0.000000\n",
      "1976    0.000000\n",
      "1980    0.486631\n",
      "1984    0.335664\n",
      "1988    0.394904\n",
      "1992    0.398089\n",
      "1996    0.400000\n",
      "2000    0.454286\n",
      "2004    0.454545\n",
      "2008    0.493540\n",
      "2012    0.493540\n",
      "2016    0.497436\n",
      "2020    0.500000\n",
      "2024    0.500000\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Ice Hockey (equity)\n",
      "Raw data for Ice Hockey (equity):\n",
      "            Sport  Year  Value\n",
      "419   Ice Hockey  1920    0.0\n",
      "484   Ice Hockey  1924    0.0\n",
      "549   Ice Hockey  1928    0.0\n",
      "614   Ice Hockey  1932    0.0\n",
      "679   Ice Hockey  1936    0.0\n",
      "744   Ice Hockey  1948    0.0\n",
      "809   Ice Hockey  1952    0.0\n",
      "874   Ice Hockey  1956    0.0\n",
      "939   Ice Hockey  1960    0.0\n",
      "1004  Ice Hockey  1964    0.0\n",
      "1069  Ice Hockey  1968    0.0\n",
      "1134  Ice Hockey  1972    0.0\n",
      "1199  Ice Hockey  1976    0.0\n",
      "1264  Ice Hockey  1980    0.0\n",
      "1329  Ice Hockey  1984    0.0\n",
      "1394  Ice Hockey  1988    0.0\n",
      "1459  Ice Hockey  1992    0.0\n",
      "\n",
      "Prepared time series data for Ice Hockey (equity):\n",
      " Year\n",
      "1920    0.0\n",
      "1924    0.0\n",
      "1928    0.0\n",
      "1932    0.0\n",
      "1936    0.0\n",
      "1948    0.0\n",
      "1952    0.0\n",
      "1956    0.0\n",
      "1960    0.0\n",
      "1964    0.0\n",
      "1968    0.0\n",
      "1972    0.0\n",
      "1976    0.0\n",
      "1980    0.0\n",
      "1984    0.0\n",
      "1988    0.0\n",
      "1992    0.0\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Jeu De Paume (equity)\n",
      "Raw data for Jeu De Paume (equity):\n",
      "             Sport  Year  Value\n",
      "290  Jeu De Paume  1908    0.0\n",
      "\n",
      "Prepared time series data for Jeu De Paume (equity):\n",
      " Year\n",
      "1908    0.0\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Judo (equity)\n",
      "Raw data for Judo (equity):\n",
      "      Sport  Year     Value\n",
      "1006  Judo  1964  0.000000\n",
      "1136  Judo  1972  0.000000\n",
      "1201  Judo  1976  0.000000\n",
      "1266  Judo  1980  0.000000\n",
      "1331  Judo  1984  0.000000\n",
      "1396  Judo  1988  0.000000\n",
      "1461  Judo  1992  0.376443\n",
      "1526  Judo  1996  0.390181\n",
      "1591  Judo  2000  0.404523\n",
      "1656  Judo  2004  0.408854\n",
      "1721  Judo  2008  0.404145\n",
      "1786  Judo  2012  0.398438\n",
      "1851  Judo  2016  0.390746\n",
      "1916  Judo  2020  0.500000\n",
      "1981  Judo  2024  0.500000\n",
      "\n",
      "Prepared time series data for Judo (equity):\n",
      " Year\n",
      "1964    0.000000\n",
      "1972    0.000000\n",
      "1976    0.000000\n",
      "1980    0.000000\n",
      "1984    0.000000\n",
      "1988    0.000000\n",
      "1992    0.376443\n",
      "1996    0.390181\n",
      "2000    0.404523\n",
      "2004    0.408854\n",
      "2008    0.404145\n",
      "2012    0.398438\n",
      "2016    0.390746\n",
      "2020    0.500000\n",
      "2024    0.500000\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Lacrosse (equity)\n",
      "Raw data for Lacrosse (equity):\n",
      "         Sport  Year  Value\n",
      "162  Lacrosse  1904    0.0\n",
      "292  Lacrosse  1908    0.0\n",
      "\n",
      "Prepared time series data for Lacrosse (equity):\n",
      " Year\n",
      "1904    0.0\n",
      "1908    0.0\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Luge (equity)\n",
      "Raw data for Luge (equity):\n",
      "      Sport  Year     Value\n",
      "1008  Luge  1964  0.200000\n",
      "1073  Luge  1968  0.245283\n",
      "1138  Luge  1972  0.205607\n",
      "1203  Luge  1976  0.218487\n",
      "1268  Luge  1980  0.276596\n",
      "1333  Luge  1984  0.303371\n",
      "1398  Luge  1988  0.244898\n",
      "1463  Luge  1992  0.244898\n",
      "\n",
      "Prepared time series data for Luge (equity):\n",
      " Year\n",
      "1964    0.200000\n",
      "1968    0.245283\n",
      "1972    0.205607\n",
      "1976    0.218487\n",
      "1980    0.276596\n",
      "1984    0.303371\n",
      "1988    0.244898\n",
      "1992    0.244898\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Military Ski Patrol (equity)\n",
      "Raw data for Military Ski Patrol (equity):\n",
      "                    Sport  Year  Value\n",
      "489  Military Ski Patrol  1924    0.0\n",
      "\n",
      "Prepared time series data for Military Ski Patrol (equity):\n",
      " Year\n",
      "1924    0.0\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Modern Pentathlon (equity)\n",
      "Raw data for Modern Pentathlon (equity):\n",
      "                   Sport  Year  Value\n",
      "360   Modern Pentathlon  1912    0.0\n",
      "425   Modern Pentathlon  1920    0.0\n",
      "490   Modern Pentathlon  1924    0.0\n",
      "555   Modern Pentathlon  1928    0.0\n",
      "620   Modern Pentathlon  1932    0.0\n",
      "685   Modern Pentathlon  1936    0.0\n",
      "750   Modern Pentathlon  1948    0.0\n",
      "815   Modern Pentathlon  1952    0.0\n",
      "880   Modern Pentathlon  1956    0.0\n",
      "945   Modern Pentathlon  1960    0.0\n",
      "1010  Modern Pentathlon  1964    0.0\n",
      "1075  Modern Pentathlon  1968    0.0\n",
      "1140  Modern Pentathlon  1972    0.0\n",
      "1205  Modern Pentathlon  1976    0.0\n",
      "1270  Modern Pentathlon  1980    0.0\n",
      "1335  Modern Pentathlon  1984    0.0\n",
      "1400  Modern Pentathlon  1988    0.0\n",
      "1465  Modern Pentathlon  1992    0.0\n",
      "1530  Modern Pentathlon  1996    0.0\n",
      "1595  Modern Pentathlon  2000    0.5\n",
      "1660  Modern Pentathlon  2004    0.5\n",
      "1725  Modern Pentathlon  2008    0.5\n",
      "1790  Modern Pentathlon  2012    0.5\n",
      "1855  Modern Pentathlon  2016    0.5\n",
      "1920  Modern Pentathlon  2020    0.5\n",
      "1985  Modern Pentathlon  2024    0.5\n",
      "\n",
      "Prepared time series data for Modern Pentathlon (equity):\n",
      " Year\n",
      "1912    0.0\n",
      "1920    0.0\n",
      "1924    0.0\n",
      "1928    0.0\n",
      "1932    0.0\n",
      "1936    0.0\n",
      "1948    0.0\n",
      "1952    0.0\n",
      "1956    0.0\n",
      "1960    0.0\n",
      "1964    0.0\n",
      "1968    0.0\n",
      "1972    0.0\n",
      "1976    0.0\n",
      "1980    0.0\n",
      "1984    0.0\n",
      "1988    0.0\n",
      "1992    0.0\n",
      "1996    0.0\n",
      "2000    0.5\n",
      "2004    0.5\n",
      "2008    0.5\n",
      "2012    0.5\n",
      "2016    0.5\n",
      "2020    0.5\n",
      "2024    0.5\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Motorboating (equity)\n",
      "Raw data for Motorboating (equity):\n",
      "             Sport  Year     Value\n",
      "296  Motorboating  1908  0.058824\n",
      "\n",
      "Prepared time series data for Motorboating (equity):\n",
      " Year\n",
      "1908    0.058824\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Nordic Combined (equity)\n",
      "Raw data for Nordic Combined (equity):\n",
      "                 Sport  Year  Value\n",
      "492   Nordic Combined  1924    0.0\n",
      "557   Nordic Combined  1928    0.0\n",
      "622   Nordic Combined  1932    0.0\n",
      "687   Nordic Combined  1936    0.0\n",
      "752   Nordic Combined  1948    0.0\n",
      "817   Nordic Combined  1952    0.0\n",
      "882   Nordic Combined  1956    0.0\n",
      "947   Nordic Combined  1960    0.0\n",
      "1012  Nordic Combined  1964    0.0\n",
      "1077  Nordic Combined  1968    0.0\n",
      "1142  Nordic Combined  1972    0.0\n",
      "1207  Nordic Combined  1976    0.0\n",
      "1272  Nordic Combined  1980    0.0\n",
      "1337  Nordic Combined  1984    0.0\n",
      "1402  Nordic Combined  1988    0.0\n",
      "1467  Nordic Combined  1992    0.0\n",
      "\n",
      "Prepared time series data for Nordic Combined (equity):\n",
      " Year\n",
      "1924    0.0\n",
      "1928    0.0\n",
      "1932    0.0\n",
      "1936    0.0\n",
      "1948    0.0\n",
      "1952    0.0\n",
      "1956    0.0\n",
      "1960    0.0\n",
      "1964    0.0\n",
      "1968    0.0\n",
      "1972    0.0\n",
      "1976    0.0\n",
      "1980    0.0\n",
      "1984    0.0\n",
      "1988    0.0\n",
      "1992    0.0\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Polo (equity)\n",
      "Raw data for Polo (equity):\n",
      "     Sport  Year  Value\n",
      "103  Polo  1900    0.0\n",
      "298  Polo  1908    0.0\n",
      "428  Polo  1920    0.0\n",
      "493  Polo  1924    0.0\n",
      "688  Polo  1936    0.0\n",
      "\n",
      "Prepared time series data for Polo (equity):\n",
      " Year\n",
      "1900    0.0\n",
      "1908    0.0\n",
      "1920    0.0\n",
      "1924    0.0\n",
      "1936    0.0\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Racquets (equity)\n",
      "Raw data for Racquets (equity):\n",
      "         Sport  Year  Value\n",
      "299  Racquets  1908    0.0\n",
      "\n",
      "Prepared time series data for Racquets (equity):\n",
      " Year\n",
      "1908    0.0\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Rhythmic Gymnastics (equity)\n",
      "Raw data for Rhythmic Gymnastics (equity):\n",
      "                     Sport  Year  Value\n",
      "1340  Rhythmic Gymnastics  1984    1.0\n",
      "1405  Rhythmic Gymnastics  1988    1.0\n",
      "1470  Rhythmic Gymnastics  1992    1.0\n",
      "1535  Rhythmic Gymnastics  1996    1.0\n",
      "1600  Rhythmic Gymnastics  2000    1.0\n",
      "1665  Rhythmic Gymnastics  2004    1.0\n",
      "1730  Rhythmic Gymnastics  2008    1.0\n",
      "1795  Rhythmic Gymnastics  2012    1.0\n",
      "1860  Rhythmic Gymnastics  2016    1.0\n",
      "\n",
      "Prepared time series data for Rhythmic Gymnastics (equity):\n",
      " Year\n",
      "1984    1.0\n",
      "1988    1.0\n",
      "1992    1.0\n",
      "1996    1.0\n",
      "2000    1.0\n",
      "2004    1.0\n",
      "2008    1.0\n",
      "2012    1.0\n",
      "2016    1.0\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Roque (equity)\n",
      "Raw data for Roque (equity):\n",
      "      Sport  Year  Value\n",
      "171  Roque  1904    0.0\n",
      "\n",
      "Prepared time series data for Roque (equity):\n",
      " Year\n",
      "1904    0.0\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Rowing (equity)\n",
      "Raw data for Rowing (equity):\n",
      "        Sport  Year     Value\n",
      "107   Rowing  1900  0.000000\n",
      "172   Rowing  1904  0.000000\n",
      "237   Rowing  1906  0.000000\n",
      "302   Rowing  1908  0.000000\n",
      "367   Rowing  1912  0.000000\n",
      "432   Rowing  1920  0.000000\n",
      "497   Rowing  1924  0.000000\n",
      "562   Rowing  1928  0.000000\n",
      "627   Rowing  1932  0.000000\n",
      "692   Rowing  1936  0.000000\n",
      "757   Rowing  1948  0.000000\n",
      "822   Rowing  1952  0.000000\n",
      "887   Rowing  1956  0.000000\n",
      "952   Rowing  1960  0.000000\n",
      "1017  Rowing  1964  0.000000\n",
      "1082  Rowing  1968  0.000000\n",
      "1147  Rowing  1972  0.000000\n",
      "1212  Rowing  1976  0.351171\n",
      "1277  Rowing  1980  0.325820\n",
      "1342  Rowing  1984  0.384946\n",
      "1407  Rowing  1988  0.344551\n",
      "1472  Rowing  1992  0.319213\n",
      "1537  Rowing  1996  0.347826\n",
      "1602  Rowing  2000  0.345811\n",
      "1667  Rowing  2004  0.348837\n",
      "1732  Rowing  2008  0.351687\n",
      "1797  Rowing  2012  0.358182\n",
      "1862  Rowing  2016  0.398182\n",
      "1927  Rowing  2020  0.500000\n",
      "1992  Rowing  2024  0.500000\n",
      "\n",
      "Prepared time series data for Rowing (equity):\n",
      " Year\n",
      "1900    0.000000\n",
      "1904    0.000000\n",
      "1906    0.000000\n",
      "1908    0.000000\n",
      "1912    0.000000\n",
      "1920    0.000000\n",
      "1924    0.000000\n",
      "1928    0.000000\n",
      "1932    0.000000\n",
      "1936    0.000000\n",
      "1948    0.000000\n",
      "1952    0.000000\n",
      "1956    0.000000\n",
      "1960    0.000000\n",
      "1964    0.000000\n",
      "1968    0.000000\n",
      "1972    0.000000\n",
      "1976    0.351171\n",
      "1980    0.325820\n",
      "1984    0.384946\n",
      "1988    0.344551\n",
      "1992    0.319213\n",
      "1996    0.347826\n",
      "2000    0.345811\n",
      "2004    0.348837\n",
      "2008    0.351687\n",
      "2012    0.358182\n",
      "2016    0.398182\n",
      "2020    0.500000\n",
      "2024    0.500000\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Rugby (equity)\n",
      "Raw data for Rugby (equity):\n",
      "       Sport  Year  Value\n",
      "108   Rugby  1900    0.0\n",
      "303   Rugby  1908    0.0\n",
      "433   Rugby  1920    0.0\n",
      "498   Rugby  1924    0.0\n",
      "1928  Rugby  2020    0.5\n",
      "\n",
      "Prepared time series data for Rugby (equity):\n",
      " Year\n",
      "1900    0.0\n",
      "1908    0.0\n",
      "1920    0.0\n",
      "1924    0.0\n",
      "2020    0.5\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Rugby Sevens (equity)\n",
      "Raw data for Rugby Sevens (equity):\n",
      "              Sport  Year     Value\n",
      "1864  Rugby Sevens  2016  0.494983\n",
      "1994  Rugby Sevens  2024  0.500000\n",
      "\n",
      "Prepared time series data for Rugby Sevens (equity):\n",
      " Year\n",
      "2016    0.494983\n",
      "2024    0.500000\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Sailing (equity)\n",
      "Raw data for Sailing (equity):\n",
      "         Sport  Year     Value\n",
      "110   Sailing  1900  0.010714\n",
      "305   Sailing  1908  0.015625\n",
      "370   Sailing  1912  0.000000\n",
      "435   Sailing  1920  0.009901\n",
      "500   Sailing  1924  0.014493\n",
      "565   Sailing  1928  0.015625\n",
      "630   Sailing  1932  0.000000\n",
      "695   Sailing  1936  0.017442\n",
      "760   Sailing  1948  0.000000\n",
      "825   Sailing  1952  0.013216\n",
      "890   Sailing  1956  0.000000\n",
      "955   Sailing  1960  0.003448\n",
      "1020  Sailing  1964  0.004444\n",
      "1085  Sailing  1968  0.000000\n",
      "1150  Sailing  1972  0.000000\n",
      "1215  Sailing  1976  0.003891\n",
      "1280  Sailing  1980  0.006410\n",
      "1345  Sailing  1984  0.006667\n",
      "1410  Sailing  1988  0.117333\n",
      "1475  Sailing  1992  0.190476\n",
      "1540  Sailing  1996  0.218341\n",
      "1605  Sailing  2000  0.236318\n",
      "1670  Sailing  2004  0.346633\n",
      "1735  Sailing  2008  0.347500\n",
      "1800  Sailing  2012  0.374670\n",
      "1865  Sailing  2016  0.428947\n",
      "1930  Sailing  2020  0.500000\n",
      "1995  Sailing  2024  0.500000\n",
      "\n",
      "Prepared time series data for Sailing (equity):\n",
      " Year\n",
      "1900    0.010714\n",
      "1908    0.015625\n",
      "1912    0.000000\n",
      "1920    0.009901\n",
      "1924    0.014493\n",
      "1928    0.015625\n",
      "1932    0.000000\n",
      "1936    0.017442\n",
      "1948    0.000000\n",
      "1952    0.013216\n",
      "1956    0.000000\n",
      "1960    0.003448\n",
      "1964    0.004444\n",
      "1968    0.000000\n",
      "1972    0.000000\n",
      "1976    0.003891\n",
      "1980    0.006410\n",
      "1984    0.006667\n",
      "1988    0.117333\n",
      "1992    0.190476\n",
      "1996    0.218341\n",
      "2000    0.236318\n",
      "2004    0.346633\n",
      "2008    0.347500\n",
      "2012    0.374670\n",
      "2016    0.428947\n",
      "2020    0.500000\n",
      "2024    0.500000\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Shooting (equity)\n",
      "Raw data for Shooting (equity):\n",
      "          Sport  Year     Value\n",
      "46    Shooting  1896  0.000000\n",
      "111   Shooting  1900  0.000000\n",
      "241   Shooting  1906  0.000000\n",
      "306   Shooting  1908  0.000000\n",
      "371   Shooting  1912  0.000000\n",
      "436   Shooting  1920  0.000000\n",
      "501   Shooting  1924  0.000000\n",
      "631   Shooting  1932  0.000000\n",
      "696   Shooting  1936  0.000000\n",
      "761   Shooting  1948  0.000000\n",
      "826   Shooting  1952  0.000000\n",
      "891   Shooting  1956  0.000000\n",
      "956   Shooting  1960  0.000000\n",
      "1021  Shooting  1964  0.000000\n",
      "1086  Shooting  1968  0.007317\n",
      "1151  Shooting  1972  0.008475\n",
      "1216  Shooting  1976  0.024390\n",
      "1281  Shooting  1980  0.022472\n",
      "1346  Shooting  1984  0.170686\n",
      "1411  Shooting  1988  0.300917\n",
      "1476  Shooting  1992  0.317376\n",
      "1541  Shooting  1996  0.303922\n",
      "1606  Shooting  2000  0.375626\n",
      "1671  Shooting  2004  0.356631\n",
      "1736  Shooting  2008  0.370884\n",
      "1801  Shooting  2012  0.408929\n",
      "1866  Shooting  2016  0.385586\n",
      "1931  Shooting  2020  0.500000\n",
      "1996  Shooting  2024  0.500000\n",
      "\n",
      "Prepared time series data for Shooting (equity):\n",
      " Year\n",
      "1896    0.000000\n",
      "1900    0.000000\n",
      "1906    0.000000\n",
      "1908    0.000000\n",
      "1912    0.000000\n",
      "1920    0.000000\n",
      "1924    0.000000\n",
      "1932    0.000000\n",
      "1936    0.000000\n",
      "1948    0.000000\n",
      "1952    0.000000\n",
      "1956    0.000000\n",
      "1960    0.000000\n",
      "1964    0.000000\n",
      "1968    0.007317\n",
      "1972    0.008475\n",
      "1976    0.024390\n",
      "1980    0.022472\n",
      "1984    0.170686\n",
      "1988    0.300917\n",
      "1992    0.317376\n",
      "1996    0.303922\n",
      "2000    0.375626\n",
      "2004    0.356631\n",
      "2008    0.370884\n",
      "2012    0.408929\n",
      "2016    0.385586\n",
      "2020    0.500000\n",
      "2024    0.500000\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Short Track Speed Skating (equity)\n",
      "Raw data for Short Track Speed Skating (equity):\n",
      "                           Sport  Year     Value\n",
      "1477  Short Track Speed Skating  1992  0.475806\n",
      "\n",
      "Prepared time series data for Short Track Speed Skating (equity):\n",
      " Year\n",
      "1992    0.475806\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Skeleton (equity)\n",
      "Raw data for Skeleton (equity):\n",
      "         Sport  Year  Value\n",
      "568  Skeleton  1928    0.0\n",
      "763  Skeleton  1948    0.0\n",
      "\n",
      "Prepared time series data for Skeleton (equity):\n",
      " Year\n",
      "1928    0.0\n",
      "1948    0.0\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Ski Jumping (equity)\n",
      "Raw data for Ski Jumping (equity):\n",
      "             Sport  Year  Value\n",
      "504   Ski Jumping  1924    0.0\n",
      "569   Ski Jumping  1928    0.0\n",
      "634   Ski Jumping  1932    0.0\n",
      "699   Ski Jumping  1936    0.0\n",
      "764   Ski Jumping  1948    0.0\n",
      "829   Ski Jumping  1952    0.0\n",
      "894   Ski Jumping  1956    0.0\n",
      "959   Ski Jumping  1960    0.0\n",
      "1024  Ski Jumping  1964    0.0\n",
      "1089  Ski Jumping  1968    0.0\n",
      "1154  Ski Jumping  1972    0.0\n",
      "1219  Ski Jumping  1976    0.0\n",
      "1284  Ski Jumping  1980    0.0\n",
      "1349  Ski Jumping  1984    0.0\n",
      "1414  Ski Jumping  1988    0.0\n",
      "1479  Ski Jumping  1992    0.0\n",
      "\n",
      "Prepared time series data for Ski Jumping (equity):\n",
      " Year\n",
      "1924    0.0\n",
      "1928    0.0\n",
      "1932    0.0\n",
      "1936    0.0\n",
      "1948    0.0\n",
      "1952    0.0\n",
      "1956    0.0\n",
      "1960    0.0\n",
      "1964    0.0\n",
      "1968    0.0\n",
      "1972    0.0\n",
      "1976    0.0\n",
      "1980    0.0\n",
      "1984    0.0\n",
      "1988    0.0\n",
      "1992    0.0\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Snowboarding (equity)\n",
      "Raw data for Snowboarding (equity):\n",
      " Empty DataFrame\n",
      "Columns: [Sport, Year, Value]\n",
      "Index: []\n",
      "\n",
      "Prepared time series data for Snowboarding (equity):\n",
      " Series([], Name: Value, dtype: float64)\n",
      "\n",
      "Processing sport: Softball (equity)\n",
      "Raw data for Softball (equity):\n",
      "          Sport  Year  Value\n",
      "1546  Softball  1996    1.0\n",
      "1611  Softball  2000    1.0\n",
      "1676  Softball  2004    1.0\n",
      "1741  Softball  2008    1.0\n",
      "\n",
      "Prepared time series data for Softball (equity):\n",
      " Year\n",
      "1996    1.0\n",
      "2000    1.0\n",
      "2004    1.0\n",
      "2008    1.0\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Speed Skating (equity)\n",
      "Raw data for Speed Skating (equity):\n",
      "               Sport  Year     Value\n",
      "507   Speed Skating  1924  0.000000\n",
      "572   Speed Skating  1928  0.000000\n",
      "637   Speed Skating  1932  0.000000\n",
      "702   Speed Skating  1936  0.000000\n",
      "767   Speed Skating  1948  0.000000\n",
      "832   Speed Skating  1952  0.000000\n",
      "897   Speed Skating  1956  0.000000\n",
      "962   Speed Skating  1960  0.353414\n",
      "1027  Speed Skating  1964  0.397213\n",
      "1092  Speed Skating  1968  0.403571\n",
      "1157  Speed Skating  1972  0.471311\n",
      "1222  Speed Skating  1976  0.429150\n",
      "1287  Speed Skating  1980  0.432432\n",
      "1352  Speed Skating  1984  0.393293\n",
      "1417  Speed Skating  1988  0.426380\n",
      "1482  Speed Skating  1992  0.432203\n",
      "\n",
      "Prepared time series data for Speed Skating (equity):\n",
      " Year\n",
      "1924    0.000000\n",
      "1928    0.000000\n",
      "1932    0.000000\n",
      "1936    0.000000\n",
      "1948    0.000000\n",
      "1952    0.000000\n",
      "1956    0.000000\n",
      "1960    0.353414\n",
      "1964    0.397213\n",
      "1968    0.403571\n",
      "1972    0.471311\n",
      "1976    0.429150\n",
      "1980    0.432432\n",
      "1984    0.393293\n",
      "1988    0.426380\n",
      "1992    0.432203\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Swimming (equity)\n",
      "Raw data for Swimming (equity):\n",
      "          Sport  Year     Value\n",
      "53    Swimming  1896  0.000000\n",
      "118   Swimming  1900  0.000000\n",
      "183   Swimming  1904  0.000000\n",
      "248   Swimming  1906  0.000000\n",
      "313   Swimming  1908  0.000000\n",
      "378   Swimming  1912  0.213930\n",
      "443   Swimming  1920  0.224880\n",
      "508   Swimming  1924  0.315589\n",
      "573   Swimming  1928  0.388489\n",
      "638   Swimming  1932  0.394872\n",
      "703   Swimming  1936  0.370879\n",
      "768   Swimming  1948  0.364322\n",
      "833   Swimming  1952  0.376812\n",
      "898   Swimming  1956  0.435393\n",
      "963   Swimming  1960  0.395238\n",
      "1028  Swimming  1964  0.373641\n",
      "1093  Swimming  1968  0.434606\n",
      "1158  Swimming  1972  0.456057\n",
      "1223  Swimming  1976  0.469331\n",
      "1288  Swimming  1980  0.427070\n",
      "1353  Swimming  1984  0.370130\n",
      "1418  Swimming  1988  0.401487\n",
      "1483  Swimming  1992  0.407430\n",
      "1548  Swimming  1996  0.486239\n",
      "1613  Swimming  2000  0.432510\n",
      "1678  Swimming  2004  0.453646\n",
      "1743  Swimming  2008  0.474557\n",
      "1808  Swimming  2012  0.503901\n",
      "1873  Swimming  2016  0.485332\n",
      "1938  Swimming  2020  0.500000\n",
      "2003  Swimming  2024  0.500000\n",
      "\n",
      "Prepared time series data for Swimming (equity):\n",
      " Year\n",
      "1896    0.000000\n",
      "1900    0.000000\n",
      "1904    0.000000\n",
      "1906    0.000000\n",
      "1908    0.000000\n",
      "1912    0.213930\n",
      "1920    0.224880\n",
      "1924    0.315589\n",
      "1928    0.388489\n",
      "1932    0.394872\n",
      "1936    0.370879\n",
      "1948    0.364322\n",
      "1952    0.376812\n",
      "1956    0.435393\n",
      "1960    0.395238\n",
      "1964    0.373641\n",
      "1968    0.434606\n",
      "1972    0.456057\n",
      "1976    0.469331\n",
      "1980    0.427070\n",
      "1984    0.370130\n",
      "1988    0.401487\n",
      "1992    0.407430\n",
      "1996    0.486239\n",
      "2000    0.432510\n",
      "2004    0.453646\n",
      "2008    0.474557\n",
      "2012    0.503901\n",
      "2016    0.485332\n",
      "2020    0.500000\n",
      "2024    0.500000\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Synchronized Swimming (equity)\n",
      "Raw data for Synchronized Swimming (equity):\n",
      "                       Sport  Year  Value\n",
      "1354  Synchronized Swimming  1984    1.0\n",
      "1419  Synchronized Swimming  1988    1.0\n",
      "1484  Synchronized Swimming  1992    1.0\n",
      "1549  Synchronized Swimming  1996    1.0\n",
      "1614  Synchronized Swimming  2000    1.0\n",
      "1679  Synchronized Swimming  2004    1.0\n",
      "1744  Synchronized Swimming  2008    1.0\n",
      "1809  Synchronized Swimming  2012    1.0\n",
      "1874  Synchronized Swimming  2016    1.0\n",
      "1939  Synchronized Swimming  2020    1.0\n",
      "\n",
      "Prepared time series data for Synchronized Swimming (equity):\n",
      " Year\n",
      "1984    1.0\n",
      "1988    1.0\n",
      "1992    1.0\n",
      "1996    1.0\n",
      "2000    1.0\n",
      "2004    1.0\n",
      "2008    1.0\n",
      "2012    1.0\n",
      "2016    1.0\n",
      "2020    1.0\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Table Tennis (equity)\n",
      "Raw data for Table Tennis (equity):\n",
      "              Sport  Year     Value\n",
      "1420  Table Tennis  1988  0.378641\n",
      "1485  Table Tennis  1992  0.500000\n",
      "1550  Table Tennis  1996  0.498008\n",
      "1615  Table Tennis  2000  0.492537\n",
      "1680  Table Tennis  2004  0.507692\n",
      "1745  Table Tennis  2008  0.500000\n",
      "1810  Table Tennis  2012  0.504237\n",
      "1875  Table Tennis  2016  0.500000\n",
      "1940  Table Tennis  2020  0.500000\n",
      "2005  Table Tennis  2024  0.500000\n",
      "\n",
      "Prepared time series data for Table Tennis (equity):\n",
      " Year\n",
      "1988    0.378641\n",
      "1992    0.500000\n",
      "1996    0.498008\n",
      "2000    0.492537\n",
      "2004    0.507692\n",
      "2008    0.500000\n",
      "2012    0.504237\n",
      "2016    0.500000\n",
      "2020    0.500000\n",
      "2024    0.500000\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Taekwondo (equity)\n",
      "Raw data for Taekwondo (equity):\n",
      "           Sport  Year     Value\n",
      "1616  Taekwondo  2000  0.470588\n",
      "1681  Taekwondo  2004  0.483871\n",
      "1746  Taekwondo  2008  0.500000\n",
      "1811  Taekwondo  2012  0.500000\n",
      "1876  Taekwondo  2016  0.507937\n",
      "1941  Taekwondo  2020  0.500000\n",
      "2006  Taekwondo  2024  0.500000\n",
      "\n",
      "Prepared time series data for Taekwondo (equity):\n",
      " Year\n",
      "2000    0.470588\n",
      "2004    0.483871\n",
      "2008    0.500000\n",
      "2012    0.500000\n",
      "2016    0.507937\n",
      "2020    0.500000\n",
      "2024    0.500000\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Tennis (equity)\n",
      "Raw data for Tennis (equity):\n",
      "        Sport  Year     Value\n",
      "57    Tennis  1896  0.000000\n",
      "122   Tennis  1900  0.255319\n",
      "187   Tennis  1904  0.000000\n",
      "252   Tennis  1906  0.229167\n",
      "317   Tennis  1908  0.142857\n",
      "382   Tennis  1912  0.173410\n",
      "447   Tennis  1920  0.339869\n",
      "512   Tennis  1924  0.292490\n",
      "1422  Tennis  1988  0.376238\n",
      "1487  Tennis  1992  0.504000\n",
      "1552  Tennis  1996  0.487805\n",
      "1617  Tennis  2000  0.508065\n",
      "1682  Tennis  2004  0.507937\n",
      "1747  Tennis  2008  0.496063\n",
      "1812  Tennis  2012  0.496503\n",
      "1877  Tennis  2016  0.500000\n",
      "1942  Tennis  2020  0.500000\n",
      "2007  Tennis  2024  0.500000\n",
      "\n",
      "Prepared time series data for Tennis (equity):\n",
      " Year\n",
      "1896    0.000000\n",
      "1900    0.255319\n",
      "1904    0.000000\n",
      "1906    0.229167\n",
      "1908    0.142857\n",
      "1912    0.173410\n",
      "1920    0.339869\n",
      "1924    0.292490\n",
      "1988    0.376238\n",
      "1992    0.504000\n",
      "1996    0.487805\n",
      "2000    0.508065\n",
      "2004    0.507937\n",
      "2008    0.496063\n",
      "2012    0.496503\n",
      "2016    0.500000\n",
      "2020    0.500000\n",
      "2024    0.500000\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Trampolining (equity)\n",
      "Raw data for Trampolining (equity):\n",
      "              Sport  Year  Value\n",
      "1618  Trampolining  2000    0.5\n",
      "1683  Trampolining  2004    0.5\n",
      "1748  Trampolining  2008    0.5\n",
      "1813  Trampolining  2012    0.5\n",
      "1878  Trampolining  2016    0.5\n",
      "\n",
      "Prepared time series data for Trampolining (equity):\n",
      " Year\n",
      "2000    0.5\n",
      "2004    0.5\n",
      "2008    0.5\n",
      "2012    0.5\n",
      "2016    0.5\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Triathlon (equity)\n",
      "Raw data for Triathlon (equity):\n",
      "           Sport  Year     Value\n",
      "1619  Triathlon  2000  0.480000\n",
      "1684  Triathlon  2004  0.505051\n",
      "1749  Triathlon  2008  0.500000\n",
      "1814  Triathlon  2012  0.500000\n",
      "1879  Triathlon  2016  0.500000\n",
      "1944  Triathlon  2020  0.500000\n",
      "2009  Triathlon  2024  0.500000\n",
      "\n",
      "Prepared time series data for Triathlon (equity):\n",
      " Year\n",
      "2000    0.480000\n",
      "2004    0.505051\n",
      "2008    0.500000\n",
      "2012    0.500000\n",
      "2016    0.500000\n",
      "2020    0.500000\n",
      "2024    0.500000\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Tug-Of-War (equity)\n",
      "Raw data for Tug-Of-War (equity):\n",
      "           Sport  Year  Value\n",
      "125  Tug-Of-War  1900    0.0\n",
      "190  Tug-Of-War  1904    0.0\n",
      "255  Tug-Of-War  1906    0.0\n",
      "320  Tug-Of-War  1908    0.0\n",
      "385  Tug-Of-War  1912    0.0\n",
      "450  Tug-Of-War  1920    0.0\n",
      "\n",
      "Prepared time series data for Tug-Of-War (equity):\n",
      " Year\n",
      "1900    0.0\n",
      "1904    0.0\n",
      "1906    0.0\n",
      "1908    0.0\n",
      "1912    0.0\n",
      "1920    0.0\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Volleyball (equity)\n",
      "Raw data for Volleyball (equity):\n",
      "            Sport  Year     Value\n",
      "1036  Volleyball  1964  0.379888\n",
      "1101  Volleyball  1968  0.422330\n",
      "1166  Volleyball  1972  0.393939\n",
      "1231  Volleyball  1976  0.444444\n",
      "1296  Volleyball  1980  0.441176\n",
      "1361  Volleyball  1984  0.432692\n",
      "1426  Volleyball  1988  0.397490\n",
      "1491  Volleyball  1992  0.385281\n",
      "1556  Volleyball  1996  0.487273\n",
      "1621  Volleyball  2000  0.494624\n",
      "1686  Volleyball  2004  0.494700\n",
      "1751  Volleyball  2008  0.494700\n",
      "1816  Volleyball  2012  0.498258\n",
      "1881  Volleyball  2016  0.501767\n",
      "1946  Volleyball  2020  0.500000\n",
      "2011  Volleyball  2024  0.500000\n",
      "\n",
      "Prepared time series data for Volleyball (equity):\n",
      " Year\n",
      "1964    0.379888\n",
      "1968    0.422330\n",
      "1972    0.393939\n",
      "1976    0.444444\n",
      "1980    0.441176\n",
      "1984    0.432692\n",
      "1988    0.397490\n",
      "1992    0.385281\n",
      "1996    0.487273\n",
      "2000    0.494624\n",
      "2004    0.494700\n",
      "2008    0.494700\n",
      "2012    0.498258\n",
      "2016    0.501767\n",
      "2020    0.500000\n",
      "2024    0.500000\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Water Polo (equity)\n",
      "Raw data for Water Polo (equity):\n",
      "            Sport  Year     Value\n",
      "127   Water Polo  1900  0.000000\n",
      "192   Water Polo  1904  0.000000\n",
      "322   Water Polo  1908  0.000000\n",
      "387   Water Polo  1912  0.000000\n",
      "452   Water Polo  1920  0.000000\n",
      "517   Water Polo  1924  0.000000\n",
      "582   Water Polo  1928  0.000000\n",
      "647   Water Polo  1932  0.000000\n",
      "712   Water Polo  1936  0.000000\n",
      "777   Water Polo  1948  0.000000\n",
      "842   Water Polo  1952  0.000000\n",
      "907   Water Polo  1956  0.000000\n",
      "972   Water Polo  1960  0.000000\n",
      "1037  Water Polo  1964  0.000000\n",
      "1102  Water Polo  1968  0.000000\n",
      "1167  Water Polo  1972  0.000000\n",
      "1232  Water Polo  1976  0.000000\n",
      "1297  Water Polo  1980  0.000000\n",
      "1362  Water Polo  1984  0.000000\n",
      "1427  Water Polo  1988  0.000000\n",
      "1492  Water Polo  1992  0.000000\n",
      "1557  Water Polo  1996  0.000000\n",
      "1622  Water Polo  2000  0.337662\n",
      "1687  Water Polo  2004  0.396078\n",
      "1752  Water Polo  2008  0.402344\n",
      "1817  Water Polo  2012  0.396887\n",
      "1882  Water Polo  2016  0.403101\n",
      "1947  Water Polo  2020  0.454545\n",
      "2012  Water Polo  2024  0.545455\n",
      "\n",
      "Prepared time series data for Water Polo (equity):\n",
      " Year\n",
      "1900    0.000000\n",
      "1904    0.000000\n",
      "1908    0.000000\n",
      "1912    0.000000\n",
      "1920    0.000000\n",
      "1924    0.000000\n",
      "1928    0.000000\n",
      "1932    0.000000\n",
      "1936    0.000000\n",
      "1948    0.000000\n",
      "1952    0.000000\n",
      "1956    0.000000\n",
      "1960    0.000000\n",
      "1964    0.000000\n",
      "1968    0.000000\n",
      "1972    0.000000\n",
      "1976    0.000000\n",
      "1980    0.000000\n",
      "1984    0.000000\n",
      "1988    0.000000\n",
      "1992    0.000000\n",
      "1996    0.000000\n",
      "2000    0.337662\n",
      "2004    0.396078\n",
      "2008    0.402344\n",
      "2012    0.396887\n",
      "2016    0.403101\n",
      "2020    0.454545\n",
      "2024    0.545455\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Weightlifting (equity)\n",
      "Raw data for Weightlifting (equity):\n",
      "               Sport  Year     Value\n",
      "63    Weightlifting  1896  0.000000\n",
      "193   Weightlifting  1904  0.000000\n",
      "258   Weightlifting  1906  0.000000\n",
      "453   Weightlifting  1920  0.000000\n",
      "518   Weightlifting  1924  0.000000\n",
      "583   Weightlifting  1928  0.000000\n",
      "648   Weightlifting  1932  0.000000\n",
      "713   Weightlifting  1936  0.000000\n",
      "778   Weightlifting  1948  0.000000\n",
      "843   Weightlifting  1952  0.000000\n",
      "908   Weightlifting  1956  0.000000\n",
      "973   Weightlifting  1960  0.000000\n",
      "1038  Weightlifting  1964  0.000000\n",
      "1103  Weightlifting  1968  0.000000\n",
      "1168  Weightlifting  1972  0.000000\n",
      "1233  Weightlifting  1976  0.000000\n",
      "1298  Weightlifting  1980  0.000000\n",
      "1363  Weightlifting  1984  0.000000\n",
      "1428  Weightlifting  1988  0.000000\n",
      "1493  Weightlifting  1992  0.000000\n",
      "1558  Weightlifting  1996  0.000000\n",
      "1623  Weightlifting  2000  0.345528\n",
      "1688  Weightlifting  2004  0.341365\n",
      "1753  Weightlifting  2008  0.343874\n",
      "1818  Weightlifting  2012  0.408730\n",
      "1883  Weightlifting  2016  0.403922\n",
      "1948  Weightlifting  2020  0.500000\n",
      "2013  Weightlifting  2024  0.500000\n",
      "\n",
      "Prepared time series data for Weightlifting (equity):\n",
      " Year\n",
      "1896    0.000000\n",
      "1904    0.000000\n",
      "1906    0.000000\n",
      "1920    0.000000\n",
      "1924    0.000000\n",
      "1928    0.000000\n",
      "1932    0.000000\n",
      "1936    0.000000\n",
      "1948    0.000000\n",
      "1952    0.000000\n",
      "1956    0.000000\n",
      "1960    0.000000\n",
      "1964    0.000000\n",
      "1968    0.000000\n",
      "1972    0.000000\n",
      "1976    0.000000\n",
      "1980    0.000000\n",
      "1984    0.000000\n",
      "1988    0.000000\n",
      "1992    0.000000\n",
      "1996    0.000000\n",
      "2000    0.345528\n",
      "2004    0.341365\n",
      "2008    0.343874\n",
      "2012    0.408730\n",
      "2016    0.403922\n",
      "2020    0.500000\n",
      "2024    0.500000\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Wrestling (equity)\n",
      "Raw data for Wrestling (equity):\n",
      "           Sport  Year     Value\n",
      "64    Wrestling  1896  0.000000\n",
      "194   Wrestling  1904  0.000000\n",
      "259   Wrestling  1906  0.000000\n",
      "324   Wrestling  1908  0.000000\n",
      "389   Wrestling  1912  0.000000\n",
      "454   Wrestling  1920  0.000000\n",
      "519   Wrestling  1924  0.000000\n",
      "584   Wrestling  1928  0.000000\n",
      "649   Wrestling  1932  0.000000\n",
      "714   Wrestling  1936  0.000000\n",
      "779   Wrestling  1948  0.000000\n",
      "844   Wrestling  1952  0.000000\n",
      "909   Wrestling  1956  0.000000\n",
      "974   Wrestling  1960  0.000000\n",
      "1039  Wrestling  1964  0.000000\n",
      "1104  Wrestling  1968  0.000000\n",
      "1169  Wrestling  1972  0.000000\n",
      "1234  Wrestling  1976  0.000000\n",
      "1299  Wrestling  1980  0.000000\n",
      "1364  Wrestling  1984  0.000000\n",
      "1429  Wrestling  1988  0.000000\n",
      "1494  Wrestling  1992  0.000000\n",
      "1559  Wrestling  1996  0.000000\n",
      "1624  Wrestling  2000  0.000000\n",
      "1689  Wrestling  2004  0.146199\n",
      "1754  Wrestling  2008  0.192420\n",
      "1819  Wrestling  2012  0.224189\n",
      "1884  Wrestling  2016  0.323699\n",
      "1949  Wrestling  2020  0.333333\n",
      "2014  Wrestling  2024  0.666667\n",
      "\n",
      "Prepared time series data for Wrestling (equity):\n",
      " Year\n",
      "1896    0.000000\n",
      "1904    0.000000\n",
      "1906    0.000000\n",
      "1908    0.000000\n",
      "1912    0.000000\n",
      "1920    0.000000\n",
      "1924    0.000000\n",
      "1928    0.000000\n",
      "1932    0.000000\n",
      "1936    0.000000\n",
      "1948    0.000000\n",
      "1952    0.000000\n",
      "1956    0.000000\n",
      "1960    0.000000\n",
      "1964    0.000000\n",
      "1968    0.000000\n",
      "1972    0.000000\n",
      "1976    0.000000\n",
      "1980    0.000000\n",
      "1984    0.000000\n",
      "1988    0.000000\n",
      "1992    0.000000\n",
      "1996    0.000000\n",
      "2000    0.000000\n",
      "2004    0.146199\n",
      "2008    0.192420\n",
      "2012    0.224189\n",
      "2016    0.323699\n",
      "2020    0.333333\n",
      "2024    0.666667\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing parameter: popularity\n",
      "\n",
      "Processing sport: Alpine Skiing (popularity)\n",
      "Raw data for Alpine Skiing (popularity):\n",
      "               Sport  Year     Value\n",
      "650   Alpine Skiing  1936  0.013919\n",
      "715   Alpine Skiing  1948  0.048128\n",
      "780   Alpine Skiing  1952  0.040393\n",
      "845   Alpine Skiing  1956  0.062636\n",
      "910   Alpine Skiing  1960  0.034651\n",
      "975   Alpine Skiing  1964  0.043354\n",
      "1040  Alpine Skiing  1968  0.040271\n",
      "1105  Alpine Skiing  1972  0.027176\n",
      "1170  Alpine Skiing  1976  0.037136\n",
      "1235  Alpine Skiing  1980  0.036589\n",
      "1300  Alpine Skiing  1984  0.034605\n",
      "1365  Alpine Skiing  1988  0.045516\n",
      "1430  Alpine Skiing  1992  0.045695\n",
      "\n",
      "Prepared time series data for Alpine Skiing (popularity):\n",
      " Year\n",
      "1936    0.013919\n",
      "1948    0.048128\n",
      "1952    0.040393\n",
      "1956    0.062636\n",
      "1960    0.034651\n",
      "1964    0.043354\n",
      "1968    0.040271\n",
      "1972    0.027176\n",
      "1976    0.037136\n",
      "1980    0.036589\n",
      "1984    0.034605\n",
      "1988    0.045516\n",
      "1992    0.045695\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Alpinism (popularity)\n",
      "Raw data for Alpinism (popularity):\n",
      "         Sport  Year     Value\n",
      "456  Alpinism  1924  0.003689\n",
      "586  Alpinism  1932  0.000602\n",
      "651  Alpinism  1936  0.000270\n",
      "\n",
      "Prepared time series data for Alpinism (popularity):\n",
      " Year\n",
      "1924    0.003689\n",
      "1932    0.000602\n",
      "1936    0.000270\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Archery (popularity)\n",
      "Raw data for Archery (popularity):\n",
      "         Sport  Year     Value\n",
      "67    Archery  1900  0.016529\n",
      "132   Archery  1904  0.053805\n",
      "262   Archery  1908  0.024831\n",
      "392   Archery  1920  0.020037\n",
      "1107  Archery  1972  0.007944\n",
      "1172  Archery  1976  0.006094\n",
      "1237  Archery  1980  0.007497\n",
      "1302  Archery  1984  0.009406\n",
      "1367  Archery  1988  0.017512\n",
      "1432  Archery  1992  0.015049\n",
      "1497  Archery  1996  0.015820\n",
      "1562  Archery  2000  0.014905\n",
      "1627  Archery  2004  0.015770\n",
      "1692  Archery  2008  0.014263\n",
      "1757  Archery  2012  0.015480\n",
      "1822  Archery  2016  0.014611\n",
      "1887  Archery  2020  0.012112\n",
      "1952  Archery  2024  0.012554\n",
      "\n",
      "Prepared time series data for Archery (popularity):\n",
      " Year\n",
      "1900    0.016529\n",
      "1904    0.053805\n",
      "1908    0.024831\n",
      "1920    0.020037\n",
      "1972    0.007944\n",
      "1976    0.006094\n",
      "1980    0.007497\n",
      "1984    0.009406\n",
      "1988    0.017512\n",
      "1992    0.015049\n",
      "1996    0.015820\n",
      "2000    0.014905\n",
      "2004    0.015770\n",
      "2008    0.014263\n",
      "2012    0.015480\n",
      "2016    0.014611\n",
      "2020    0.012112\n",
      "2024    0.012554\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Art Competitions (popularity)\n",
      "Raw data for Art Competitions (popularity):\n",
      "                 Sport  Year     Value\n",
      "328  Art Competitions  1912  0.008168\n",
      "393  Art Competitions  1920  0.002563\n",
      "458  Art Competitions  1924  0.055858\n",
      "523  Art Competitions  1928  0.144959\n",
      "588  Art Competitions  1932  0.338452\n",
      "653  Art Competitions  1936  0.109865\n",
      "718  Art Competitions  1948  0.062968\n",
      "\n",
      "Prepared time series data for Art Competitions (popularity):\n",
      " Year\n",
      "1912    0.008168\n",
      "1920    0.002563\n",
      "1924    0.055858\n",
      "1928    0.144959\n",
      "1932    0.338452\n",
      "1936    0.109865\n",
      "1948    0.062968\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Athletics (popularity)\n",
      "Raw data for Athletics (popularity):\n",
      "           Sport  Year     Value\n",
      "4     Athletics  1896  0.278947\n",
      "69    Athletics  1900  0.120868\n",
      "134   Athletics  1904  0.154497\n",
      "199   Athletics  1906  0.271206\n",
      "264   Athletics  1908  0.250887\n",
      "329   Athletics  1912  0.238119\n",
      "394   Athletics  1920  0.197810\n",
      "459   Athletics  1924  0.176181\n",
      "524   Athletics  1928  0.177969\n",
      "589   Athletics  1932  0.157182\n",
      "654   Athletics  1936  0.136081\n",
      "719   Athletics  1948  0.140508\n",
      "784   Athletics  1952  0.143620\n",
      "849   Athletics  1956  0.157445\n",
      "914   Athletics  1960  0.142068\n",
      "979   Athletics  1964  0.140823\n",
      "1044  Athletics  1968  0.128352\n",
      "1109  Athletics  1972  0.140982\n",
      "1174  Athletics  1976  0.123500\n",
      "1239  Athletics  1980  0.141882\n",
      "1304  Athletics  1984  0.144460\n",
      "1369  Athletics  1988  0.140501\n",
      "1434  Athletics  1992  0.125145\n",
      "1499  Athletics  1996  0.173149\n",
      "1564  Athletics  2000  0.178569\n",
      "1629  Athletics  2004  0.161794\n",
      "1694  Athletics  2008  0.164976\n",
      "1759  Athletics  2012  0.176316\n",
      "1824  Athletics  2016  0.183226\n",
      "1889  Athletics  2020  0.179788\n",
      "1954  Athletics  2024  0.177521\n",
      "\n",
      "Prepared time series data for Athletics (popularity):\n",
      " Year\n",
      "1896    0.278947\n",
      "1900    0.120868\n",
      "1904    0.154497\n",
      "1906    0.271206\n",
      "1908    0.250887\n",
      "1912    0.238119\n",
      "1920    0.197810\n",
      "1924    0.176181\n",
      "1928    0.177969\n",
      "1932    0.157182\n",
      "1936    0.136081\n",
      "1948    0.140508\n",
      "1952    0.143620\n",
      "1956    0.157445\n",
      "1960    0.142068\n",
      "1964    0.140823\n",
      "1968    0.128352\n",
      "1972    0.140982\n",
      "1976    0.123500\n",
      "1980    0.141882\n",
      "1984    0.144460\n",
      "1988    0.140501\n",
      "1992    0.125145\n",
      "1996    0.173149\n",
      "2000    0.178569\n",
      "2004    0.161794\n",
      "2008    0.164976\n",
      "2012    0.176316\n",
      "2016    0.183226\n",
      "2020    0.179788\n",
      "2024    0.177521\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Badminton (popularity)\n",
      "Raw data for Badminton (popularity):\n",
      "           Sport  Year     Value\n",
      "1435  Badminton  1992  0.013770\n",
      "1500  Badminton  1996  0.019086\n",
      "1565  Badminton  2000  0.016280\n",
      "1630  Badminton  2004  0.014878\n",
      "1695  Badminton  2008  0.013527\n",
      "1760  Badminton  2012  0.014087\n",
      "1825  Badminton  2016  0.012931\n",
      "1890  Badminton  2020  0.016276\n",
      "1955  Badminton  2024  0.016869\n",
      "\n",
      "Prepared time series data for Badminton (popularity):\n",
      " Year\n",
      "1992    0.013770\n",
      "1996    0.019086\n",
      "2000    0.016280\n",
      "2004    0.014878\n",
      "2008    0.013527\n",
      "2012    0.014087\n",
      "2016    0.012931\n",
      "2020    0.016276\n",
      "2024    0.016869\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Baseball (popularity)\n",
      "Raw data for Baseball (popularity):\n",
      "          Sport  Year     Value\n",
      "1436  Baseball  1992  0.009748\n",
      "1501  Baseball  1996  0.011611\n",
      "1566  Baseball  2000  0.013892\n",
      "1631  Baseball  2004  0.014208\n",
      "1696  Baseball  2008  0.014042\n",
      "\n",
      "Prepared time series data for Baseball (popularity):\n",
      " Year\n",
      "1992    0.009748\n",
      "1996    0.011611\n",
      "2000    0.013892\n",
      "2004    0.014208\n",
      "2008    0.014042\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Basketball (popularity)\n",
      "Raw data for Basketball (popularity):\n",
      "            Sport  Year     Value\n",
      "657   Basketball  1936  0.026892\n",
      "722   Basketball  1948  0.038369\n",
      "787   Basketball  1952  0.031417\n",
      "852   Basketball  1956  0.026267\n",
      "917   Basketball  1960  0.020790\n",
      "982   Basketball  1964  0.019937\n",
      "1047  Basketball  1968  0.018227\n",
      "1112  Basketball  1972  0.015888\n",
      "1177  Basketball  1976  0.020282\n",
      "1242  Basketball  1980  0.024057\n",
      "1307  Basketball  1984  0.018381\n",
      "1372  Basketball  1988  0.016081\n",
      "1437  Basketball  1992  0.014379\n",
      "1502  Basketball  1996  0.020610\n",
      "1567  Basketball  2000  0.020693\n",
      "1632  Basketball  2004  0.021349\n",
      "1697  Basketball  2008  0.021100\n",
      "1762  Basketball  2012  0.022214\n",
      "1827  Basketball  2016  0.020529\n",
      "1892  Basketball  2020  0.033308\n",
      "1957  Basketball  2024  0.034523\n",
      "\n",
      "Prepared time series data for Basketball (popularity):\n",
      " Year\n",
      "1936    0.026892\n",
      "1948    0.038369\n",
      "1952    0.031417\n",
      "1956    0.026267\n",
      "1960    0.020790\n",
      "1964    0.019937\n",
      "1968    0.018227\n",
      "1972    0.015888\n",
      "1976    0.020282\n",
      "1980    0.024057\n",
      "1984    0.018381\n",
      "1988    0.016081\n",
      "1992    0.014379\n",
      "1996    0.020610\n",
      "2000    0.020693\n",
      "2004    0.021349\n",
      "2008    0.021100\n",
      "2012    0.022214\n",
      "2016    0.020529\n",
      "2020    0.033308\n",
      "2024    0.034523\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Basque Pelota (popularity)\n",
      "Raw data for Basque Pelota (popularity):\n",
      "             Sport  Year     Value\n",
      "73  Basque Pelota  1900  0.001033\n",
      "\n",
      "Prepared time series data for Basque Pelota (popularity):\n",
      " Year\n",
      "1900    0.001033\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Beach Volleyball (popularity)\n",
      "Raw data for Beach Volleyball (popularity):\n",
      "                  Sport  Year     Value\n",
      "1504  Beach Volleyball  1996  0.006096\n",
      "1569  Beach Volleyball  2000  0.006946\n",
      "1634  Beach Volleyball  2004  0.007141\n",
      "1699  Beach Volleyball  2008  0.007058\n",
      "1764  Beach Volleyball  2012  0.007430\n",
      "1829  Beach Volleyball  2016  0.007013\n",
      "1959  Beach Volleyball  2024  0.009415\n",
      "\n",
      "Prepared time series data for Beach Volleyball (popularity):\n",
      " Year\n",
      "1996    0.006096\n",
      "2000    0.006946\n",
      "2004    0.007141\n",
      "2008    0.007058\n",
      "2012    0.007430\n",
      "2016    0.007013\n",
      "2024    0.009415\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Biathlon (popularity)\n",
      "Raw data for Biathlon (popularity):\n",
      "          Sport  Year     Value\n",
      "920   Biathlon  1960  0.003249\n",
      "985   Biathlon  1964  0.005380\n",
      "1050  Biathlon  1968  0.011070\n",
      "1115  Biathlon  1972  0.008864\n",
      "1180  Biathlon  1976  0.010665\n",
      "1245  Biathlon  1980  0.017791\n",
      "1310  Biathlon  1984  0.016828\n",
      "1375  Biathlon  1988  0.014105\n",
      "1440  Biathlon  1992  0.027844\n",
      "\n",
      "Prepared time series data for Biathlon (popularity):\n",
      " Year\n",
      "1960    0.003249\n",
      "1964    0.005380\n",
      "1968    0.011070\n",
      "1972    0.008864\n",
      "1976    0.010665\n",
      "1980    0.017791\n",
      "1984    0.016828\n",
      "1988    0.014105\n",
      "1992    0.027844\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Bobsleigh (popularity)\n",
      "Raw data for Bobsleigh (popularity):\n",
      "           Sport  Year     Value\n",
      "466   Bobsleigh  1924  0.006851\n",
      "531   Bobsleigh  1928  0.020811\n",
      "596   Bobsleigh  1932  0.015658\n",
      "661   Bobsleigh  1936  0.015946\n",
      "726   Bobsleigh  1948  0.012299\n",
      "791   Bobsleigh  1952  0.010259\n",
      "856   Bobsleigh  1956  0.020982\n",
      "986   Bobsleigh  1964  0.012342\n",
      "1051  Bobsleigh  1968  0.011451\n",
      "1116  Bobsleigh  1972  0.009533\n",
      "1181  Bobsleigh  1976  0.012664\n",
      "1246  Bobsleigh  1980  0.012085\n",
      "1311  Bobsleigh  1984  0.013117\n",
      "1376  Bobsleigh  1988  0.012674\n",
      "1441  Bobsleigh  1992  0.013160\n",
      "\n",
      "Prepared time series data for Bobsleigh (popularity):\n",
      " Year\n",
      "1924    0.006851\n",
      "1928    0.020811\n",
      "1932    0.015658\n",
      "1936    0.015946\n",
      "1948    0.012299\n",
      "1952    0.010259\n",
      "1956    0.020982\n",
      "1964    0.012342\n",
      "1968    0.011451\n",
      "1972    0.009533\n",
      "1976    0.012664\n",
      "1980    0.012085\n",
      "1984    0.013117\n",
      "1988    0.012674\n",
      "1992    0.013160\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Boxing (popularity)\n",
      "Raw data for Boxing (popularity):\n",
      "        Sport  Year     Value\n",
      "142   Boxing  1904  0.018447\n",
      "272   Boxing  1908  0.013544\n",
      "402   Boxing  1920  0.027027\n",
      "467   Boxing  1924  0.031793\n",
      "532   Boxing  1928  0.025834\n",
      "597   Boxing  1932  0.025595\n",
      "662   Boxing  1936  0.024189\n",
      "727   Boxing  1948  0.027406\n",
      "792   Boxing  1952  0.026608\n",
      "857   Boxing  1956  0.025023\n",
      "922   Boxing  1960  0.030428\n",
      "987   Boxing  1964  0.028376\n",
      "1052  Boxing  1968  0.029297\n",
      "1117  Boxing  1972  0.029601\n",
      "1182  Boxing  1976  0.025329\n",
      "1247  Boxing  1980  0.030323\n",
      "1312  Boxing  1984  0.030549\n",
      "1377  Boxing  1988  0.029436\n",
      "1442  Boxing  1992  0.020472\n",
      "1507  Boxing  1996  0.025762\n",
      "1572  Boxing  2000  0.022213\n",
      "1637  Boxing  2004  0.020829\n",
      "1702  Boxing  2008  0.020806\n",
      "1767  Boxing  2012  0.021904\n",
      "1832  Boxing  2016  0.020675\n",
      "1897  Boxing  2020  0.027063\n",
      "1962  Boxing  2024  0.024323\n",
      "\n",
      "Prepared time series data for Boxing (popularity):\n",
      " Year\n",
      "1904    0.018447\n",
      "1908    0.013544\n",
      "1920    0.027027\n",
      "1924    0.031793\n",
      "1928    0.025834\n",
      "1932    0.025595\n",
      "1936    0.024189\n",
      "1948    0.027406\n",
      "1952    0.026608\n",
      "1956    0.025023\n",
      "1960    0.030428\n",
      "1964    0.028376\n",
      "1968    0.029297\n",
      "1972    0.029601\n",
      "1976    0.025329\n",
      "1980    0.030323\n",
      "1984    0.030549\n",
      "1988    0.029436\n",
      "1992    0.020472\n",
      "1996    0.025762\n",
      "2000    0.022213\n",
      "2004    0.020829\n",
      "2008    0.020806\n",
      "2012    0.021904\n",
      "2016    0.020675\n",
      "2020    0.027063\n",
      "2024    0.024323\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Canoeing (popularity)\n",
      "Raw data for Canoeing (popularity):\n",
      "          Sport  Year     Value\n",
      "663   Canoeing  1936  0.019324\n",
      "728   Canoeing  1948  0.018583\n",
      "793   Canoeing  1952  0.019662\n",
      "858   Canoeing  1956  0.022692\n",
      "923   Canoeing  1960  0.022848\n",
      "988   Canoeing  1964  0.017616\n",
      "1053  Canoeing  1968  0.019372\n",
      "1118  Canoeing  1972  0.030019\n",
      "1183  Canoeing  1976  0.032375\n",
      "1248  Canoeing  1980  0.028309\n",
      "1313  Canoeing  1984  0.025803\n",
      "1378  Canoeing  1988  0.026438\n",
      "1443  Canoeing  1992  0.035764\n",
      "1508  Canoeing  1996  0.041727\n",
      "1573  Canoeing  2000  0.032414\n",
      "1638  Canoeing  2004  0.032284\n",
      "1703  Canoeing  2008  0.032054\n",
      "1768  Canoeing  2012  0.032353\n",
      "1833  Canoeing  2016  0.032218\n",
      "1898  Canoeing  2020  0.031226\n",
      "1963  Canoeing  2024  0.031189\n",
      "\n",
      "Prepared time series data for Canoeing (popularity):\n",
      " Year\n",
      "1936    0.019324\n",
      "1948    0.018583\n",
      "1952    0.019662\n",
      "1956    0.022692\n",
      "1960    0.022848\n",
      "1964    0.017616\n",
      "1968    0.019372\n",
      "1972    0.030019\n",
      "1976    0.032375\n",
      "1980    0.028309\n",
      "1984    0.025803\n",
      "1988    0.026438\n",
      "1992    0.035764\n",
      "1996    0.041727\n",
      "2000    0.032414\n",
      "2004    0.032284\n",
      "2008    0.032054\n",
      "2012    0.032353\n",
      "2016    0.032218\n",
      "2020    0.031226\n",
      "2024    0.031189\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Cricket (popularity)\n",
      "Raw data for Cricket (popularity):\n",
      "       Sport  Year     Value\n",
      "79  Cricket  1900  0.012397\n",
      "\n",
      "Prepared time series data for Cricket (popularity):\n",
      " Year\n",
      "1900    0.012397\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Croquet (popularity)\n",
      "Raw data for Croquet (popularity):\n",
      "       Sport  Year     Value\n",
      "80  Croquet  1900  0.009814\n",
      "\n",
      "Prepared time series data for Croquet (popularity):\n",
      " Year\n",
      "1900    0.009814\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Cross Country Skiing (popularity)\n",
      "Raw data for Cross Country Skiing (popularity):\n",
      "                      Sport  Year     Value\n",
      "471   Cross Country Skiing  1924  0.012998\n",
      "536   Cross Country Skiing  1928  0.016146\n",
      "601   Cross Country Skiing  1932  0.022282\n",
      "666   Cross Country Skiing  1936  0.023649\n",
      "731   Cross Country Skiing  1948  0.020856\n",
      "796   Cross Country Skiing  1952  0.020090\n",
      "861   Cross Country Skiing  1956  0.042742\n",
      "926   Cross Country Skiing  1960  0.023389\n",
      "991   Cross Country Skiing  1964  0.035021\n",
      "1056  Cross Country Skiing  1968  0.032828\n",
      "1121  Cross Country Skiing  1972  0.028012\n",
      "1186  Cross Country Skiing  1976  0.037612\n",
      "1251  Cross Country Skiing  1980  0.034575\n",
      "1316  Cross Country Skiing  1984  0.041163\n",
      "1381  Cross Country Skiing  1988  0.035977\n",
      "1446  Cross Country Skiing  1992  0.043685\n",
      "\n",
      "Prepared time series data for Cross Country Skiing (popularity):\n",
      " Year\n",
      "1924    0.012998\n",
      "1928    0.016146\n",
      "1932    0.022282\n",
      "1936    0.023649\n",
      "1948    0.020856\n",
      "1952    0.020090\n",
      "1956    0.042742\n",
      "1960    0.023389\n",
      "1964    0.035021\n",
      "1968    0.032828\n",
      "1972    0.028012\n",
      "1976    0.037612\n",
      "1980    0.034575\n",
      "1984    0.041163\n",
      "1988    0.035977\n",
      "1992    0.043685\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Curling (popularity)\n",
      "Raw data for Curling (popularity):\n",
      "        Sport  Year    Value\n",
      "472  Curling  1924  0.00281\n",
      "\n",
      "Prepared time series data for Curling (popularity):\n",
      " Year\n",
      "1924    0.00281\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Cycling (popularity)\n",
      "Raw data for Cycling (popularity):\n",
      "         Sport  Year     Value\n",
      "18    Cycling  1896  0.107895\n",
      "83    Cycling  1900  0.047521\n",
      "148   Cycling  1904  0.046887\n",
      "213   Cycling  1906  0.079631\n",
      "278   Cycling  1908  0.086746\n",
      "343   Cycling  1912  0.059901\n",
      "408   Cycling  1920  0.049394\n",
      "473   Cycling  1924  0.043738\n",
      "538   Cycling  1928  0.040725\n",
      "603   Cycling  1932  0.032821\n",
      "668   Cycling  1936  0.040676\n",
      "733   Cycling  1948  0.042781\n",
      "798   Cycling  1952  0.041569\n",
      "863   Cycling  1956  0.045384\n",
      "928   Cycling  1960  0.045804\n",
      "993   Cycling  1964  0.047574\n",
      "1058  Cycling  1968  0.046092\n",
      "1123  Cycling  1972  0.043984\n",
      "1188  Cycling  1976  0.037326\n",
      "1253  Cycling  1980  0.034352\n",
      "1318  Cycling  1984  0.040991\n",
      "1383  Cycling  1988  0.035296\n",
      "1448  Cycling  1992  0.034485\n",
      "1513  Cycling  1996  0.042380\n",
      "1578  Cycling  2000  0.044932\n",
      "1643  Cycling  2004  0.046344\n",
      "1708  Cycling  2008  0.047934\n",
      "1773  Cycling  2012  0.048684\n",
      "1838  Cycling  2016  0.048729\n",
      "1903  Cycling  2020  0.049962\n",
      "1968  Cycling  2024  0.050412\n",
      "\n",
      "Prepared time series data for Cycling (popularity):\n",
      " Year\n",
      "1896    0.107895\n",
      "1900    0.047521\n",
      "1904    0.046887\n",
      "1906    0.079631\n",
      "1908    0.086746\n",
      "1912    0.059901\n",
      "1920    0.049394\n",
      "1924    0.043738\n",
      "1928    0.040725\n",
      "1932    0.032821\n",
      "1936    0.040676\n",
      "1948    0.042781\n",
      "1952    0.041569\n",
      "1956    0.045384\n",
      "1960    0.045804\n",
      "1964    0.047574\n",
      "1968    0.046092\n",
      "1972    0.043984\n",
      "1976    0.037326\n",
      "1980    0.034352\n",
      "1984    0.040991\n",
      "1988    0.035296\n",
      "1992    0.034485\n",
      "1996    0.042380\n",
      "2000    0.044932\n",
      "2004    0.046344\n",
      "2008    0.047934\n",
      "2012    0.048684\n",
      "2016    0.048729\n",
      "2020    0.049962\n",
      "2024    0.050412\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Diving (popularity)\n",
      "Raw data for Diving (popularity):\n",
      "        Sport  Year     Value\n",
      "149   Diving  1904  0.003843\n",
      "214   Diving  1906  0.013849\n",
      "279   Diving  1908  0.015156\n",
      "344   Diving  1912  0.021287\n",
      "409   Diving  1920  0.016309\n",
      "474   Diving  1924  0.015809\n",
      "539   Diving  1928  0.013276\n",
      "604   Diving  1932  0.010840\n",
      "669   Diving  1936  0.011892\n",
      "734   Diving  1948  0.011230\n",
      "799   Diving  1952  0.010365\n",
      "864   Diving  1956  0.012745\n",
      "929   Diving  1960  0.010395\n",
      "994   Diving  1964  0.010759\n",
      "1059  Diving  1968  0.010402\n",
      "1124  Diving  1972  0.010369\n",
      "1189  Diving  1976  0.009998\n",
      "1254  Diving  1980  0.009847\n",
      "1319  Diving  1984  0.008716\n",
      "1384  Diving  1988  0.007359\n",
      "1449  Diving  1992  0.006824\n",
      "1514  Diving  1996  0.010087\n",
      "1579  Diving  2000  0.017220\n",
      "1644  Diving  2004  0.014580\n",
      "1709  Diving  2008  0.013380\n",
      "1774  Diving  2012  0.014009\n",
      "1839  Diving  2016  0.013004\n",
      "1904  Diving  2020  0.012869\n",
      "1969  Diving  2024  0.013339\n",
      "\n",
      "Prepared time series data for Diving (popularity):\n",
      " Year\n",
      "1904    0.003843\n",
      "1906    0.013849\n",
      "1908    0.015156\n",
      "1912    0.021287\n",
      "1920    0.016309\n",
      "1924    0.015809\n",
      "1928    0.013276\n",
      "1932    0.010840\n",
      "1936    0.011892\n",
      "1948    0.011230\n",
      "1952    0.010365\n",
      "1956    0.012745\n",
      "1960    0.010395\n",
      "1964    0.010759\n",
      "1968    0.010402\n",
      "1972    0.010369\n",
      "1976    0.009998\n",
      "1980    0.009847\n",
      "1984    0.008716\n",
      "1988    0.007359\n",
      "1992    0.006824\n",
      "1996    0.010087\n",
      "2000    0.017220\n",
      "2004    0.014580\n",
      "2008    0.013380\n",
      "2012    0.014009\n",
      "2016    0.013004\n",
      "2020    0.012869\n",
      "2024    0.013339\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Equestrianism (popularity)\n",
      "Raw data for Equestrianism (popularity):\n",
      "               Sport  Year     Value\n",
      "85    Equestrianism  1900  0.040806\n",
      "345   Equestrianism  1912  0.031683\n",
      "410   Equestrianism  1920  0.030755\n",
      "475   Equestrianism  1924  0.034077\n",
      "540   Equestrianism  1928  0.041622\n",
      "605   Equestrianism  1932  0.019572\n",
      "670   Equestrianism  1936  0.034595\n",
      "735   Equestrianism  1948  0.027674\n",
      "800   Equestrianism  1952  0.028104\n",
      "865   Equestrianism  1956  0.046316\n",
      "930   Equestrianism  1960  0.029886\n",
      "995   Equestrianism  1964  0.023629\n",
      "1060  Equestrianism  1968  0.022235\n",
      "1125  Equestrianism  1972  0.027260\n",
      "1190  Equestrianism  1976  0.023424\n",
      "1255  Equestrianism  1980  0.013651\n",
      "1320  Equestrianism  1984  0.024249\n",
      "1385  Equestrianism  1988  0.022077\n",
      "1450  Equestrianism  1992  0.024615\n",
      "1515  Equestrianism  1996  0.024891\n",
      "1580  Equestrianism  2000  0.021344\n",
      "1645  Equestrianism  2004  0.027598\n",
      "1710  Equestrianism  2008  0.024996\n",
      "1775  Equestrianism  2012  0.027090\n",
      "1840  Equestrianism  2016  0.025935\n",
      "1905  Equestrianism  2020  0.018925\n",
      "1970  Equestrianism  2024  0.019616\n",
      "\n",
      "Prepared time series data for Equestrianism (popularity):\n",
      " Year\n",
      "1900    0.040806\n",
      "1912    0.031683\n",
      "1920    0.030755\n",
      "1924    0.034077\n",
      "1928    0.041622\n",
      "1932    0.019572\n",
      "1936    0.034595\n",
      "1948    0.027674\n",
      "1952    0.028104\n",
      "1956    0.046316\n",
      "1960    0.029886\n",
      "1964    0.023629\n",
      "1968    0.022235\n",
      "1972    0.027260\n",
      "1976    0.023424\n",
      "1980    0.013651\n",
      "1984    0.024249\n",
      "1988    0.022077\n",
      "1992    0.024615\n",
      "1996    0.024891\n",
      "2000    0.021344\n",
      "2004    0.027598\n",
      "2008    0.024996\n",
      "2012    0.027090\n",
      "2016    0.025935\n",
      "2020    0.018925\n",
      "2024    0.019616\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Fencing (popularity)\n",
      "Raw data for Fencing (popularity):\n",
      "         Sport  Year     Value\n",
      "21    Fencing  1896  0.039474\n",
      "86    Fencing  1900  0.163740\n",
      "151   Fencing  1904  0.021522\n",
      "216   Fencing  1906  0.092902\n",
      "281   Fencing  1908  0.077394\n",
      "346   Fencing  1912  0.093812\n",
      "411   Fencing  1920  0.081547\n",
      "476   Fencing  1924  0.074477\n",
      "541   Fencing  1928  0.077144\n",
      "606   Fencing  1932  0.057814\n",
      "671   Fencing  1936  0.075135\n",
      "736   Fencing  1948  0.067914\n",
      "801   Fencing  1952  0.054392\n",
      "866   Fencing  1956  0.043208\n",
      "931   Fencing  1960  0.065079\n",
      "996   Fencing  1964  0.050738\n",
      "1061  Fencing  1968  0.046760\n",
      "1126  Fencing  1972  0.041726\n",
      "1191  Fencing  1976  0.046182\n",
      "1256  Fencing  1980  0.035918\n",
      "1321  Fencing  1984  0.036590\n",
      "1386  Fencing  1988  0.034478\n",
      "1451  Fencing  1992  0.027905\n",
      "1516  Fencing  1996  0.028157\n",
      "1581  Fencing  2000  0.025251\n",
      "1646  Fencing  2004  0.024027\n",
      "1711  Fencing  2008  0.024408\n",
      "1776  Fencing  2012  0.026703\n",
      "1841  Fencing  2016  0.025278\n",
      "1906  Fencing  2020  0.020061\n",
      "1971  Fencing  2024  0.020792\n",
      "\n",
      "Prepared time series data for Fencing (popularity):\n",
      " Year\n",
      "1896    0.039474\n",
      "1900    0.163740\n",
      "1904    0.021522\n",
      "1906    0.092902\n",
      "1908    0.077394\n",
      "1912    0.093812\n",
      "1920    0.081547\n",
      "1924    0.074477\n",
      "1928    0.077144\n",
      "1932    0.057814\n",
      "1936    0.075135\n",
      "1948    0.067914\n",
      "1952    0.054392\n",
      "1956    0.043208\n",
      "1960    0.065079\n",
      "1964    0.050738\n",
      "1968    0.046760\n",
      "1972    0.041726\n",
      "1976    0.046182\n",
      "1980    0.035918\n",
      "1984    0.036590\n",
      "1988    0.034478\n",
      "1992    0.027905\n",
      "1996    0.028157\n",
      "2000    0.025251\n",
      "2004    0.024027\n",
      "2008    0.024408\n",
      "2012    0.026703\n",
      "2016    0.025278\n",
      "2020    0.020061\n",
      "2024    0.020792\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Figure Skating (popularity)\n",
      "Raw data for Figure Skating (popularity):\n",
      "                Sport  Year     Value\n",
      "282   Figure Skating  1908  0.007417\n",
      "412   Figure Skating  1920  0.007223\n",
      "477   Figure Skating  1924  0.006499\n",
      "542   Figure Skating  1928  0.011302\n",
      "607   Figure Skating  1932  0.012346\n",
      "672   Figure Skating  1936  0.011757\n",
      "737   Figure Skating  1948  0.009492\n",
      "802   Figure Skating  1952  0.006946\n",
      "867   Figure Skating  1956  0.009170\n",
      "932   Figure Skating  1960  0.007688\n",
      "997   Figure Skating  1964  0.009283\n",
      "1062  Figure Skating  1968  0.009161\n",
      "1127  Figure Skating  1972  0.005686\n",
      "1192  Figure Skating  1976  0.009998\n",
      "1257  Figure Skating  1980  0.009511\n",
      "1322  Figure Skating  1984  0.009838\n",
      "1387  Figure Skating  1988  0.008790\n",
      "1452  Figure Skating  1992  0.008103\n",
      "\n",
      "Prepared time series data for Figure Skating (popularity):\n",
      " Year\n",
      "1908    0.007417\n",
      "1920    0.007223\n",
      "1924    0.006499\n",
      "1928    0.011302\n",
      "1932    0.012346\n",
      "1936    0.011757\n",
      "1948    0.009492\n",
      "1952    0.006946\n",
      "1956    0.009170\n",
      "1960    0.007688\n",
      "1964    0.009283\n",
      "1968    0.009161\n",
      "1972    0.005686\n",
      "1976    0.009998\n",
      "1980    0.009511\n",
      "1984    0.009838\n",
      "1988    0.008790\n",
      "1992    0.008103\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Football (popularity)\n",
      "Raw data for Football (popularity):\n",
      "          Sport  Year     Value\n",
      "88    Football  1900  0.018079\n",
      "153   Football  1904  0.027671\n",
      "218   Football  1906  0.025967\n",
      "283   Football  1908  0.023218\n",
      "348   Football  1912  0.040347\n",
      "413   Football  1920  0.044268\n",
      "478   Football  1924  0.049008\n",
      "543   Football  1928  0.039290\n",
      "673   Football  1936  0.027162\n",
      "738   Football  1948  0.029144\n",
      "803   Football  1952  0.031417\n",
      "868   Football  1956  0.022226\n",
      "933   Football  1960  0.025447\n",
      "998   Football  1964  0.022574\n",
      "1063  Football  1968  0.026052\n",
      "1128  Football  1972  0.022494\n",
      "1193  Football  1976  0.019234\n",
      "1258  Football  1980  0.028645\n",
      "1323  Football  1984  0.021229\n",
      "1388  Football  1988  0.018397\n",
      "1453  Football  1992  0.016572\n",
      "1518  Football  1996  0.028157\n",
      "1583  Football  2000  0.028290\n",
      "1648  Football  2004  0.031615\n",
      "1713  Football  2008  0.034480\n",
      "1778  Football  2012  0.036146\n",
      "1843  Football  2016  0.034556\n",
      "1908  Football  2020  0.047691\n",
      "1973  Football  2024  0.056493\n",
      "\n",
      "Prepared time series data for Football (popularity):\n",
      " Year\n",
      "1900    0.018079\n",
      "1904    0.027671\n",
      "1906    0.025967\n",
      "1908    0.023218\n",
      "1912    0.040347\n",
      "1920    0.044268\n",
      "1924    0.049008\n",
      "1928    0.039290\n",
      "1936    0.027162\n",
      "1948    0.029144\n",
      "1952    0.031417\n",
      "1956    0.022226\n",
      "1960    0.025447\n",
      "1964    0.022574\n",
      "1968    0.026052\n",
      "1972    0.022494\n",
      "1976    0.019234\n",
      "1980    0.028645\n",
      "1984    0.021229\n",
      "1988    0.018397\n",
      "1992    0.016572\n",
      "1996    0.028157\n",
      "2000    0.028290\n",
      "2004    0.031615\n",
      "2008    0.034480\n",
      "2012    0.036146\n",
      "2016    0.034556\n",
      "2020    0.047691\n",
      "2024    0.056493\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Freestyle Skiing (popularity)\n",
      "Raw data for Freestyle Skiing (popularity):\n",
      "                  Sport  Year     Value\n",
      "1454  Freestyle Skiing  1992  0.004326\n",
      "\n",
      "Prepared time series data for Freestyle Skiing (popularity):\n",
      " Year\n",
      "1992    0.004326\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Golf (popularity)\n",
      "Raw data for Golf (popularity):\n",
      "      Sport  Year     Value\n",
      "90    Golf  1900  0.011364\n",
      "155   Golf  1904  0.080707\n",
      "1845  Golf  2016  0.008767\n",
      "1910  Golf  2020  0.011355\n",
      "1975  Golf  2024  0.011769\n",
      "\n",
      "Prepared time series data for Golf (popularity):\n",
      " Year\n",
      "1900    0.011364\n",
      "1904    0.080707\n",
      "2016    0.008767\n",
      "2020    0.011355\n",
      "2024    0.011769\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Gymnastics (popularity)\n",
      "Raw data for Gymnastics (popularity):\n",
      "            Sport  Year     Value\n",
      "26    Gymnastics  1896  0.255263\n",
      "91    Gymnastics  1900  0.069731\n",
      "156   Gymnastics  1904  0.352037\n",
      "221   Gymnastics  1906  0.090017\n",
      "286   Gymnastics  1908  0.112544\n",
      "351   Gymnastics  1912  0.076733\n",
      "416   Gymnastics  1920  0.061277\n",
      "481   Gymnastics  1924  0.112067\n",
      "546   Gymnastics  1928  0.119125\n",
      "611   Gymnastics  1932  0.044264\n",
      "676   Gymnastics  1936  0.127973\n",
      "741   Gymnastics  1948  0.141711\n",
      "806   Gymnastics  1952  0.255503\n",
      "871   Gymnastics  1956  0.141902\n",
      "936   Gymnastics  1960  0.189063\n",
      "1001  Gymnastics  1964  0.156540\n",
      "1066  Gymnastics  1968  0.142762\n",
      "1131  Gymnastics  1972  0.132453\n",
      "1196  Gymnastics  1976  0.114645\n",
      "1261  Gymnastics  1980  0.096901\n",
      "1326  Gymnastics  1984  0.080255\n",
      "1391  Gymnastics  1988  0.082925\n",
      "1456  Gymnastics  1992  0.076464\n",
      "1521  Gymnastics  1996  0.101379\n",
      "1586  Gymnastics  2000  0.082773\n",
      "1651  Gymnastics  2004  0.085621\n",
      "1716  Gymnastics  2008  0.073225\n",
      "1781  Gymnastics  2012  0.065635\n",
      "1846  Gymnastics  2016  0.062902\n",
      "1911  Gymnastics  2020  0.030659\n",
      "1976  Gymnastics  2024  0.031189\n",
      "\n",
      "Prepared time series data for Gymnastics (popularity):\n",
      " Year\n",
      "1896    0.255263\n",
      "1900    0.069731\n",
      "1904    0.352037\n",
      "1906    0.090017\n",
      "1908    0.112544\n",
      "1912    0.076733\n",
      "1920    0.061277\n",
      "1924    0.112067\n",
      "1928    0.119125\n",
      "1932    0.044264\n",
      "1936    0.127973\n",
      "1948    0.141711\n",
      "1952    0.255503\n",
      "1956    0.141902\n",
      "1960    0.189063\n",
      "1964    0.156540\n",
      "1968    0.142762\n",
      "1972    0.132453\n",
      "1976    0.114645\n",
      "1980    0.096901\n",
      "1984    0.080255\n",
      "1988    0.082925\n",
      "1992    0.076464\n",
      "1996    0.101379\n",
      "2000    0.082773\n",
      "2004    0.085621\n",
      "2008    0.073225\n",
      "2012    0.065635\n",
      "2016    0.062902\n",
      "2020    0.030659\n",
      "2024    0.031189\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Handball (popularity)\n",
      "Raw data for Handball (popularity):\n",
      "          Sport  Year     Value\n",
      "677   Handball  1936  0.014189\n",
      "1132  Handball  1972  0.020319\n",
      "1197  Handball  1976  0.023138\n",
      "1262  Handball  1980  0.027750\n",
      "1327  Handball  1984  0.022351\n",
      "1392  Handball  1988  0.019147\n",
      "1457  Handball  1992  0.017791\n",
      "1522  Handball  1996  0.021771\n",
      "1587  Handball  2000  0.023370\n",
      "1652  Handball  2004  0.024399\n",
      "1717  Handball  2008  0.025217\n",
      "1782  Handball  2012  0.026858\n",
      "1847  Handball  2016  0.025789\n",
      "1912  Handball  2020  0.031794\n",
      "1977  Handball  2024  0.032954\n",
      "\n",
      "Prepared time series data for Handball (popularity):\n",
      " Year\n",
      "1936    0.014189\n",
      "1972    0.020319\n",
      "1976    0.023138\n",
      "1980    0.027750\n",
      "1984    0.022351\n",
      "1988    0.019147\n",
      "1992    0.017791\n",
      "1996    0.021771\n",
      "2000    0.023370\n",
      "2004    0.024399\n",
      "2008    0.025217\n",
      "2012    0.026858\n",
      "2016    0.025789\n",
      "2020    0.031794\n",
      "2024    0.032954\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Hockey (popularity)\n",
      "Raw data for Hockey (popularity):\n",
      "        Sport  Year     Value\n",
      "288   Hockey  1908  0.021928\n",
      "418   Hockey  1920  0.011883\n",
      "548   Hockey  1928  0.024578\n",
      "613   Hockey  1932  0.012045\n",
      "678   Hockey  1936  0.022568\n",
      "743   Hockey  1948  0.025000\n",
      "808   Hockey  1952  0.016777\n",
      "873   Hockey  1956  0.026888\n",
      "938   Hockey  1960  0.025555\n",
      "1003  Hockey  1964  0.023840\n",
      "1068  Hockey  1968  0.024144\n",
      "1133  Hockey  1972  0.021992\n",
      "1198  Hockey  1976  0.016378\n",
      "1263  Hockey  1980  0.020924\n",
      "1328  Hockey  1984  0.024681\n",
      "1393  Hockey  1988  0.021395\n",
      "1458  Hockey  1992  0.019131\n",
      "1523  Hockey  1996  0.023222\n",
      "1588  Hockey  2000  0.025324\n",
      "1653  Hockey  2004  0.026185\n",
      "1718  Hockey  2008  0.028452\n",
      "1783  Hockey  2012  0.029954\n",
      "1848  Hockey  2016  0.028492\n",
      "1913  Hockey  2020  0.036336\n",
      "1978  Hockey  2024  0.037662\n",
      "\n",
      "Prepared time series data for Hockey (popularity):\n",
      " Year\n",
      "1908    0.021928\n",
      "1920    0.011883\n",
      "1928    0.024578\n",
      "1932    0.012045\n",
      "1936    0.022568\n",
      "1948    0.025000\n",
      "1952    0.016777\n",
      "1956    0.026888\n",
      "1960    0.025555\n",
      "1964    0.023840\n",
      "1968    0.024144\n",
      "1972    0.021992\n",
      "1976    0.016378\n",
      "1980    0.020924\n",
      "1984    0.024681\n",
      "1988    0.021395\n",
      "1992    0.019131\n",
      "1996    0.023222\n",
      "2000    0.025324\n",
      "2004    0.026185\n",
      "2008    0.028452\n",
      "2012    0.029954\n",
      "2016    0.028492\n",
      "2020    0.036336\n",
      "2024    0.037662\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Ice Hockey (popularity)\n",
      "Raw data for Ice Hockey (popularity):\n",
      "            Sport  Year     Value\n",
      "419   Ice Hockey  1920  0.013979\n",
      "484   Ice Hockey  1924  0.014404\n",
      "549   Ice Hockey  1928  0.022246\n",
      "614   Ice Hockey  1932  0.014453\n",
      "679   Ice Hockey  1936  0.023378\n",
      "744   Ice Hockey  1948  0.018583\n",
      "809   Ice Hockey  1952  0.015708\n",
      "874   Ice Hockey  1956  0.026267\n",
      "939   Ice Hockey  1960  0.016459\n",
      "1004  Ice Hockey  1964  0.028481\n",
      "1069  Ice Hockey  1968  0.023857\n",
      "1134  Ice Hockey  1972  0.017393\n",
      "1199  Ice Hockey  1976  0.020663\n",
      "1264  Ice Hockey  1980  0.026743\n",
      "1329  Ice Hockey  1984  0.020625\n",
      "1394  Ice Hockey  1988  0.018057\n",
      "1459  Ice Hockey  1992  0.016268\n",
      "\n",
      "Prepared time series data for Ice Hockey (popularity):\n",
      " Year\n",
      "1920    0.013979\n",
      "1924    0.014404\n",
      "1928    0.022246\n",
      "1932    0.014453\n",
      "1936    0.023378\n",
      "1948    0.018583\n",
      "1952    0.015708\n",
      "1956    0.026267\n",
      "1960    0.016459\n",
      "1964    0.028481\n",
      "1968    0.023857\n",
      "1972    0.017393\n",
      "1976    0.020663\n",
      "1980    0.026743\n",
      "1984    0.020625\n",
      "1988    0.018057\n",
      "1992    0.016268\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Jeu De Paume (popularity)\n",
      "Raw data for Jeu De Paume (popularity):\n",
      "             Sport  Year     Value\n",
      "290  Jeu De Paume  1908  0.003547\n",
      "\n",
      "Prepared time series data for Jeu De Paume (popularity):\n",
      " Year\n",
      "1908    0.003547\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Judo (popularity)\n",
      "Raw data for Judo (popularity):\n",
      "      Sport  Year     Value\n",
      "1006  Judo  1964  0.007595\n",
      "1136  Judo  1972  0.013881\n",
      "1201  Judo  1976  0.014664\n",
      "1266  Judo  1980  0.021596\n",
      "1331  Judo  1984  0.018295\n",
      "1396  Judo  1988  0.016558\n",
      "1461  Judo  1992  0.026382\n",
      "1526  Judo  1996  0.028084\n",
      "1591  Judo  2000  0.028797\n",
      "1656  Judo  2004  0.028565\n",
      "1721  Judo  2008  0.028378\n",
      "1786  Judo  2012  0.029721\n",
      "1851  Judo  2016  0.028419\n",
      "1916  Judo  2020  0.036525\n",
      "1981  Judo  2024  0.036485\n",
      "\n",
      "Prepared time series data for Judo (popularity):\n",
      " Year\n",
      "1964    0.007595\n",
      "1972    0.013881\n",
      "1976    0.014664\n",
      "1980    0.021596\n",
      "1984    0.018295\n",
      "1988    0.016558\n",
      "1992    0.026382\n",
      "1996    0.028084\n",
      "2000    0.028797\n",
      "2004    0.028565\n",
      "2008    0.028378\n",
      "2012    0.029721\n",
      "2016    0.028419\n",
      "2020    0.036525\n",
      "2024    0.036485\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Lacrosse (popularity)\n",
      "Raw data for Lacrosse (popularity):\n",
      "         Sport  Year     Value\n",
      "162  Lacrosse  1904  0.027671\n",
      "292  Lacrosse  1908  0.007739\n",
      "\n",
      "Prepared time series data for Lacrosse (popularity):\n",
      " Year\n",
      "1904    0.027671\n",
      "1908    0.007739\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Luge (popularity)\n",
      "Raw data for Luge (popularity):\n",
      "      Sport  Year     Value\n",
      "1008  Luge  1964  0.008966\n",
      "1073  Luge  1968  0.010115\n",
      "1138  Luge  1972  0.008947\n",
      "1203  Luge  1976  0.011331\n",
      "1268  Luge  1980  0.010518\n",
      "1333  Luge  1984  0.007680\n",
      "1398  Luge  1988  0.006678\n",
      "1463  Luge  1992  0.005971\n",
      "\n",
      "Prepared time series data for Luge (popularity):\n",
      " Year\n",
      "1964    0.008966\n",
      "1968    0.010115\n",
      "1972    0.008947\n",
      "1976    0.011331\n",
      "1980    0.010518\n",
      "1984    0.007680\n",
      "1988    0.006678\n",
      "1992    0.005971\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Military Ski Patrol (popularity)\n",
      "Raw data for Military Ski Patrol (popularity):\n",
      "                    Sport  Year     Value\n",
      "489  Military Ski Patrol  1924  0.004216\n",
      "\n",
      "Prepared time series data for Military Ski Patrol (popularity):\n",
      " Year\n",
      "1924    0.004216\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Modern Pentathlon (popularity)\n",
      "Raw data for Modern Pentathlon (popularity):\n",
      "                   Sport  Year     Value\n",
      "360   Modern Pentathlon  1912  0.007921\n",
      "425   Modern Pentathlon  1920  0.005359\n",
      "490   Modern Pentathlon  1924  0.006675\n",
      "555   Modern Pentathlon  1928  0.006638\n",
      "620   Modern Pentathlon  1932  0.007528\n",
      "685   Modern Pentathlon  1936  0.005676\n",
      "750   Modern Pentathlon  1948  0.006016\n",
      "815   Modern Pentathlon  1952  0.010579\n",
      "880   Modern Pentathlon  1956  0.011812\n",
      "945   Modern Pentathlon  1960  0.012019\n",
      "1010  Modern Pentathlon  1964  0.007384\n",
      "1075  Modern Pentathlon  1968  0.008875\n",
      "1140  Modern Pentathlon  1972  0.009700\n",
      "1205  Modern Pentathlon  1976  0.008475\n",
      "1270  Modern Pentathlon  1980  0.008840\n",
      "1335  Modern Pentathlon  1984  0.008889\n",
      "1400  Modern Pentathlon  1988  0.008313\n",
      "1465  Modern Pentathlon  1992  0.007128\n",
      "1530  Modern Pentathlon  1996  0.002322\n",
      "1595  Modern Pentathlon  2000  0.003473\n",
      "1660  Modern Pentathlon  2004  0.004761\n",
      "1725  Modern Pentathlon  2008  0.005293\n",
      "1790  Modern Pentathlon  2012  0.005573\n",
      "1855  Modern Pentathlon  2016  0.005260\n",
      "1920  Modern Pentathlon  2020  0.006813\n",
      "1985  Modern Pentathlon  2024  0.007062\n",
      "\n",
      "Prepared time series data for Modern Pentathlon (popularity):\n",
      " Year\n",
      "1912    0.007921\n",
      "1920    0.005359\n",
      "1924    0.006675\n",
      "1928    0.006638\n",
      "1932    0.007528\n",
      "1936    0.005676\n",
      "1948    0.006016\n",
      "1952    0.010579\n",
      "1956    0.011812\n",
      "1960    0.012019\n",
      "1964    0.007384\n",
      "1968    0.008875\n",
      "1972    0.009700\n",
      "1976    0.008475\n",
      "1980    0.008840\n",
      "1984    0.008889\n",
      "1988    0.008313\n",
      "1992    0.007128\n",
      "1996    0.002322\n",
      "2000    0.003473\n",
      "2004    0.004761\n",
      "2008    0.005293\n",
      "2012    0.005573\n",
      "2016    0.005260\n",
      "2020    0.006813\n",
      "2024    0.007062\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Motorboating (popularity)\n",
      "Raw data for Motorboating (popularity):\n",
      "             Sport  Year     Value\n",
      "296  Motorboating  1908  0.005482\n",
      "\n",
      "Prepared time series data for Motorboating (popularity):\n",
      " Year\n",
      "1908    0.005482\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Nordic Combined (popularity)\n",
      "Raw data for Nordic Combined (popularity):\n",
      "                 Sport  Year     Value\n",
      "492   Nordic Combined  1924  0.005270\n",
      "557   Nordic Combined  1928  0.006279\n",
      "622   Nordic Combined  1932  0.009937\n",
      "687   Nordic Combined  1936  0.006892\n",
      "752   Nordic Combined  1948  0.005214\n",
      "817   Nordic Combined  1952  0.002672\n",
      "882   Nordic Combined  1956  0.005595\n",
      "947   Nordic Combined  1960  0.003573\n",
      "1012  Nordic Combined  1964  0.003376\n",
      "1077  Nordic Combined  1968  0.003913\n",
      "1142  Nordic Combined  1972  0.003345\n",
      "1207  Nordic Combined  1976  0.003237\n",
      "1272  Nordic Combined  1980  0.003469\n",
      "1337  Nordic Combined  1984  0.002416\n",
      "1402  Nordic Combined  1988  0.005110\n",
      "1467  Nordic Combined  1992  0.004752\n",
      "\n",
      "Prepared time series data for Nordic Combined (popularity):\n",
      " Year\n",
      "1924    0.005270\n",
      "1928    0.006279\n",
      "1932    0.009937\n",
      "1936    0.006892\n",
      "1948    0.005214\n",
      "1952    0.002672\n",
      "1956    0.005595\n",
      "1960    0.003573\n",
      "1964    0.003376\n",
      "1968    0.003913\n",
      "1972    0.003345\n",
      "1976    0.003237\n",
      "1980    0.003469\n",
      "1984    0.002416\n",
      "1988    0.005110\n",
      "1992    0.004752\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Polo (popularity)\n",
      "Raw data for Polo (popularity):\n",
      "     Sport  Year     Value\n",
      "103  Polo  1900  0.010847\n",
      "298  Polo  1908  0.003870\n",
      "428  Polo  1920  0.003961\n",
      "493  Polo  1924  0.004216\n",
      "688  Polo  1936  0.002838\n",
      "\n",
      "Prepared time series data for Polo (popularity):\n",
      " Year\n",
      "1900    0.010847\n",
      "1908    0.003870\n",
      "1920    0.003961\n",
      "1924    0.004216\n",
      "1936    0.002838\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Racquets (popularity)\n",
      "Raw data for Racquets (popularity):\n",
      "         Sport  Year    Value\n",
      "299  Racquets  1908  0.00387\n",
      "\n",
      "Prepared time series data for Racquets (popularity):\n",
      " Year\n",
      "1908    0.00387\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Rhythmic Gymnastics (popularity)\n",
      "Raw data for Rhythmic Gymnastics (popularity):\n",
      "                     Sport  Year     Value\n",
      "1340  Rhythmic Gymnastics  1984  0.002848\n",
      "1405  Rhythmic Gymnastics  1988  0.002657\n",
      "1470  Rhythmic Gymnastics  1992  0.002559\n",
      "1535  Rhythmic Gymnastics  1996  0.006531\n",
      "1600  Rhythmic Gymnastics  2000  0.006078\n",
      "1665  Rhythmic Gymnastics  2004  0.006249\n",
      "1730  Rhythmic Gymnastics  2008  0.006984\n",
      "1795  Rhythmic Gymnastics  2012  0.007353\n",
      "1860  Rhythmic Gymnastics  2016  0.007013\n",
      "\n",
      "Prepared time series data for Rhythmic Gymnastics (popularity):\n",
      " Year\n",
      "1984    0.002848\n",
      "1988    0.002657\n",
      "1992    0.002559\n",
      "1996    0.006531\n",
      "2000    0.006078\n",
      "2004    0.006249\n",
      "2008    0.006984\n",
      "2012    0.007353\n",
      "2016    0.007013\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Roque (popularity)\n",
      "Raw data for Roque (popularity):\n",
      "      Sport  Year     Value\n",
      "171  Roque  1904  0.003075\n",
      "\n",
      "Prepared time series data for Roque (popularity):\n",
      " Year\n",
      "1904    0.003075\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Rowing (popularity)\n",
      "Raw data for Rowing (popularity):\n",
      "        Sport  Year     Value\n",
      "107   Rowing  1900  0.068698\n",
      "172   Rowing  1904  0.035357\n",
      "237   Rowing  1906  0.115407\n",
      "302   Rowing  1908  0.028055\n",
      "367   Rowing  1912  0.048762\n",
      "432   Rowing  1920  0.033551\n",
      "497   Rowing  1924  0.034428\n",
      "562   Rowing  1928  0.044313\n",
      "627   Rowing  1932  0.049985\n",
      "692   Rowing  1936  0.047027\n",
      "757   Rowing  1948  0.042513\n",
      "822   Rowing  1952  0.043385\n",
      "887   Rowing  1956  0.040099\n",
      "952   Rowing  1960  0.046670\n",
      "1017  Rowing  1964  0.039873\n",
      "1082  Rowing  1968  0.034164\n",
      "1147  Rowing  1972  0.036960\n",
      "1212  Rowing  1976  0.056942\n",
      "1277  Rowing  1980  0.054604\n",
      "1342  Rowing  1984  0.040128\n",
      "1407  Rowing  1988  0.042518\n",
      "1472  Rowing  1992  0.040273\n",
      "1537  Rowing  1996  0.045065\n",
      "1602  Rowing  2000  0.040590\n",
      "1667  Rowing  2004  0.041583\n",
      "1732  Rowing  2008  0.041391\n",
      "1797  Rowing  2012  0.042570\n",
      "1862  Rowing  2016  0.040181\n",
      "1927  Rowing  2020  0.049773\n",
      "1992  Rowing  2024  0.049235\n",
      "\n",
      "Prepared time series data for Rowing (popularity):\n",
      " Year\n",
      "1900    0.068698\n",
      "1904    0.035357\n",
      "1906    0.115407\n",
      "1908    0.028055\n",
      "1912    0.048762\n",
      "1920    0.033551\n",
      "1924    0.034428\n",
      "1928    0.044313\n",
      "1932    0.049985\n",
      "1936    0.047027\n",
      "1948    0.042513\n",
      "1952    0.043385\n",
      "1956    0.040099\n",
      "1960    0.046670\n",
      "1964    0.039873\n",
      "1968    0.034164\n",
      "1972    0.036960\n",
      "1976    0.056942\n",
      "1980    0.054604\n",
      "1984    0.040128\n",
      "1988    0.042518\n",
      "1992    0.040273\n",
      "1996    0.045065\n",
      "2000    0.040590\n",
      "2004    0.041583\n",
      "2008    0.041391\n",
      "2012    0.042570\n",
      "2016    0.040181\n",
      "2020    0.049773\n",
      "2024    0.049235\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Rugby (popularity)\n",
      "Raw data for Rugby (popularity):\n",
      "       Sport  Year     Value\n",
      "108   Rugby  1900  0.024277\n",
      "303   Rugby  1908  0.009674\n",
      "433   Rugby  1920  0.007223\n",
      "498   Rugby  1924  0.009485\n",
      "1928  Rugby  2020  0.027252\n",
      "\n",
      "Prepared time series data for Rugby (popularity):\n",
      " Year\n",
      "1900    0.024277\n",
      "1908    0.009674\n",
      "1920    0.007223\n",
      "1924    0.009485\n",
      "2020    0.027252\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Rugby Sevens (popularity)\n",
      "Raw data for Rugby Sevens (popularity):\n",
      "              Sport  Year     Value\n",
      "1864  Rugby Sevens  2016  0.021844\n",
      "1994  Rugby Sevens  2024  0.028246\n",
      "\n",
      "Prepared time series data for Rugby Sevens (popularity):\n",
      " Year\n",
      "2016    0.021844\n",
      "2024    0.028246\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Sailing (popularity)\n",
      "Raw data for Sailing (popularity):\n",
      "         Sport  Year     Value\n",
      "110   Sailing  1900  0.144628\n",
      "305   Sailing  1908  0.020639\n",
      "370   Sailing  1912  0.026980\n",
      "435   Sailing  1920  0.023532\n",
      "500   Sailing  1924  0.012120\n",
      "565   Sailing  1928  0.022964\n",
      "630   Sailing  1932  0.017164\n",
      "695   Sailing  1936  0.023243\n",
      "760   Sailing  1948  0.024866\n",
      "825   Sailing  1952  0.024257\n",
      "890   Sailing  1956  0.023935\n",
      "955   Sailing  1960  0.031402\n",
      "1020  Sailing  1964  0.023734\n",
      "1085  Sailing  1968  0.024048\n",
      "1150  Sailing  1972  0.027009\n",
      "1215  Sailing  1976  0.024472\n",
      "1280  Sailing  1980  0.017456\n",
      "1345  Sailing  1984  0.025889\n",
      "1410  Sailing  1988  0.025552\n",
      "1475  Sailing  1992  0.026869\n",
      "1540  Sailing  1996  0.033237\n",
      "1605  Sailing  2000  0.029086\n",
      "1670  Sailing  2004  0.029830\n",
      "1735  Sailing  2008  0.029407\n",
      "1800  Sailing  2012  0.029334\n",
      "1865  Sailing  2016  0.027762\n",
      "1930  Sailing  2020  0.033119\n",
      "1995  Sailing  2024  0.032366\n",
      "\n",
      "Prepared time series data for Sailing (popularity):\n",
      " Year\n",
      "1900    0.144628\n",
      "1908    0.020639\n",
      "1912    0.026980\n",
      "1920    0.023532\n",
      "1924    0.012120\n",
      "1928    0.022964\n",
      "1932    0.017164\n",
      "1936    0.023243\n",
      "1948    0.024866\n",
      "1952    0.024257\n",
      "1956    0.023935\n",
      "1960    0.031402\n",
      "1964    0.023734\n",
      "1968    0.024048\n",
      "1972    0.027009\n",
      "1976    0.024472\n",
      "1980    0.017456\n",
      "1984    0.025889\n",
      "1988    0.025552\n",
      "1992    0.026869\n",
      "1996    0.033237\n",
      "2000    0.029086\n",
      "2004    0.029830\n",
      "2008    0.029407\n",
      "2012    0.029334\n",
      "2016    0.027762\n",
      "2020    0.033119\n",
      "2024    0.032366\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Shooting (popularity)\n",
      "Raw data for Shooting (popularity):\n",
      "          Sport  Year     Value\n",
      "46    Shooting  1896  0.171053\n",
      "111   Shooting  1900  0.114153\n",
      "241   Shooting  1906  0.184651\n",
      "306   Shooting  1908  0.143180\n",
      "371   Shooting  1912  0.196535\n",
      "436   Shooting  1920  0.195247\n",
      "501   Shooting  1924  0.089232\n",
      "631   Shooting  1932  0.013249\n",
      "696   Shooting  1936  0.021892\n",
      "761   Shooting  1948  0.028877\n",
      "826   Shooting  1952  0.030883\n",
      "891   Shooting  1956  0.034038\n",
      "956   Shooting  1960  0.042122\n",
      "1021  Shooting  1964  0.032911\n",
      "1086  Shooting  1968  0.039126\n",
      "1151  Shooting  1972  0.039468\n",
      "1216  Shooting  1976  0.035136\n",
      "1281  Shooting  1980  0.029876\n",
      "1346  Shooting  1984  0.046514\n",
      "1411  Shooting  1988  0.037135\n",
      "1476  Shooting  1992  0.034363\n",
      "1541  Shooting  1996  0.044412\n",
      "1606  Shooting  2000  0.043340\n",
      "1671  Shooting  2004  0.041509\n",
      "1736  Shooting  2008  0.042420\n",
      "1801  Shooting  2012  0.043344\n",
      "1866  Shooting  2016  0.040546\n",
      "1931  Shooting  2020  0.034065\n",
      "1996  Shooting  2024  0.033346\n",
      "\n",
      "Prepared time series data for Shooting (popularity):\n",
      " Year\n",
      "1896    0.171053\n",
      "1900    0.114153\n",
      "1906    0.184651\n",
      "1908    0.143180\n",
      "1912    0.196535\n",
      "1920    0.195247\n",
      "1924    0.089232\n",
      "1932    0.013249\n",
      "1936    0.021892\n",
      "1948    0.028877\n",
      "1952    0.030883\n",
      "1956    0.034038\n",
      "1960    0.042122\n",
      "1964    0.032911\n",
      "1968    0.039126\n",
      "1972    0.039468\n",
      "1976    0.035136\n",
      "1980    0.029876\n",
      "1984    0.046514\n",
      "1988    0.037135\n",
      "1992    0.034363\n",
      "1996    0.044412\n",
      "2000    0.043340\n",
      "2004    0.041509\n",
      "2008    0.042420\n",
      "2012    0.043344\n",
      "2016    0.040546\n",
      "2020    0.034065\n",
      "2024    0.033346\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Short Track Speed Skating (popularity)\n",
      "Raw data for Short Track Speed Skating (popularity):\n",
      "                           Sport  Year     Value\n",
      "1477  Short Track Speed Skating  1992  0.007555\n",
      "\n",
      "Prepared time series data for Short Track Speed Skating (popularity):\n",
      " Year\n",
      "1992    0.007555\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Skeleton (popularity)\n",
      "Raw data for Skeleton (popularity):\n",
      "         Sport  Year     Value\n",
      "568  Skeleton  1928  0.001794\n",
      "763  Skeleton  1948  0.002005\n",
      "\n",
      "Prepared time series data for Skeleton (popularity):\n",
      " Year\n",
      "1928    0.001794\n",
      "1948    0.002005\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Ski Jumping (popularity)\n",
      "Raw data for Ski Jumping (popularity):\n",
      "             Sport  Year     Value\n",
      "504   Ski Jumping  1924  0.004743\n",
      "569   Ski Jumping  1928  0.006817\n",
      "634   Ski Jumping  1932  0.010238\n",
      "699   Ski Jumping  1936  0.006486\n",
      "764   Ski Jumping  1948  0.006551\n",
      "829   Ski Jumping  1952  0.004702\n",
      "894   Ski Jumping  1956  0.007927\n",
      "959   Ski Jumping  1960  0.004873\n",
      "1024  Ski Jumping  1964  0.011076\n",
      "1089  Ski Jumping  1968  0.011070\n",
      "1154  Ski Jumping  1972  0.009031\n",
      "1219  Ski Jumping  1976  0.010379\n",
      "1284  Ski Jumping  1980  0.010966\n",
      "1349  Ski Jumping  1984  0.009579\n",
      "1414  Ski Jumping  1988  0.010698\n",
      "1479  Ski Jumping  1992  0.010419\n",
      "\n",
      "Prepared time series data for Ski Jumping (popularity):\n",
      " Year\n",
      "1924    0.004743\n",
      "1928    0.006817\n",
      "1932    0.010238\n",
      "1936    0.006486\n",
      "1948    0.006551\n",
      "1952    0.004702\n",
      "1956    0.007927\n",
      "1960    0.004873\n",
      "1964    0.011076\n",
      "1968    0.011070\n",
      "1972    0.009031\n",
      "1976    0.010379\n",
      "1980    0.010966\n",
      "1984    0.009579\n",
      "1988    0.010698\n",
      "1992    0.010419\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Snowboarding (popularity)\n",
      "Raw data for Snowboarding (popularity):\n",
      " Empty DataFrame\n",
      "Columns: [Sport, Year, Value]\n",
      "Index: []\n",
      "\n",
      "Prepared time series data for Snowboarding (popularity):\n",
      " Series([], Name: Value, dtype: float64)\n",
      "\n",
      "Processing sport: Softball (popularity)\n",
      "Raw data for Softball (popularity):\n",
      "          Sport  Year     Value\n",
      "1546  Softball  1996  0.008708\n",
      "1611  Softball  2000  0.008682\n",
      "1676  Softball  2004  0.008778\n",
      "1741  Softball  2008  0.008822\n",
      "\n",
      "Prepared time series data for Softball (popularity):\n",
      " Year\n",
      "1996    0.008708\n",
      "2000    0.008682\n",
      "2004    0.008778\n",
      "2008    0.008822\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Speed Skating (popularity)\n",
      "Raw data for Speed Skating (popularity):\n",
      "               Sport  Year     Value\n",
      "507   Speed Skating  1924  0.019322\n",
      "572   Speed Skating  1928  0.019017\n",
      "637   Speed Skating  1932  0.021078\n",
      "702   Speed Skating  1936  0.018919\n",
      "767   Speed Skating  1948  0.020588\n",
      "832   Speed Skating  1952  0.015495\n",
      "897   Speed Skating  1956  0.027821\n",
      "962   Speed Skating  1960  0.026963\n",
      "1027  Speed Skating  1964  0.030274\n",
      "1092  Speed Skating  1968  0.026720\n",
      "1157  Speed Skating  1972  0.020403\n",
      "1222  Speed Skating  1976  0.023519\n",
      "1287  Speed Skating  1980  0.033121\n",
      "1352  Speed Skating  1984  0.028305\n",
      "1417  Speed Skating  1988  0.022213\n",
      "1482  Speed Skating  1992  0.021568\n",
      "\n",
      "Prepared time series data for Speed Skating (popularity):\n",
      " Year\n",
      "1924    0.019322\n",
      "1928    0.019017\n",
      "1932    0.021078\n",
      "1936    0.018919\n",
      "1948    0.020588\n",
      "1952    0.015495\n",
      "1956    0.027821\n",
      "1960    0.026963\n",
      "1964    0.030274\n",
      "1968    0.026720\n",
      "1972    0.020403\n",
      "1976    0.023519\n",
      "1980    0.033121\n",
      "1984    0.028305\n",
      "1988    0.022213\n",
      "1992    0.021568\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Swimming (popularity)\n",
      "Raw data for Swimming (popularity):\n",
      "          Sport  Year     Value\n",
      "53    Swimming  1896  0.047368\n",
      "118   Swimming  1900  0.067665\n",
      "183   Swimming  1904  0.049193\n",
      "248   Swimming  1906  0.045009\n",
      "313   Swimming  1908  0.048371\n",
      "378   Swimming  1912  0.049752\n",
      "443   Swimming  1920  0.048695\n",
      "508   Swimming  1924  0.046197\n",
      "573   Swimming  1928  0.049874\n",
      "638   Swimming  1932  0.058717\n",
      "703   Swimming  1936  0.049189\n",
      "768   Swimming  1948  0.053209\n",
      "833   Swimming  1952  0.051614\n",
      "898   Swimming  1956  0.055331\n",
      "963   Swimming  1960  0.068219\n",
      "1028  Swimming  1964  0.077637\n",
      "1093  Swimming  1968  0.117473\n",
      "1158  Swimming  1972  0.105611\n",
      "1223  Swimming  1976  0.102457\n",
      "1288  Swimming  1980  0.085152\n",
      "1353  Swimming  1984  0.106317\n",
      "1418  Swimming  1988  0.109975\n",
      "1483  Swimming  1992  0.098398\n",
      "1548  Swimming  1996  0.118650\n",
      "1613  Swimming  2000  0.125968\n",
      "1678  Swimming  2004  0.120360\n",
      "1743  Swimming  2008  0.128584\n",
      "1808  Swimming  2012  0.119040\n",
      "1873  Swimming  2016  0.114553\n",
      "1938  Swimming  2020  0.083081\n",
      "2003  Swimming  2024  0.083562\n",
      "\n",
      "Prepared time series data for Swimming (popularity):\n",
      " Year\n",
      "1896    0.047368\n",
      "1900    0.067665\n",
      "1904    0.049193\n",
      "1906    0.045009\n",
      "1908    0.048371\n",
      "1912    0.049752\n",
      "1920    0.048695\n",
      "1924    0.046197\n",
      "1928    0.049874\n",
      "1932    0.058717\n",
      "1936    0.049189\n",
      "1948    0.053209\n",
      "1952    0.051614\n",
      "1956    0.055331\n",
      "1960    0.068219\n",
      "1964    0.077637\n",
      "1968    0.117473\n",
      "1972    0.105611\n",
      "1976    0.102457\n",
      "1980    0.085152\n",
      "1984    0.106317\n",
      "1988    0.109975\n",
      "1992    0.098398\n",
      "1996    0.118650\n",
      "2000    0.125968\n",
      "2004    0.120360\n",
      "2008    0.128584\n",
      "2012    0.119040\n",
      "2016    0.114553\n",
      "2020    0.083081\n",
      "2024    0.083562\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Synchronized Swimming (popularity)\n",
      "Raw data for Synchronized Swimming (popularity):\n",
      "                       Sport  Year     Value\n",
      "1354  Synchronized Swimming  1984  0.007421\n",
      "1419  Synchronized Swimming  1988  0.005179\n",
      "1484  Synchronized Swimming  1992  0.005423\n",
      "1549  Synchronized Swimming  1996  0.005225\n",
      "1614  Synchronized Swimming  2000  0.008465\n",
      "1679  Synchronized Swimming  2004  0.008703\n",
      "1744  Synchronized Swimming  2008  0.008602\n",
      "1809  Synchronized Swimming  2012  0.009056\n",
      "1874  Synchronized Swimming  2016  0.008621\n",
      "1939  Synchronized Swimming  2020  0.009841\n",
      "\n",
      "Prepared time series data for Synchronized Swimming (popularity):\n",
      " Year\n",
      "1984    0.007421\n",
      "1988    0.005179\n",
      "1992    0.005423\n",
      "1996    0.005225\n",
      "2000    0.008465\n",
      "2004    0.008703\n",
      "2008    0.008602\n",
      "2012    0.009056\n",
      "2016    0.008621\n",
      "2020    0.009841\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Table Tennis (popularity)\n",
      "Raw data for Table Tennis (popularity):\n",
      "              Sport  Year     Value\n",
      "1420  Table Tennis  1988  0.014037\n",
      "1485  Table Tennis  1992  0.015110\n",
      "1550  Table Tennis  1996  0.018215\n",
      "1615  Table Tennis  2000  0.019391\n",
      "1680  Table Tennis  2004  0.019341\n",
      "1745  Table Tennis  2008  0.018380\n",
      "1810  Table Tennis  2012  0.018266\n",
      "1875  Table Tennis  2016  0.017241\n",
      "1940  Table Tennis  2020  0.016276\n",
      "2005  Table Tennis  2024  0.016869\n",
      "\n",
      "Prepared time series data for Table Tennis (popularity):\n",
      " Year\n",
      "1988    0.014037\n",
      "1992    0.015110\n",
      "1996    0.018215\n",
      "2000    0.019391\n",
      "2004    0.019341\n",
      "2008    0.018380\n",
      "2012    0.018266\n",
      "2016    0.017241\n",
      "2020    0.016276\n",
      "2024    0.016869\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Taekwondo (popularity)\n",
      "Raw data for Taekwondo (popularity):\n",
      "           Sport  Year     Value\n",
      "1616  Taekwondo  2000  0.007380\n",
      "1681  Taekwondo  2004  0.009224\n",
      "1746  Taekwondo  2008  0.009263\n",
      "1811  Taekwondo  2012  0.009907\n",
      "1876  Taekwondo  2016  0.009205\n",
      "1941  Taekwondo  2020  0.012112\n",
      "2006  Taekwondo  2024  0.012554\n",
      "\n",
      "Prepared time series data for Taekwondo (popularity):\n",
      " Year\n",
      "2000    0.007380\n",
      "2004    0.009224\n",
      "2008    0.009263\n",
      "2012    0.009907\n",
      "2016    0.009205\n",
      "2020    0.012112\n",
      "2024    0.012554\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Tennis (popularity)\n",
      "Raw data for Tennis (popularity):\n",
      "        Sport  Year     Value\n",
      "57    Tennis  1896  0.060526\n",
      "122   Tennis  1900  0.024277\n",
      "187   Tennis  1904  0.043812\n",
      "252   Tennis  1906  0.027698\n",
      "317   Tennis  1908  0.027088\n",
      "382   Tennis  1912  0.042822\n",
      "447   Tennis  1920  0.035648\n",
      "512   Tennis  1924  0.044441\n",
      "1422  Tennis  1988  0.013764\n",
      "1487  Tennis  1992  0.015232\n",
      "1552  Tennis  1996  0.017852\n",
      "1617  Tennis  2000  0.017944\n",
      "1682  Tennis  2004  0.018746\n",
      "1747  Tennis  2008  0.018674\n",
      "1812  Tennis  2012  0.022136\n",
      "1877  Tennis  2016  0.020894\n",
      "1942  Tennis  2020  0.016276\n",
      "2007  Tennis  2024  0.016869\n",
      "\n",
      "Prepared time series data for Tennis (popularity):\n",
      " Year\n",
      "1896    0.060526\n",
      "1900    0.024277\n",
      "1904    0.043812\n",
      "1906    0.027698\n",
      "1908    0.027088\n",
      "1912    0.042822\n",
      "1920    0.035648\n",
      "1924    0.044441\n",
      "1988    0.013764\n",
      "1992    0.015232\n",
      "1996    0.017852\n",
      "2000    0.017944\n",
      "2004    0.018746\n",
      "2008    0.018674\n",
      "2012    0.022136\n",
      "2016    0.020894\n",
      "2020    0.016276\n",
      "2024    0.016869\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Trampolining (popularity)\n",
      "Raw data for Trampolining (popularity):\n",
      "              Sport  Year     Value\n",
      "1618  Trampolining  2000  0.001736\n",
      "1683  Trampolining  2004  0.002380\n",
      "1748  Trampolining  2008  0.002353\n",
      "1813  Trampolining  2012  0.002477\n",
      "1878  Trampolining  2016  0.002338\n",
      "\n",
      "Prepared time series data for Trampolining (popularity):\n",
      " Year\n",
      "2000    0.001736\n",
      "2004    0.002380\n",
      "2008    0.002353\n",
      "2012    0.002477\n",
      "2016    0.002338\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Triathlon (popularity)\n",
      "Raw data for Triathlon (popularity):\n",
      "           Sport  Year     Value\n",
      "1619  Triathlon  2000  0.007235\n",
      "1684  Triathlon  2004  0.007364\n",
      "1749  Triathlon  2008  0.008087\n",
      "1814  Triathlon  2012  0.008514\n",
      "1879  Triathlon  2016  0.008036\n",
      "1944  Triathlon  2020  0.010409\n",
      "2009  Triathlon  2024  0.010789\n",
      "\n",
      "Prepared time series data for Triathlon (popularity):\n",
      " Year\n",
      "2000    0.007235\n",
      "2004    0.007364\n",
      "2008    0.008087\n",
      "2012    0.008514\n",
      "2016    0.008036\n",
      "2020    0.010409\n",
      "2024    0.010789\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Tug-Of-War (popularity)\n",
      "Raw data for Tug-Of-War (popularity):\n",
      "           Sport  Year     Value\n",
      "125  Tug-Of-War  1900  0.006198\n",
      "190  Tug-Of-War  1904  0.023059\n",
      "255  Tug-Of-War  1906  0.018465\n",
      "320  Tug-Of-War  1908  0.012899\n",
      "385  Tug-Of-War  1912  0.003960\n",
      "450  Tug-Of-War  1920  0.009320\n",
      "\n",
      "Prepared time series data for Tug-Of-War (popularity):\n",
      " Year\n",
      "1900    0.006198\n",
      "1904    0.023059\n",
      "1906    0.018465\n",
      "1908    0.012899\n",
      "1912    0.003960\n",
      "1920    0.009320\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Volleyball (popularity)\n",
      "Raw data for Volleyball (popularity):\n",
      "            Sport  Year     Value\n",
      "1036  Volleyball  1964  0.018882\n",
      "1101  Volleyball  1968  0.019658\n",
      "1166  Volleyball  1972  0.019316\n",
      "1231  Volleyball  1976  0.020568\n",
      "1296  Volleyball  1980  0.022826\n",
      "1361  Volleyball  1984  0.017950\n",
      "1426  Volleyball  1988  0.016285\n",
      "1491  Volleyball  1992  0.014074\n",
      "1556  Volleyball  1996  0.019956\n",
      "1621  Volleyball  2000  0.020187\n",
      "1686  Volleyball  2004  0.021052\n",
      "1751  Volleyball  2008  0.020806\n",
      "1816  Volleyball  2012  0.022214\n",
      "1881  Volleyball  2016  0.020675\n",
      "1946  Volleyball  2020  0.036336\n",
      "2011  Volleyball  2024  0.028246\n",
      "\n",
      "Prepared time series data for Volleyball (popularity):\n",
      " Year\n",
      "1964    0.018882\n",
      "1968    0.019658\n",
      "1972    0.019316\n",
      "1976    0.020568\n",
      "1980    0.022826\n",
      "1984    0.017950\n",
      "1988    0.016285\n",
      "1992    0.014074\n",
      "1996    0.019956\n",
      "2000    0.020187\n",
      "2004    0.021052\n",
      "2008    0.020806\n",
      "2012    0.022214\n",
      "2016    0.020675\n",
      "2020    0.036336\n",
      "2024    0.028246\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Water Polo (popularity)\n",
      "Raw data for Water Polo (popularity):\n",
      "            Sport  Year     Value\n",
      "127   Water Polo  1900  0.027376\n",
      "192   Water Polo  1904  0.016141\n",
      "322   Water Polo  1908  0.009029\n",
      "387   Water Polo  1912  0.011139\n",
      "452   Water Polo  1920  0.023532\n",
      "517   Water Polo  1924  0.017741\n",
      "582   Water Polo  1928  0.020093\n",
      "647   Water Polo  1932  0.012346\n",
      "712   Water Polo  1936  0.019189\n",
      "777   Water Polo  1948  0.020856\n",
      "842   Water Polo  1952  0.020410\n",
      "907   Water Polo  1956  0.014921\n",
      "972   Water Polo  1960  0.016243\n",
      "1037  Water Polo  1964  0.014451\n",
      "1102  Water Polo  1968  0.015459\n",
      "1167  Water Polo  1972  0.014717\n",
      "1232  Water Polo  1976  0.012474\n",
      "1297  Water Polo  1980  0.014770\n",
      "1362  Water Polo  1984  0.013203\n",
      "1427  Water Polo  1988  0.010630\n",
      "1492  Water Polo  1992  0.009261\n",
      "1557  Water Polo  1996  0.011103\n",
      "1622  Water Polo  2000  0.016714\n",
      "1687  Water Polo  2004  0.018969\n",
      "1752  Water Polo  2008  0.018821\n",
      "1817  Water Polo  2012  0.019892\n",
      "1882  Water Polo  2016  0.018849\n",
      "1947  Water Polo  2020  0.022899\n",
      "2012  Water Polo  2024  0.023735\n",
      "\n",
      "Prepared time series data for Water Polo (popularity):\n",
      " Year\n",
      "1900    0.027376\n",
      "1904    0.016141\n",
      "1908    0.009029\n",
      "1912    0.011139\n",
      "1920    0.023532\n",
      "1924    0.017741\n",
      "1928    0.020093\n",
      "1932    0.012346\n",
      "1936    0.019189\n",
      "1948    0.020856\n",
      "1952    0.020410\n",
      "1956    0.014921\n",
      "1960    0.016243\n",
      "1964    0.014451\n",
      "1968    0.015459\n",
      "1972    0.014717\n",
      "1976    0.012474\n",
      "1980    0.014770\n",
      "1984    0.013203\n",
      "1988    0.010630\n",
      "1992    0.009261\n",
      "1996    0.011103\n",
      "2000    0.016714\n",
      "2004    0.018969\n",
      "2008    0.018821\n",
      "2012    0.019892\n",
      "2016    0.018849\n",
      "2020    0.022899\n",
      "2024    0.023735\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Weightlifting (popularity)\n",
      "Raw data for Weightlifting (popularity):\n",
      "               Sport  Year     Value\n",
      "63    Weightlifting  1896  0.026316\n",
      "193   Weightlifting  1904  0.005380\n",
      "258   Weightlifting  1906  0.012695\n",
      "453   Weightlifting  1920  0.012349\n",
      "518   Weightlifting  1924  0.018795\n",
      "583   Weightlifting  1928  0.016864\n",
      "648   Weightlifting  1932  0.008732\n",
      "713   Weightlifting  1936  0.010811\n",
      "778   Weightlifting  1948  0.016043\n",
      "843   Weightlifting  1952  0.015174\n",
      "908   Weightlifting  1956  0.016320\n",
      "973   Weightlifting  1960  0.018625\n",
      "1038  Weightlifting  1964  0.015717\n",
      "1103  Weightlifting  1968  0.015269\n",
      "1168  Weightlifting  1972  0.015720\n",
      "1233  Weightlifting  1976  0.016473\n",
      "1298  Weightlifting  1980  0.019246\n",
      "1363  Weightlifting  1984  0.016051\n",
      "1428  Weightlifting  1988  0.015399\n",
      "1493  Weightlifting  1992  0.014866\n",
      "1558  Weightlifting  1996  0.017634\n",
      "1623  Weightlifting  2000  0.017799\n",
      "1688  Weightlifting  2004  0.018523\n",
      "1753  Weightlifting  2008  0.018600\n",
      "1818  Weightlifting  2012  0.019505\n",
      "1883  Weightlifting  2016  0.018629\n",
      "1948  Weightlifting  2020  0.018547\n",
      "2013  Weightlifting  2024  0.011769\n",
      "\n",
      "Prepared time series data for Weightlifting (popularity):\n",
      " Year\n",
      "1896    0.026316\n",
      "1904    0.005380\n",
      "1906    0.012695\n",
      "1920    0.012349\n",
      "1924    0.018795\n",
      "1928    0.016864\n",
      "1932    0.008732\n",
      "1936    0.010811\n",
      "1948    0.016043\n",
      "1952    0.015174\n",
      "1956    0.016320\n",
      "1960    0.018625\n",
      "1964    0.015717\n",
      "1968    0.015269\n",
      "1972    0.015720\n",
      "1976    0.016473\n",
      "1980    0.019246\n",
      "1984    0.016051\n",
      "1988    0.015399\n",
      "1992    0.014866\n",
      "1996    0.017634\n",
      "2000    0.017799\n",
      "2004    0.018523\n",
      "2008    0.018600\n",
      "2012    0.019505\n",
      "2016    0.018629\n",
      "2020    0.018547\n",
      "2024    0.011769\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Wrestling (popularity)\n",
      "Raw data for Wrestling (popularity):\n",
      "           Sport  Year     Value\n",
      "64    Wrestling  1896  0.013158\n",
      "194   Wrestling  1904  0.036895\n",
      "259   Wrestling  1906  0.022504\n",
      "324   Wrestling  1908  0.042889\n",
      "389   Wrestling  1912  0.042079\n",
      "454   Wrestling  1920  0.037512\n",
      "519   Wrestling  1924  0.042860\n",
      "584   Wrestling  1928  0.030319\n",
      "649   Wrestling  1932  0.027100\n",
      "714   Wrestling  1936  0.028378\n",
      "779   Wrestling  1948  0.030615\n",
      "844   Wrestling  1952  0.027997\n",
      "909   Wrestling  1956  0.030308\n",
      "974   Wrestling  1960  0.036492\n",
      "1039  Wrestling  1964  0.031857\n",
      "1104  Wrestling  1968  0.031778\n",
      "1169  Wrestling  1972  0.034200\n",
      "1234  Wrestling  1976  0.033232\n",
      "1299  Wrestling  1980  0.030211\n",
      "1364  Wrestling  1984  0.024681\n",
      "1429  Wrestling  1988  0.031139\n",
      "1494  Wrestling  1992  0.022604\n",
      "1559  Wrestling  1996  0.029100\n",
      "1624  Wrestling  2000  0.022719\n",
      "1689  Wrestling  2004  0.025441\n",
      "1754  Wrestling  2008  0.025217\n",
      "1819  Wrestling  2012  0.026238\n",
      "1884  Wrestling  2016  0.025278\n",
      "1949  Wrestling  2020  0.027252\n",
      "2014  Wrestling  2024  0.028246\n",
      "\n",
      "Prepared time series data for Wrestling (popularity):\n",
      " Year\n",
      "1896    0.013158\n",
      "1904    0.036895\n",
      "1906    0.022504\n",
      "1908    0.042889\n",
      "1912    0.042079\n",
      "1920    0.037512\n",
      "1924    0.042860\n",
      "1928    0.030319\n",
      "1932    0.027100\n",
      "1936    0.028378\n",
      "1948    0.030615\n",
      "1952    0.027997\n",
      "1956    0.030308\n",
      "1960    0.036492\n",
      "1964    0.031857\n",
      "1968    0.031778\n",
      "1972    0.034200\n",
      "1976    0.033232\n",
      "1980    0.030211\n",
      "1984    0.024681\n",
      "1988    0.031139\n",
      "1992    0.022604\n",
      "1996    0.029100\n",
      "2000    0.022719\n",
      "2004    0.025441\n",
      "2008    0.025217\n",
      "2012    0.026238\n",
      "2016    0.025278\n",
      "2020    0.027252\n",
      "2024    0.028246\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing parameter: normalizedcountry\n",
      "\n",
      "Processing sport: Alpine Skiing (normalizedcountry)\n",
      "Raw data for Alpine Skiing (normalizedcountry):\n",
      "               Sport  Year  Value\n",
      "650   Alpine Skiing  1936  0.130\n",
      "715   Alpine Skiing  1948  0.125\n",
      "780   Alpine Skiing  1952  0.140\n",
      "845   Alpine Skiing  1956  0.145\n",
      "910   Alpine Skiing  1960  0.110\n",
      "975   Alpine Skiing  1964  0.155\n",
      "1040  Alpine Skiing  1968  0.165\n",
      "1105  Alpine Skiing  1972  0.135\n",
      "1170  Alpine Skiing  1976  0.165\n",
      "1235  Alpine Skiing  1980  0.150\n",
      "1300  Alpine Skiing  1984  0.210\n",
      "1365  Alpine Skiing  1988  0.215\n",
      "1430  Alpine Skiing  1992  0.250\n",
      "\n",
      "Prepared time series data for Alpine Skiing (normalizedcountry):\n",
      " Year\n",
      "1936    0.130\n",
      "1948    0.125\n",
      "1952    0.140\n",
      "1956    0.145\n",
      "1960    0.110\n",
      "1964    0.155\n",
      "1968    0.165\n",
      "1972    0.135\n",
      "1976    0.165\n",
      "1980    0.150\n",
      "1984    0.210\n",
      "1988    0.215\n",
      "1992    0.250\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Alpinism (normalizedcountry)\n",
      "Raw data for Alpinism (normalizedcountry):\n",
      "         Sport  Year  Value\n",
      "456  Alpinism  1924  0.020\n",
      "586  Alpinism  1932  0.005\n",
      "651  Alpinism  1936  0.005\n",
      "\n",
      "Prepared time series data for Alpinism (normalizedcountry):\n",
      " Year\n",
      "1924    0.020\n",
      "1932    0.005\n",
      "1936    0.005\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Archery (normalizedcountry)\n",
      "Raw data for Archery (normalizedcountry):\n",
      "         Sport  Year  Value\n",
      "67    Archery  1900  0.015\n",
      "132   Archery  1904  0.005\n",
      "262   Archery  1908  0.015\n",
      "392   Archery  1920  0.015\n",
      "1107  Archery  1972  0.135\n",
      "1172  Archery  1976  0.120\n",
      "1237  Archery  1980  0.125\n",
      "1302  Archery  1984  0.175\n",
      "1367  Archery  1988  0.205\n",
      "1432  Archery  1992  0.220\n",
      "1497  Archery  1996  0.205\n",
      "1562  Archery  2000  0.230\n",
      "1627  Archery  2004  0.215\n",
      "1692  Archery  2008  0.245\n",
      "1757  Archery  2012  0.275\n",
      "1822  Archery  2016  0.280\n",
      "\n",
      "Prepared time series data for Archery (normalizedcountry):\n",
      " Year\n",
      "1900    0.015\n",
      "1904    0.005\n",
      "1908    0.015\n",
      "1920    0.015\n",
      "1972    0.135\n",
      "1976    0.120\n",
      "1980    0.125\n",
      "1984    0.175\n",
      "1988    0.205\n",
      "1992    0.220\n",
      "1996    0.205\n",
      "2000    0.230\n",
      "2004    0.215\n",
      "2008    0.245\n",
      "2012    0.275\n",
      "2016    0.280\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Art Competitions (normalizedcountry)\n",
      "Raw data for Art Competitions (normalizedcountry):\n",
      "                 Sport  Year  Value\n",
      "328  Art Competitions  1912  0.060\n",
      "393  Art Competitions  1920  0.025\n",
      "458  Art Competitions  1924  0.120\n",
      "523  Art Competitions  1928  0.095\n",
      "588  Art Competitions  1932  0.180\n",
      "653  Art Competitions  1936  0.120\n",
      "718  Art Competitions  1948  0.135\n",
      "\n",
      "Prepared time series data for Art Competitions (normalizedcountry):\n",
      " Year\n",
      "1912    0.060\n",
      "1920    0.025\n",
      "1924    0.120\n",
      "1928    0.095\n",
      "1932    0.180\n",
      "1936    0.120\n",
      "1948    0.135\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Athletics (normalizedcountry)\n",
      "Raw data for Athletics (normalizedcountry):\n",
      "           Sport  Year  Value\n",
      "4     Athletics  1896  0.045\n",
      "69    Athletics  1900  0.085\n",
      "134   Athletics  1904  0.055\n",
      "199   Athletics  1906  0.100\n",
      "264   Athletics  1908  0.100\n",
      "329   Athletics  1912  0.135\n",
      "394   Athletics  1920  0.125\n",
      "459   Athletics  1924  0.200\n",
      "524   Athletics  1928  0.200\n",
      "589   Athletics  1932  0.170\n",
      "654   Athletics  1936  0.215\n",
      "719   Athletics  1948  0.265\n",
      "784   Athletics  1952  0.285\n",
      "849   Athletics  1956  0.295\n",
      "914   Athletics  1960  0.360\n",
      "979   Athletics  1964  0.400\n",
      "1044  Athletics  1968  0.460\n",
      "1109  Athletics  1972  0.520\n",
      "1174  Athletics  1976  0.395\n",
      "1239  Athletics  1980  0.350\n",
      "1304  Athletics  1984  0.620\n",
      "1369  Athletics  1988  0.740\n",
      "1434  Athletics  1992  0.780\n",
      "1499  Athletics  1996  0.950\n",
      "1564  Athletics  2000  0.965\n",
      "1629  Athletics  2004  0.980\n",
      "1694  Athletics  2008  1.000\n",
      "1759  Athletics  2012  1.005\n",
      "1824  Athletics  2016  1.000\n",
      "\n",
      "Prepared time series data for Athletics (normalizedcountry):\n",
      " Year\n",
      "1896    0.045\n",
      "1900    0.085\n",
      "1904    0.055\n",
      "1906    0.100\n",
      "1908    0.100\n",
      "1912    0.135\n",
      "1920    0.125\n",
      "1924    0.200\n",
      "1928    0.200\n",
      "1932    0.170\n",
      "1936    0.215\n",
      "1948    0.265\n",
      "1952    0.285\n",
      "1956    0.295\n",
      "1960    0.360\n",
      "1964    0.400\n",
      "1968    0.460\n",
      "1972    0.520\n",
      "1976    0.395\n",
      "1980    0.350\n",
      "1984    0.620\n",
      "1988    0.740\n",
      "1992    0.780\n",
      "1996    0.950\n",
      "2000    0.965\n",
      "2004    0.980\n",
      "2008    1.000\n",
      "2012    1.005\n",
      "2016    1.000\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Badminton (normalizedcountry)\n",
      "Raw data for Badminton (normalizedcountry):\n",
      "           Sport  Year  Value\n",
      "1435  Badminton  1992  0.180\n",
      "1500  Badminton  1996  0.185\n",
      "1565  Badminton  2000  0.140\n",
      "1630  Badminton  2004  0.160\n",
      "1695  Badminton  2008  0.250\n",
      "1760  Badminton  2012  0.255\n",
      "1825  Badminton  2016  0.230\n",
      "\n",
      "Prepared time series data for Badminton (normalizedcountry):\n",
      " Year\n",
      "1992    0.180\n",
      "1996    0.185\n",
      "2000    0.140\n",
      "2004    0.160\n",
      "2008    0.250\n",
      "2012    0.255\n",
      "2016    0.230\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Baseball (normalizedcountry)\n",
      "Raw data for Baseball (normalizedcountry):\n",
      "          Sport  Year  Value\n",
      "1436  Baseball  1992   0.04\n",
      "1501  Baseball  1996   0.04\n",
      "1566  Baseball  2000   0.04\n",
      "1631  Baseball  2004   0.04\n",
      "1696  Baseball  2008   0.04\n",
      "\n",
      "Prepared time series data for Baseball (normalizedcountry):\n",
      " Year\n",
      "1992    0.04\n",
      "1996    0.04\n",
      "2000    0.04\n",
      "2004    0.04\n",
      "2008    0.04\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Basketball (normalizedcountry)\n",
      "Raw data for Basketball (normalizedcountry):\n",
      "            Sport  Year  Value\n",
      "657   Basketball  1936  0.105\n",
      "722   Basketball  1948  0.115\n",
      "787   Basketball  1952  0.115\n",
      "852   Basketball  1956  0.075\n",
      "917   Basketball  1960  0.080\n",
      "982   Basketball  1964  0.080\n",
      "1047  Basketball  1968  0.080\n",
      "1112  Basketball  1972  0.080\n",
      "1177  Basketball  1976  0.065\n",
      "1242  Basketball  1980  0.070\n",
      "1307  Basketball  1984  0.065\n",
      "1372  Basketball  1988  0.070\n",
      "1437  Basketball  1992  0.075\n",
      "1502  Basketball  1996  0.095\n",
      "1567  Basketball  2000  0.090\n",
      "1632  Basketball  2004  0.090\n",
      "1697  Basketball  2008  0.095\n",
      "1762  Basketball  2012  0.085\n",
      "1827  Basketball  2016  0.085\n",
      "\n",
      "Prepared time series data for Basketball (normalizedcountry):\n",
      " Year\n",
      "1936    0.105\n",
      "1948    0.115\n",
      "1952    0.115\n",
      "1956    0.075\n",
      "1960    0.080\n",
      "1964    0.080\n",
      "1968    0.080\n",
      "1972    0.080\n",
      "1976    0.065\n",
      "1980    0.070\n",
      "1984    0.065\n",
      "1988    0.070\n",
      "1992    0.075\n",
      "1996    0.095\n",
      "2000    0.090\n",
      "2004    0.090\n",
      "2008    0.095\n",
      "2012    0.085\n",
      "2016    0.085\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Basque Pelota (normalizedcountry)\n",
      "Raw data for Basque Pelota (normalizedcountry):\n",
      "             Sport  Year  Value\n",
      "73  Basque Pelota  1900  0.005\n",
      "\n",
      "Prepared time series data for Basque Pelota (normalizedcountry):\n",
      " Year\n",
      "1900    0.005\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Beach Volleyball (normalizedcountry)\n",
      "Raw data for Beach Volleyball (normalizedcountry):\n",
      "                  Sport  Year  Value\n",
      "1504  Beach Volleyball  1996  0.105\n",
      "1569  Beach Volleyball  2000  0.115\n",
      "1634  Beach Volleyball  2004  0.120\n",
      "1699  Beach Volleyball  2008  0.115\n",
      "1764  Beach Volleyball  2012  0.115\n",
      "1829  Beach Volleyball  2016  0.120\n",
      "\n",
      "Prepared time series data for Beach Volleyball (normalizedcountry):\n",
      " Year\n",
      "1996    0.105\n",
      "2000    0.115\n",
      "2004    0.120\n",
      "2008    0.115\n",
      "2012    0.115\n",
      "2016    0.120\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Biathlon (normalizedcountry)\n",
      "Raw data for Biathlon (normalizedcountry):\n",
      "          Sport  Year  Value\n",
      "920   Biathlon  1960  0.045\n",
      "985   Biathlon  1964  0.070\n",
      "1050  Biathlon  1968  0.080\n",
      "1115  Biathlon  1972  0.070\n",
      "1180  Biathlon  1976  0.090\n",
      "1245  Biathlon  1980  0.090\n",
      "1310  Biathlon  1984  0.125\n",
      "1375  Biathlon  1988  0.110\n",
      "1440  Biathlon  1992  0.140\n",
      "\n",
      "Prepared time series data for Biathlon (normalizedcountry):\n",
      " Year\n",
      "1960    0.045\n",
      "1964    0.070\n",
      "1968    0.080\n",
      "1972    0.070\n",
      "1976    0.090\n",
      "1980    0.090\n",
      "1984    0.125\n",
      "1988    0.110\n",
      "1992    0.140\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Bobsleigh (normalizedcountry)\n",
      "Raw data for Bobsleigh (normalizedcountry):\n",
      "           Sport  Year  Value\n",
      "466   Bobsleigh  1924  0.025\n",
      "531   Bobsleigh  1928  0.070\n",
      "596   Bobsleigh  1932  0.040\n",
      "661   Bobsleigh  1936  0.065\n",
      "726   Bobsleigh  1948  0.045\n",
      "791   Bobsleigh  1952  0.050\n",
      "856   Bobsleigh  1956  0.070\n",
      "986   Bobsleigh  1964  0.055\n",
      "1051  Bobsleigh  1968  0.055\n",
      "1116  Bobsleigh  1972  0.055\n",
      "1181  Bobsleigh  1976  0.065\n",
      "1246  Bobsleigh  1980  0.055\n",
      "1311  Bobsleigh  1984  0.080\n",
      "1376  Bobsleigh  1988  0.115\n",
      "1441  Bobsleigh  1992  0.125\n",
      "\n",
      "Prepared time series data for Bobsleigh (normalizedcountry):\n",
      " Year\n",
      "1924    0.025\n",
      "1928    0.070\n",
      "1932    0.040\n",
      "1936    0.065\n",
      "1948    0.045\n",
      "1952    0.050\n",
      "1956    0.070\n",
      "1964    0.055\n",
      "1968    0.055\n",
      "1972    0.055\n",
      "1976    0.065\n",
      "1980    0.055\n",
      "1984    0.080\n",
      "1988    0.115\n",
      "1992    0.125\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Boxing (normalizedcountry)\n",
      "Raw data for Boxing (normalizedcountry):\n",
      "        Sport  Year  Value\n",
      "142   Boxing  1904  0.005\n",
      "272   Boxing  1908  0.020\n",
      "402   Boxing  1920  0.060\n",
      "467   Boxing  1924  0.135\n",
      "532   Boxing  1928  0.145\n",
      "597   Boxing  1932  0.090\n",
      "662   Boxing  1936  0.155\n",
      "727   Boxing  1948  0.195\n",
      "792   Boxing  1952  0.215\n",
      "857   Boxing  1956  0.170\n",
      "922   Boxing  1960  0.270\n",
      "987   Boxing  1964  0.280\n",
      "1052  Boxing  1968  0.325\n",
      "1117  Boxing  1972  0.400\n",
      "1182  Boxing  1976  0.270\n",
      "1247  Boxing  1980  0.255\n",
      "1312  Boxing  1984  0.405\n",
      "1377  Boxing  1988  0.530\n",
      "1442  Boxing  1992  0.390\n",
      "1507  Boxing  1996  0.485\n",
      "1572  Boxing  2000  0.375\n",
      "1637  Boxing  2004  0.360\n",
      "1702  Boxing  2008  0.385\n",
      "1767  Boxing  2012  0.385\n",
      "1832  Boxing  2016  0.380\n",
      "\n",
      "Prepared time series data for Boxing (normalizedcountry):\n",
      " Year\n",
      "1904    0.005\n",
      "1908    0.020\n",
      "1920    0.060\n",
      "1924    0.135\n",
      "1928    0.145\n",
      "1932    0.090\n",
      "1936    0.155\n",
      "1948    0.195\n",
      "1952    0.215\n",
      "1956    0.170\n",
      "1960    0.270\n",
      "1964    0.280\n",
      "1968    0.325\n",
      "1972    0.400\n",
      "1976    0.270\n",
      "1980    0.255\n",
      "1984    0.405\n",
      "1988    0.530\n",
      "1992    0.390\n",
      "1996    0.485\n",
      "2000    0.375\n",
      "2004    0.360\n",
      "2008    0.385\n",
      "2012    0.385\n",
      "2016    0.380\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Canoeing (normalizedcountry)\n",
      "Raw data for Canoeing (normalizedcountry):\n",
      "          Sport  Year  Value\n",
      "663   Canoeing  1936  0.095\n",
      "728   Canoeing  1948  0.080\n",
      "793   Canoeing  1952  0.105\n",
      "858   Canoeing  1956  0.085\n",
      "923   Canoeing  1960  0.120\n",
      "988   Canoeing  1964  0.110\n",
      "1053  Canoeing  1968  0.135\n",
      "1118  Canoeing  1972  0.150\n",
      "1183  Canoeing  1976  0.140\n",
      "1248  Canoeing  1980  0.115\n",
      "1313  Canoeing  1984  0.140\n",
      "1378  Canoeing  1988  0.160\n",
      "1443  Canoeing  1992  0.230\n",
      "1508  Canoeing  1996  0.270\n",
      "1573  Canoeing  2000  0.235\n",
      "1638  Canoeing  2004  0.255\n",
      "1703  Canoeing  2008  0.285\n",
      "1768  Canoeing  2012  0.280\n",
      "1833  Canoeing  2016  0.270\n",
      "\n",
      "Prepared time series data for Canoeing (normalizedcountry):\n",
      " Year\n",
      "1936    0.095\n",
      "1948    0.080\n",
      "1952    0.105\n",
      "1956    0.085\n",
      "1960    0.120\n",
      "1964    0.110\n",
      "1968    0.135\n",
      "1972    0.150\n",
      "1976    0.140\n",
      "1980    0.115\n",
      "1984    0.140\n",
      "1988    0.160\n",
      "1992    0.230\n",
      "1996    0.270\n",
      "2000    0.235\n",
      "2004    0.255\n",
      "2008    0.285\n",
      "2012    0.280\n",
      "2016    0.270\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Cricket (normalizedcountry)\n",
      "Raw data for Cricket (normalizedcountry):\n",
      "       Sport  Year  Value\n",
      "79  Cricket  1900   0.01\n",
      "\n",
      "Prepared time series data for Cricket (normalizedcountry):\n",
      " Year\n",
      "1900    0.01\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Croquet (normalizedcountry)\n",
      "Raw data for Croquet (normalizedcountry):\n",
      "       Sport  Year  Value\n",
      "80  Croquet  1900  0.005\n",
      "\n",
      "Prepared time series data for Croquet (normalizedcountry):\n",
      " Year\n",
      "1900    0.005\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Cross Country Skiing (normalizedcountry)\n",
      "Raw data for Cross Country Skiing (normalizedcountry):\n",
      "                      Sport  Year  Value\n",
      "471   Cross Country Skiing  1924  0.060\n",
      "536   Cross Country Skiing  1928  0.075\n",
      "601   Cross Country Skiing  1932  0.055\n",
      "666   Cross Country Skiing  1936  0.110\n",
      "731   Cross Country Skiing  1948  0.075\n",
      "796   Cross Country Skiing  1952  0.095\n",
      "861   Cross Country Skiing  1956  0.100\n",
      "926   Cross Country Skiing  1960  0.095\n",
      "991   Cross Country Skiing  1964  0.120\n",
      "1056  Cross Country Skiing  1968  0.125\n",
      "1121  Cross Country Skiing  1972  0.095\n",
      "1186  Cross Country Skiing  1976  0.120\n",
      "1251  Cross Country Skiing  1980  0.120\n",
      "1316  Cross Country Skiing  1984  0.160\n",
      "1381  Cross Country Skiing  1988  0.175\n",
      "1446  Cross Country Skiing  1992  0.200\n",
      "\n",
      "Prepared time series data for Cross Country Skiing (normalizedcountry):\n",
      " Year\n",
      "1924    0.060\n",
      "1928    0.075\n",
      "1932    0.055\n",
      "1936    0.110\n",
      "1948    0.075\n",
      "1952    0.095\n",
      "1956    0.100\n",
      "1960    0.095\n",
      "1964    0.120\n",
      "1968    0.125\n",
      "1972    0.095\n",
      "1976    0.120\n",
      "1980    0.120\n",
      "1984    0.160\n",
      "1988    0.175\n",
      "1992    0.200\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Curling (normalizedcountry)\n",
      "Raw data for Curling (normalizedcountry):\n",
      "        Sport  Year  Value\n",
      "472  Curling  1924  0.015\n",
      "\n",
      "Prepared time series data for Curling (normalizedcountry):\n",
      " Year\n",
      "1924    0.015\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Cycling (normalizedcountry)\n",
      "Raw data for Cycling (normalizedcountry):\n",
      "         Sport  Year  Value\n",
      "18    Cycling  1896  0.025\n",
      "83    Cycling  1900  0.035\n",
      "148   Cycling  1904  0.010\n",
      "213   Cycling  1906  0.055\n",
      "278   Cycling  1908  0.055\n",
      "343   Cycling  1912  0.080\n",
      "408   Cycling  1920  0.070\n",
      "473   Cycling  1924  0.120\n",
      "538   Cycling  1928  0.135\n",
      "603   Cycling  1932  0.065\n",
      "668   Cycling  1936  0.150\n",
      "733   Cycling  1948  0.165\n",
      "798   Cycling  1952  0.180\n",
      "863   Cycling  1956  0.150\n",
      "928   Cycling  1960  0.240\n",
      "993   Cycling  1964  0.200\n",
      "1058  Cycling  1968  0.260\n",
      "1123  Cycling  1972  0.270\n",
      "1188  Cycling  1976  0.245\n",
      "1253  Cycling  1980  0.170\n",
      "1318  Cycling  1984  0.270\n",
      "1383  Cycling  1988  0.310\n",
      "1448  Cycling  1992  0.380\n",
      "1513  Cycling  1996  0.340\n",
      "1578  Cycling  2000  0.275\n",
      "1643  Cycling  2004  0.305\n",
      "1708  Cycling  2008  0.330\n",
      "1773  Cycling  2012  0.370\n",
      "1838  Cycling  2016  0.395\n",
      "\n",
      "Prepared time series data for Cycling (normalizedcountry):\n",
      " Year\n",
      "1896    0.025\n",
      "1900    0.035\n",
      "1904    0.010\n",
      "1906    0.055\n",
      "1908    0.055\n",
      "1912    0.080\n",
      "1920    0.070\n",
      "1924    0.120\n",
      "1928    0.135\n",
      "1932    0.065\n",
      "1936    0.150\n",
      "1948    0.165\n",
      "1952    0.180\n",
      "1956    0.150\n",
      "1960    0.240\n",
      "1964    0.200\n",
      "1968    0.260\n",
      "1972    0.270\n",
      "1976    0.245\n",
      "1980    0.170\n",
      "1984    0.270\n",
      "1988    0.310\n",
      "1992    0.380\n",
      "1996    0.340\n",
      "2000    0.275\n",
      "2004    0.305\n",
      "2008    0.330\n",
      "2012    0.370\n",
      "2016    0.395\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Diving (normalizedcountry)\n",
      "Raw data for Diving (normalizedcountry):\n",
      "        Sport  Year  Value\n",
      "149   Diving  1904  0.010\n",
      "214   Diving  1906  0.035\n",
      "279   Diving  1908  0.045\n",
      "344   Diving  1912  0.050\n",
      "409   Diving  1920  0.070\n",
      "474   Diving  1924  0.070\n",
      "539   Diving  1928  0.085\n",
      "604   Diving  1932  0.045\n",
      "669   Diving  1936  0.105\n",
      "734   Diving  1948  0.110\n",
      "799   Diving  1952  0.110\n",
      "864   Diving  1956  0.080\n",
      "929   Diving  1960  0.125\n",
      "994   Diving  1964  0.100\n",
      "1059  Diving  1968  0.105\n",
      "1124  Diving  1972  0.125\n",
      "1189  Diving  1976  0.110\n",
      "1254  Diving  1980  0.105\n",
      "1319  Diving  1984  0.145\n",
      "1384  Diving  1988  0.155\n",
      "1449  Diving  1992  0.155\n",
      "1514  Diving  1996  0.195\n",
      "1579  Diving  2000  0.210\n",
      "1644  Diving  2004  0.150\n",
      "1709  Diving  2008  0.145\n",
      "1774  Diving  2012  0.125\n",
      "1839  Diving  2016  0.145\n",
      "\n",
      "Prepared time series data for Diving (normalizedcountry):\n",
      " Year\n",
      "1904    0.010\n",
      "1906    0.035\n",
      "1908    0.045\n",
      "1912    0.050\n",
      "1920    0.070\n",
      "1924    0.070\n",
      "1928    0.085\n",
      "1932    0.045\n",
      "1936    0.105\n",
      "1948    0.110\n",
      "1952    0.110\n",
      "1956    0.080\n",
      "1960    0.125\n",
      "1964    0.100\n",
      "1968    0.105\n",
      "1972    0.125\n",
      "1976    0.110\n",
      "1980    0.105\n",
      "1984    0.145\n",
      "1988    0.155\n",
      "1992    0.155\n",
      "1996    0.195\n",
      "2000    0.210\n",
      "2004    0.150\n",
      "2008    0.145\n",
      "2012    0.125\n",
      "2016    0.145\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Equestrianism (normalizedcountry)\n",
      "Raw data for Equestrianism (normalizedcountry):\n",
      "               Sport  Year  Value\n",
      "85    Equestrianism  1900  0.040\n",
      "345   Equestrianism  1912  0.050\n",
      "410   Equestrianism  1920  0.040\n",
      "475   Equestrianism  1924  0.085\n",
      "540   Equestrianism  1928  0.100\n",
      "605   Equestrianism  1932  0.030\n",
      "670   Equestrianism  1936  0.105\n",
      "735   Equestrianism  1948  0.085\n",
      "800   Equestrianism  1952  0.125\n",
      "865   Equestrianism  1956  0.145\n",
      "930   Equestrianism  1960  0.145\n",
      "995   Equestrianism  1964  0.100\n",
      "1060  Equestrianism  1968  0.090\n",
      "1125  Equestrianism  1972  0.135\n",
      "1190  Equestrianism  1976  0.115\n",
      "1255  Equestrianism  1980  0.055\n",
      "1320  Equestrianism  1984  0.150\n",
      "1385  Equestrianism  1988  0.160\n",
      "1450  Equestrianism  1992  0.175\n",
      "1515  Equestrianism  1996  0.150\n",
      "1580  Equestrianism  2000  0.185\n",
      "1645  Equestrianism  2004  0.190\n",
      "1710  Equestrianism  2008  0.210\n",
      "1775  Equestrianism  2012  0.200\n",
      "1840  Equestrianism  2016  0.215\n",
      "\n",
      "Prepared time series data for Equestrianism (normalizedcountry):\n",
      " Year\n",
      "1900    0.040\n",
      "1912    0.050\n",
      "1920    0.040\n",
      "1924    0.085\n",
      "1928    0.100\n",
      "1932    0.030\n",
      "1936    0.105\n",
      "1948    0.085\n",
      "1952    0.125\n",
      "1956    0.145\n",
      "1960    0.145\n",
      "1964    0.100\n",
      "1968    0.090\n",
      "1972    0.135\n",
      "1976    0.115\n",
      "1980    0.055\n",
      "1984    0.150\n",
      "1988    0.160\n",
      "1992    0.175\n",
      "1996    0.150\n",
      "2000    0.185\n",
      "2004    0.190\n",
      "2008    0.210\n",
      "2012    0.200\n",
      "2016    0.215\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Fencing (normalizedcountry)\n",
      "Raw data for Fencing (normalizedcountry):\n",
      "         Sport  Year  Value\n",
      "21    Fencing  1896  0.020\n",
      "86    Fencing  1900  0.095\n",
      "151   Fencing  1904  0.020\n",
      "216   Fencing  1906  0.060\n",
      "281   Fencing  1908  0.070\n",
      "346   Fencing  1912  0.080\n",
      "411   Fencing  1920  0.065\n",
      "476   Fencing  1924  0.115\n",
      "541   Fencing  1928  0.135\n",
      "606   Fencing  1932  0.080\n",
      "671   Fencing  1936  0.145\n",
      "736   Fencing  1948  0.150\n",
      "801   Fencing  1952  0.160\n",
      "866   Fencing  1956  0.115\n",
      "931   Fencing  1960  0.210\n",
      "996   Fencing  1964  0.150\n",
      "1061  Fencing  1968  0.170\n",
      "1126  Fencing  1972  0.185\n",
      "1191  Fencing  1976  0.170\n",
      "1256  Fencing  1980  0.100\n",
      "1321  Fencing  1984  0.190\n",
      "1386  Fencing  1988  0.210\n",
      "1451  Fencing  1992  0.210\n",
      "1516  Fencing  1996  0.230\n",
      "1581  Fencing  2000  0.200\n",
      "1646  Fencing  2004  0.210\n",
      "1711  Fencing  2008  0.225\n",
      "1776  Fencing  2012  0.220\n",
      "1841  Fencing  2016  0.235\n",
      "\n",
      "Prepared time series data for Fencing (normalizedcountry):\n",
      " Year\n",
      "1896    0.020\n",
      "1900    0.095\n",
      "1904    0.020\n",
      "1906    0.060\n",
      "1908    0.070\n",
      "1912    0.080\n",
      "1920    0.065\n",
      "1924    0.115\n",
      "1928    0.135\n",
      "1932    0.080\n",
      "1936    0.145\n",
      "1948    0.150\n",
      "1952    0.160\n",
      "1956    0.115\n",
      "1960    0.210\n",
      "1964    0.150\n",
      "1968    0.170\n",
      "1972    0.185\n",
      "1976    0.170\n",
      "1980    0.100\n",
      "1984    0.190\n",
      "1988    0.210\n",
      "1992    0.210\n",
      "1996    0.230\n",
      "2000    0.200\n",
      "2004    0.210\n",
      "2008    0.225\n",
      "2012    0.220\n",
      "2016    0.235\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Figure Skating (normalizedcountry)\n",
      "Raw data for Figure Skating (normalizedcountry):\n",
      "                Sport  Year  Value\n",
      "282   Figure Skating  1908  0.030\n",
      "412   Figure Skating  1920  0.040\n",
      "477   Figure Skating  1924  0.055\n",
      "542   Figure Skating  1928  0.060\n",
      "607   Figure Skating  1932  0.065\n",
      "672   Figure Skating  1936  0.085\n",
      "737   Figure Skating  1948  0.060\n",
      "802   Figure Skating  1952  0.075\n",
      "867   Figure Skating  1956  0.075\n",
      "932   Figure Skating  1960  0.070\n",
      "997   Figure Skating  1964  0.075\n",
      "1062  Figure Skating  1968  0.085\n",
      "1127  Figure Skating  1972  0.090\n",
      "1192  Figure Skating  1976  0.090\n",
      "1257  Figure Skating  1980  0.100\n",
      "1322  Figure Skating  1984  0.100\n",
      "1387  Figure Skating  1988  0.130\n",
      "1452  Figure Skating  1992  0.140\n",
      "\n",
      "Prepared time series data for Figure Skating (normalizedcountry):\n",
      " Year\n",
      "1908    0.030\n",
      "1920    0.040\n",
      "1924    0.055\n",
      "1928    0.060\n",
      "1932    0.065\n",
      "1936    0.085\n",
      "1948    0.060\n",
      "1952    0.075\n",
      "1956    0.075\n",
      "1960    0.070\n",
      "1964    0.075\n",
      "1968    0.085\n",
      "1972    0.090\n",
      "1976    0.090\n",
      "1980    0.100\n",
      "1984    0.100\n",
      "1988    0.130\n",
      "1992    0.140\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Football (normalizedcountry)\n",
      "Raw data for Football (normalizedcountry):\n",
      "          Sport  Year  Value\n",
      "88    Football  1900  0.020\n",
      "153   Football  1904  0.010\n",
      "218   Football  1906  0.020\n",
      "283   Football  1908  0.025\n",
      "348   Football  1912  0.055\n",
      "413   Football  1920  0.070\n",
      "478   Football  1924  0.110\n",
      "543   Football  1928  0.085\n",
      "673   Football  1936  0.080\n",
      "738   Football  1948  0.090\n",
      "803   Football  1952  0.125\n",
      "868   Football  1956  0.055\n",
      "933   Football  1960  0.080\n",
      "998   Football  1964  0.070\n",
      "1063  Football  1968  0.080\n",
      "1128  Football  1972  0.080\n",
      "1193  Football  1976  0.065\n",
      "1258  Football  1980  0.080\n",
      "1323  Football  1984  0.080\n",
      "1388  Football  1988  0.080\n",
      "1453  Football  1992  0.080\n",
      "1518  Football  1996  0.105\n",
      "1583  Football  2000  0.100\n",
      "1648  Football  2004  0.110\n",
      "1713  Football  2008  0.105\n",
      "1778  Football  2012  0.120\n",
      "1843  Football  2016  0.115\n",
      "\n",
      "Prepared time series data for Football (normalizedcountry):\n",
      " Year\n",
      "1900    0.020\n",
      "1904    0.010\n",
      "1906    0.020\n",
      "1908    0.025\n",
      "1912    0.055\n",
      "1920    0.070\n",
      "1924    0.110\n",
      "1928    0.085\n",
      "1936    0.080\n",
      "1948    0.090\n",
      "1952    0.125\n",
      "1956    0.055\n",
      "1960    0.080\n",
      "1964    0.070\n",
      "1968    0.080\n",
      "1972    0.080\n",
      "1976    0.065\n",
      "1980    0.080\n",
      "1984    0.080\n",
      "1988    0.080\n",
      "1992    0.080\n",
      "1996    0.105\n",
      "2000    0.100\n",
      "2004    0.110\n",
      "2008    0.105\n",
      "2012    0.120\n",
      "2016    0.115\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Freestyle Skiing (normalizedcountry)\n",
      "Raw data for Freestyle Skiing (normalizedcountry):\n",
      "                  Sport  Year  Value\n",
      "1454  Freestyle Skiing  1992   0.09\n",
      "\n",
      "Prepared time series data for Freestyle Skiing (normalizedcountry):\n",
      " Year\n",
      "1992    0.09\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Golf (normalizedcountry)\n",
      "Raw data for Golf (normalizedcountry):\n",
      "      Sport  Year  Value\n",
      "90    Golf  1900  0.020\n",
      "155   Golf  1904  0.015\n",
      "1845  Golf  2016  0.205\n",
      "\n",
      "Prepared time series data for Golf (normalizedcountry):\n",
      " Year\n",
      "1900    0.020\n",
      "1904    0.015\n",
      "2016    0.205\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Gymnastics (normalizedcountry)\n",
      "Raw data for Gymnastics (normalizedcountry):\n",
      "            Sport  Year  Value\n",
      "26    Gymnastics  1896  0.040\n",
      "91    Gymnastics  1900  0.040\n",
      "156   Gymnastics  1904  0.025\n",
      "221   Gymnastics  1906  0.045\n",
      "286   Gymnastics  1908  0.065\n",
      "351   Gymnastics  1912  0.060\n",
      "416   Gymnastics  1920  0.055\n",
      "481   Gymnastics  1924  0.045\n",
      "546   Gymnastics  1928  0.055\n",
      "611   Gymnastics  1932  0.035\n",
      "676   Gymnastics  1936  0.080\n",
      "741   Gymnastics  1948  0.095\n",
      "806   Gymnastics  1952  0.150\n",
      "871   Gymnastics  1956  0.105\n",
      "936   Gymnastics  1960  0.165\n",
      "1001  Gymnastics  1964  0.170\n",
      "1066  Gymnastics  1968  0.150\n",
      "1131  Gymnastics  1972  0.140\n",
      "1196  Gymnastics  1976  0.115\n",
      "1261  Gymnastics  1980  0.090\n",
      "1326  Gymnastics  1984  0.095\n",
      "1391  Gymnastics  1988  0.140\n",
      "1456  Gymnastics  1992  0.145\n",
      "1521  Gymnastics  1996  0.180\n",
      "1586  Gymnastics  2000  0.215\n",
      "1651  Gymnastics  2004  0.210\n",
      "1716  Gymnastics  2008  0.200\n",
      "1781  Gymnastics  2012  0.265\n",
      "1846  Gymnastics  2016  0.300\n",
      "\n",
      "Prepared time series data for Gymnastics (normalizedcountry):\n",
      " Year\n",
      "1896    0.040\n",
      "1900    0.040\n",
      "1904    0.025\n",
      "1906    0.045\n",
      "1908    0.065\n",
      "1912    0.060\n",
      "1920    0.055\n",
      "1924    0.045\n",
      "1928    0.055\n",
      "1932    0.035\n",
      "1936    0.080\n",
      "1948    0.095\n",
      "1952    0.150\n",
      "1956    0.105\n",
      "1960    0.165\n",
      "1964    0.170\n",
      "1968    0.150\n",
      "1972    0.140\n",
      "1976    0.115\n",
      "1980    0.090\n",
      "1984    0.095\n",
      "1988    0.140\n",
      "1992    0.145\n",
      "1996    0.180\n",
      "2000    0.215\n",
      "2004    0.210\n",
      "2008    0.200\n",
      "2012    0.265\n",
      "2016    0.300\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Handball (normalizedcountry)\n",
      "Raw data for Handball (normalizedcountry):\n",
      "          Sport  Year  Value\n",
      "677   Handball  1936  0.030\n",
      "1132  Handball  1972  0.080\n",
      "1197  Handball  1976  0.065\n",
      "1262  Handball  1980  0.070\n",
      "1327  Handball  1984  0.070\n",
      "1392  Handball  1988  0.075\n",
      "1457  Handball  1992  0.080\n",
      "1522  Handball  1996  0.090\n",
      "1587  Handball  2000  0.095\n",
      "1652  Handball  2004  0.080\n",
      "1717  Handball  2008  0.090\n",
      "1782  Handball  2012  0.085\n",
      "1847  Handball  2016  0.100\n",
      "\n",
      "Prepared time series data for Handball (normalizedcountry):\n",
      " Year\n",
      "1936    0.030\n",
      "1972    0.080\n",
      "1976    0.065\n",
      "1980    0.070\n",
      "1984    0.070\n",
      "1988    0.075\n",
      "1992    0.080\n",
      "1996    0.090\n",
      "2000    0.095\n",
      "2004    0.080\n",
      "2008    0.090\n",
      "2012    0.085\n",
      "2016    0.100\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Hockey (normalizedcountry)\n",
      "Raw data for Hockey (normalizedcountry):\n",
      "        Sport  Year  Value\n",
      "288   Hockey  1908  0.015\n",
      "418   Hockey  1920  0.020\n",
      "548   Hockey  1928  0.045\n",
      "613   Hockey  1932  0.015\n",
      "678   Hockey  1936  0.055\n",
      "743   Hockey  1948  0.065\n",
      "808   Hockey  1952  0.060\n",
      "873   Hockey  1956  0.060\n",
      "938   Hockey  1960  0.080\n",
      "1003  Hockey  1964  0.075\n",
      "1068  Hockey  1968  0.080\n",
      "1133  Hockey  1972  0.080\n",
      "1198  Hockey  1976  0.055\n",
      "1263  Hockey  1980  0.045\n",
      "1328  Hockey  1984  0.060\n",
      "1393  Hockey  1988  0.065\n",
      "1458  Hockey  1992  0.070\n",
      "1523  Hockey  1996  0.060\n",
      "1588  Hockey  2000  0.075\n",
      "1653  Hockey  2004  0.070\n",
      "1718  Hockey  2008  0.075\n",
      "1783  Hockey  2012  0.075\n",
      "1848  Hockey  2016  0.080\n",
      "\n",
      "Prepared time series data for Hockey (normalizedcountry):\n",
      " Year\n",
      "1908    0.015\n",
      "1920    0.020\n",
      "1928    0.045\n",
      "1932    0.015\n",
      "1936    0.055\n",
      "1948    0.065\n",
      "1952    0.060\n",
      "1956    0.060\n",
      "1960    0.080\n",
      "1964    0.075\n",
      "1968    0.080\n",
      "1972    0.080\n",
      "1976    0.055\n",
      "1980    0.045\n",
      "1984    0.060\n",
      "1988    0.065\n",
      "1992    0.070\n",
      "1996    0.060\n",
      "2000    0.075\n",
      "2004    0.070\n",
      "2008    0.075\n",
      "2012    0.075\n",
      "2016    0.080\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Ice Hockey (normalizedcountry)\n",
      "Raw data for Ice Hockey (normalizedcountry):\n",
      "            Sport  Year  Value\n",
      "419   Ice Hockey  1920  0.035\n",
      "484   Ice Hockey  1924  0.040\n",
      "549   Ice Hockey  1928  0.055\n",
      "614   Ice Hockey  1932  0.020\n",
      "679   Ice Hockey  1936  0.075\n",
      "744   Ice Hockey  1948  0.045\n",
      "809   Ice Hockey  1952  0.045\n",
      "874   Ice Hockey  1956  0.050\n",
      "939   Ice Hockey  1960  0.045\n",
      "1004  Ice Hockey  1964  0.080\n",
      "1069  Ice Hockey  1968  0.070\n",
      "1134  Ice Hockey  1972  0.055\n",
      "1199  Ice Hockey  1976  0.060\n",
      "1264  Ice Hockey  1980  0.060\n",
      "1329  Ice Hockey  1984  0.060\n",
      "1394  Ice Hockey  1988  0.060\n",
      "1459  Ice Hockey  1992  0.060\n",
      "\n",
      "Prepared time series data for Ice Hockey (normalizedcountry):\n",
      " Year\n",
      "1920    0.035\n",
      "1924    0.040\n",
      "1928    0.055\n",
      "1932    0.020\n",
      "1936    0.075\n",
      "1948    0.045\n",
      "1952    0.045\n",
      "1956    0.050\n",
      "1960    0.045\n",
      "1964    0.080\n",
      "1968    0.070\n",
      "1972    0.055\n",
      "1976    0.060\n",
      "1980    0.060\n",
      "1984    0.060\n",
      "1988    0.060\n",
      "1992    0.060\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Jeu De Paume (normalizedcountry)\n",
      "Raw data for Jeu De Paume (normalizedcountry):\n",
      "             Sport  Year  Value\n",
      "290  Jeu De Paume  1908   0.01\n",
      "\n",
      "Prepared time series data for Jeu De Paume (normalizedcountry):\n",
      " Year\n",
      "1908    0.01\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Judo (normalizedcountry)\n",
      "Raw data for Judo (normalizedcountry):\n",
      "      Sport  Year  Value\n",
      "1006  Judo  1964  0.135\n",
      "1136  Judo  1972  0.230\n",
      "1201  Judo  1976  0.230\n",
      "1266  Judo  1980  0.210\n",
      "1331  Judo  1984  0.305\n",
      "1396  Judo  1988  0.345\n",
      "1461  Judo  1992  0.460\n",
      "1526  Judo  1996  0.460\n",
      "1591  Judo  2000  0.450\n",
      "1656  Judo  2004  0.470\n",
      "1721  Judo  2008  0.460\n",
      "1786  Judo  2012  0.660\n",
      "1851  Judo  2016  0.680\n",
      "\n",
      "Prepared time series data for Judo (normalizedcountry):\n",
      " Year\n",
      "1964    0.135\n",
      "1972    0.230\n",
      "1976    0.230\n",
      "1980    0.210\n",
      "1984    0.305\n",
      "1988    0.345\n",
      "1992    0.460\n",
      "1996    0.460\n",
      "2000    0.450\n",
      "2004    0.470\n",
      "2008    0.460\n",
      "2012    0.660\n",
      "2016    0.680\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Lacrosse (normalizedcountry)\n",
      "Raw data for Lacrosse (normalizedcountry):\n",
      "         Sport  Year  Value\n",
      "162  Lacrosse  1904   0.01\n",
      "292  Lacrosse  1908   0.01\n",
      "\n",
      "Prepared time series data for Lacrosse (normalizedcountry):\n",
      " Year\n",
      "1904    0.01\n",
      "1908    0.01\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Luge (normalizedcountry)\n",
      "Raw data for Luge (normalizedcountry):\n",
      "      Sport  Year  Value\n",
      "1008  Luge  1964  0.060\n",
      "1073  Luge  1968  0.070\n",
      "1138  Luge  1972  0.065\n",
      "1203  Luge  1976  0.080\n",
      "1268  Luge  1980  0.070\n",
      "1333  Luge  1984  0.085\n",
      "1398  Luge  1988  0.110\n",
      "1463  Luge  1992  0.110\n",
      "\n",
      "Prepared time series data for Luge (normalizedcountry):\n",
      " Year\n",
      "1964    0.060\n",
      "1968    0.070\n",
      "1972    0.065\n",
      "1976    0.080\n",
      "1980    0.070\n",
      "1984    0.085\n",
      "1988    0.110\n",
      "1992    0.110\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Military Ski Patrol (normalizedcountry)\n",
      "Raw data for Military Ski Patrol (normalizedcountry):\n",
      "                    Sport  Year  Value\n",
      "489  Military Ski Patrol  1924   0.03\n",
      "\n",
      "Prepared time series data for Military Ski Patrol (normalizedcountry):\n",
      " Year\n",
      "1924    0.03\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Modern Pentathlon (normalizedcountry)\n",
      "Raw data for Modern Pentathlon (normalizedcountry):\n",
      "                   Sport  Year  Value\n",
      "360   Modern Pentathlon  1912  0.050\n",
      "425   Modern Pentathlon  1920  0.040\n",
      "490   Modern Pentathlon  1924  0.055\n",
      "555   Modern Pentathlon  1928  0.070\n",
      "620   Modern Pentathlon  1932  0.050\n",
      "685   Modern Pentathlon  1936  0.080\n",
      "750   Modern Pentathlon  1948  0.080\n",
      "815   Modern Pentathlon  1952  0.095\n",
      "880   Modern Pentathlon  1956  0.080\n",
      "945   Modern Pentathlon  1960  0.115\n",
      "1010  Modern Pentathlon  1964  0.075\n",
      "1075  Modern Pentathlon  1968  0.090\n",
      "1140  Modern Pentathlon  1972  0.100\n",
      "1205  Modern Pentathlon  1976  0.085\n",
      "1270  Modern Pentathlon  1980  0.085\n",
      "1335  Modern Pentathlon  1984  0.090\n",
      "1400  Modern Pentathlon  1988  0.130\n",
      "1465  Modern Pentathlon  1992  0.150\n",
      "1530  Modern Pentathlon  1996  0.110\n",
      "1595  Modern Pentathlon  2000  0.120\n",
      "1660  Modern Pentathlon  2004  0.130\n",
      "1725  Modern Pentathlon  2008  0.135\n",
      "1790  Modern Pentathlon  2012  0.130\n",
      "1855  Modern Pentathlon  2016  0.140\n",
      "\n",
      "Prepared time series data for Modern Pentathlon (normalizedcountry):\n",
      " Year\n",
      "1912    0.050\n",
      "1920    0.040\n",
      "1924    0.055\n",
      "1928    0.070\n",
      "1932    0.050\n",
      "1936    0.080\n",
      "1948    0.080\n",
      "1952    0.095\n",
      "1956    0.080\n",
      "1960    0.115\n",
      "1964    0.075\n",
      "1968    0.090\n",
      "1972    0.100\n",
      "1976    0.085\n",
      "1980    0.085\n",
      "1984    0.090\n",
      "1988    0.130\n",
      "1992    0.150\n",
      "1996    0.110\n",
      "2000    0.120\n",
      "2004    0.130\n",
      "2008    0.135\n",
      "2012    0.130\n",
      "2016    0.140\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Motorboating (normalizedcountry)\n",
      "Raw data for Motorboating (normalizedcountry):\n",
      "             Sport  Year  Value\n",
      "296  Motorboating  1908   0.01\n",
      "\n",
      "Prepared time series data for Motorboating (normalizedcountry):\n",
      " Year\n",
      "1908    0.01\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Nordic Combined (normalizedcountry)\n",
      "Raw data for Nordic Combined (normalizedcountry):\n",
      "                 Sport  Year  Value\n",
      "492   Nordic Combined  1924  0.045\n",
      "557   Nordic Combined  1928  0.070\n",
      "622   Nordic Combined  1932  0.050\n",
      "687   Nordic Combined  1936  0.080\n",
      "752   Nordic Combined  1948  0.065\n",
      "817   Nordic Combined  1952  0.055\n",
      "882   Nordic Combined  1956  0.060\n",
      "947   Nordic Combined  1960  0.065\n",
      "1012  Nordic Combined  1964  0.055\n",
      "1077  Nordic Combined  1968  0.065\n",
      "1142  Nordic Combined  1972  0.070\n",
      "1207  Nordic Combined  1976  0.070\n",
      "1272  Nordic Combined  1980  0.045\n",
      "1337  Nordic Combined  1984  0.055\n",
      "1402  Nordic Combined  1988  0.065\n",
      "1467  Nordic Combined  1992  0.060\n",
      "\n",
      "Prepared time series data for Nordic Combined (normalizedcountry):\n",
      " Year\n",
      "1924    0.045\n",
      "1928    0.070\n",
      "1932    0.050\n",
      "1936    0.080\n",
      "1948    0.065\n",
      "1952    0.055\n",
      "1956    0.060\n",
      "1960    0.065\n",
      "1964    0.055\n",
      "1968    0.065\n",
      "1972    0.070\n",
      "1976    0.070\n",
      "1980    0.045\n",
      "1984    0.055\n",
      "1988    0.065\n",
      "1992    0.060\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Polo (normalizedcountry)\n",
      "Raw data for Polo (normalizedcountry):\n",
      "     Sport  Year  Value\n",
      "103  Polo  1900  0.020\n",
      "298  Polo  1908  0.005\n",
      "428  Polo  1920  0.020\n",
      "493  Polo  1924  0.025\n",
      "688  Polo  1936  0.025\n",
      "\n",
      "Prepared time series data for Polo (normalizedcountry):\n",
      " Year\n",
      "1900    0.020\n",
      "1908    0.005\n",
      "1920    0.020\n",
      "1924    0.025\n",
      "1936    0.025\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Racquets (normalizedcountry)\n",
      "Raw data for Racquets (normalizedcountry):\n",
      "         Sport  Year  Value\n",
      "299  Racquets  1908  0.005\n",
      "\n",
      "Prepared time series data for Racquets (normalizedcountry):\n",
      " Year\n",
      "1908    0.005\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Rhythmic Gymnastics (normalizedcountry)\n",
      "Raw data for Rhythmic Gymnastics (normalizedcountry):\n",
      "                     Sport  Year  Value\n",
      "1340  Rhythmic Gymnastics  1984  0.100\n",
      "1405  Rhythmic Gymnastics  1988  0.115\n",
      "1470  Rhythmic Gymnastics  1992  0.115\n",
      "1535  Rhythmic Gymnastics  1996  0.110\n",
      "1600  Rhythmic Gymnastics  2000  0.100\n",
      "1665  Rhythmic Gymnastics  2004  0.105\n",
      "1730  Rhythmic Gymnastics  2008  0.105\n",
      "1795  Rhythmic Gymnastics  2012  0.120\n",
      "1860  Rhythmic Gymnastics  2016  0.120\n",
      "\n",
      "Prepared time series data for Rhythmic Gymnastics (normalizedcountry):\n",
      " Year\n",
      "1984    0.100\n",
      "1988    0.115\n",
      "1992    0.115\n",
      "1996    0.110\n",
      "2000    0.100\n",
      "2004    0.105\n",
      "2008    0.105\n",
      "2012    0.120\n",
      "2016    0.120\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Roque (normalizedcountry)\n",
      "Raw data for Roque (normalizedcountry):\n",
      "      Sport  Year  Value\n",
      "171  Roque  1904  0.005\n",
      "\n",
      "Prepared time series data for Roque (normalizedcountry):\n",
      " Year\n",
      "1904    0.005\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Rowing (normalizedcountry)\n",
      "Raw data for Rowing (normalizedcountry):\n",
      "        Sport  Year  Value\n",
      "107   Rowing  1900  0.035\n",
      "172   Rowing  1904  0.010\n",
      "237   Rowing  1906  0.030\n",
      "302   Rowing  1908  0.040\n",
      "367   Rowing  1912  0.070\n",
      "432   Rowing  1920  0.070\n",
      "497   Rowing  1924  0.070\n",
      "562   Rowing  1928  0.095\n",
      "627   Rowing  1932  0.065\n",
      "692   Rowing  1936  0.120\n",
      "757   Rowing  1948  0.135\n",
      "822   Rowing  1952  0.165\n",
      "887   Rowing  1956  0.125\n",
      "952   Rowing  1960  0.165\n",
      "1017  Rowing  1964  0.135\n",
      "1082  Rowing  1968  0.145\n",
      "1147  Rowing  1972  0.175\n",
      "1212  Rowing  1976  0.155\n",
      "1277  Rowing  1980  0.125\n",
      "1342  Rowing  1984  0.150\n",
      "1407  Rowing  1988  0.190\n",
      "1472  Rowing  1992  0.225\n",
      "1537  Rowing  1996  0.225\n",
      "1602  Rowing  2000  0.255\n",
      "1667  Rowing  2004  0.275\n",
      "1732  Rowing  2008  0.300\n",
      "1797  Rowing  2012  0.290\n",
      "1862  Rowing  2016  0.345\n",
      "\n",
      "Prepared time series data for Rowing (normalizedcountry):\n",
      " Year\n",
      "1900    0.035\n",
      "1904    0.010\n",
      "1906    0.030\n",
      "1908    0.040\n",
      "1912    0.070\n",
      "1920    0.070\n",
      "1924    0.070\n",
      "1928    0.095\n",
      "1932    0.065\n",
      "1936    0.120\n",
      "1948    0.135\n",
      "1952    0.165\n",
      "1956    0.125\n",
      "1960    0.165\n",
      "1964    0.135\n",
      "1968    0.145\n",
      "1972    0.175\n",
      "1976    0.155\n",
      "1980    0.125\n",
      "1984    0.150\n",
      "1988    0.190\n",
      "1992    0.225\n",
      "1996    0.225\n",
      "2000    0.255\n",
      "2004    0.275\n",
      "2008    0.300\n",
      "2012    0.290\n",
      "2016    0.345\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Rugby (normalizedcountry)\n",
      "Raw data for Rugby (normalizedcountry):\n",
      "      Sport  Year  Value\n",
      "108  Rugby  1900  0.025\n",
      "303  Rugby  1908  0.010\n",
      "433  Rugby  1920  0.010\n",
      "498  Rugby  1924  0.015\n",
      "\n",
      "Prepared time series data for Rugby (normalizedcountry):\n",
      " Year\n",
      "1900    0.025\n",
      "1908    0.010\n",
      "1920    0.010\n",
      "1924    0.015\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Rugby Sevens (normalizedcountry)\n",
      "Raw data for Rugby Sevens (normalizedcountry):\n",
      "              Sport  Year  Value\n",
      "1864  Rugby Sevens  2016   0.07\n",
      "\n",
      "Prepared time series data for Rugby Sevens (normalizedcountry):\n",
      " Year\n",
      "2016    0.07\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Sailing (normalizedcountry)\n",
      "Raw data for Sailing (normalizedcountry):\n",
      "         Sport  Year  Value\n",
      "110   Sailing  1900  0.030\n",
      "305   Sailing  1908  0.025\n",
      "370   Sailing  1912  0.030\n",
      "435   Sailing  1920  0.030\n",
      "500   Sailing  1924  0.095\n",
      "565   Sailing  1928  0.115\n",
      "630   Sailing  1932  0.055\n",
      "695   Sailing  1936  0.130\n",
      "760   Sailing  1948  0.115\n",
      "825   Sailing  1952  0.145\n",
      "890   Sailing  1956  0.140\n",
      "955   Sailing  1960  0.230\n",
      "1020  Sailing  1964  0.200\n",
      "1085  Sailing  1968  0.205\n",
      "1150  Sailing  1972  0.210\n",
      "1215  Sailing  1976  0.200\n",
      "1280  Sailing  1980  0.115\n",
      "1345  Sailing  1984  0.300\n",
      "1410  Sailing  1988  0.300\n",
      "1475  Sailing  1992  0.340\n",
      "1540  Sailing  1996  0.390\n",
      "1605  Sailing  2000  0.345\n",
      "1670  Sailing  2004  0.305\n",
      "1735  Sailing  2008  0.310\n",
      "1800  Sailing  2012  0.315\n",
      "1865  Sailing  2016  0.330\n",
      "\n",
      "Prepared time series data for Sailing (normalizedcountry):\n",
      " Year\n",
      "1900    0.030\n",
      "1908    0.025\n",
      "1912    0.030\n",
      "1920    0.030\n",
      "1924    0.095\n",
      "1928    0.115\n",
      "1932    0.055\n",
      "1936    0.130\n",
      "1948    0.115\n",
      "1952    0.145\n",
      "1956    0.140\n",
      "1960    0.230\n",
      "1964    0.200\n",
      "1968    0.205\n",
      "1972    0.210\n",
      "1976    0.200\n",
      "1980    0.115\n",
      "1984    0.300\n",
      "1988    0.300\n",
      "1992    0.340\n",
      "1996    0.390\n",
      "2000    0.345\n",
      "2004    0.305\n",
      "2008    0.310\n",
      "2012    0.315\n",
      "2016    0.330\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Shooting (normalizedcountry)\n",
      "Raw data for Shooting (normalizedcountry):\n",
      "          Sport  Year  Value\n",
      "46    Shooting  1896  0.035\n",
      "111   Shooting  1900  0.040\n",
      "241   Shooting  1906  0.060\n",
      "306   Shooting  1908  0.070\n",
      "371   Shooting  1912  0.080\n",
      "436   Shooting  1920  0.090\n",
      "501   Shooting  1924  0.135\n",
      "631   Shooting  1932  0.050\n",
      "696   Shooting  1936  0.145\n",
      "761   Shooting  1948  0.140\n",
      "826   Shooting  1952  0.205\n",
      "891   Shooting  1956  0.185\n",
      "956   Shooting  1960  0.295\n",
      "1021  Shooting  1964  0.255\n",
      "1086  Shooting  1968  0.310\n",
      "1151  Shooting  1972  0.355\n",
      "1216  Shooting  1976  0.300\n",
      "1281  Shooting  1980  0.190\n",
      "1346  Shooting  1984  0.340\n",
      "1411  Shooting  1988  0.330\n",
      "1476  Shooting  1992  0.415\n",
      "1541  Shooting  1996  0.500\n",
      "1606  Shooting  2000  0.515\n",
      "1671  Shooting  2004  0.530\n",
      "1736  Shooting  2008  0.515\n",
      "1801  Shooting  2012  0.540\n",
      "1866  Shooting  2016  0.485\n",
      "\n",
      "Prepared time series data for Shooting (normalizedcountry):\n",
      " Year\n",
      "1896    0.035\n",
      "1900    0.040\n",
      "1906    0.060\n",
      "1908    0.070\n",
      "1912    0.080\n",
      "1920    0.090\n",
      "1924    0.135\n",
      "1932    0.050\n",
      "1936    0.145\n",
      "1948    0.140\n",
      "1952    0.205\n",
      "1956    0.185\n",
      "1960    0.295\n",
      "1964    0.255\n",
      "1968    0.310\n",
      "1972    0.355\n",
      "1976    0.300\n",
      "1980    0.190\n",
      "1984    0.340\n",
      "1988    0.330\n",
      "1992    0.415\n",
      "1996    0.500\n",
      "2000    0.515\n",
      "2004    0.530\n",
      "2008    0.515\n",
      "2012    0.540\n",
      "2016    0.485\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Short Track Speed Skating (normalizedcountry)\n",
      "Raw data for Short Track Speed Skating (normalizedcountry):\n",
      "                           Sport  Year  Value\n",
      "1477  Short Track Speed Skating  1992   0.08\n",
      "\n",
      "Prepared time series data for Short Track Speed Skating (normalizedcountry):\n",
      " Year\n",
      "1992    0.08\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Skeleton (normalizedcountry)\n",
      "Raw data for Skeleton (normalizedcountry):\n",
      "         Sport  Year  Value\n",
      "568  Skeleton  1928   0.03\n",
      "763  Skeleton  1948   0.03\n",
      "\n",
      "Prepared time series data for Skeleton (normalizedcountry):\n",
      " Year\n",
      "1928    0.03\n",
      "1948    0.03\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Ski Jumping (normalizedcountry)\n",
      "Raw data for Ski Jumping (normalizedcountry):\n",
      "             Sport  Year  Value\n",
      "504   Ski Jumping  1924  0.045\n",
      "569   Ski Jumping  1928  0.065\n",
      "634   Ski Jumping  1932  0.050\n",
      "699   Ski Jumping  1936  0.070\n",
      "764   Ski Jumping  1948  0.070\n",
      "829   Ski Jumping  1952  0.065\n",
      "894   Ski Jumping  1956  0.080\n",
      "959   Ski Jumping  1960  0.075\n",
      "1024  Ski Jumping  1964  0.075\n",
      "1089  Ski Jumping  1968  0.085\n",
      "1154  Ski Jumping  1972  0.080\n",
      "1219  Ski Jumping  1976  0.075\n",
      "1284  Ski Jumping  1980  0.080\n",
      "1349  Ski Jumping  1984  0.085\n",
      "1414  Ski Jumping  1988  0.095\n",
      "1479  Ski Jumping  1992  0.085\n",
      "\n",
      "Prepared time series data for Ski Jumping (normalizedcountry):\n",
      " Year\n",
      "1924    0.045\n",
      "1928    0.065\n",
      "1932    0.050\n",
      "1936    0.070\n",
      "1948    0.070\n",
      "1952    0.065\n",
      "1956    0.080\n",
      "1960    0.075\n",
      "1964    0.075\n",
      "1968    0.085\n",
      "1972    0.080\n",
      "1976    0.075\n",
      "1980    0.080\n",
      "1984    0.085\n",
      "1988    0.095\n",
      "1992    0.085\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Snowboarding (normalizedcountry)\n",
      "Raw data for Snowboarding (normalizedcountry):\n",
      " Empty DataFrame\n",
      "Columns: [Sport, Year, Value]\n",
      "Index: []\n",
      "\n",
      "Prepared time series data for Snowboarding (normalizedcountry):\n",
      " Series([], Name: Value, dtype: float64)\n",
      "\n",
      "Processing sport: Softball (normalizedcountry)\n",
      "Raw data for Softball (normalizedcountry):\n",
      "          Sport  Year  Value\n",
      "1546  Softball  1996   0.04\n",
      "1611  Softball  2000   0.04\n",
      "1676  Softball  2004   0.04\n",
      "1741  Softball  2008   0.04\n",
      "\n",
      "Prepared time series data for Softball (normalizedcountry):\n",
      " Year\n",
      "1996    0.04\n",
      "2000    0.04\n",
      "2004    0.04\n",
      "2008    0.04\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Speed Skating (normalizedcountry)\n",
      "Raw data for Speed Skating (normalizedcountry):\n",
      "               Sport  Year  Value\n",
      "507   Speed Skating  1924  0.050\n",
      "572   Speed Skating  1928  0.070\n",
      "637   Speed Skating  1932  0.030\n",
      "702   Speed Skating  1936  0.080\n",
      "767   Speed Skating  1948  0.075\n",
      "832   Speed Skating  1952  0.070\n",
      "897   Speed Skating  1956  0.090\n",
      "962   Speed Skating  1960  0.085\n",
      "1027  Speed Skating  1964  0.110\n",
      "1092  Speed Skating  1968  0.095\n",
      "1157  Speed Skating  1972  0.090\n",
      "1222  Speed Skating  1976  0.095\n",
      "1287  Speed Skating  1980  0.100\n",
      "1352  Speed Skating  1984  0.120\n",
      "1417  Speed Skating  1988  0.105\n",
      "1482  Speed Skating  1992  0.115\n",
      "\n",
      "Prepared time series data for Speed Skating (normalizedcountry):\n",
      " Year\n",
      "1924    0.050\n",
      "1928    0.070\n",
      "1932    0.030\n",
      "1936    0.080\n",
      "1948    0.075\n",
      "1952    0.070\n",
      "1956    0.090\n",
      "1960    0.085\n",
      "1964    0.110\n",
      "1968    0.095\n",
      "1972    0.090\n",
      "1976    0.095\n",
      "1980    0.100\n",
      "1984    0.120\n",
      "1988    0.105\n",
      "1992    0.115\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Swimming (normalizedcountry)\n",
      "Raw data for Swimming (normalizedcountry):\n",
      "          Sport  Year  Value\n",
      "53    Swimming  1896  0.020\n",
      "118   Swimming  1900  0.060\n",
      "183   Swimming  1904  0.025\n",
      "248   Swimming  1906  0.055\n",
      "313   Swimming  1908  0.070\n",
      "378   Swimming  1912  0.085\n",
      "443   Swimming  1920  0.095\n",
      "508   Swimming  1924  0.115\n",
      "573   Swimming  1928  0.140\n",
      "638   Swimming  1932  0.100\n",
      "703   Swimming  1936  0.145\n",
      "768   Swimming  1948  0.170\n",
      "833   Swimming  1952  0.240\n",
      "898   Swimming  1956  0.165\n",
      "963   Swimming  1960  0.225\n",
      "1028  Swimming  1964  0.210\n",
      "1093  Swimming  1968  0.255\n",
      "1158  Swimming  1972  0.260\n",
      "1223  Swimming  1976  0.255\n",
      "1288  Swimming  1980  0.205\n",
      "1353  Swimming  1984  0.335\n",
      "1418  Swimming  1988  0.385\n",
      "1483  Swimming  1992  0.460\n",
      "1548  Swimming  1996  0.585\n",
      "1613  Swimming  2000  0.750\n",
      "1678  Swimming  2004  0.760\n",
      "1743  Swimming  2008  0.815\n",
      "1808  Swimming  2012  0.835\n",
      "1873  Swimming  2016  0.865\n",
      "\n",
      "Prepared time series data for Swimming (normalizedcountry):\n",
      " Year\n",
      "1896    0.020\n",
      "1900    0.060\n",
      "1904    0.025\n",
      "1906    0.055\n",
      "1908    0.070\n",
      "1912    0.085\n",
      "1920    0.095\n",
      "1924    0.115\n",
      "1928    0.140\n",
      "1932    0.100\n",
      "1936    0.145\n",
      "1948    0.170\n",
      "1952    0.240\n",
      "1956    0.165\n",
      "1960    0.225\n",
      "1964    0.210\n",
      "1968    0.255\n",
      "1972    0.260\n",
      "1976    0.255\n",
      "1980    0.205\n",
      "1984    0.335\n",
      "1988    0.385\n",
      "1992    0.460\n",
      "1996    0.585\n",
      "2000    0.750\n",
      "2004    0.760\n",
      "2008    0.815\n",
      "2012    0.835\n",
      "2016    0.865\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Synchronized Swimming (normalizedcountry)\n",
      "Raw data for Synchronized Swimming (normalizedcountry):\n",
      "                       Sport  Year  Value\n",
      "1354  Synchronized Swimming  1984  0.105\n",
      "1419  Synchronized Swimming  1988  0.090\n",
      "1484  Synchronized Swimming  1992  0.110\n",
      "1549  Synchronized Swimming  1996  0.040\n",
      "1614  Synchronized Swimming  2000  0.120\n",
      "1679  Synchronized Swimming  2004  0.120\n",
      "1744  Synchronized Swimming  2008  0.120\n",
      "1809  Synchronized Swimming  2012  0.120\n",
      "1874  Synchronized Swimming  2016  0.120\n",
      "\n",
      "Prepared time series data for Synchronized Swimming (normalizedcountry):\n",
      " Year\n",
      "1984    0.105\n",
      "1988    0.090\n",
      "1992    0.110\n",
      "1996    0.040\n",
      "2000    0.120\n",
      "2004    0.120\n",
      "2008    0.120\n",
      "2012    0.120\n",
      "2016    0.120\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Table Tennis (normalizedcountry)\n",
      "Raw data for Table Tennis (normalizedcountry):\n",
      "              Sport  Year  Value\n",
      "1420  Table Tennis  1988  0.205\n",
      "1485  Table Tennis  1992  0.240\n",
      "1550  Table Tennis  1996  0.255\n",
      "1615  Table Tennis  2000  0.240\n",
      "1680  Table Tennis  2004  0.250\n",
      "1745  Table Tennis  2008  0.280\n",
      "1810  Table Tennis  2012  0.285\n",
      "1875  Table Tennis  2016  0.280\n",
      "\n",
      "Prepared time series data for Table Tennis (normalizedcountry):\n",
      " Year\n",
      "1988    0.205\n",
      "1992    0.240\n",
      "1996    0.255\n",
      "2000    0.240\n",
      "2004    0.250\n",
      "2008    0.280\n",
      "2012    0.285\n",
      "2016    0.280\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Taekwondo (normalizedcountry)\n",
      "Raw data for Taekwondo (normalizedcountry):\n",
      "           Sport  Year  Value\n",
      "1616  Taekwondo  2000  0.250\n",
      "1681  Taekwondo  2004  0.300\n",
      "1746  Taekwondo  2008  0.310\n",
      "1811  Taekwondo  2012  0.315\n",
      "1876  Taekwondo  2016  0.310\n",
      "\n",
      "Prepared time series data for Taekwondo (normalizedcountry):\n",
      " Year\n",
      "2000    0.250\n",
      "2004    0.300\n",
      "2008    0.310\n",
      "2012    0.315\n",
      "2016    0.310\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Tennis (normalizedcountry)\n",
      "Raw data for Tennis (normalizedcountry):\n",
      "        Sport  Year  Value\n",
      "57    Tennis  1896  0.030\n",
      "122   Tennis  1900  0.020\n",
      "187   Tennis  1904  0.010\n",
      "252   Tennis  1906  0.030\n",
      "317   Tennis  1908  0.050\n",
      "382   Tennis  1912  0.070\n",
      "447   Tennis  1920  0.070\n",
      "512   Tennis  1924  0.135\n",
      "1422  Tennis  1988  0.190\n",
      "1487  Tennis  1992  0.240\n",
      "1552  Tennis  1996  0.275\n",
      "1617  Tennis  2000  0.260\n",
      "1682  Tennis  2004  0.260\n",
      "1747  Tennis  2008  0.240\n",
      "1812  Tennis  2012  0.220\n",
      "1877  Tennis  2016  0.280\n",
      "\n",
      "Prepared time series data for Tennis (normalizedcountry):\n",
      " Year\n",
      "1896    0.030\n",
      "1900    0.020\n",
      "1904    0.010\n",
      "1906    0.030\n",
      "1908    0.050\n",
      "1912    0.070\n",
      "1920    0.070\n",
      "1924    0.135\n",
      "1988    0.190\n",
      "1992    0.240\n",
      "1996    0.275\n",
      "2000    0.260\n",
      "2004    0.260\n",
      "2008    0.240\n",
      "2012    0.220\n",
      "2016    0.280\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Trampolining (normalizedcountry)\n",
      "Raw data for Trampolining (normalizedcountry):\n",
      "              Sport  Year  Value\n",
      "1618  Trampolining  2000  0.080\n",
      "1683  Trampolining  2004  0.100\n",
      "1748  Trampolining  2008  0.085\n",
      "1813  Trampolining  2012  0.090\n",
      "1878  Trampolining  2016  0.085\n",
      "\n",
      "Prepared time series data for Trampolining (normalizedcountry):\n",
      " Year\n",
      "2000    0.080\n",
      "2004    0.100\n",
      "2008    0.085\n",
      "2012    0.090\n",
      "2016    0.085\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Triathlon (normalizedcountry)\n",
      "Raw data for Triathlon (normalizedcountry):\n",
      "           Sport  Year  Value\n",
      "1619  Triathlon  2000  0.170\n",
      "1684  Triathlon  2004  0.165\n",
      "1749  Triathlon  2008  0.185\n",
      "1814  Triathlon  2012  0.195\n",
      "1879  Triathlon  2016  0.210\n",
      "\n",
      "Prepared time series data for Triathlon (normalizedcountry):\n",
      " Year\n",
      "2000    0.170\n",
      "2004    0.165\n",
      "2008    0.185\n",
      "2012    0.195\n",
      "2016    0.210\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Tug-Of-War (normalizedcountry)\n",
      "Raw data for Tug-Of-War (normalizedcountry):\n",
      "           Sport  Year  Value\n",
      "125  Tug-Of-War  1900  0.020\n",
      "190  Tug-Of-War  1904  0.020\n",
      "255  Tug-Of-War  1906  0.020\n",
      "320  Tug-Of-War  1908  0.015\n",
      "385  Tug-Of-War  1912  0.010\n",
      "450  Tug-Of-War  1920  0.025\n",
      "\n",
      "Prepared time series data for Tug-Of-War (normalizedcountry):\n",
      " Year\n",
      "1900    0.020\n",
      "1904    0.020\n",
      "1906    0.020\n",
      "1908    0.015\n",
      "1912    0.010\n",
      "1920    0.025\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Volleyball (normalizedcountry)\n",
      "Raw data for Volleyball (normalizedcountry):\n",
      "            Sport  Year  Value\n",
      "1036  Volleyball  1964  0.055\n",
      "1101  Volleyball  1968  0.060\n",
      "1166  Volleyball  1972  0.070\n",
      "1231  Volleyball  1976  0.065\n",
      "1296  Volleyball  1980  0.065\n",
      "1361  Volleyball  1984  0.060\n",
      "1426  Volleyball  1988  0.075\n",
      "1491  Volleyball  1992  0.065\n",
      "1556  Volleyball  1996  0.090\n",
      "1621  Volleyball  2000  0.085\n",
      "1686  Volleyball  2004  0.095\n",
      "1751  Volleyball  2008  0.075\n",
      "1816  Volleyball  2012  0.090\n",
      "1881  Volleyball  2016  0.095\n",
      "\n",
      "Prepared time series data for Volleyball (normalizedcountry):\n",
      " Year\n",
      "1964    0.055\n",
      "1968    0.060\n",
      "1972    0.070\n",
      "1976    0.065\n",
      "1980    0.065\n",
      "1984    0.060\n",
      "1988    0.075\n",
      "1992    0.065\n",
      "1996    0.090\n",
      "2000    0.085\n",
      "2004    0.095\n",
      "2008    0.075\n",
      "2012    0.090\n",
      "2016    0.095\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Water Polo (normalizedcountry)\n",
      "Raw data for Water Polo (normalizedcountry):\n",
      "            Sport  Year  Value\n",
      "127   Water Polo  1900  0.025\n",
      "192   Water Polo  1904  0.005\n",
      "322   Water Polo  1908  0.020\n",
      "387   Water Polo  1912  0.030\n",
      "452   Water Polo  1920  0.060\n",
      "517   Water Polo  1924  0.065\n",
      "582   Water Polo  1928  0.070\n",
      "647   Water Polo  1932  0.025\n",
      "712   Water Polo  1936  0.080\n",
      "777   Water Polo  1948  0.090\n",
      "842   Water Polo  1952  0.105\n",
      "907   Water Polo  1956  0.050\n",
      "972   Water Polo  1960  0.080\n",
      "1037  Water Polo  1964  0.065\n",
      "1102  Water Polo  1968  0.075\n",
      "1167  Water Polo  1972  0.080\n",
      "1232  Water Polo  1976  0.060\n",
      "1297  Water Polo  1980  0.060\n",
      "1362  Water Polo  1984  0.060\n",
      "1427  Water Polo  1988  0.060\n",
      "1492  Water Polo  1992  0.060\n",
      "1557  Water Polo  1996  0.060\n",
      "1622  Water Polo  2000  0.065\n",
      "1687  Water Polo  2004  0.065\n",
      "1752  Water Polo  2008  0.070\n",
      "1817  Water Polo  2012  0.070\n",
      "1882  Water Polo  2016  0.070\n",
      "\n",
      "Prepared time series data for Water Polo (normalizedcountry):\n",
      " Year\n",
      "1900    0.025\n",
      "1904    0.005\n",
      "1908    0.020\n",
      "1912    0.030\n",
      "1920    0.060\n",
      "1924    0.065\n",
      "1928    0.070\n",
      "1932    0.025\n",
      "1936    0.080\n",
      "1948    0.090\n",
      "1952    0.105\n",
      "1956    0.050\n",
      "1960    0.080\n",
      "1964    0.065\n",
      "1968    0.075\n",
      "1972    0.080\n",
      "1976    0.060\n",
      "1980    0.060\n",
      "1984    0.060\n",
      "1988    0.060\n",
      "1992    0.060\n",
      "1996    0.060\n",
      "2000    0.065\n",
      "2004    0.065\n",
      "2008    0.070\n",
      "2012    0.070\n",
      "2016    0.070\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Weightlifting (normalizedcountry)\n",
      "Raw data for Weightlifting (normalizedcountry):\n",
      "               Sport  Year  Value\n",
      "63    Weightlifting  1896  0.025\n",
      "193   Weightlifting  1904  0.015\n",
      "258   Weightlifting  1906  0.035\n",
      "453   Weightlifting  1920  0.070\n",
      "518   Weightlifting  1924  0.080\n",
      "583   Weightlifting  1928  0.095\n",
      "648   Weightlifting  1932  0.040\n",
      "713   Weightlifting  1936  0.075\n",
      "778   Weightlifting  1948  0.150\n",
      "843   Weightlifting  1952  0.205\n",
      "908   Weightlifting  1956  0.170\n",
      "973   Weightlifting  1960  0.265\n",
      "1038  Weightlifting  1964  0.210\n",
      "1103  Weightlifting  1968  0.275\n",
      "1168  Weightlifting  1972  0.270\n",
      "1233  Weightlifting  1976  0.230\n",
      "1298  Weightlifting  1980  0.195\n",
      "1363  Weightlifting  1984  0.240\n",
      "1428  Weightlifting  1988  0.310\n",
      "1493  Weightlifting  1992  0.345\n",
      "1558  Weightlifting  1996  0.385\n",
      "1623  Weightlifting  2000  0.380\n",
      "1688  Weightlifting  2004  0.395\n",
      "1753  Weightlifting  2008  0.420\n",
      "1818  Weightlifting  2012  0.420\n",
      "1883  Weightlifting  2016  0.460\n",
      "\n",
      "Prepared time series data for Weightlifting (normalizedcountry):\n",
      " Year\n",
      "1896    0.025\n",
      "1904    0.015\n",
      "1906    0.035\n",
      "1920    0.070\n",
      "1924    0.080\n",
      "1928    0.095\n",
      "1932    0.040\n",
      "1936    0.075\n",
      "1948    0.150\n",
      "1952    0.205\n",
      "1956    0.170\n",
      "1960    0.265\n",
      "1964    0.210\n",
      "1968    0.275\n",
      "1972    0.270\n",
      "1976    0.230\n",
      "1980    0.195\n",
      "1984    0.240\n",
      "1988    0.310\n",
      "1992    0.345\n",
      "1996    0.385\n",
      "2000    0.380\n",
      "2004    0.395\n",
      "2008    0.420\n",
      "2012    0.420\n",
      "2016    0.460\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Wrestling (normalizedcountry)\n",
      "Raw data for Wrestling (normalizedcountry):\n",
      "           Sport  Year  Value\n",
      "64    Wrestling  1896  0.020\n",
      "194   Wrestling  1904  0.025\n",
      "259   Wrestling  1906  0.055\n",
      "324   Wrestling  1908  0.075\n",
      "389   Wrestling  1912  0.090\n",
      "454   Wrestling  1920  0.095\n",
      "519   Wrestling  1924  0.130\n",
      "584   Wrestling  1928  0.145\n",
      "649   Wrestling  1932  0.090\n",
      "714   Wrestling  1936  0.145\n",
      "779   Wrestling  1948  0.145\n",
      "844   Wrestling  1952  0.185\n",
      "909   Wrestling  1956  0.150\n",
      "974   Wrestling  1960  0.230\n",
      "1039  Wrestling  1964  0.210\n",
      "1104  Wrestling  1968  0.230\n",
      "1169  Wrestling  1972  0.245\n",
      "1234  Wrestling  1976  0.205\n",
      "1299  Wrestling  1980  0.175\n",
      "1364  Wrestling  1984  0.220\n",
      "1429  Wrestling  1988  0.345\n",
      "1494  Wrestling  1992  0.295\n",
      "1559  Wrestling  1996  0.375\n",
      "1624  Wrestling  2000  0.275\n",
      "1689  Wrestling  2004  0.330\n",
      "1754  Wrestling  2008  0.295\n",
      "1819  Wrestling  2012  0.350\n",
      "1884  Wrestling  2016  0.330\n",
      "\n",
      "Prepared time series data for Wrestling (normalizedcountry):\n",
      " Year\n",
      "1896    0.020\n",
      "1904    0.025\n",
      "1906    0.055\n",
      "1908    0.075\n",
      "1912    0.090\n",
      "1920    0.095\n",
      "1924    0.130\n",
      "1928    0.145\n",
      "1932    0.090\n",
      "1936    0.145\n",
      "1948    0.145\n",
      "1952    0.185\n",
      "1956    0.150\n",
      "1960    0.230\n",
      "1964    0.210\n",
      "1968    0.230\n",
      "1972    0.245\n",
      "1976    0.205\n",
      "1980    0.175\n",
      "1984    0.220\n",
      "1988    0.345\n",
      "1992    0.295\n",
      "1996    0.375\n",
      "2000    0.275\n",
      "2004    0.330\n",
      "2008    0.295\n",
      "2012    0.350\n",
      "2016    0.330\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing parameter: CV\n",
      "\n",
      "Processing sport: Alpine Skiing (CV)\n",
      "Raw data for Alpine Skiing (CV):\n",
      "               Sport  Year     Value\n",
      "650   Alpine Skiing  1936  0.870456\n",
      "715   Alpine Skiing  1948  0.898061\n",
      "780   Alpine Skiing  1952  0.818058\n",
      "845   Alpine Skiing  1956  0.953060\n",
      "910   Alpine Skiing  1960  0.668501\n",
      "975   Alpine Skiing  1964  1.027839\n",
      "1040  Alpine Skiing  1968  0.800125\n",
      "1105  Alpine Skiing  1972  0.945393\n",
      "1170  Alpine Skiing  1976  0.627770\n",
      "1235  Alpine Skiing  1980  0.941454\n",
      "1300  Alpine Skiing  1984  0.810152\n",
      "1365  Alpine Skiing  1988  0.975410\n",
      "1430  Alpine Skiing  1992  1.038671\n",
      "\n",
      "Prepared time series data for Alpine Skiing (CV):\n",
      " Year\n",
      "1936    0.870456\n",
      "1948    0.898061\n",
      "1952    0.818058\n",
      "1956    0.953060\n",
      "1960    0.668501\n",
      "1964    1.027839\n",
      "1968    0.800125\n",
      "1972    0.945393\n",
      "1976    0.627770\n",
      "1980    0.941454\n",
      "1984    0.810152\n",
      "1988    0.975410\n",
      "1992    1.038671\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Alpinism (CV)\n",
      "Raw data for Alpinism (CV):\n",
      "         Sport  Year     Value\n",
      "456  Alpinism  1924  0.657342\n",
      "586  Alpinism  1932  0.866025\n",
      "651  Alpinism  1936  0.866025\n",
      "\n",
      "Prepared time series data for Alpinism (CV):\n",
      " Year\n",
      "1924    0.657342\n",
      "1932    0.866025\n",
      "1936    0.866025\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Archery (CV)\n",
      "Raw data for Archery (CV):\n",
      "         Sport  Year     Value\n",
      "67    Archery  1900  0.786203\n",
      "132   Archery  1904  0.484278\n",
      "262   Archery  1908  0.568251\n",
      "392   Archery  1920  1.091650\n",
      "1107  Archery  1972  0.551065\n",
      "1172  Archery  1976  0.584722\n",
      "1237  Archery  1980  0.518674\n",
      "1302  Archery  1984  0.486000\n",
      "1367  Archery  1988  0.736622\n",
      "1432  Archery  1992  0.877037\n",
      "1497  Archery  1996  0.872777\n",
      "1562  Archery  2000  0.840279\n",
      "1627  Archery  2004  0.893923\n",
      "1692  Archery  2008  0.819216\n",
      "1757  Archery  2012  0.751548\n",
      "1822  Archery  2016  0.849326\n",
      "\n",
      "Prepared time series data for Archery (CV):\n",
      " Year\n",
      "1900    0.786203\n",
      "1904    0.484278\n",
      "1908    0.568251\n",
      "1920    1.091650\n",
      "1972    0.551065\n",
      "1976    0.584722\n",
      "1980    0.518674\n",
      "1984    0.486000\n",
      "1988    0.736622\n",
      "1992    0.877037\n",
      "1996    0.872777\n",
      "2000    0.840279\n",
      "2004    0.893923\n",
      "2008    0.819216\n",
      "2012    0.751548\n",
      "2016    0.849326\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Art Competitions (CV)\n",
      "Raw data for Art Competitions (CV):\n",
      "                 Sport  Year     Value\n",
      "328  Art Competitions  1912  0.559832\n",
      "393  Art Competitions  1920  0.516042\n",
      "458  Art Competitions  1924  0.874013\n",
      "523  Art Competitions  1928  0.859417\n",
      "588  Art Competitions  1932  0.829420\n",
      "653  Art Competitions  1936  0.680922\n",
      "718  Art Competitions  1948  0.867483\n",
      "\n",
      "Prepared time series data for Art Competitions (CV):\n",
      " Year\n",
      "1912    0.559832\n",
      "1920    0.516042\n",
      "1924    0.874013\n",
      "1928    0.859417\n",
      "1932    0.829420\n",
      "1936    0.680922\n",
      "1948    0.867483\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Athletics (CV)\n",
      "Raw data for Athletics (CV):\n",
      "           Sport  Year     Value\n",
      "4     Athletics  1896  1.001050\n",
      "69    Athletics  1900  0.975667\n",
      "134   Athletics  1904  0.978102\n",
      "199   Athletics  1906  0.892952\n",
      "264   Athletics  1908  1.032252\n",
      "329   Athletics  1912  1.179248\n",
      "394   Athletics  1920  1.024756\n",
      "459   Athletics  1924  1.126996\n",
      "524   Athletics  1928  1.152680\n",
      "589   Athletics  1932  1.250911\n",
      "654   Athletics  1936  1.180475\n",
      "719   Athletics  1948  1.064279\n",
      "784   Athletics  1952  1.064429\n",
      "849   Athletics  1956  1.059613\n",
      "914   Athletics  1960  1.064921\n",
      "979   Athletics  1964  1.024451\n",
      "1044  Athletics  1968  0.971013\n",
      "1109  Athletics  1972  1.062339\n",
      "1174  Athletics  1976  1.207508\n",
      "1239  Athletics  1980  1.012697\n",
      "1304  Athletics  1984  1.053289\n",
      "1369  Athletics  1988  1.032190\n",
      "1434  Athletics  1992  0.986700\n",
      "1499  Athletics  1996  1.016212\n",
      "1564  Athletics  2000  0.982383\n",
      "1629  Athletics  2004  0.984688\n",
      "1694  Athletics  2008  1.058562\n",
      "1759  Athletics  2012  0.964608\n",
      "1824  Athletics  2016  0.974802\n",
      "\n",
      "Prepared time series data for Athletics (CV):\n",
      " Year\n",
      "1896    1.001050\n",
      "1900    0.975667\n",
      "1904    0.978102\n",
      "1906    0.892952\n",
      "1908    1.032252\n",
      "1912    1.179248\n",
      "1920    1.024756\n",
      "1924    1.126996\n",
      "1928    1.152680\n",
      "1932    1.250911\n",
      "1936    1.180475\n",
      "1948    1.064279\n",
      "1952    1.064429\n",
      "1956    1.059613\n",
      "1960    1.064921\n",
      "1964    1.024451\n",
      "1968    0.971013\n",
      "1972    1.062339\n",
      "1976    1.207508\n",
      "1980    1.012697\n",
      "1984    1.053289\n",
      "1988    1.032190\n",
      "1992    0.986700\n",
      "1996    1.016212\n",
      "2000    0.982383\n",
      "2004    0.984688\n",
      "2008    1.058562\n",
      "2012    0.964608\n",
      "2016    0.974802\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Badminton (CV)\n",
      "Raw data for Badminton (CV):\n",
      "           Sport  Year     Value\n",
      "1435  Badminton  1992  0.612121\n",
      "1500  Badminton  1996  0.790704\n",
      "1565  Badminton  2000  0.799155\n",
      "1630  Badminton  2004  0.836245\n",
      "1695  Badminton  2008  0.837055\n",
      "1760  Badminton  2012  0.818298\n",
      "1825  Badminton  2016  0.729782\n",
      "\n",
      "Prepared time series data for Badminton (CV):\n",
      " Year\n",
      "1992    0.612121\n",
      "1996    0.790704\n",
      "2000    0.799155\n",
      "2004    0.836245\n",
      "2008    0.837055\n",
      "2012    0.818298\n",
      "2016    0.729782\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Baseball (CV)\n",
      "Raw data for Baseball (CV):\n",
      "          Sport  Year     Value\n",
      "1436  Baseball  1992  0.658106\n",
      "1501  Baseball  1996  0.626836\n",
      "1566  Baseball  2000  0.701918\n",
      "1631  Baseball  2004  0.752698\n",
      "1696  Baseball  2008  0.654850\n",
      "\n",
      "Prepared time series data for Baseball (CV):\n",
      " Year\n",
      "1992    0.658106\n",
      "1996    0.626836\n",
      "2000    0.701918\n",
      "2004    0.752698\n",
      "2008    0.654850\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Basketball (CV)\n",
      "Raw data for Basketball (CV):\n",
      "            Sport  Year     Value\n",
      "657   Basketball  1936  0.844732\n",
      "722   Basketball  1948  0.974528\n",
      "787   Basketball  1952  0.745002\n",
      "852   Basketball  1956  0.797033\n",
      "917   Basketball  1960  0.858029\n",
      "982   Basketball  1964  0.815516\n",
      "1047  Basketball  1968  0.695476\n",
      "1112  Basketball  1972  0.901234\n",
      "1177  Basketball  1976  0.767874\n",
      "1242  Basketball  1980  0.743914\n",
      "1307  Basketball  1984  0.834188\n",
      "1372  Basketball  1988  0.769807\n",
      "1437  Basketball  1992  0.672681\n",
      "1502  Basketball  1996  0.732982\n",
      "1567  Basketball  2000  0.718220\n",
      "1632  Basketball  2004  0.793271\n",
      "1697  Basketball  2008  0.703898\n",
      "1762  Basketball  2012  0.714055\n",
      "1827  Basketball  2016  0.513255\n",
      "\n",
      "Prepared time series data for Basketball (CV):\n",
      " Year\n",
      "1936    0.844732\n",
      "1948    0.974528\n",
      "1952    0.745002\n",
      "1956    0.797033\n",
      "1960    0.858029\n",
      "1964    0.815516\n",
      "1968    0.695476\n",
      "1972    0.901234\n",
      "1976    0.767874\n",
      "1980    0.743914\n",
      "1984    0.834188\n",
      "1988    0.769807\n",
      "1992    0.672681\n",
      "1996    0.732982\n",
      "2000    0.718220\n",
      "2004    0.793271\n",
      "2008    0.703898\n",
      "2012    0.714055\n",
      "2016    0.513255\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Basque Pelota (CV)\n",
      "Raw data for Basque Pelota (CV):\n",
      "             Sport  Year     Value\n",
      "73  Basque Pelota  1900  1.414214\n",
      "\n",
      "Prepared time series data for Basque Pelota (CV):\n",
      " Year\n",
      "1900    1.414214\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Beach Volleyball (CV)\n",
      "Raw data for Beach Volleyball (CV):\n",
      "                  Sport  Year     Value\n",
      "1504  Beach Volleyball  1996  0.736098\n",
      "1569  Beach Volleyball  2000  0.748415\n",
      "1634  Beach Volleyball  2004  0.674318\n",
      "1699  Beach Volleyball  2008  0.676258\n",
      "1764  Beach Volleyball  2012  0.534791\n",
      "1829  Beach Volleyball  2016  0.831743\n",
      "\n",
      "Prepared time series data for Beach Volleyball (CV):\n",
      " Year\n",
      "1996    0.736098\n",
      "2000    0.748415\n",
      "2004    0.674318\n",
      "2008    0.676258\n",
      "2012    0.534791\n",
      "2016    0.831743\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Biathlon (CV)\n",
      "Raw data for Biathlon (CV):\n",
      "          Sport  Year     Value\n",
      "920   Biathlon  1960  0.773492\n",
      "985   Biathlon  1964  0.772802\n",
      "1050  Biathlon  1968  0.715755\n",
      "1115  Biathlon  1972  0.837475\n",
      "1180  Biathlon  1976  0.737878\n",
      "1245  Biathlon  1980  0.620813\n",
      "1310  Biathlon  1984  0.623603\n",
      "1375  Biathlon  1988  0.868731\n",
      "1440  Biathlon  1992  0.719238\n",
      "\n",
      "Prepared time series data for Biathlon (CV):\n",
      " Year\n",
      "1960    0.773492\n",
      "1964    0.772802\n",
      "1968    0.715755\n",
      "1972    0.837475\n",
      "1976    0.737878\n",
      "1980    0.620813\n",
      "1984    0.623603\n",
      "1988    0.868731\n",
      "1992    0.719238\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Bobsleigh (CV)\n",
      "Raw data for Bobsleigh (CV):\n",
      "           Sport  Year     Value\n",
      "466   Bobsleigh  1924  0.514496\n",
      "531   Bobsleigh  1928  0.811255\n",
      "596   Bobsleigh  1932  0.647300\n",
      "661   Bobsleigh  1936  0.652617\n",
      "726   Bobsleigh  1948  0.732900\n",
      "791   Bobsleigh  1952  0.534958\n",
      "856   Bobsleigh  1956  0.522545\n",
      "986   Bobsleigh  1964  0.840136\n",
      "1051  Bobsleigh  1968  0.819221\n",
      "1116  Bobsleigh  1972  0.632066\n",
      "1181  Bobsleigh  1976  0.783341\n",
      "1246  Bobsleigh  1980  0.691510\n",
      "1311  Bobsleigh  1984  0.954771\n",
      "1376  Bobsleigh  1988  1.192080\n",
      "1441  Bobsleigh  1992  0.870840\n",
      "\n",
      "Prepared time series data for Bobsleigh (CV):\n",
      " Year\n",
      "1924    0.514496\n",
      "1928    0.811255\n",
      "1932    0.647300\n",
      "1936    0.652617\n",
      "1948    0.732900\n",
      "1952    0.534958\n",
      "1956    0.522545\n",
      "1964    0.840136\n",
      "1968    0.819221\n",
      "1972    0.632066\n",
      "1976    0.783341\n",
      "1980    0.691510\n",
      "1984    0.954771\n",
      "1988    1.192080\n",
      "1992    0.870840\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Boxing (CV)\n",
      "Raw data for Boxing (CV):\n",
      "        Sport  Year     Value\n",
      "142   Boxing  1904  0.786067\n",
      "272   Boxing  1908  0.628822\n",
      "402   Boxing  1920  0.750226\n",
      "467   Boxing  1924  1.054965\n",
      "532   Boxing  1928  0.937766\n",
      "597   Boxing  1932  0.814954\n",
      "662   Boxing  1936  0.700344\n",
      "727   Boxing  1948  1.024023\n",
      "792   Boxing  1952  0.980205\n",
      "857   Boxing  1956  0.846589\n",
      "922   Boxing  1960  0.807287\n",
      "987   Boxing  1964  0.832533\n",
      "1052  Boxing  1968  0.812713\n",
      "1117  Boxing  1972  0.847176\n",
      "1182  Boxing  1976  0.911038\n",
      "1247  Boxing  1980  0.852352\n",
      "1312  Boxing  1984  0.958858\n",
      "1377  Boxing  1988  0.852681\n",
      "1442  Boxing  1992  0.695463\n",
      "1507  Boxing  1996  0.807374\n",
      "1572  Boxing  2000  0.719462\n",
      "1637  Boxing  2004  0.730719\n",
      "1702  Boxing  2008  0.798542\n",
      "1767  Boxing  2012  0.605546\n",
      "1832  Boxing  2016  0.694801\n",
      "\n",
      "Prepared time series data for Boxing (CV):\n",
      " Year\n",
      "1904    0.786067\n",
      "1908    0.628822\n",
      "1920    0.750226\n",
      "1924    1.054965\n",
      "1928    0.937766\n",
      "1932    0.814954\n",
      "1936    0.700344\n",
      "1948    1.024023\n",
      "1952    0.980205\n",
      "1956    0.846589\n",
      "1960    0.807287\n",
      "1964    0.832533\n",
      "1968    0.812713\n",
      "1972    0.847176\n",
      "1976    0.911038\n",
      "1980    0.852352\n",
      "1984    0.958858\n",
      "1988    0.852681\n",
      "1992    0.695463\n",
      "1996    0.807374\n",
      "2000    0.719462\n",
      "2004    0.730719\n",
      "2008    0.798542\n",
      "2012    0.605546\n",
      "2016    0.694801\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Canoeing (CV)\n",
      "Raw data for Canoeing (CV):\n",
      "          Sport  Year     Value\n",
      "663   Canoeing  1936  0.830869\n",
      "728   Canoeing  1948  0.671240\n",
      "793   Canoeing  1952  0.818411\n",
      "858   Canoeing  1956  0.847053\n",
      "923   Canoeing  1960  0.869341\n",
      "988   Canoeing  1964  0.940927\n",
      "1053  Canoeing  1968  0.903741\n",
      "1118  Canoeing  1972  0.878195\n",
      "1183  Canoeing  1976  0.772797\n",
      "1248  Canoeing  1980  0.775787\n",
      "1313  Canoeing  1984  0.687830\n",
      "1378  Canoeing  1988  0.681330\n",
      "1443  Canoeing  1992  0.781753\n",
      "1508  Canoeing  1996  0.741853\n",
      "1573  Canoeing  2000  0.855637\n",
      "1638  Canoeing  2004  0.838738\n",
      "1703  Canoeing  2008  0.903088\n",
      "1768  Canoeing  2012  0.851007\n",
      "1833  Canoeing  2016  0.739574\n",
      "\n",
      "Prepared time series data for Canoeing (CV):\n",
      " Year\n",
      "1936    0.830869\n",
      "1948    0.671240\n",
      "1952    0.818411\n",
      "1956    0.847053\n",
      "1960    0.869341\n",
      "1964    0.940927\n",
      "1968    0.903741\n",
      "1972    0.878195\n",
      "1976    0.772797\n",
      "1980    0.775787\n",
      "1984    0.687830\n",
      "1988    0.681330\n",
      "1992    0.781753\n",
      "1996    0.741853\n",
      "2000    0.855637\n",
      "2004    0.838738\n",
      "2008    0.903088\n",
      "2012    0.851007\n",
      "2016    0.739574\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Cricket (CV)\n",
      "Raw data for Cricket (CV):\n",
      "       Sport  Year     Value\n",
      "79  Cricket  1900  0.828775\n",
      "\n",
      "Prepared time series data for Cricket (CV):\n",
      " Year\n",
      "1900    0.828775\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Croquet (CV)\n",
      "Raw data for Croquet (CV):\n",
      "       Sport  Year     Value\n",
      "80  Croquet  1900  0.424264\n",
      "\n",
      "Prepared time series data for Croquet (CV):\n",
      " Year\n",
      "1900    0.424264\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Cross Country Skiing (CV)\n",
      "Raw data for Cross Country Skiing (CV):\n",
      "                      Sport  Year     Value\n",
      "471   Cross Country Skiing  1924  0.632181\n",
      "536   Cross Country Skiing  1928  0.727190\n",
      "601   Cross Country Skiing  1932  0.615260\n",
      "666   Cross Country Skiing  1936  0.848795\n",
      "731   Cross Country Skiing  1948  0.821674\n",
      "796   Cross Country Skiing  1952  0.945958\n",
      "861   Cross Country Skiing  1956  0.812628\n",
      "926   Cross Country Skiing  1960  0.874202\n",
      "991   Cross Country Skiing  1964  0.833128\n",
      "1056  Cross Country Skiing  1968  0.776989\n",
      "1121  Cross Country Skiing  1972  0.717063\n",
      "1186  Cross Country Skiing  1976  0.793358\n",
      "1251  Cross Country Skiing  1980  0.687767\n",
      "1316  Cross Country Skiing  1984  0.783694\n",
      "1381  Cross Country Skiing  1988  0.940878\n",
      "1446  Cross Country Skiing  1992  0.895307\n",
      "\n",
      "Prepared time series data for Cross Country Skiing (CV):\n",
      " Year\n",
      "1924    0.632181\n",
      "1928    0.727190\n",
      "1932    0.615260\n",
      "1936    0.848795\n",
      "1948    0.821674\n",
      "1952    0.945958\n",
      "1956    0.812628\n",
      "1960    0.874202\n",
      "1964    0.833128\n",
      "1968    0.776989\n",
      "1972    0.717063\n",
      "1976    0.793358\n",
      "1980    0.687767\n",
      "1984    0.783694\n",
      "1988    0.940878\n",
      "1992    0.895307\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Curling (CV)\n",
      "Raw data for Curling (CV):\n",
      "        Sport  Year     Value\n",
      "472  Curling  1924  0.467707\n",
      "\n",
      "Prepared time series data for Curling (CV):\n",
      " Year\n",
      "1924    0.467707\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Cycling (CV)\n",
      "Raw data for Cycling (CV):\n",
      "         Sport  Year     Value\n",
      "18    Cycling  1896  0.464830\n",
      "83    Cycling  1900  0.880528\n",
      "148   Cycling  1904  0.808696\n",
      "213   Cycling  1906  0.796790\n",
      "278   Cycling  1908  0.772564\n",
      "343   Cycling  1912  0.810139\n",
      "408   Cycling  1920  0.806663\n",
      "473   Cycling  1924  0.783737\n",
      "538   Cycling  1928  1.080982\n",
      "603   Cycling  1932  0.839691\n",
      "668   Cycling  1936  1.218995\n",
      "733   Cycling  1948  0.744645\n",
      "798   Cycling  1952  0.901054\n",
      "863   Cycling  1956  1.018986\n",
      "928   Cycling  1960  0.877009\n",
      "993   Cycling  1964  0.892452\n",
      "1058  Cycling  1968  0.942452\n",
      "1123  Cycling  1972  0.974726\n",
      "1188  Cycling  1976  0.768095\n",
      "1253  Cycling  1980  1.002249\n",
      "1318  Cycling  1984  1.029319\n",
      "1383  Cycling  1988  0.986207\n",
      "1448  Cycling  1992  0.996982\n",
      "1513  Cycling  1996  0.814259\n",
      "1578  Cycling  2000  0.832670\n",
      "1643  Cycling  2004  0.658619\n",
      "1708  Cycling  2008  0.712451\n",
      "1773  Cycling  2012  0.736437\n",
      "1838  Cycling  2016  0.850879\n",
      "\n",
      "Prepared time series data for Cycling (CV):\n",
      " Year\n",
      "1896    0.464830\n",
      "1900    0.880528\n",
      "1904    0.808696\n",
      "1906    0.796790\n",
      "1908    0.772564\n",
      "1912    0.810139\n",
      "1920    0.806663\n",
      "1924    0.783737\n",
      "1928    1.080982\n",
      "1932    0.839691\n",
      "1936    1.218995\n",
      "1948    0.744645\n",
      "1952    0.901054\n",
      "1956    1.018986\n",
      "1960    0.877009\n",
      "1964    0.892452\n",
      "1968    0.942452\n",
      "1972    0.974726\n",
      "1976    0.768095\n",
      "1980    1.002249\n",
      "1984    1.029319\n",
      "1988    0.986207\n",
      "1992    0.996982\n",
      "1996    0.814259\n",
      "2000    0.832670\n",
      "2004    0.658619\n",
      "2008    0.712451\n",
      "2012    0.736437\n",
      "2016    0.850879\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Diving (CV)\n",
      "Raw data for Diving (CV):\n",
      "        Sport  Year     Value\n",
      "149   Diving  1904  0.666667\n",
      "214   Diving  1906  0.361372\n",
      "279   Diving  1908  0.532153\n",
      "344   Diving  1912  0.845639\n",
      "409   Diving  1920  0.792982\n",
      "474   Diving  1924  0.579033\n",
      "539   Diving  1928  0.807178\n",
      "604   Diving  1932  0.801043\n",
      "669   Diving  1936  0.684390\n",
      "734   Diving  1948  0.728827\n",
      "799   Diving  1952  0.684570\n",
      "864   Diving  1956  0.600510\n",
      "929   Diving  1960  0.799214\n",
      "994   Diving  1964  0.780908\n",
      "1059  Diving  1968  0.856157\n",
      "1124  Diving  1972  0.717546\n",
      "1189  Diving  1976  0.683665\n",
      "1254  Diving  1980  0.741365\n",
      "1319  Diving  1984  0.721507\n",
      "1384  Diving  1988  0.598734\n",
      "1449  Diving  1992  0.661590\n",
      "1514  Diving  1996  0.721938\n",
      "1579  Diving  2000  0.693598\n",
      "1644  Diving  2004  0.728515\n",
      "1709  Diving  2008  0.677314\n",
      "1774  Diving  2012  0.697442\n",
      "1839  Diving  2016  0.559902\n",
      "\n",
      "Prepared time series data for Diving (CV):\n",
      " Year\n",
      "1904    0.666667\n",
      "1906    0.361372\n",
      "1908    0.532153\n",
      "1912    0.845639\n",
      "1920    0.792982\n",
      "1924    0.579033\n",
      "1928    0.807178\n",
      "1932    0.801043\n",
      "1936    0.684390\n",
      "1948    0.728827\n",
      "1952    0.684570\n",
      "1956    0.600510\n",
      "1960    0.799214\n",
      "1964    0.780908\n",
      "1968    0.856157\n",
      "1972    0.717546\n",
      "1976    0.683665\n",
      "1980    0.741365\n",
      "1984    0.721507\n",
      "1988    0.598734\n",
      "1992    0.661590\n",
      "1996    0.721938\n",
      "2000    0.693598\n",
      "2004    0.728515\n",
      "2008    0.677314\n",
      "2012    0.697442\n",
      "2016    0.559902\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Equestrianism (CV)\n",
      "Raw data for Equestrianism (CV):\n",
      "               Sport  Year     Value\n",
      "85    Equestrianism  1900  0.609954\n",
      "345   Equestrianism  1912  0.801586\n",
      "410   Equestrianism  1920  0.767753\n",
      "475   Equestrianism  1924  0.898989\n",
      "540   Equestrianism  1928  0.793643\n",
      "605   Equestrianism  1932  0.845761\n",
      "670   Equestrianism  1936  0.955062\n",
      "735   Equestrianism  1948  0.700035\n",
      "800   Equestrianism  1952  0.676993\n",
      "865   Equestrianism  1956  0.775717\n",
      "930   Equestrianism  1960  0.744746\n",
      "995   Equestrianism  1964  0.785564\n",
      "1060  Equestrianism  1968  0.727036\n",
      "1125  Equestrianism  1972  0.708297\n",
      "1190  Equestrianism  1976  0.674576\n",
      "1255  Equestrianism  1980  0.488844\n",
      "1320  Equestrianism  1984  0.620765\n",
      "1385  Equestrianism  1988  0.914279\n",
      "1450  Equestrianism  1992  0.673800\n",
      "1515  Equestrianism  1996  0.699851\n",
      "1580  Equestrianism  2000  0.548105\n",
      "1645  Equestrianism  2004  0.563338\n",
      "1710  Equestrianism  2008  0.741468\n",
      "1775  Equestrianism  2012  0.632023\n",
      "1840  Equestrianism  2016  0.651269\n",
      "\n",
      "Prepared time series data for Equestrianism (CV):\n",
      " Year\n",
      "1900    0.609954\n",
      "1912    0.801586\n",
      "1920    0.767753\n",
      "1924    0.898989\n",
      "1928    0.793643\n",
      "1932    0.845761\n",
      "1936    0.955062\n",
      "1948    0.700035\n",
      "1952    0.676993\n",
      "1956    0.775717\n",
      "1960    0.744746\n",
      "1964    0.785564\n",
      "1968    0.727036\n",
      "1972    0.708297\n",
      "1976    0.674576\n",
      "1980    0.488844\n",
      "1984    0.620765\n",
      "1988    0.914279\n",
      "1992    0.673800\n",
      "1996    0.699851\n",
      "2000    0.548105\n",
      "2004    0.563338\n",
      "2008    0.741468\n",
      "2012    0.632023\n",
      "2016    0.651269\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Fencing (CV)\n",
      "Raw data for Fencing (CV):\n",
      "         Sport  Year     Value\n",
      "21    Fencing  1896  0.666667\n",
      "86    Fencing  1900  0.793313\n",
      "151   Fencing  1904  0.659966\n",
      "216   Fencing  1906  0.743330\n",
      "281   Fencing  1908  0.887736\n",
      "346   Fencing  1912  0.765545\n",
      "411   Fencing  1920  0.575154\n",
      "476   Fencing  1924  0.657097\n",
      "541   Fencing  1928  0.726393\n",
      "606   Fencing  1932  0.819036\n",
      "671   Fencing  1936  0.851211\n",
      "736   Fencing  1948  0.761829\n",
      "801   Fencing  1952  0.750446\n",
      "866   Fencing  1956  0.800270\n",
      "931   Fencing  1960  0.969656\n",
      "996   Fencing  1964  0.788658\n",
      "1061  Fencing  1968  0.834113\n",
      "1126  Fencing  1972  0.747523\n",
      "1191  Fencing  1976  0.865844\n",
      "1256  Fencing  1980  0.711648\n",
      "1321  Fencing  1984  0.834778\n",
      "1386  Fencing  1988  0.914656\n",
      "1451  Fencing  1992  0.766387\n",
      "1516  Fencing  1996  0.798969\n",
      "1581  Fencing  2000  0.796778\n",
      "1646  Fencing  2004  0.622530\n",
      "1711  Fencing  2008  0.882770\n",
      "1776  Fencing  2012  0.780008\n",
      "1841  Fencing  2016  0.773009\n",
      "\n",
      "Prepared time series data for Fencing (CV):\n",
      " Year\n",
      "1896    0.666667\n",
      "1900    0.793313\n",
      "1904    0.659966\n",
      "1906    0.743330\n",
      "1908    0.887736\n",
      "1912    0.765545\n",
      "1920    0.575154\n",
      "1924    0.657097\n",
      "1928    0.726393\n",
      "1932    0.819036\n",
      "1936    0.851211\n",
      "1948    0.761829\n",
      "1952    0.750446\n",
      "1956    0.800270\n",
      "1960    0.969656\n",
      "1964    0.788658\n",
      "1968    0.834113\n",
      "1972    0.747523\n",
      "1976    0.865844\n",
      "1980    0.711648\n",
      "1984    0.834778\n",
      "1988    0.914656\n",
      "1992    0.766387\n",
      "1996    0.798969\n",
      "2000    0.796778\n",
      "2004    0.622530\n",
      "2008    0.882770\n",
      "2012    0.780008\n",
      "2016    0.773009\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Figure Skating (CV)\n",
      "Raw data for Figure Skating (CV):\n",
      "                Sport  Year     Value\n",
      "282   Figure Skating  1908  0.661918\n",
      "412   Figure Skating  1920  0.674576\n",
      "477   Figure Skating  1924  0.774597\n",
      "542   Figure Skating  1928  0.686694\n",
      "607   Figure Skating  1932  0.769848\n",
      "672   Figure Skating  1936  0.632402\n",
      "737   Figure Skating  1948  0.888802\n",
      "802   Figure Skating  1952  0.876423\n",
      "867   Figure Skating  1956  0.848872\n",
      "932   Figure Skating  1960  0.875948\n",
      "997   Figure Skating  1964  0.949433\n",
      "1062  Figure Skating  1968  0.992819\n",
      "1127  Figure Skating  1972  0.650464\n",
      "1192  Figure Skating  1976  0.645682\n",
      "1257  Figure Skating  1980  0.866025\n",
      "1322  Figure Skating  1984  0.618472\n",
      "1387  Figure Skating  1988  0.776086\n",
      "1452  Figure Skating  1992  0.551486\n",
      "\n",
      "Prepared time series data for Figure Skating (CV):\n",
      " Year\n",
      "1908    0.661918\n",
      "1920    0.674576\n",
      "1924    0.774597\n",
      "1928    0.686694\n",
      "1932    0.769848\n",
      "1936    0.632402\n",
      "1948    0.888802\n",
      "1952    0.876423\n",
      "1956    0.848872\n",
      "1960    0.875948\n",
      "1964    0.949433\n",
      "1968    0.992819\n",
      "1972    0.650464\n",
      "1976    0.645682\n",
      "1980    0.866025\n",
      "1984    0.618472\n",
      "1988    0.776086\n",
      "1992    0.551486\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Football (CV)\n",
      "Raw data for Football (CV):\n",
      "          Sport  Year     Value\n",
      "88    Football  1900  0.712061\n",
      "153   Football  1904  0.707107\n",
      "218   Football  1906  0.702728\n",
      "283   Football  1908  0.717440\n",
      "348   Football  1912  0.916742\n",
      "413   Football  1920  0.677752\n",
      "478   Football  1924  0.846773\n",
      "543   Football  1928  0.774222\n",
      "673   Football  1936  0.842458\n",
      "738   Football  1948  0.816210\n",
      "803   Football  1952  0.719267\n",
      "868   Football  1956  0.856121\n",
      "933   Football  1960  0.914501\n",
      "998   Football  1964  0.779273\n",
      "1063  Football  1968  0.958817\n",
      "1128  Football  1972  0.826412\n",
      "1193  Football  1976  0.687504\n",
      "1258  Football  1980  0.727299\n",
      "1323  Football  1984  0.893110\n",
      "1388  Football  1988  0.892617\n",
      "1453  Football  1992  0.946092\n",
      "1518  Football  1996  1.296968\n",
      "1583  Football  2000  1.252190\n",
      "1648  Football  2004  1.151576\n",
      "1713  Football  2008  1.150719\n",
      "1778  Football  2012  1.183452\n",
      "1843  Football  2016  1.140818\n",
      "\n",
      "Prepared time series data for Football (CV):\n",
      " Year\n",
      "1900    0.712061\n",
      "1904    0.707107\n",
      "1906    0.702728\n",
      "1908    0.717440\n",
      "1912    0.916742\n",
      "1920    0.677752\n",
      "1924    0.846773\n",
      "1928    0.774222\n",
      "1936    0.842458\n",
      "1948    0.816210\n",
      "1952    0.719267\n",
      "1956    0.856121\n",
      "1960    0.914501\n",
      "1964    0.779273\n",
      "1968    0.958817\n",
      "1972    0.826412\n",
      "1976    0.687504\n",
      "1980    0.727299\n",
      "1984    0.893110\n",
      "1988    0.892617\n",
      "1992    0.946092\n",
      "1996    1.296968\n",
      "2000    1.252190\n",
      "2004    1.151576\n",
      "2008    1.150719\n",
      "2012    1.183452\n",
      "2016    1.140818\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Freestyle Skiing (CV)\n",
      "Raw data for Freestyle Skiing (CV):\n",
      "                  Sport  Year    Value\n",
      "1454  Freestyle Skiing  1992  0.70713\n",
      "\n",
      "Prepared time series data for Freestyle Skiing (CV):\n",
      " Year\n",
      "1992    0.70713\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Golf (CV)\n",
      "Raw data for Golf (CV):\n",
      "      Sport  Year     Value\n",
      "90    Golf  1900  0.482090\n",
      "155   Golf  1904  0.740036\n",
      "1845  Golf  2016  0.587447\n",
      "\n",
      "Prepared time series data for Golf (CV):\n",
      " Year\n",
      "1900    0.482090\n",
      "1904    0.740036\n",
      "2016    0.587447\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Gymnastics (CV)\n",
      "Raw data for Gymnastics (CV):\n",
      "            Sport  Year     Value\n",
      "26    Gymnastics  1896  0.740867\n",
      "91    Gymnastics  1900  0.693889\n",
      "156   Gymnastics  1904  0.715902\n",
      "221   Gymnastics  1906  0.565015\n",
      "286   Gymnastics  1908  0.944089\n",
      "351   Gymnastics  1912  0.881402\n",
      "416   Gymnastics  1920  0.823307\n",
      "481   Gymnastics  1924  0.790771\n",
      "546   Gymnastics  1928  0.865067\n",
      "611   Gymnastics  1932  0.775685\n",
      "676   Gymnastics  1936  0.941012\n",
      "741   Gymnastics  1948  0.753465\n",
      "806   Gymnastics  1952  0.835230\n",
      "871   Gymnastics  1956  0.818370\n",
      "936   Gymnastics  1960  0.857371\n",
      "1001  Gymnastics  1964  0.740685\n",
      "1066  Gymnastics  1968  0.717087\n",
      "1131  Gymnastics  1972  0.616569\n",
      "1196  Gymnastics  1976  0.581846\n",
      "1261  Gymnastics  1980  0.638414\n",
      "1326  Gymnastics  1984  0.623577\n",
      "1391  Gymnastics  1988  0.560846\n",
      "1456  Gymnastics  1992  0.645743\n",
      "1521  Gymnastics  1996  0.506390\n",
      "1586  Gymnastics  2000  0.699032\n",
      "1651  Gymnastics  2004  0.583603\n",
      "1716  Gymnastics  2008  0.593242\n",
      "1781  Gymnastics  2012  0.807635\n",
      "1846  Gymnastics  2016  0.751481\n",
      "\n",
      "Prepared time series data for Gymnastics (CV):\n",
      " Year\n",
      "1896    0.740867\n",
      "1900    0.693889\n",
      "1904    0.715902\n",
      "1906    0.565015\n",
      "1908    0.944089\n",
      "1912    0.881402\n",
      "1920    0.823307\n",
      "1924    0.790771\n",
      "1928    0.865067\n",
      "1932    0.775685\n",
      "1936    0.941012\n",
      "1948    0.753465\n",
      "1952    0.835230\n",
      "1956    0.818370\n",
      "1960    0.857371\n",
      "1964    0.740685\n",
      "1968    0.717087\n",
      "1972    0.616569\n",
      "1976    0.581846\n",
      "1980    0.638414\n",
      "1984    0.623577\n",
      "1988    0.560846\n",
      "1992    0.645743\n",
      "1996    0.506390\n",
      "2000    0.699032\n",
      "2004    0.583603\n",
      "2008    0.593242\n",
      "2012    0.807635\n",
      "2016    0.751481\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Handball (CV)\n",
      "Raw data for Handball (CV):\n",
      "          Sport  Year     Value\n",
      "677   Handball  1936  0.894579\n",
      "1132  Handball  1972  0.848863\n",
      "1197  Handball  1976  0.703500\n",
      "1262  Handball  1980  0.575373\n",
      "1327  Handball  1984  0.784078\n",
      "1392  Handball  1988  0.854535\n",
      "1457  Handball  1992  0.789756\n",
      "1522  Handball  1996  0.775751\n",
      "1587  Handball  2000  0.740294\n",
      "1652  Handball  2004  0.804348\n",
      "1717  Handball  2008  0.683232\n",
      "1782  Handball  2012  0.770110\n",
      "1847  Handball  2016  0.658856\n",
      "\n",
      "Prepared time series data for Handball (CV):\n",
      " Year\n",
      "1936    0.894579\n",
      "1972    0.848863\n",
      "1976    0.703500\n",
      "1980    0.575373\n",
      "1984    0.784078\n",
      "1988    0.854535\n",
      "1992    0.789756\n",
      "1996    0.775751\n",
      "2000    0.740294\n",
      "2004    0.804348\n",
      "2008    0.683232\n",
      "2012    0.770110\n",
      "2016    0.658856\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Hockey (CV)\n",
      "Raw data for Hockey (CV):\n",
      "        Sport  Year     Value\n",
      "288   Hockey  1908  0.683050\n",
      "418   Hockey  1920  0.548598\n",
      "548   Hockey  1928  0.731529\n",
      "613   Hockey  1932  0.622638\n",
      "678   Hockey  1936  0.771054\n",
      "743   Hockey  1948  0.676468\n",
      "808   Hockey  1952  0.768672\n",
      "873   Hockey  1956  0.852724\n",
      "938   Hockey  1960  0.809496\n",
      "1003  Hockey  1964  0.800731\n",
      "1068  Hockey  1968  0.844248\n",
      "1133  Hockey  1972  0.999836\n",
      "1198  Hockey  1976  0.720787\n",
      "1263  Hockey  1980  0.706582\n",
      "1328  Hockey  1984  0.804999\n",
      "1393  Hockey  1988  0.716856\n",
      "1458  Hockey  1992  0.783670\n",
      "1523  Hockey  1996  0.760460\n",
      "1588  Hockey  2000  0.728136\n",
      "1653  Hockey  2004  0.825105\n",
      "1718  Hockey  2008  0.724538\n",
      "1783  Hockey  2012  0.823549\n",
      "1848  Hockey  2016  0.767864\n",
      "\n",
      "Prepared time series data for Hockey (CV):\n",
      " Year\n",
      "1908    0.683050\n",
      "1920    0.548598\n",
      "1928    0.731529\n",
      "1932    0.622638\n",
      "1936    0.771054\n",
      "1948    0.676468\n",
      "1952    0.768672\n",
      "1956    0.852724\n",
      "1960    0.809496\n",
      "1964    0.800731\n",
      "1968    0.844248\n",
      "1972    0.999836\n",
      "1976    0.720787\n",
      "1980    0.706582\n",
      "1984    0.804999\n",
      "1988    0.716856\n",
      "1992    0.783670\n",
      "1996    0.760460\n",
      "2000    0.728136\n",
      "2004    0.825105\n",
      "2008    0.724538\n",
      "2012    0.823549\n",
      "2016    0.767864\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Ice Hockey (CV)\n",
      "Raw data for Ice Hockey (CV):\n",
      "            Sport  Year     Value\n",
      "419   Ice Hockey  1920  0.731916\n",
      "484   Ice Hockey  1924  0.662106\n",
      "549   Ice Hockey  1928  0.709721\n",
      "614   Ice Hockey  1932  0.877547\n",
      "679   Ice Hockey  1936  0.900320\n",
      "744   Ice Hockey  1948  0.728396\n",
      "809   Ice Hockey  1952  0.853363\n",
      "874   Ice Hockey  1956  0.804912\n",
      "939   Ice Hockey  1960  0.604194\n",
      "1004  Ice Hockey  1964  0.705351\n",
      "1069  Ice Hockey  1968  0.990356\n",
      "1134  Ice Hockey  1972  0.862438\n",
      "1199  Ice Hockey  1976  0.787586\n",
      "1264  Ice Hockey  1980  0.767187\n",
      "1329  Ice Hockey  1984  0.812590\n",
      "1394  Ice Hockey  1988  0.765703\n",
      "1459  Ice Hockey  1992  0.759741\n",
      "\n",
      "Prepared time series data for Ice Hockey (CV):\n",
      " Year\n",
      "1920    0.731916\n",
      "1924    0.662106\n",
      "1928    0.709721\n",
      "1932    0.877547\n",
      "1936    0.900320\n",
      "1948    0.728396\n",
      "1952    0.853363\n",
      "1956    0.804912\n",
      "1960    0.604194\n",
      "1964    0.705351\n",
      "1968    0.990356\n",
      "1972    0.862438\n",
      "1976    0.787586\n",
      "1980    0.767187\n",
      "1984    0.812590\n",
      "1988    0.765703\n",
      "1992    0.759741\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Jeu De Paume (CV)\n",
      "Raw data for Jeu De Paume (CV):\n",
      "             Sport  Year     Value\n",
      "290  Jeu De Paume  1908  0.516042\n",
      "\n",
      "Prepared time series data for Jeu De Paume (CV):\n",
      " Year\n",
      "1908    0.516042\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Judo (CV)\n",
      "Raw data for Judo (CV):\n",
      "      Sport  Year     Value\n",
      "1006  Judo  1964  0.750785\n",
      "1136  Judo  1972  1.637093\n",
      "1201  Judo  1976  0.473819\n",
      "1266  Judo  1980  0.947741\n",
      "1331  Judo  1984  0.716827\n",
      "1396  Judo  1988  0.702141\n",
      "1461  Judo  1992  0.841097\n",
      "1526  Judo  1996  0.823050\n",
      "1591  Judo  2000  0.859037\n",
      "1656  Judo  2004  0.821097\n",
      "1721  Judo  2008  0.845571\n",
      "1786  Judo  2012  0.729284\n",
      "1851  Judo  2016  0.823441\n",
      "\n",
      "Prepared time series data for Judo (CV):\n",
      " Year\n",
      "1964    0.750785\n",
      "1972    1.637093\n",
      "1976    0.473819\n",
      "1980    0.947741\n",
      "1984    0.716827\n",
      "1988    0.702141\n",
      "1992    0.841097\n",
      "1996    0.823050\n",
      "2000    0.859037\n",
      "2004    0.821097\n",
      "2008    0.845571\n",
      "2012    0.729284\n",
      "2016    0.823441\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Lacrosse (CV)\n",
      "Raw data for Lacrosse (CV):\n",
      "         Sport  Year     Value\n",
      "162  Lacrosse  1904  0.564653\n",
      "292  Lacrosse  1908  0.620345\n",
      "\n",
      "Prepared time series data for Lacrosse (CV):\n",
      " Year\n",
      "1904    0.564653\n",
      "1908    0.620345\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Luge (CV)\n",
      "Raw data for Luge (CV):\n",
      "      Sport  Year     Value\n",
      "1008  Luge  1964  0.955183\n",
      "1073  Luge  1968  0.732288\n",
      "1138  Luge  1972  0.876554\n",
      "1203  Luge  1976  0.719436\n",
      "1268  Luge  1980  0.808275\n",
      "1333  Luge  1984  0.649612\n",
      "1398  Luge  1988  0.785390\n",
      "1463  Luge  1992  0.845748\n",
      "\n",
      "Prepared time series data for Luge (CV):\n",
      " Year\n",
      "1964    0.955183\n",
      "1968    0.732288\n",
      "1972    0.876554\n",
      "1976    0.719436\n",
      "1980    0.808275\n",
      "1984    0.649612\n",
      "1988    0.785390\n",
      "1992    0.845748\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Military Ski Patrol (CV)\n",
      "Raw data for Military Ski Patrol (CV):\n",
      "                    Sport  Year     Value\n",
      "489  Military Ski Patrol  1924  0.677202\n",
      "\n",
      "Prepared time series data for Military Ski Patrol (CV):\n",
      " Year\n",
      "1924    0.677202\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Modern Pentathlon (CV)\n",
      "Raw data for Modern Pentathlon (CV):\n",
      "                   Sport  Year     Value\n",
      "360   Modern Pentathlon  1912  0.645737\n",
      "425   Modern Pentathlon  1920  0.591485\n",
      "490   Modern Pentathlon  1924  0.856587\n",
      "555   Modern Pentathlon  1928  0.622569\n",
      "620   Modern Pentathlon  1932  0.816497\n",
      "685   Modern Pentathlon  1936  0.605022\n",
      "750   Modern Pentathlon  1948  0.588760\n",
      "815   Modern Pentathlon  1952  0.779898\n",
      "880   Modern Pentathlon  1956  0.876524\n",
      "945   Modern Pentathlon  1960  0.856728\n",
      "1010  Modern Pentathlon  1964  0.636018\n",
      "1075  Modern Pentathlon  1968  1.986483\n",
      "1140  Modern Pentathlon  1972  0.766110\n",
      "1205  Modern Pentathlon  1976  0.796825\n",
      "1270  Modern Pentathlon  1980  0.740879\n",
      "1335  Modern Pentathlon  1984  0.652414\n",
      "1400  Modern Pentathlon  1988  0.686606\n",
      "1465  Modern Pentathlon  1992  0.557660\n",
      "1530  Modern Pentathlon  1996  0.605530\n",
      "1595  Modern Pentathlon  2000  0.732655\n",
      "1660  Modern Pentathlon  2004  0.684172\n",
      "1725  Modern Pentathlon  2008  0.687563\n",
      "1790  Modern Pentathlon  2012  0.587493\n",
      "1855  Modern Pentathlon  2016  0.691051\n",
      "\n",
      "Prepared time series data for Modern Pentathlon (CV):\n",
      " Year\n",
      "1912    0.645737\n",
      "1920    0.591485\n",
      "1924    0.856587\n",
      "1928    0.622569\n",
      "1932    0.816497\n",
      "1936    0.605022\n",
      "1948    0.588760\n",
      "1952    0.779898\n",
      "1956    0.876524\n",
      "1960    0.856728\n",
      "1964    0.636018\n",
      "1968    1.986483\n",
      "1972    0.766110\n",
      "1976    0.796825\n",
      "1980    0.740879\n",
      "1984    0.652414\n",
      "1988    0.686606\n",
      "1992    0.557660\n",
      "1996    0.605530\n",
      "2000    0.732655\n",
      "2004    0.684172\n",
      "2008    0.687563\n",
      "2012    0.587493\n",
      "2016    0.691051\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Motorboating (CV)\n",
      "Raw data for Motorboating (CV):\n",
      "             Sport  Year  Value\n",
      "296  Motorboating  1908    0.6\n",
      "\n",
      "Prepared time series data for Motorboating (CV):\n",
      " Year\n",
      "1908    0.6\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Nordic Combined (CV)\n",
      "Raw data for Nordic Combined (CV):\n",
      "                 Sport  Year     Value\n",
      "492   Nordic Combined  1924  0.550895\n",
      "557   Nordic Combined  1928  0.610319\n",
      "622   Nordic Combined  1932  0.880605\n",
      "687   Nordic Combined  1936  0.802446\n",
      "752   Nordic Combined  1948  0.649559\n",
      "817   Nordic Combined  1952  0.805536\n",
      "882   Nordic Combined  1956  0.884047\n",
      "947   Nordic Combined  1960  0.696311\n",
      "1012  Nordic Combined  1964  0.788714\n",
      "1077  Nordic Combined  1968  0.591432\n",
      "1142  Nordic Combined  1972  0.762587\n",
      "1207  Nordic Combined  1976  0.467823\n",
      "1272  Nordic Combined  1980  0.582597\n",
      "1337  Nordic Combined  1984  0.587438\n",
      "1402  Nordic Combined  1988  0.755968\n",
      "1467  Nordic Combined  1992  0.635256\n",
      "\n",
      "Prepared time series data for Nordic Combined (CV):\n",
      " Year\n",
      "1924    0.550895\n",
      "1928    0.610319\n",
      "1932    0.880605\n",
      "1936    0.802446\n",
      "1948    0.649559\n",
      "1952    0.805536\n",
      "1956    0.884047\n",
      "1960    0.696311\n",
      "1964    0.788714\n",
      "1968    0.591432\n",
      "1972    0.762587\n",
      "1976    0.467823\n",
      "1980    0.582597\n",
      "1984    0.587438\n",
      "1988    0.755968\n",
      "1992    0.635256\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Polo (CV)\n",
      "Raw data for Polo (CV):\n",
      "     Sport  Year     Value\n",
      "103  Polo  1900  0.555578\n",
      "298  Polo  1908  0.516042\n",
      "428  Polo  1920  0.580119\n",
      "493  Polo  1924  0.658498\n",
      "688  Polo  1936  0.440996\n",
      "\n",
      "Prepared time series data for Polo (CV):\n",
      " Year\n",
      "1900    0.555578\n",
      "1908    0.516042\n",
      "1920    0.580119\n",
      "1924    0.658498\n",
      "1936    0.440996\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Racquets (CV)\n",
      "Raw data for Racquets (CV):\n",
      "         Sport  Year     Value\n",
      "299  Racquets  1908  0.503953\n",
      "\n",
      "Prepared time series data for Racquets (CV):\n",
      " Year\n",
      "1908    0.503953\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Rhythmic Gymnastics (CV)\n",
      "Raw data for Rhythmic Gymnastics (CV):\n",
      "                     Sport  Year     Value\n",
      "1340  Rhythmic Gymnastics  1984  0.892409\n",
      "1405  Rhythmic Gymnastics  1988  0.750104\n",
      "1470  Rhythmic Gymnastics  1992  0.718130\n",
      "1535  Rhythmic Gymnastics  1996  0.799520\n",
      "1600  Rhythmic Gymnastics  2000  0.773113\n",
      "1665  Rhythmic Gymnastics  2004  0.837016\n",
      "1730  Rhythmic Gymnastics  2008  0.786924\n",
      "1795  Rhythmic Gymnastics  2012  0.847281\n",
      "1860  Rhythmic Gymnastics  2016  0.642262\n",
      "\n",
      "Prepared time series data for Rhythmic Gymnastics (CV):\n",
      " Year\n",
      "1984    0.892409\n",
      "1988    0.750104\n",
      "1992    0.718130\n",
      "1996    0.799520\n",
      "2000    0.773113\n",
      "2004    0.837016\n",
      "2008    0.786924\n",
      "2012    0.847281\n",
      "2016    0.642262\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Roque (CV)\n",
      "Raw data for Roque (CV):\n",
      "      Sport  Year     Value\n",
      "171  Roque  1904  0.666667\n",
      "\n",
      "Prepared time series data for Roque (CV):\n",
      " Year\n",
      "1904    0.666667\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Rowing (CV)\n",
      "Raw data for Rowing (CV):\n",
      "        Sport  Year     Value\n",
      "107   Rowing  1900  0.862017\n",
      "172   Rowing  1904  0.611067\n",
      "237   Rowing  1906  0.939234\n",
      "302   Rowing  1908  0.937623\n",
      "367   Rowing  1912  0.758842\n",
      "432   Rowing  1920  0.617899\n",
      "497   Rowing  1924  0.866921\n",
      "562   Rowing  1928  0.991426\n",
      "627   Rowing  1932  0.985305\n",
      "692   Rowing  1936  1.030136\n",
      "757   Rowing  1948  0.949776\n",
      "822   Rowing  1952  1.183576\n",
      "887   Rowing  1956  1.079190\n",
      "952   Rowing  1960  1.003744\n",
      "1017  Rowing  1964  1.090655\n",
      "1082  Rowing  1968  1.082725\n",
      "1147  Rowing  1972  1.074826\n",
      "1212  Rowing  1976  0.970448\n",
      "1277  Rowing  1980  1.013011\n",
      "1342  Rowing  1984  1.161647\n",
      "1407  Rowing  1988  1.024266\n",
      "1472  Rowing  1992  1.024522\n",
      "1537  Rowing  1996  0.933240\n",
      "1602  Rowing  2000  0.914912\n",
      "1667  Rowing  2004  0.815839\n",
      "1732  Rowing  2008  0.916340\n",
      "1797  Rowing  2012  0.919531\n",
      "1862  Rowing  2016  0.882665\n",
      "\n",
      "Prepared time series data for Rowing (CV):\n",
      " Year\n",
      "1900    0.862017\n",
      "1904    0.611067\n",
      "1906    0.939234\n",
      "1908    0.937623\n",
      "1912    0.758842\n",
      "1920    0.617899\n",
      "1924    0.866921\n",
      "1928    0.991426\n",
      "1932    0.985305\n",
      "1936    1.030136\n",
      "1948    0.949776\n",
      "1952    1.183576\n",
      "1956    1.079190\n",
      "1960    1.003744\n",
      "1964    1.090655\n",
      "1968    1.082725\n",
      "1972    1.074826\n",
      "1976    0.970448\n",
      "1980    1.013011\n",
      "1984    1.161647\n",
      "1988    1.024266\n",
      "1992    1.024522\n",
      "1996    0.933240\n",
      "2000    0.914912\n",
      "2004    0.815839\n",
      "2008    0.916340\n",
      "2012    0.919531\n",
      "2016    0.882665\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Rugby (CV)\n",
      "Raw data for Rugby (CV):\n",
      "      Sport  Year     Value\n",
      "108  Rugby  1900  0.592012\n",
      "303  Rugby  1908  0.621906\n",
      "433  Rugby  1920  0.891411\n",
      "498  Rugby  1924  0.819882\n",
      "\n",
      "Prepared time series data for Rugby (CV):\n",
      " Year\n",
      "1900    0.592012\n",
      "1908    0.621906\n",
      "1920    0.891411\n",
      "1924    0.819882\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Rugby Sevens (CV)\n",
      "Raw data for Rugby Sevens (CV):\n",
      "              Sport  Year     Value\n",
      "1864  Rugby Sevens  2016  0.674445\n",
      "\n",
      "Prepared time series data for Rugby Sevens (CV):\n",
      " Year\n",
      "2016    0.674445\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Sailing (CV)\n",
      "Raw data for Sailing (CV):\n",
      "         Sport  Year     Value\n",
      "110   Sailing  1900  0.675679\n",
      "305   Sailing  1908  0.642195\n",
      "370   Sailing  1912  0.660706\n",
      "435   Sailing  1920  0.674406\n",
      "500   Sailing  1924  0.762052\n",
      "565   Sailing  1928  0.664383\n",
      "630   Sailing  1932  0.695079\n",
      "695   Sailing  1936  0.755110\n",
      "760   Sailing  1948  0.707717\n",
      "825   Sailing  1952  0.677866\n",
      "890   Sailing  1956  0.765096\n",
      "955   Sailing  1960  0.697160\n",
      "1020  Sailing  1964  0.678268\n",
      "1085  Sailing  1968  0.669943\n",
      "1150  Sailing  1972  0.735578\n",
      "1215  Sailing  1976  0.890492\n",
      "1280  Sailing  1980  0.693309\n",
      "1345  Sailing  1984  1.031356\n",
      "1410  Sailing  1988  1.046487\n",
      "1475  Sailing  1992  1.026684\n",
      "1540  Sailing  1996  0.852858\n",
      "1605  Sailing  2000  0.815035\n",
      "1670  Sailing  2004  0.883016\n",
      "1735  Sailing  2008  0.856560\n",
      "1800  Sailing  2012  0.751921\n",
      "1865  Sailing  2016  0.817180\n",
      "\n",
      "Prepared time series data for Sailing (CV):\n",
      " Year\n",
      "1900    0.675679\n",
      "1908    0.642195\n",
      "1912    0.660706\n",
      "1920    0.674406\n",
      "1924    0.762052\n",
      "1928    0.664383\n",
      "1932    0.695079\n",
      "1936    0.755110\n",
      "1948    0.707717\n",
      "1952    0.677866\n",
      "1956    0.765096\n",
      "1960    0.697160\n",
      "1964    0.678268\n",
      "1968    0.669943\n",
      "1972    0.735578\n",
      "1976    0.890492\n",
      "1980    0.693309\n",
      "1984    1.031356\n",
      "1988    1.046487\n",
      "1992    1.026684\n",
      "1996    0.852858\n",
      "2000    0.815035\n",
      "2004    0.883016\n",
      "2008    0.856560\n",
      "2012    0.751921\n",
      "2016    0.817180\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Shooting (CV)\n",
      "Raw data for Shooting (CV):\n",
      "          Sport  Year     Value\n",
      "46    Shooting  1896  0.461840\n",
      "111   Shooting  1900  0.675476\n",
      "241   Shooting  1906  0.451540\n",
      "306   Shooting  1908  0.753140\n",
      "371   Shooting  1912  0.847248\n",
      "436   Shooting  1920  0.863425\n",
      "501   Shooting  1924  0.905885\n",
      "631   Shooting  1932  0.519557\n",
      "696   Shooting  1936  0.755543\n",
      "761   Shooting  1948  0.769415\n",
      "826   Shooting  1952  0.805346\n",
      "891   Shooting  1956  0.650710\n",
      "956   Shooting  1960  0.711915\n",
      "1021  Shooting  1964  0.887982\n",
      "1086  Shooting  1968  0.836832\n",
      "1151  Shooting  1972  0.745811\n",
      "1216  Shooting  1976  0.778973\n",
      "1281  Shooting  1980  0.751998\n",
      "1346  Shooting  1984  0.702677\n",
      "1411  Shooting  1988  0.762065\n",
      "1476  Shooting  1992  0.846846\n",
      "1541  Shooting  1996  0.856939\n",
      "1606  Shooting  2000  0.683008\n",
      "1671  Shooting  2004  0.705965\n",
      "1736  Shooting  2008  0.705019\n",
      "1801  Shooting  2012  0.720304\n",
      "1866  Shooting  2016  0.758921\n",
      "\n",
      "Prepared time series data for Shooting (CV):\n",
      " Year\n",
      "1896    0.461840\n",
      "1900    0.675476\n",
      "1906    0.451540\n",
      "1908    0.753140\n",
      "1912    0.847248\n",
      "1920    0.863425\n",
      "1924    0.905885\n",
      "1932    0.519557\n",
      "1936    0.755543\n",
      "1948    0.769415\n",
      "1952    0.805346\n",
      "1956    0.650710\n",
      "1960    0.711915\n",
      "1964    0.887982\n",
      "1968    0.836832\n",
      "1972    0.745811\n",
      "1976    0.778973\n",
      "1980    0.751998\n",
      "1984    0.702677\n",
      "1988    0.762065\n",
      "1992    0.846846\n",
      "1996    0.856939\n",
      "2000    0.683008\n",
      "2004    0.705965\n",
      "2008    0.705019\n",
      "2012    0.720304\n",
      "2016    0.758921\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Short Track Speed Skating (CV)\n",
      "Raw data for Short Track Speed Skating (CV):\n",
      "                           Sport  Year     Value\n",
      "1477  Short Track Speed Skating  1992  0.606885\n",
      "\n",
      "Prepared time series data for Short Track Speed Skating (CV):\n",
      " Year\n",
      "1992    0.606885\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Skeleton (CV)\n",
      "Raw data for Skeleton (CV):\n",
      "         Sport  Year     Value\n",
      "568  Skeleton  1928  0.375000\n",
      "763  Skeleton  1948  0.442989\n",
      "\n",
      "Prepared time series data for Skeleton (CV):\n",
      " Year\n",
      "1928    0.375000\n",
      "1948    0.442989\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Ski Jumping (CV)\n",
      "Raw data for Ski Jumping (CV):\n",
      "             Sport  Year     Value\n",
      "504   Ski Jumping  1924  1.022475\n",
      "569   Ski Jumping  1928  0.874315\n",
      "634   Ski Jumping  1932  0.622776\n",
      "699   Ski Jumping  1936  0.629210\n",
      "764   Ski Jumping  1948  0.873156\n",
      "829   Ski Jumping  1952  0.845015\n",
      "894   Ski Jumping  1956  0.714143\n",
      "959   Ski Jumping  1960  0.590937\n",
      "1024  Ski Jumping  1964  0.677865\n",
      "1089  Ski Jumping  1968  0.836725\n",
      "1154  Ski Jumping  1972  0.589723\n",
      "1219  Ski Jumping  1976  0.604559\n",
      "1284  Ski Jumping  1980  0.643772\n",
      "1349  Ski Jumping  1984  0.887317\n",
      "1414  Ski Jumping  1988  0.715864\n",
      "1479  Ski Jumping  1992  0.576931\n",
      "\n",
      "Prepared time series data for Ski Jumping (CV):\n",
      " Year\n",
      "1924    1.022475\n",
      "1928    0.874315\n",
      "1932    0.622776\n",
      "1936    0.629210\n",
      "1948    0.873156\n",
      "1952    0.845015\n",
      "1956    0.714143\n",
      "1960    0.590937\n",
      "1964    0.677865\n",
      "1968    0.836725\n",
      "1972    0.589723\n",
      "1976    0.604559\n",
      "1980    0.643772\n",
      "1984    0.887317\n",
      "1988    0.715864\n",
      "1992    0.576931\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Snowboarding (CV)\n",
      "Raw data for Snowboarding (CV):\n",
      " Empty DataFrame\n",
      "Columns: [Sport, Year, Value]\n",
      "Index: []\n",
      "\n",
      "Prepared time series data for Snowboarding (CV):\n",
      " Series([], Name: Value, dtype: float64)\n",
      "\n",
      "Processing sport: Softball (CV)\n",
      "Raw data for Softball (CV):\n",
      "          Sport  Year     Value\n",
      "1546  Softball  1996  1.020698\n",
      "1611  Softball  2000  0.621261\n",
      "1676  Softball  2004  0.756340\n",
      "1741  Softball  2008  0.995718\n",
      "\n",
      "Prepared time series data for Softball (CV):\n",
      " Year\n",
      "1996    1.020698\n",
      "2000    0.621261\n",
      "2004    0.756340\n",
      "2008    0.995718\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Speed Skating (CV)\n",
      "Raw data for Speed Skating (CV):\n",
      "               Sport  Year     Value\n",
      "507   Speed Skating  1924  0.878112\n",
      "572   Speed Skating  1928  0.733536\n",
      "637   Speed Skating  1932  0.894759\n",
      "702   Speed Skating  1936  0.726180\n",
      "767   Speed Skating  1948  0.741062\n",
      "832   Speed Skating  1952  0.982720\n",
      "897   Speed Skating  1956  1.057254\n",
      "962   Speed Skating  1960  0.847411\n",
      "1027  Speed Skating  1964  0.654585\n",
      "1092  Speed Skating  1968  0.737062\n",
      "1157  Speed Skating  1972  0.813980\n",
      "1222  Speed Skating  1976  0.797098\n",
      "1287  Speed Skating  1980  0.748665\n",
      "1352  Speed Skating  1984  0.846922\n",
      "1417  Speed Skating  1988  0.954371\n",
      "1482  Speed Skating  1992  0.695296\n",
      "\n",
      "Prepared time series data for Speed Skating (CV):\n",
      " Year\n",
      "1924    0.878112\n",
      "1928    0.733536\n",
      "1932    0.894759\n",
      "1936    0.726180\n",
      "1948    0.741062\n",
      "1952    0.982720\n",
      "1956    1.057254\n",
      "1960    0.847411\n",
      "1964    0.654585\n",
      "1968    0.737062\n",
      "1972    0.813980\n",
      "1976    0.797098\n",
      "1980    0.748665\n",
      "1984    0.846922\n",
      "1988    0.954371\n",
      "1992    0.695296\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Swimming (CV)\n",
      "Raw data for Swimming (CV):\n",
      "          Sport  Year     Value\n",
      "53    Swimming  1896  0.654654\n",
      "118   Swimming  1900  1.122644\n",
      "183   Swimming  1904  0.750000\n",
      "248   Swimming  1906  0.718626\n",
      "313   Swimming  1908  0.816587\n",
      "378   Swimming  1912  0.915182\n",
      "443   Swimming  1920  1.002829\n",
      "508   Swimming  1924  1.039689\n",
      "573   Swimming  1928  1.045615\n",
      "638   Swimming  1932  0.788364\n",
      "703   Swimming  1936  0.889350\n",
      "768   Swimming  1948  0.958512\n",
      "833   Swimming  1952  1.061378\n",
      "898   Swimming  1956  0.928657\n",
      "963   Swimming  1960  1.123942\n",
      "1028  Swimming  1964  0.900955\n",
      "1093  Swimming  1968  0.928242\n",
      "1158  Swimming  1972  0.923874\n",
      "1223  Swimming  1976  0.952943\n",
      "1288  Swimming  1980  0.949527\n",
      "1353  Swimming  1984  0.947173\n",
      "1418  Swimming  1988  0.911810\n",
      "1483  Swimming  1992  0.876263\n",
      "1548  Swimming  1996  0.854737\n",
      "1613  Swimming  2000  0.860861\n",
      "1678  Swimming  2004  0.898172\n",
      "1743  Swimming  2008  1.017970\n",
      "1808  Swimming  2012  1.027002\n",
      "1873  Swimming  2016  1.009730\n",
      "\n",
      "Prepared time series data for Swimming (CV):\n",
      " Year\n",
      "1896    0.654654\n",
      "1900    1.122644\n",
      "1904    0.750000\n",
      "1906    0.718626\n",
      "1908    0.816587\n",
      "1912    0.915182\n",
      "1920    1.002829\n",
      "1924    1.039689\n",
      "1928    1.045615\n",
      "1932    0.788364\n",
      "1936    0.889350\n",
      "1948    0.958512\n",
      "1952    1.061378\n",
      "1956    0.928657\n",
      "1960    1.123942\n",
      "1964    0.900955\n",
      "1968    0.928242\n",
      "1972    0.923874\n",
      "1976    0.952943\n",
      "1980    0.949527\n",
      "1984    0.947173\n",
      "1988    0.911810\n",
      "1992    0.876263\n",
      "1996    0.854737\n",
      "2000    0.860861\n",
      "2004    0.898172\n",
      "2008    1.017970\n",
      "2012    1.027002\n",
      "2016    1.009730\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Synchronized Swimming (CV)\n",
      "Raw data for Synchronized Swimming (CV):\n",
      "                       Sport  Year     Value\n",
      "1354  Synchronized Swimming  1984  0.638904\n",
      "1419  Synchronized Swimming  1988  0.548509\n",
      "1484  Synchronized Swimming  1992  0.586147\n",
      "1549  Synchronized Swimming  1996  0.714871\n",
      "1614  Synchronized Swimming  2000  0.599843\n",
      "1679  Synchronized Swimming  2004  0.697511\n",
      "1744  Synchronized Swimming  2008  0.649559\n",
      "1809  Synchronized Swimming  2012  0.764945\n",
      "1874  Synchronized Swimming  2016  0.706650\n",
      "\n",
      "Prepared time series data for Synchronized Swimming (CV):\n",
      " Year\n",
      "1984    0.638904\n",
      "1988    0.548509\n",
      "1992    0.586147\n",
      "1996    0.714871\n",
      "2000    0.599843\n",
      "2004    0.697511\n",
      "2008    0.649559\n",
      "2012    0.764945\n",
      "2016    0.706650\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Table Tennis (CV)\n",
      "Raw data for Table Tennis (CV):\n",
      "              Sport  Year     Value\n",
      "1420  Table Tennis  1988  0.763424\n",
      "1485  Table Tennis  1992  0.902211\n",
      "1550  Table Tennis  1996  0.811329\n",
      "1615  Table Tennis  2000  0.619952\n",
      "1680  Table Tennis  2004  0.626099\n",
      "1745  Table Tennis  2008  0.777902\n",
      "1810  Table Tennis  2012  0.698930\n",
      "1875  Table Tennis  2016  0.707772\n",
      "\n",
      "Prepared time series data for Table Tennis (CV):\n",
      " Year\n",
      "1988    0.763424\n",
      "1992    0.902211\n",
      "1996    0.811329\n",
      "2000    0.619952\n",
      "2004    0.626099\n",
      "2008    0.777902\n",
      "2012    0.698930\n",
      "2016    0.707772\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Taekwondo (CV)\n",
      "Raw data for Taekwondo (CV):\n",
      "           Sport  Year     Value\n",
      "1616  Taekwondo  2000  0.484231\n",
      "1681  Taekwondo  2004  0.633405\n",
      "1746  Taekwondo  2008  0.642149\n",
      "1811  Taekwondo  2012  0.628689\n",
      "1876  Taekwondo  2016  0.633214\n",
      "\n",
      "Prepared time series data for Taekwondo (CV):\n",
      " Year\n",
      "2000    0.484231\n",
      "2004    0.633405\n",
      "2008    0.642149\n",
      "2012    0.628689\n",
      "2016    0.633214\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Tennis (CV)\n",
      "Raw data for Tennis (CV):\n",
      "        Sport  Year     Value\n",
      "57    Tennis  1896  0.471405\n",
      "122   Tennis  1900  0.588760\n",
      "187   Tennis  1904  0.590014\n",
      "252   Tennis  1906  0.706444\n",
      "317   Tennis  1908  0.573836\n",
      "382   Tennis  1912  0.748364\n",
      "447   Tennis  1920  0.688844\n",
      "512   Tennis  1924  0.856530\n",
      "1422  Tennis  1988  0.837317\n",
      "1487  Tennis  1992  0.712716\n",
      "1552  Tennis  1996  0.809754\n",
      "1617  Tennis  2000  0.734108\n",
      "1682  Tennis  2004  0.662216\n",
      "1747  Tennis  2008  0.682227\n",
      "1812  Tennis  2012  0.751818\n",
      "1877  Tennis  2016  0.784143\n",
      "\n",
      "Prepared time series data for Tennis (CV):\n",
      " Year\n",
      "1896    0.471405\n",
      "1900    0.588760\n",
      "1904    0.590014\n",
      "1906    0.706444\n",
      "1908    0.573836\n",
      "1912    0.748364\n",
      "1920    0.688844\n",
      "1924    0.856530\n",
      "1988    0.837317\n",
      "1992    0.712716\n",
      "1996    0.809754\n",
      "2000    0.734108\n",
      "2004    0.662216\n",
      "2008    0.682227\n",
      "2012    0.751818\n",
      "2016    0.784143\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Trampolining (CV)\n",
      "Raw data for Trampolining (CV):\n",
      "              Sport  Year     Value\n",
      "1618  Trampolining  2000  0.564076\n",
      "1683  Trampolining  2004  0.748883\n",
      "1748  Trampolining  2008  0.619606\n",
      "1813  Trampolining  2012  0.604967\n",
      "1878  Trampolining  2016  0.604967\n",
      "\n",
      "Prepared time series data for Trampolining (CV):\n",
      " Year\n",
      "2000    0.564076\n",
      "2004    0.748883\n",
      "2008    0.619606\n",
      "2012    0.604967\n",
      "2016    0.604967\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Triathlon (CV)\n",
      "Raw data for Triathlon (CV):\n",
      "           Sport  Year     Value\n",
      "1619  Triathlon  2000  0.663551\n",
      "1684  Triathlon  2004  0.673144\n",
      "1749  Triathlon  2008  0.638632\n",
      "1814  Triathlon  2012  0.632240\n",
      "1879  Triathlon  2016  0.743104\n",
      "\n",
      "Prepared time series data for Triathlon (CV):\n",
      " Year\n",
      "2000    0.663551\n",
      "2004    0.673144\n",
      "2008    0.638632\n",
      "2012    0.632240\n",
      "2016    0.743104\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Tug-Of-War (CV)\n",
      "Raw data for Tug-Of-War (CV):\n",
      "           Sport  Year     Value\n",
      "125  Tug-Of-War  1900  0.447214\n",
      "190  Tug-Of-War  1904  0.701857\n",
      "255  Tug-Of-War  1906  0.577350\n",
      "320  Tug-Of-War  1908  0.728913\n",
      "385  Tug-Of-War  1912  0.665719\n",
      "450  Tug-Of-War  1920  0.546211\n",
      "\n",
      "Prepared time series data for Tug-Of-War (CV):\n",
      " Year\n",
      "1900    0.447214\n",
      "1904    0.701857\n",
      "1906    0.577350\n",
      "1908    0.728913\n",
      "1912    0.665719\n",
      "1920    0.546211\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Volleyball (CV)\n",
      "Raw data for Volleyball (CV):\n",
      "            Sport  Year     Value\n",
      "1036  Volleyball  1964  0.750855\n",
      "1101  Volleyball  1968  0.823535\n",
      "1166  Volleyball  1972  0.806482\n",
      "1231  Volleyball  1976  0.749115\n",
      "1296  Volleyball  1980  0.622247\n",
      "1361  Volleyball  1984  0.695435\n",
      "1426  Volleyball  1988  0.807777\n",
      "1491  Volleyball  1992  0.745100\n",
      "1556  Volleyball  1996  0.762567\n",
      "1621  Volleyball  2000  0.851845\n",
      "1686  Volleyball  2004  0.699898\n",
      "1751  Volleyball  2008  0.749466\n",
      "1816  Volleyball  2012  0.819519\n",
      "1881  Volleyball  2016  0.833920\n",
      "\n",
      "Prepared time series data for Volleyball (CV):\n",
      " Year\n",
      "1964    0.750855\n",
      "1968    0.823535\n",
      "1972    0.806482\n",
      "1976    0.749115\n",
      "1980    0.622247\n",
      "1984    0.695435\n",
      "1988    0.807777\n",
      "1992    0.745100\n",
      "1996    0.762567\n",
      "2000    0.851845\n",
      "2004    0.699898\n",
      "2008    0.749466\n",
      "2012    0.819519\n",
      "2016    0.833920\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Water Polo (CV)\n",
      "Raw data for Water Polo (CV):\n",
      "            Sport  Year     Value\n",
      "127   Water Polo  1900  0.829379\n",
      "192   Water Polo  1904  0.684484\n",
      "322   Water Polo  1908  0.841625\n",
      "387   Water Polo  1912  0.642416\n",
      "452   Water Polo  1920  0.612018\n",
      "517   Water Polo  1924  0.721301\n",
      "582   Water Polo  1928  0.625032\n",
      "647   Water Polo  1932  0.727624\n",
      "712   Water Polo  1936  0.900037\n",
      "777   Water Polo  1948  0.727649\n",
      "842   Water Polo  1952  0.738761\n",
      "907   Water Polo  1956  0.820718\n",
      "972   Water Polo  1960  0.726036\n",
      "1037  Water Polo  1964  0.876662\n",
      "1102  Water Polo  1968  0.641416\n",
      "1167  Water Polo  1972  0.757972\n",
      "1232  Water Polo  1976  0.601312\n",
      "1297  Water Polo  1980  0.668043\n",
      "1362  Water Polo  1984  0.729981\n",
      "1427  Water Polo  1988  0.656304\n",
      "1492  Water Polo  1992  0.653906\n",
      "1557  Water Polo  1996  0.700382\n",
      "1622  Water Polo  2000  0.857286\n",
      "1687  Water Polo  2004  0.634060\n",
      "1752  Water Polo  2008  0.591568\n",
      "1817  Water Polo  2012  0.691985\n",
      "1882  Water Polo  2016  0.776958\n",
      "\n",
      "Prepared time series data for Water Polo (CV):\n",
      " Year\n",
      "1900    0.829379\n",
      "1904    0.684484\n",
      "1908    0.841625\n",
      "1912    0.642416\n",
      "1920    0.612018\n",
      "1924    0.721301\n",
      "1928    0.625032\n",
      "1932    0.727624\n",
      "1936    0.900037\n",
      "1948    0.727649\n",
      "1952    0.738761\n",
      "1956    0.820718\n",
      "1960    0.726036\n",
      "1964    0.876662\n",
      "1968    0.641416\n",
      "1972    0.757972\n",
      "1976    0.601312\n",
      "1980    0.668043\n",
      "1984    0.729981\n",
      "1988    0.656304\n",
      "1992    0.653906\n",
      "1996    0.700382\n",
      "2000    0.857286\n",
      "2004    0.634060\n",
      "2008    0.591568\n",
      "2012    0.691985\n",
      "2016    0.776958\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Weightlifting (CV)\n",
      "Raw data for Weightlifting (CV):\n",
      "               Sport  Year     Value\n",
      "63    Weightlifting  1896  0.866025\n",
      "193   Weightlifting  1904  0.866025\n",
      "258   Weightlifting  1906  0.176383\n",
      "453   Weightlifting  1920  0.625154\n",
      "518   Weightlifting  1924  0.728620\n",
      "583   Weightlifting  1928  0.666901\n",
      "648   Weightlifting  1932  0.702728\n",
      "713   Weightlifting  1936  0.757600\n",
      "778   Weightlifting  1948  0.622452\n",
      "843   Weightlifting  1952  0.734931\n",
      "908   Weightlifting  1956  0.836690\n",
      "973   Weightlifting  1960  0.773385\n",
      "1038  Weightlifting  1964  0.896006\n",
      "1103  Weightlifting  1968  0.751872\n",
      "1168  Weightlifting  1972  0.668417\n",
      "1233  Weightlifting  1976  0.779279\n",
      "1298  Weightlifting  1980  0.868112\n",
      "1363  Weightlifting  1984  0.705156\n",
      "1428  Weightlifting  1988  0.864418\n",
      "1493  Weightlifting  1992  0.863619\n",
      "1558  Weightlifting  1996  0.750228\n",
      "1623  Weightlifting  2000  0.828824\n",
      "1688  Weightlifting  2004  0.722117\n",
      "1753  Weightlifting  2008  0.810926\n",
      "1818  Weightlifting  2012  0.701123\n",
      "1883  Weightlifting  2016  0.802138\n",
      "\n",
      "Prepared time series data for Weightlifting (CV):\n",
      " Year\n",
      "1896    0.866025\n",
      "1904    0.866025\n",
      "1906    0.176383\n",
      "1920    0.625154\n",
      "1924    0.728620\n",
      "1928    0.666901\n",
      "1932    0.702728\n",
      "1936    0.757600\n",
      "1948    0.622452\n",
      "1952    0.734931\n",
      "1956    0.836690\n",
      "1960    0.773385\n",
      "1964    0.896006\n",
      "1968    0.751872\n",
      "1972    0.668417\n",
      "1976    0.779279\n",
      "1980    0.868112\n",
      "1984    0.705156\n",
      "1988    0.864418\n",
      "1992    0.863619\n",
      "1996    0.750228\n",
      "2000    0.828824\n",
      "2004    0.722117\n",
      "2008    0.810926\n",
      "2012    0.701123\n",
      "2016    0.802138\n",
      "Name: Value, dtype: float64\n",
      "\n",
      "Processing sport: Wrestling (CV)\n",
      "Raw data for Wrestling (CV):\n",
      "           Sport  Year     Value\n",
      "64    Wrestling  1896  2.442317\n",
      "194   Wrestling  1904  0.760136\n",
      "259   Wrestling  1906  0.736466\n",
      "324   Wrestling  1908  0.725721\n",
      "389   Wrestling  1912  0.879255\n",
      "454   Wrestling  1920  0.778276\n",
      "519   Wrestling  1924  0.737599\n",
      "584   Wrestling  1928  0.988212\n",
      "649   Wrestling  1932  0.885647\n",
      "714   Wrestling  1936  0.691623\n",
      "779   Wrestling  1948  0.672422\n",
      "844   Wrestling  1952  0.716118\n",
      "909   Wrestling  1956  0.890871\n",
      "974   Wrestling  1960  0.870245\n",
      "1039  Wrestling  1964  0.742989\n",
      "1104  Wrestling  1968  0.706155\n",
      "1169  Wrestling  1972  0.894440\n",
      "1234  Wrestling  1976  0.778619\n",
      "1299  Wrestling  1980  0.842081\n",
      "1364  Wrestling  1984  0.751240\n",
      "1429  Wrestling  1988  0.835817\n",
      "1494  Wrestling  1992  0.892269\n",
      "1559  Wrestling  1996  0.899076\n",
      "1624  Wrestling  2000  0.764692\n",
      "1689  Wrestling  2004  0.645342\n",
      "1754  Wrestling  2008  0.722179\n",
      "1819  Wrestling  2012  0.767672\n",
      "1884  Wrestling  2016  0.709537\n",
      "\n",
      "Prepared time series data for Wrestling (CV):\n",
      " Year\n",
      "1896    2.442317\n",
      "1904    0.760136\n",
      "1906    0.736466\n",
      "1908    0.725721\n",
      "1912    0.879255\n",
      "1920    0.778276\n",
      "1924    0.737599\n",
      "1928    0.988212\n",
      "1932    0.885647\n",
      "1936    0.691623\n",
      "1948    0.672422\n",
      "1952    0.716118\n",
      "1956    0.890871\n",
      "1960    0.870245\n",
      "1964    0.742989\n",
      "1968    0.706155\n",
      "1972    0.894440\n",
      "1976    0.778619\n",
      "1980    0.842081\n",
      "1984    0.751240\n",
      "1988    0.835817\n",
      "1992    0.892269\n",
      "1996    0.899076\n",
      "2000    0.764692\n",
      "2004    0.645342\n",
      "2008    0.722179\n",
      "2012    0.767672\n",
      "2016    0.709537\n",
      "Name: Value, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Reload the dataset\n",
    "df = pd.read_csv(\"not_final3.csv\")\n",
    "df = df.rename(columns={'Sport_-1': 'Sport'})\n",
    "\n",
    "# List of sports to exclude\n",
    "excluded_sports = ['climbing', 'Fitness', 'Headis']\n",
    "\n",
    "# Filter out excluded sports\n",
    "df = df[~df['Sport'].isin(excluded_sports)]\n",
    "\n",
    "parameters = ['drug', 'equity', 'popularity', 'normalizedcountry', 'CV']\n",
    "\n",
    "for parameter in parameters:\n",
    "    print(f\"\\nProcessing parameter: {parameter}\")\n",
    "    \n",
    "    # Melt the data for this parameter\n",
    "    param_columns = [col for col in df.columns if col.startswith(f\"{parameter}_\")]\n",
    "    melted_data = df[['Sport'] + param_columns].melt(id_vars='Sport', var_name='Year', value_name='Value')\n",
    "    melted_data['Year'] = melted_data['Year'].str.extract(r'(\\d+)').astype(int)  # Use raw string\n",
    "\n",
    "    for sport_name in melted_data['Sport'].unique():\n",
    "        print(f\"\\nProcessing sport: {sport_name} ({parameter})\")\n",
    "\n",
    "        # Filter and sort the data for the specific sport and parameter\n",
    "        sport_data = melted_data[melted_data['Sport'] == sport_name].sort_values('Year')\n",
    "        \n",
    "        if parameter == 'drug':\n",
    "            # For 'drug', replace missing values with 0\n",
    "            sport_data['Value'] = sport_data['Value'].fillna(0)\n",
    "        elif parameter in ['CV', 'popularity']:\n",
    "            # For 'CV' and 'popularity', treat 0 as missing and drop\n",
    "            sport_data = sport_data[sport_data['Value'] != 0].dropna(subset=['Value'])\n",
    "        else:\n",
    "            # For other parameters, drop missing values\n",
    "            sport_data = sport_data.dropna(subset=['Value'])\n",
    "\n",
    "        # Set Year as index and ensure continuity\n",
    "        ts_data = sport_data.set_index('Year')['Value']\n",
    "        \n",
    "        print(f\"Raw data for {sport_name} ({parameter}):\\n\", sport_data)\n",
    "        print(f\"\\nPrepared time series data for {sport_name} ({parameter}):\\n\", ts_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sport</th>\n",
       "      <th>Year</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alpine Skiing</td>\n",
       "      <td>1896</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alpinism</td>\n",
       "      <td>1896</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Archery</td>\n",
       "      <td>1896</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Art Competitions</td>\n",
       "      <td>1896</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Athletics</td>\n",
       "      <td>1896</td>\n",
       "      <td>1.001050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1880</th>\n",
       "      <td>Tug-Of-War</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1881</th>\n",
       "      <td>Volleyball</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.833920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1882</th>\n",
       "      <td>Water Polo</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.776958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1883</th>\n",
       "      <td>Weightlifting</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.802138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1884</th>\n",
       "      <td>Wrestling</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.709537</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1885 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Sport  Year     Value\n",
       "0        Alpine Skiing  1896  0.000000\n",
       "1             Alpinism  1896  0.000000\n",
       "2              Archery  1896  0.000000\n",
       "3     Art Competitions  1896  0.000000\n",
       "4            Athletics  1896  1.001050\n",
       "...                ...   ...       ...\n",
       "1880        Tug-Of-War  2016  0.000000\n",
       "1881        Volleyball  2016  0.833920\n",
       "1882        Water Polo  2016  0.776958\n",
       "1883     Weightlifting  2016  0.802138\n",
       "1884         Wrestling  2016  0.709537\n",
       "\n",
       "[1885 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "melted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from pmdarima.arima import auto_arima\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def incremental_backtest(ts_data, model_func, order, seasonal_order=None, sport_name=\"\", parameter=\"\"):\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "    indices = []\n",
    "\n",
    "    for t in range(len(ts_data) - 1):\n",
    "        train = ts_data.iloc[: t + 1]\n",
    "\n",
    "        if len(train) <= max(order):\n",
    "            continue\n",
    "\n",
    "        if model_func == ARIMA:\n",
    "            model = model_func(train, order=order)\n",
    "        elif model_func == SARIMAX:\n",
    "            model = model_func(train, order=order, seasonal_order=seasonal_order)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported model function\")\n",
    "\n",
    "        try:\n",
    "            model_fit = model.fit()\n",
    "            forecast = model_fit.forecast(steps=1)\n",
    "            forecast_value = forecast.iloc[0] if isinstance(forecast, pd.Series) else forecast[0]\n",
    "        except ValueError as e:\n",
    "            print(f\"Error for {sport_name} ({parameter}): {e}\")\n",
    "            continue\n",
    "\n",
    "        predictions.append(forecast_value)\n",
    "        actuals.append(ts_data.iloc[t + 1])\n",
    "        indices.append(ts_data.index[t + 1])\n",
    "\n",
    "    mse = mean_squared_error(actuals, predictions)\n",
    "    print(f\"\\nMSE for {sport_name} ({parameter}): {mse:.4f}\")\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(indices, actuals, label=\"Actual\", marker=\"o\")\n",
    "    plt.plot(indices, predictions, label=f\"{model_func.__name__} Predicted\", linestyle=\"--\", marker=\"x\")\n",
    "    plt.title(f\"{model_func.__name__} Predictions for {sport_name} ({parameter})\")\n",
    "    plt.xlabel(\"Year\")\n",
    "    plt.ylabel(f\"{parameter} Values\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    return mse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from statsmodels.tsa.arima.model import ARIMA\n",
    "# from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "# from sklearn.metrics import mean_squared_error, r2_score  # Added r2_score import\n",
    "# from pmdarima.arima import auto_arima\n",
    "# import warnings\n",
    "# import os\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "# # Ensure output directory for plots\n",
    "# output_dir = \"model_plots\"\n",
    "# os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# MIN_DATA_POINTS = 5  # Minimum data points to fit the model\n",
    "\n",
    "# # Data tracking\n",
    "# metrics = []\n",
    "\n",
    "# def incremental_backtest(ts_data, model_func, order, seasonal_order=None, sport_name=\"\", parameter=\"\"):\n",
    "#     predictions, actuals, indices = [], [], []\n",
    "\n",
    "#     for t in range(len(ts_data) - 1):\n",
    "#         train = ts_data.iloc[:t + 1]\n",
    "\n",
    "#         if len(train) <= max(order):\n",
    "#             continue\n",
    "\n",
    "#         if model_func == ARIMA:\n",
    "#             model = model_func(train, order=order)\n",
    "#         elif model_func == SARIMAX:\n",
    "#             model = model_func(train, order=order, seasonal_order=seasonal_order)\n",
    "#         else:\n",
    "#             raise ValueError(\"Unsupported model function\")\n",
    "\n",
    "#         try:\n",
    "#             model_fit = model.fit(disp=False)\n",
    "#             forecast = model_fit.forecast(steps=1)\n",
    "#             forecast_value = forecast.iloc[0] if isinstance(forecast, pd.Series) else forecast[0]\n",
    "#         except Exception as e:\n",
    "#             print(f\"Fitting error for {sport_name} ({parameter}): {e}\")\n",
    "#             break\n",
    "\n",
    "#         predictions.append(forecast_value)\n",
    "#         actuals.append(ts_data.iloc[t + 1])\n",
    "#         indices.append(ts_data.index[t + 1])\n",
    "\n",
    "#     if predictions:\n",
    "#         # Check for all-zero predictions\n",
    "#         if np.all(np.array(predictions) == 0):\n",
    "#             print(f\"Model predicted all zeros for {sport_name} ({parameter}). Investigate model or data.\")\n",
    "#             return\n",
    "\n",
    "#         # Calculate metrics\n",
    "#         mse = mean_squared_error(actuals, predictions)\n",
    "#         r2 = r2_score(actuals, predictions)\n",
    "#         metrics.append({\n",
    "#             'Sport': sport_name,\n",
    "#             'Parameter': parameter,\n",
    "#             'Model': model_func.__name__,\n",
    "#             'MSE': mse,\n",
    "#             'R2': r2\n",
    "#         })\n",
    "\n",
    "#         # Save plot\n",
    "#         plt.figure(figsize=(10, 6))\n",
    "#         plt.plot(indices, actuals, label='Actual', marker='o', linestyle='-')\n",
    "#         plt.plot(indices, predictions, label=f'{model_func.__name__} Predicted', marker='x', linestyle='--')\n",
    "#         plt.title(f'Actual vs Predicted for {sport_name} ({parameter})')\n",
    "#         plt.xlabel('Year')\n",
    "#         plt.ylabel('Value')\n",
    "#         plt.legend()\n",
    "#         plt.grid(True)\n",
    "#         plt.tight_layout()\n",
    "#         plt.savefig(f\"{output_dir}/{sport_name}_{parameter}_{model_func.__name__}.png\")\n",
    "#         plt.close()\n",
    "#     else:\n",
    "#         print(f\"No predictions made for {sport_name} ({parameter}).\")\n",
    "\n",
    "\n",
    "# # Load dataset\n",
    "# df = pd.read_csv(\"not_final3.csv\")\n",
    "# df = df.rename(columns={'Sport_-1': 'Sport'})\n",
    "\n",
    "# parameters = ['drug', 'equity', 'popularity', 'normalizedcountry', 'CV']\n",
    "\n",
    "# for parameter in parameters:\n",
    "#     print(f\"\\nProcessing parameter: {parameter}\")\n",
    "\n",
    "#     param_columns = [col for col in df.columns if col.startswith(f\"{parameter}_\")]\n",
    "#     melted_data = df[['Sport'] + param_columns].melt(id_vars='Sport', var_name='Year', value_name='Value')\n",
    "#     melted_data['Year'] = melted_data['Year'].str.extract(r'(\\d+)').astype(int)\n",
    "\n",
    "#     for sport_name in melted_data['Sport'].unique():\n",
    "#         sport_data = melted_data[melted_data['Sport'] == sport_name].sort_values('Year')\n",
    "\n",
    "#         if parameter == 'drug':\n",
    "#             sport_data['Value'] = sport_data['Value'].fillna(0)\n",
    "#         elif parameter in ['CV', 'popularity']:\n",
    "#             sport_data = sport_data[sport_data['Value'] != 0].dropna(subset=['Value'])\n",
    "#         else:\n",
    "#             sport_data = sport_data.dropna(subset=['Value'])\n",
    "\n",
    "#         if sport_data['Value'].sum() == 0:\n",
    "#             print(f\"All zero values for {sport_name} ({parameter}), skipping.\")\n",
    "#             continue\n",
    "\n",
    "#         ts_data = sport_data.set_index('Year')['Value']\n",
    "\n",
    "#         if len(ts_data) < MIN_DATA_POINTS:\n",
    "#             print(f\"Insufficient data for {sport_name} ({parameter})\")\n",
    "#             continue\n",
    "\n",
    "#         auto_arima_model = auto_arima(ts_data, seasonal=False, trace=False)\n",
    "#         arima_order = auto_arima_model.order\n",
    "\n",
    "#         auto_sarima_model = auto_arima(ts_data, seasonal=True, m=1, trace=False)\n",
    "#         sarima_order = auto_sarima_model.order\n",
    "#         sarima_seasonal_order = auto_sarima_model.seasonal_order\n",
    "\n",
    "#         print(f\"Optimal ARIMA order: {arima_order}\")\n",
    "#         print(f\"Optimal SARIMA order: {sarima_order}, Seasonal: {sarima_seasonal_order}\")\n",
    "\n",
    "#         incremental_backtest(ts_data, ARIMA, arima_order, sport_name=sport_name, parameter=parameter)\n",
    "#         incremental_backtest(ts_data, SARIMAX, sarima_order, seasonal_order=sarima_seasonal_order, sport_name=sport_name, parameter=parameter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing parameter: drug\n",
      "All zero values for Alpine Skiing (drug), skipping.\n",
      "All zero values for Alpinism (drug), skipping.\n",
      "All zero values for Archery (drug), skipping.\n",
      "All zero values for Art Competitions (drug), skipping.\n",
      "Checking stationarity for Athletics (drug):\n",
      "ADF Statistic: -4.192742011211175, p-value: 0.0006777900599018148\n",
      "Optimal ARIMA order: (1, 0, 0)\n",
      "Optimal SARIMA order: (1, 0, 0), Seasonal: (0, 0, 0, 0)\n",
      "Constant series detected for Athletics (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Athletics (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Athletics (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Athletics (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Athletics (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Athletics (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Athletics (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Athletics (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Athletics (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Athletics (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Athletics (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Athletics (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Athletics (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Athletics (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Athletics (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Athletics (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Athletics (drug). Predicting constant value: 0.0\n",
      "Metrics for Athletics (drug) - MSE: 336.70620255527194, R2: -0.1066079813552061\n",
      "Constant series detected for Athletics (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Athletics (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Athletics (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Athletics (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Athletics (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Athletics (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Athletics (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Athletics (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Athletics (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Athletics (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Athletics (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Athletics (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Athletics (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Athletics (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Athletics (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Athletics (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Athletics (drug). Predicting constant value: 0.0\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -5.25631D-02    |proj g|=  2.23463D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      4     14      1     0     0   1.115D-05  -5.328D-02\n",
      "  F =  -5.3280955957645343E-002\n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -7.82810D-02    |proj g|=  2.18121D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      3      6      1     0     0   4.846D-06  -7.893D-02\n",
      "  F =  -7.8927603084256281E-002\n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.31387D+00    |proj g|=  5.16610D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      3      6      1     0     0   8.685D-07   1.313D+00\n",
      "  F =   1.3132839863977825     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.29358D+00    |proj g|=  5.04442D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      4      7      1     0     0   7.072D-06   1.293D+00\n",
      "  F =   1.2929844823238659     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.68326D+00    |proj g|=  3.28718D-02\n",
      "\n",
      "At iterate    5    f=  1.68202D+00    |proj g|=  2.45481D-06\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      5      8      1     0     0   2.455D-06   1.682D+00\n",
      "  F =   1.6820223291082419     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.21443D+00    |proj g|=  8.97612D-01\n",
      "\n",
      "At iterate    5    f=  1.80072D+00    |proj g|=  3.21825D-02\n",
      "\n",
      "At iterate   10    f=  1.79480D+00    |proj g|=  1.16867D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     12     14      1     0     0   2.041D-06   1.795D+00\n",
      "  F =   1.7948040727853869     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.80114D+00    |proj g|=  2.72704D-02\n",
      "\n",
      "At iterate    5    f=  1.79922D+00    |proj g|=  3.39217D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      6      9      1     0     0   3.311D-07   1.799D+00\n",
      "  F =   1.7992195548230461     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.88163D+00    |proj g|=  6.24614D-01\n",
      "\n",
      "At iterate    5    f=  2.54665D+00    |proj g|=  4.16727D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      9     10      1     0     0   1.447D-06   2.546D+00\n",
      "  F =   2.5462287172262070     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  5.50392D+00    |proj g|=  2.38843D+00\n",
      "\n",
      "At iterate    5    f=  3.34496D+00    |proj g|=  3.49838D-02\n",
      "\n",
      "At iterate   10    f=  3.32359D+00    |proj g|=  5.95989D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     13     14      1     0     0   6.464D-06   3.324D+00\n",
      "  F =   3.3235604127238729     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.31658D+01    |proj g|=  1.06836D+01\n",
      "\n",
      "At iterate    5    f=  4.07636D+00    |proj g|=  2.10328D-01\n",
      "\n",
      "At iterate   10    f=  3.77539D+00    |proj g|=  6.21129D-03\n",
      "\n",
      "At iterate   15    f=  3.77228D+00    |proj g|=  4.73217D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     16     17      1     0     0   5.979D-07   3.772D+00\n",
      "  F =   3.7722783865536411     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  4.19128D+00    |proj g|=  1.51175D-02\n",
      "\n",
      "At iterate    5    f=  4.19078D+00    |proj g|=  2.85558D-06\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      5      9      1     0     0   2.856D-06   4.191D+00\n",
      "  F =   4.1907798191551118     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  4.17660D+00    |proj g|=  1.46360D-02\n",
      "\n",
      "At iterate    5    f=  4.17612D+00    |proj g|=  1.75806D-06\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      5      9      1     0     0   1.758D-06   4.176D+00\n",
      "  F =   4.1761242293101546     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "Metrics for Athletics (drug) - MSE: 336.242130373824, R2: -0.10508277636635266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All zero values for Badminton (drug), skipping.\n",
      "Checking stationarity for Baseball (drug):\n",
      "ADF Statistic: -5.47722557505166, p-value: 2.3270204083626223e-06\n",
      "Optimal ARIMA order: (0, 0, 0)\n",
      "Optimal SARIMA order: (0, 0, 0), Seasonal: (0, 0, 0, 0)\n",
      "Constant series detected for Baseball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Baseball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Baseball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Baseball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Baseball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Baseball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Baseball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Baseball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Baseball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Baseball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Baseball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Baseball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Baseball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Baseball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Baseball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Baseball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Baseball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Baseball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Baseball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Baseball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Baseball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Baseball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Baseball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Baseball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Baseball (drug). Predicting constant value: 0.0\n",
      "Metrics for Baseball (drug) - MSE: 0.13419011100727646, R2: -0.04113017160817978\n",
      "Constant series detected for Baseball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Baseball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Baseball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Baseball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Baseball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Baseball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Baseball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Baseball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Baseball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Baseball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Baseball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Baseball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Baseball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Baseball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Baseball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Baseball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Baseball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Baseball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Baseball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Baseball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Baseball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Baseball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Baseball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Baseball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Baseball (drug). Predicting constant value: 0.0\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  4.83037D-01    |proj g|=  6.49972D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     14      1     0     0   6.498D-05   4.830D-01\n",
      "  F =  0.48303744475387689     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  4.64167D-01    |proj g|=  6.74971D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     18      1     0     0   6.750D-05   4.642D-01\n",
      "  F =  0.46416728076245339     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  4.45983D-01    |proj g|=  6.99969D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     14      1     0     0   6.998D-05   4.460D-01\n",
      "  F =  0.44598345867701594     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  4.28438D-01    |proj g|=  7.24967D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     15      1     0     0   7.249D-05   4.284D-01\n",
      "  F =  0.42843779877138088     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  4.11487D-01    |proj g|=  7.49966D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     14      1     0     0   7.497D-05   4.115D-01\n",
      "  F =  0.41148702293354006     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "Metrics for Baseball (drug) - MSE: 0.13333333333333333, R2: -0.034482758620689946\n",
      "Checking stationarity for Basketball (drug):\n",
      "ADF Statistic: -5.4772255750516585, p-value: 2.3270204083626345e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal ARIMA order: (0, 0, 0)\n",
      "Optimal SARIMA order: (0, 0, 0), Seasonal: (0, 0, 0, 0)\n",
      "Constant series detected for Basketball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Basketball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Basketball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Basketball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Basketball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Basketball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Basketball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Basketball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Basketball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Basketball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Basketball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Basketball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Basketball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Basketball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Basketball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Basketball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Basketball (drug). Predicting constant value: 0.0\n",
      "Metrics for Basketball (drug) - MSE: 0.03414459614485816, R2: -0.05965988035766734\n",
      "Constant series detected for Basketball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Basketball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Basketball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Basketball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Basketball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Basketball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Basketball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Basketball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Basketball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Basketball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Basketball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Basketball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Basketball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Basketball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Basketball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Basketball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Basketball (drug). Predicting constant value: 0.0\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.62473D-02    |proj g|=  1.79987D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     21      1     0     0   1.800D-04  -2.625D-02\n",
      "  F =  -2.6247345743409884E-002\n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -5.32810D-02    |proj g|=  1.89986D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     15      1     0     0   1.900D-04  -5.328D-02\n",
      "  F =  -5.3280956378547732E-002\n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -7.89276D-02    |proj g|=  1.99985D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     21      1     0     0   2.000D-04  -7.893D-02\n",
      "  F =  -7.8927603572322980E-002\n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.03323D-01    |proj g|=  2.09984D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     15      1     0     0   2.100D-04  -1.033D-01\n",
      "  F = -0.10332268565703899     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.26583D-01    |proj g|=  2.19983D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     14      1     0     0   2.200D-04  -1.266D-01\n",
      "  F = -0.12658269347448534     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.48809D-01    |proj g|=  2.29982D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     21      1     0     0   2.300D-04  -1.488D-01\n",
      "  F = -0.14880857475990228     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.70088D-01    |proj g|=  2.39980D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     17      1     0     0   2.400D-04  -1.701D-01\n",
      "  F = -0.17008838196930021     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.90499D-01    |proj g|=  2.49979D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     16      1     0     0   2.500D-04  -1.905D-01\n",
      "  F = -0.19049937922942786     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.10110D-01    |proj g|=  2.59978D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     14      1     0     0   2.600D-04  -2.101D-01\n",
      "  F = -0.21010973580606848     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.28980D-01    |proj g|=  2.69977D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     21      1     0     0   2.700D-04  -2.290D-01\n",
      "  F = -0.22897989979749200     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.47164D-01    |proj g|=  2.79975D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     18      1     0     0   2.800D-04  -2.472D-01\n",
      "  F = -0.24716372188292940     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.64709D-01    |proj g|=  2.89974D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     20      1     0     0   2.900D-04  -2.647D-01\n",
      "  F = -0.26470938178856440     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.81660D-01    |proj g|=  2.99973D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     17      1     0     0   2.999D-04  -2.817D-01\n",
      "  F = -0.28166015762640506     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "Metrics for Basketball (drug) - MSE: 0.03333333333333333, R2: -0.034482758620689946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All zero values for Basque Pelota (drug), skipping.\n",
      "All zero values for Beach Volleyball (drug), skipping.\n",
      "All zero values for Biathlon (drug), skipping.\n",
      "All zero values for Bobsleigh (drug), skipping.\n",
      "Checking stationarity for Boxing (drug):\n",
      "ADF Statistic: 3.982272035664781, p-value: 1.0\n",
      "Skipping ARIMA fitting for non-stationary series: Boxing (drug)\n",
      "Checking stationarity for Canoeing (drug):\n",
      "ADF Statistic: -0.28284271247461873, p-value: 0.9278994117565711\n",
      "Skipping ARIMA fitting for non-stationary series: Canoeing (drug)\n",
      "All zero values for Cricket (drug), skipping.\n",
      "All zero values for Croquet (drug), skipping.\n",
      "All zero values for Cross Country Skiing (drug), skipping.\n",
      "All zero values for Curling (drug), skipping.\n",
      "Checking stationarity for Cycling (drug):\n",
      "ADF Statistic: 2.906819354215189, p-value: 1.0\n",
      "Skipping ARIMA fitting for non-stationary series: Cycling (drug)\n",
      "All zero values for Diving (drug), skipping.\n",
      "Checking stationarity for Equestrianism (drug):\n",
      "ADF Statistic: 12.510381522532892, p-value: 1.0\n",
      "Skipping ARIMA fitting for non-stationary series: Equestrianism (drug)\n",
      "All zero values for Fencing (drug), skipping.\n",
      "All zero values for Figure Skating (drug), skipping.\n",
      "All zero values for Football (drug), skipping.\n",
      "All zero values for Freestyle Skiing (drug), skipping.\n",
      "All zero values for Golf (drug), skipping.\n",
      "Checking stationarity for Gymnastics (drug):\n",
      "ADF Statistic: -5.884502222199201, p-value: 3.02381454975808e-07\n",
      "Optimal ARIMA order: (1, 0, 0)\n",
      "Optimal SARIMA order: (1, 0, 0), Seasonal: (0, 0, 0, 0)\n",
      "Constant series detected for Gymnastics (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Gymnastics (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Gymnastics (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Gymnastics (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Gymnastics (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Gymnastics (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Gymnastics (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Gymnastics (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Gymnastics (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Gymnastics (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Gymnastics (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Gymnastics (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Gymnastics (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Gymnastics (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Gymnastics (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Gymnastics (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Gymnastics (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Gymnastics (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Gymnastics (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Gymnastics (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Gymnastics (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Gymnastics (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Gymnastics (drug). Predicting constant value: 0.0\n",
      "Metrics for Gymnastics (drug) - MSE: 0.1088078247536141, R2: -0.17317154638191634\n",
      "Constant series detected for Gymnastics (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Gymnastics (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Gymnastics (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Gymnastics (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Gymnastics (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Gymnastics (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Gymnastics (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Gymnastics (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Gymnastics (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Gymnastics (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Gymnastics (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Gymnastics (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Gymnastics (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Gymnastics (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Gymnastics (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Gymnastics (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Gymnastics (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Gymnastics (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Gymnastics (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Gymnastics (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Gymnastics (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Gymnastics (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Gymnastics (drug). Predicting constant value: 0.0\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.90088D-01    |proj g|=  1.96185D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      3      6      1     0     0   1.307D-06  -1.905D-01\n",
      "  F = -0.19049937861094621     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.09730D-01    |proj g|=  1.92543D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      3      6      1     0     0   4.886D-06  -2.101D-01\n",
      "  F = -0.21010973516379886     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.17945D-01    |proj g|=  1.33662D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      4     17      1     0     0   1.585D-05   1.176D-01\n",
      "  F =  0.11759369074538843     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.16446D-01    |proj g|=  1.17471D-01\n",
      "\n",
      "At iterate    5    f=  2.15796D-01    |proj g|=  1.09941D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      6     11      1     0     0   2.989D-07   2.158D-01\n",
      "  F =  0.21579552752929215     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.28040D-01    |proj g|=  1.11836D-01\n",
      "\n",
      "At iterate    5    f=  2.27665D-01    |proj g|=  7.20779D-06\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      5     10      1     0     0   7.208D-06   2.277D-01\n",
      "  F =  0.22766471459581639     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.11002D-01    |proj g|=  1.10028D-01\n",
      "\n",
      "At iterate    5    f=  2.10651D-01    |proj g|=  1.26309D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      7     11      1     0     0   1.891D-06   2.107D-01\n",
      "  F =  0.21065082935739649     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "Metrics for Gymnastics (drug) - MSE: 0.11115666719603452, R2: -0.19849688604955196\n",
      "All zero values for Handball (drug), skipping.\n",
      "All zero values for Hockey (drug), skipping.\n",
      "All zero values for Ice Hockey (drug), skipping.\n",
      "All zero values for Jeu De Paume (drug), skipping.\n",
      "Checking stationarity for Judo (drug):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADF Statistic: 0.7499437105973383, p-value: 0.9907836538469655\n",
      "Skipping ARIMA fitting for non-stationary series: Judo (drug)\n",
      "All zero values for Lacrosse (drug), skipping.\n",
      "All zero values for Luge (drug), skipping.\n",
      "All zero values for Military Ski Patrol (drug), skipping.\n",
      "Checking stationarity for Modern Pentathlon (drug):\n",
      "ADF Statistic: -4.040252017342034, p-value: 0.0012138030979205426\n",
      "Optimal ARIMA order: (0, 0, 0)\n",
      "Optimal SARIMA order: (0, 0, 0), Seasonal: (0, 0, 0, 0)\n",
      "Constant series detected for Modern Pentathlon (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Modern Pentathlon (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Modern Pentathlon (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Modern Pentathlon (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Modern Pentathlon (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Modern Pentathlon (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Modern Pentathlon (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Modern Pentathlon (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Modern Pentathlon (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Modern Pentathlon (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Modern Pentathlon (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Modern Pentathlon (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Modern Pentathlon (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Modern Pentathlon (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Modern Pentathlon (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Modern Pentathlon (drug). Predicting constant value: 0.0\n",
      "Metrics for Modern Pentathlon (drug) - MSE: 0.19169866787910464, R2: -0.0520048847024035\n",
      "Constant series detected for Modern Pentathlon (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Modern Pentathlon (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Modern Pentathlon (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Modern Pentathlon (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Modern Pentathlon (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Modern Pentathlon (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Modern Pentathlon (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Modern Pentathlon (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Modern Pentathlon (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Modern Pentathlon (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Modern Pentathlon (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Modern Pentathlon (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Modern Pentathlon (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Modern Pentathlon (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Modern Pentathlon (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Modern Pentathlon (drug). Predicting constant value: 0.0\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.33186D-03    |proj g|=  1.69988D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     18      1     0     0   1.700D-04   2.332D-03\n",
      "  F =   2.3318611765645869E-003\n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.62473D-02    |proj g|=  1.79987D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     21      1     0     0   1.800D-04  -2.625D-02\n",
      "  F =  -2.6247345743409849E-002\n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -5.32810D-02    |proj g|=  1.89986D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     15      1     0     0   1.900D-04  -5.328D-02\n",
      "  F =  -5.3280956378547698E-002\n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -7.89276D-02    |proj g|=  1.99985D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     21      1     0     0   2.000D-04  -7.893D-02\n",
      "  F =  -7.8927603572322980E-002\n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.03323D-01    |proj g|=  2.09984D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     16      1     0     0   2.100D-04  -1.033D-01\n",
      "  F = -0.10332268565703898     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  6.78136D-01    |proj g|=  4.39985D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     15      1     0     0   4.400D-05   6.781D-01\n",
      "  F =  0.67813626274256489     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  6.55910D-01    |proj g|=  4.59983D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     17      1     0     0   4.599D-05   6.559D-01\n",
      "  F =  0.65591038145714786     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  6.34631D-01    |proj g|=  4.79983D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     17      1     0     0   4.799D-05   6.346D-01\n",
      "  F =  0.63463057424774993     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  6.14220D-01    |proj g|=  4.99981D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     15      1     0     0   5.000D-05   6.142D-01\n",
      "  F =  0.61421957698762242     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  5.94609D-01    |proj g|=  5.19980D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     17      1     0     0   5.199D-05   5.946D-01\n",
      "  F =  0.59460922041098174     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  6.66900D-01    |proj g|=  4.49984D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     17      1     0     0   4.499D-05   6.669D-01\n",
      "  F =  0.66689983481653548     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  6.48716D-01    |proj g|=  4.66650D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     21      1     0     0   4.666D-05   6.487D-01\n",
      "  F =  0.64871601273109814     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  6.31170D-01    |proj g|=  4.83316D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     14      1     0     0   4.832D-05   6.312D-01\n",
      "  F =  0.63117035282546297     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  6.14220D-01    |proj g|=  4.99981D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     17      1     0     0   4.999D-05   6.142D-01\n",
      "  F =  0.61421957698762231     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "Metrics for Modern Pentathlon (drug) - MSE: 0.2, R2: -0.09756097560975618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All zero values for Motorboating (drug), skipping.\n",
      "All zero values for Nordic Combined (drug), skipping.\n",
      "All zero values for Polo (drug), skipping.\n",
      "All zero values for Racquets (drug), skipping.\n",
      "All zero values for Rhythmic Gymnastics (drug), skipping.\n",
      "All zero values for Roque (drug), skipping.\n",
      "Checking stationarity for Rowing (drug):\n",
      "ADF Statistic: -3.980420832022666, p-value: 0.0015165757967219096\n",
      "Optimal ARIMA order: (2, 1, 0)\n",
      "Optimal SARIMA order: (2, 1, 0), Seasonal: (0, 0, 0, 0)\n",
      "Constant series detected for Rowing (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Rowing (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Rowing (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Rowing (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Rowing (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Rowing (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Rowing (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Rowing (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Rowing (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Rowing (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Rowing (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Rowing (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Rowing (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Rowing (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Rowing (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Rowing (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Rowing (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Rowing (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Rowing (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Rowing (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Rowing (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Rowing (drug). Predicting constant value: 0.0\n",
      "Metrics for Rowing (drug) - MSE: 0.12563138407843413, R2: -0.025989636640545433\n",
      "Constant series detected for Rowing (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Rowing (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Rowing (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Rowing (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Rowing (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Rowing (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Rowing (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Rowing (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Rowing (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Rowing (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Rowing (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Rowing (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Rowing (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Rowing (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Rowing (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Rowing (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Rowing (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Rowing (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Rowing (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Rowing (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Rowing (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Rowing (drug). Predicting constant value: 0.0\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.61519D-01    |proj g|=  3.75434D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3      4      7      1     0     0   7.661D-06  -1.633D-01\n",
      "  F = -0.16328484607559457     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.81547D-01    |proj g|=  3.69111D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3      4      7      1     0     0   4.715D-06  -1.832D-01\n",
      "  F = -0.18317247940347833     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.43619D-01    |proj g|=  3.99122D+00\n",
      "\n",
      "At iterate    5    f= -6.59589D-04    |proj g|=  3.87614D-01\n",
      "\n",
      "At iterate   10    f= -1.45667D-01    |proj g|=  3.64141D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3     14     18      1     0     0   1.757D-04  -1.457D-01\n",
      "  F = -0.14572048015565298     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  4.22511D-01    |proj g|=  3.35312D+00\n",
      "\n",
      "At iterate    5    f=  1.10235D-01    |proj g|=  1.61302D+00\n",
      "\n",
      "At iterate   10    f=  2.78574D-02    |proj g|=  1.76503D-01\n",
      "\n",
      "At iterate   15    f=  2.49321D-02    |proj g|=  3.23174D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3     15     22      1     0     0   3.232D-05   2.493D-02\n",
      "  F =   2.4932141815695381E-002\n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.68111D-02    |proj g|=  2.78151D-01\n",
      "\n",
      "At iterate    5    f=  2.38561D-02    |proj g|=  1.70755D-01\n",
      "\n",
      "At iterate   10    f=  1.84862D-02    |proj g|=  5.03223D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3     13     21      1     0     0   3.679D-05   1.849D-02\n",
      "  F =   1.8485126635983194E-002\n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  3.03057D-02    |proj g|=  2.71891D-01\n",
      "\n",
      "At iterate    5    f=  2.77766D-02    |proj g|=  1.36084D-01\n",
      "\n",
      "At iterate   10    f=  1.90472D-02    |proj g|=  6.36816D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3     14     58      2     0     0   1.360D-05   1.903D-02\n",
      "  F =   1.9026700523913132E-002\n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "Metrics for Rowing (drug) - MSE: 0.12563138407843413, R2: -0.025989636640545433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All zero values for Rugby (drug), skipping.\n",
      "All zero values for Rugby Sevens (drug), skipping.\n",
      "Checking stationarity for Sailing (drug):\n",
      "ADF Statistic: -5.4772255750516585, p-value: 2.3270204083626345e-06\n",
      "Optimal ARIMA order: (0, 0, 0)\n",
      "Optimal SARIMA order: (0, 0, 0), Seasonal: (0, 0, 0, 0)\n",
      "Constant series detected for Sailing (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Sailing (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Sailing (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Sailing (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Sailing (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Sailing (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Sailing (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Sailing (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Sailing (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Sailing (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Sailing (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Sailing (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Sailing (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Sailing (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Sailing (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Sailing (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Sailing (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Sailing (drug). Predicting constant value: 0.0\n",
      "Metrics for Sailing (drug) - MSE: 0.034041733744776946, R2: -0.05646759897583675\n",
      "Constant series detected for Sailing (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Sailing (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Sailing (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Sailing (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Sailing (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Sailing (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Sailing (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Sailing (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Sailing (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Sailing (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Sailing (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Sailing (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Sailing (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Sailing (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Sailing (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Sailing (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Sailing (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Sailing (drug). Predicting constant value: 0.0\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -5.32810D-02    |proj g|=  1.89986D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     17      1     0     0   1.900D-04  -5.328D-02\n",
      "  F =  -5.3280956378547670E-002\n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -7.89276D-02    |proj g|=  1.99985D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     21      1     0     0   2.000D-04  -7.893D-02\n",
      "  F =  -7.8927603572322980E-002\n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.03323D-01    |proj g|=  2.09984D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     14      1     0     0   2.100D-04  -1.033D-01\n",
      "  F = -0.10332268565703906     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.26583D-01    |proj g|=  2.19983D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     15      1     0     0   2.200D-04  -1.266D-01\n",
      "  F = -0.12658269347448534     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.48809D-01    |proj g|=  2.29982D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     21      1     0     0   2.300D-04  -1.488D-01\n",
      "  F = -0.14880857475990231     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.70088D-01    |proj g|=  2.39980D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     17      1     0     0   2.400D-04  -1.701D-01\n",
      "  F = -0.17008838196930021     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.90499D-01    |proj g|=  2.49979D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     16      1     0     0   2.500D-04  -1.905D-01\n",
      "  F = -0.19049937922942786     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.10110D-01    |proj g|=  2.59978D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     14      1     0     0   2.600D-04  -2.101D-01\n",
      "  F = -0.21010973580606848     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.28980D-01    |proj g|=  2.69977D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     21      1     0     0   2.700D-04  -2.290D-01\n",
      "  F = -0.22897989979749200     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.47164D-01    |proj g|=  2.79975D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     18      1     0     0   2.800D-04  -2.472D-01\n",
      "  F = -0.24716372188292940     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.64709D-01    |proj g|=  2.89974D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     20      1     0     0   2.900D-04  -2.647D-01\n",
      "  F = -0.26470938178856440     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.81660D-01    |proj g|=  2.99973D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     17      1     0     0   2.999D-04  -2.817D-01\n",
      "  F = -0.28166015762640506     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "Metrics for Sailing (drug) - MSE: 0.03333333333333333, R2: -0.034482758620689946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking stationarity for Shooting (drug):\n",
      "ADF Statistic: -0.8301992346604335, p-value: 0.8100899473397039\n",
      "Skipping ARIMA fitting for non-stationary series: Shooting (drug)\n",
      "All zero values for Short Track Speed Skating (drug), skipping.\n",
      "All zero values for Skeleton (drug), skipping.\n",
      "All zero values for Ski Jumping (drug), skipping.\n",
      "All zero values for Snowboarding (drug), skipping.\n",
      "All zero values for Softball (drug), skipping.\n",
      "All zero values for Speed Skating (drug), skipping.\n",
      "Checking stationarity for Swimming (drug):\n",
      "ADF Statistic: -3.8704130819838043, p-value: 0.002263708352516402\n",
      "Optimal ARIMA order: (0, 0, 0)\n",
      "Optimal SARIMA order: (0, 0, 0), Seasonal: (0, 0, 0, 0)\n",
      "Constant series detected for Swimming (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Swimming (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Swimming (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Swimming (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Swimming (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Swimming (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Swimming (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Swimming (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Swimming (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Swimming (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Swimming (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Swimming (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Swimming (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Swimming (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Swimming (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Swimming (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Swimming (drug). Predicting constant value: 0.0\n",
      "Metrics for Swimming (drug) - MSE: 0.21454163643826754, R2: -0.04371606915913939\n",
      "Constant series detected for Swimming (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Swimming (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Swimming (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Swimming (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Swimming (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Swimming (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Swimming (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Swimming (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Swimming (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Swimming (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Swimming (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Swimming (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Swimming (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Swimming (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Swimming (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Swimming (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Swimming (drug). Predicting constant value: 0.0\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.62473D-02    |proj g|=  1.79987D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     21      1     0     0   1.800D-04  -2.625D-02\n",
      "  F =  -2.6247345743409884E-002\n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -5.32810D-02    |proj g|=  1.89986D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     15      1     0     0   1.900D-04  -5.328D-02\n",
      "  F =  -5.3280956378547732E-002\n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -7.89276D-02    |proj g|=  1.99985D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     21      1     0     0   2.000D-04  -7.893D-02\n",
      "  F =  -7.8927603572322980E-002\n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.03323D-01    |proj g|=  2.09984D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     15      1     0     0   2.100D-04  -1.033D-01\n",
      "  F = -0.10332268565703899     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.26583D-01    |proj g|=  2.19983D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     14      1     0     0   2.200D-04  -1.266D-01\n",
      "  F = -0.12658269347448534     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.48809D-01    |proj g|=  2.29982D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     21      1     0     0   2.300D-04  -1.488D-01\n",
      "  F = -0.14880857475990228     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.70088D-01    |proj g|=  2.39980D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     17      1     0     0   2.400D-04  -1.701D-01\n",
      "  F = -0.17008838196930021     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.90499D-01    |proj g|=  2.49979D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     16      1     0     0   2.500D-04  -1.905D-01\n",
      "  F = -0.19049937922942786     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.10110D-01    |proj g|=  2.59978D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     14      1     0     0   2.600D-04  -2.101D-01\n",
      "  F = -0.21010973580606848     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.28980D-01    |proj g|=  2.69977D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     21      1     0     0   2.700D-04  -2.290D-01\n",
      "  F = -0.22897989979749200     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.94099D-02    |proj g|=  1.39991D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     16      1     0     0   1.400D-04   9.941D-02\n",
      "  F =   9.9409868397043286E-002\n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  6.31170D-01    |proj g|=  4.83316D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     16      1     0     0   4.831D-05   6.312D-01\n",
      "  F =  0.63117035282546308     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  6.14220D-01    |proj g|=  4.99982D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     19      1     0     0   4.999D-05   6.142D-01\n",
      "  F =  0.61421957698762242     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "Metrics for Swimming (drug) - MSE: 0.23333333333333334, R2: -0.1351351351351351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All zero values for Synchronized Swimming (drug), skipping.\n",
      "All zero values for Table Tennis (drug), skipping.\n",
      "All zero values for Taekwondo (drug), skipping.\n",
      "All zero values for Tennis (drug), skipping.\n",
      "All zero values for Trampolining (drug), skipping.\n",
      "Checking stationarity for Triathlon (drug):\n",
      "ADF Statistic: -5.47722557505166, p-value: 2.3270204083626223e-06\n",
      "Optimal ARIMA order: (0, 0, 0)\n",
      "Optimal SARIMA order: (0, 0, 0), Seasonal: (0, 0, 0, 0)\n",
      "Constant series detected for Triathlon (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Triathlon (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Triathlon (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Triathlon (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Triathlon (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Triathlon (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Triathlon (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Triathlon (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Triathlon (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Triathlon (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Triathlon (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Triathlon (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Triathlon (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Triathlon (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Triathlon (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Triathlon (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Triathlon (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Triathlon (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Triathlon (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Triathlon (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Triathlon (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Triathlon (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Triathlon (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Triathlon (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Triathlon (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Triathlon (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Triathlon (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Triathlon (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Triathlon (drug). Predicting constant value: 0.0\n",
      "Metrics for Triathlon (drug) - MSE: 0.1334814595929671, R2: -0.03563201408336547\n",
      "Constant series detected for Triathlon (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Triathlon (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Triathlon (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Triathlon (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Triathlon (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Triathlon (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Triathlon (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Triathlon (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Triathlon (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Triathlon (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Triathlon (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Triathlon (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Triathlon (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Triathlon (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Triathlon (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Triathlon (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Triathlon (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Triathlon (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Triathlon (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Triathlon (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Triathlon (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Triathlon (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Triathlon (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Triathlon (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Triathlon (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Triathlon (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Triathlon (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Triathlon (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Triathlon (drug). Predicting constant value: 0.0\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  4.11487D-01    |proj g|=  7.49966D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     15      1     0     0   7.499D-05   4.115D-01\n",
      "  F =  0.41148702293354023     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "Metrics for Triathlon (drug) - MSE: 0.13333333333333333, R2: -0.034482758620689724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All zero values for Tug-Of-War (drug), skipping.\n",
      "Checking stationarity for Volleyball (drug):\n",
      "ADF Statistic: -5.835585150955646, p-value: 3.883540418735654e-07\n",
      "Optimal ARIMA order: (0, 0, 0)\n",
      "Optimal SARIMA order: (0, 0, 0), Seasonal: (0, 0, 0, 0)\n",
      "Constant series detected for Volleyball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Volleyball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Volleyball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Volleyball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Volleyball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Volleyball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Volleyball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Volleyball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Volleyball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Volleyball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Volleyball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Volleyball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Volleyball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Volleyball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Volleyball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Volleyball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Volleyball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Volleyball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Volleyball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Volleyball (drug). Predicting constant value: 0.0\n",
      "Metrics for Volleyball (drug) - MSE: 0.19137615884720724, R2: -0.05023501806394193\n",
      "Constant series detected for Volleyball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Volleyball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Volleyball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Volleyball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Volleyball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Volleyball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Volleyball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Volleyball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Volleyball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Volleyball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Volleyball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Volleyball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Volleyball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Volleyball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Volleyball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Volleyball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Volleyball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Volleyball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Volleyball (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Volleyball (drug). Predicting constant value: 0.0\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  5.89824D-01    |proj g|=  5.24980D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     19      1     0     0   5.249D-05   5.898D-01\n",
      "  F =  0.58982449490290645     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  5.66564D-01    |proj g|=  5.49979D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     16      1     0     0   5.500D-05   5.666D-01\n",
      "  F =  0.56656448708546003     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  6.55910D-01    |proj g|=  4.59984D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     17      1     0     0   4.600D-05   6.559D-01\n",
      "  F =  0.65591038145714797     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  6.34631D-01    |proj g|=  4.79983D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     16      1     0     0   4.799D-05   6.346D-01\n",
      "  F =  0.63463057424774993     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  6.14220D-01    |proj g|=  4.99981D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     16      1     0     0   5.000D-05   6.142D-01\n",
      "  F =  0.61421957698762242     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  5.94609D-01    |proj g|=  5.19980D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     16      1     0     0   5.199D-05   5.946D-01\n",
      "  F =  0.59460922041098163     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  5.75739D-01    |proj g|=  5.39979D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     21      1     0     0   5.400D-05   5.757D-01\n",
      "  F =  0.57573905641955814     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  5.57555D-01    |proj g|=  5.59978D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     16      1     0     0   5.597D-05   5.576D-01\n",
      "  F =  0.55755523433412080     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  5.40010D-01    |proj g|=  5.79976D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     14      1     0     0   5.798D-05   5.400D-01\n",
      "  F =  0.54000957442848563     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  6.14220D-01    |proj g|=  4.99981D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     18      1     0     0   5.000D-05   6.142D-01\n",
      "  F =  0.61421957698762231     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "Metrics for Volleyball (drug) - MSE: 0.2, R2: -0.09756097560975596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All zero values for Water Polo (drug), skipping.\n",
      "Checking stationarity for Weightlifting (drug):\n",
      "ADF Statistic: 6.209949002937915, p-value: 1.0\n",
      "Skipping ARIMA fitting for non-stationary series: Weightlifting (drug)\n",
      "Checking stationarity for Wrestling (drug):\n",
      "ADF Statistic: -3.666633512216656, p-value: 0.004607728290429674\n",
      "Optimal ARIMA order: (1, 0, 0)\n",
      "Optimal SARIMA order: (1, 0, 0), Seasonal: (0, 0, 0, 0)\n",
      "Constant series detected for Wrestling (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Wrestling (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Wrestling (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Wrestling (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Wrestling (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Wrestling (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Wrestling (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Wrestling (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Wrestling (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Wrestling (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Wrestling (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Wrestling (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Wrestling (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Wrestling (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Wrestling (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Wrestling (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Wrestling (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Wrestling (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Wrestling (drug). Predicting constant value: 0.0\n",
      "Metrics for Wrestling (drug) - MSE: 1.861756796622017, R2: 0.14346965757159946\n",
      "Constant series detected for Wrestling (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Wrestling (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Wrestling (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Wrestling (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Wrestling (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Wrestling (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Wrestling (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Wrestling (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Wrestling (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Wrestling (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Wrestling (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Wrestling (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Wrestling (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Wrestling (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Wrestling (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Wrestling (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Wrestling (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Wrestling (drug). Predicting constant value: 0.0\n",
      "Constant series detected for Wrestling (drug). Predicting constant value: 0.0\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.02737D-01    |proj g|=  2.13145D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      3     12      1     0     0   2.079D-04  -1.033D-01\n",
      "  F = -0.10332268565698653     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  3.51223D-01    |proj g|=  4.16548D+00\n",
      "\n",
      "At iterate    5    f= -1.60601D-02    |proj g|=  2.58169D-01\n",
      "\n",
      "At iterate   10    f= -8.62451D-02    |proj g|=  9.65672D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     14     28      1     0     0   1.386D-05  -8.634D-02\n",
      "  F =  -8.6336676090777761E-002\n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  6.06647D-02    |proj g|=  1.66646D-01\n",
      "\n",
      "At iterate    5    f=  5.99563D-02    |proj g|=  4.88863D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      9     12      1     0     0   4.841D-06   5.988D-02\n",
      "  F =   5.9883637931567778E-002\n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  3.90840D-02    |proj g|=  1.63301D-01\n",
      "\n",
      "At iterate    5    f=  3.84246D-02    |proj g|=  4.82413D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      8     11      1     0     0   9.102D-06   3.837D-02\n",
      "  F =   3.8366536761856862E-002\n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  6.68039D-01    |proj g|=  8.35983D-02\n",
      "\n",
      "At iterate    5    f=  6.66833D-01    |proj g|=  1.03826D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      7     11      1     0     0   1.529D-06   6.668D-01\n",
      "  F =  0.66683229058068261     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  6.48176D-01    |proj g|=  8.20431D-02\n",
      "\n",
      "At iterate    5    f=  6.47517D-01    |proj g|=  6.78851D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      7     12      1     0     0   1.062D-05   6.475D-01\n",
      "  F =  0.64751665058607988     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.80168D+00    |proj g|=  2.31109D-01\n",
      "\n",
      "At iterate    5    f=  1.68893D+00    |proj g|=  1.20607D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      9     11      1     0     0   9.325D-06   1.687D+00\n",
      "  F =   1.6872469964407357     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.68083D+00    |proj g|=  2.73038D-02\n",
      "\n",
      "At iterate    5    f=  1.67977D+00    |proj g|=  2.70828D-06\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      5      8      1     0     0   2.708D-06   1.680D+00\n",
      "  F =   1.6797679320394985     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.68355D+00    |proj g|=  2.62060D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      4      7      1     0     0   1.558D-06   1.683D+00\n",
      "  F =   1.6829510197086019     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.66955D+00    |proj g|=  2.56924D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      4      7      1     0     0   1.115D-06   1.669D+00\n",
      "  F =   1.6690115220942043     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "Metrics for Wrestling (drug) - MSE: 1.905014209432892, R2: 0.12356840802348901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All zero values for climbing (drug), skipping.\n",
      "All zero values for Fitness (drug), skipping.\n",
      "All zero values for Headis (drug), skipping.\n",
      "\n",
      "Processing parameter: equity\n",
      "Checking stationarity for Alpine Skiing (equity):\n",
      "ADF Statistic: -9.88170888524548, p-value: 3.7549181524079066e-17\n",
      "Optimal ARIMA order: (1, 0, 2)\n",
      "Optimal SARIMA order: (0, 0, 0), Seasonal: (0, 0, 0, 0)\n",
      "Metrics for Alpine Skiing (equity) - MSE: 0.0021456787152452747, R2: -1.825073839219299\n",
      "Constant series detected for Alpine Skiing (equity). Predicting constant value: 0.3592233009708738\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.56977D-01    |proj g|=  1.02151D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     15      1     0     0   1.021D-04   2.570D-01\n",
      "  F =  0.25697668578935295     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.81874D-01    |proj g|=  9.71895D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     14      1     0     0   9.717D-05   2.819D-01\n",
      "  F =  0.28187373944510646     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  3.11121D-01    |proj g|=  9.16677D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     15      1     0     0   9.167D-05   3.111D-01\n",
      "  F =  0.31112106477815121     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  3.57845D-01    |proj g|=  8.34898D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     15      1     0     0   8.348D-05   3.578D-01\n",
      "  F =  0.35784474709777714     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  3.49511D-01    |proj g|=  8.48931D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     20      1     0     0   8.489D-05   3.495D-01\n",
      "  F =  0.34951071428640640     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  3.40053D-01    |proj g|=  8.65141D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     14      1     0     0   8.649D-05   3.401D-01\n",
      "  F =  0.34005268246333020     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  3.57245D-01    |proj g|=  8.35901D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     18      1     0     0   8.359D-05   3.572D-01\n",
      "  F =  0.35724479591701797     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  3.49335D-01    |proj g|=  8.49228D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     15      1     0     0   8.492D-05   3.493D-01\n",
      "  F =  0.34933528981330886     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  3.59315D-01    |proj g|=  8.32446D-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     14      1     0     0   8.322D-05   3.593D-01\n",
      "  F =  0.35931507896016052     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  3.54219D-01    |proj g|=  8.40975D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     14      1     0     0   8.407D-05   3.542D-01\n",
      "  F =  0.35421856057178092     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  3.58148D-01    |proj g|=  8.34392D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     18      1     0     0   8.344D-05   3.581D-01\n",
      "  F =  0.35814786994419673     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "Metrics for Alpine Skiing (equity) - MSE: 0.11446741051822133, R2: -86.35369529837776\n",
      "Insufficient data for Alpinism (equity)\n",
      "Checking stationarity for Archery (equity):\n",
      "ADF Statistic: -0.7907711130684935, p-value: 0.8218179630518481\n",
      "Skipping ARIMA fitting for non-stationary series: Archery (equity)\n",
      "Checking stationarity for Art Competitions (equity):\n",
      "ADF Statistic: -3.3478143581664948, p-value: 0.012871848713243953\n",
      "Optimal ARIMA order: (0, 0, 0)\n",
      "Optimal SARIMA order: (0, 0, 0), Seasonal: (0, 0, 0, 0)\n",
      "Constant series detected for Art Competitions (equity). Predicting constant value: 0.0\n",
      "Metrics for Art Competitions (equity) - MSE: 0.004209920623088797, R2: -2.0861001563370634\n",
      "Constant series detected for Art Competitions (equity). Predicting constant value: 0.0\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.32553D+00    |proj g|=  2.41937D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     16      1     0     0   2.419D-03  -1.326D+00\n",
      "  F =  -1.3255303298736709     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.11115D+00    |proj g|=  1.57585D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     17      1     0     0   1.576D-03  -1.111D+00\n",
      "  F =  -1.1111470669065304     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.14605D+00    |proj g|=  1.68976D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     16      1     0     0   1.690D-03  -1.146D+00\n",
      "  F =  -1.1460486135174370     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -9.54122D-01    |proj g|=  1.15116D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     17      1     0     0   1.151D-03  -9.541D-01\n",
      "  F = -0.95412192554038511     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.00027D+00    |proj g|=  1.26245D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     16      1     0     0   1.262D-03  -1.000D+00\n",
      "  F =  -1.0002690878383644     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "Metrics for Art Competitions (equity) - MSE: 0.012490436030653149, R2: -8.156167072488705\n",
      "Checking stationarity for Athletics (equity):\n",
      "ADF Statistic: -0.32321243533871113, p-value: 0.9221518099266621\n",
      "Skipping ARIMA fitting for non-stationary series: Athletics (equity)\n",
      "Checking stationarity for Badminton (equity):\n",
      "ADF Statistic: -2.84879138641426, p-value: 0.05163515550645489\n",
      "Skipping ARIMA fitting for non-stationary series: Badminton (equity)\n",
      "All zero values for Baseball (equity), skipping.\n",
      "Checking stationarity for Basketball (equity):\n",
      "ADF Statistic: -22.559998343519112, p-value: 0.0\n",
      "Optimal ARIMA order: (0, 1, 0)\n",
      "Optimal SARIMA order: (0, 1, 0), Seasonal: (0, 0, 0, 0)\n",
      "Constant series detected for Basketball (equity). Predicting constant value: 0.0\n",
      "Constant series detected for Basketball (equity). Predicting constant value: 0.0\n",
      "Constant series detected for Basketball (equity). Predicting constant value: 0.0\n",
      "Constant series detected for Basketball (equity). Predicting constant value: 0.0\n",
      "Constant series detected for Basketball (equity). Predicting constant value: 0.0\n",
      "Constant series detected for Basketball (equity). Predicting constant value: 0.0\n",
      "Constant series detected for Basketball (equity). Predicting constant value: 0.0\n",
      "Metrics for Basketball (equity) - MSE: 0.006795151147279348, R2: 0.8531345053975548\n",
      "Constant series detected for Basketball (equity). Predicting constant value: 0.0\n",
      "Constant series detected for Basketball (equity). Predicting constant value: 0.0\n",
      "Constant series detected for Basketball (equity). Predicting constant value: 0.0\n",
      "Constant series detected for Basketball (equity). Predicting constant value: 0.0\n",
      "Constant series detected for Basketball (equity). Predicting constant value: 0.0\n",
      "Constant series detected for Basketball (equity). Predicting constant value: 0.0\n",
      "Constant series detected for Basketball (equity). Predicting constant value: 0.0\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -6.23822D-01    |proj g|=  9.85257D-01\n",
      "\n",
      "At iterate    5    f= -6.27030D-01    |proj g|=  2.29107D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      5     23      1     0     0   2.291D-05  -6.270D-01\n",
      "  F = -0.62702958462644820     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -6.85243D-01    |proj g|=  9.34554D-01\n",
      "\n",
      "At iterate    5    f= -6.87831D-01    |proj g|=  1.43191D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      5     16      1     0     0   1.432D-05  -6.878D-01\n",
      "  F = -0.68783088195716746     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -7.40529D-01    |proj g|=  8.90947D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      4      7      1     0     0   9.255D-06  -7.427D-01\n",
      "  F = -0.74266025075403230     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -7.76186D-01    |proj g|=  8.39367D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      4      7      1     0     0   5.723D-06  -7.780D-01\n",
      "  F = -0.77797220805816381     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -8.21983D-01    |proj g|=  8.06297D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      4      7      1     0     0   4.003D-06  -8.235D-01\n",
      "  F = -0.82350142729759035     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -8.22619D-01    |proj g|=  7.42827D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      4      7      1     0     0   1.814D-06  -8.239D-01\n",
      "  F = -0.82392570041685187     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -8.61420D-01    |proj g|=  7.17353D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      4      7      1     0     0   1.395D-06  -8.626D-01\n",
      "  F = -0.86255663184584541     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -8.97739D-01    |proj g|=  6.94535D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      4      7      1     0     0   1.007D-06  -8.987D-01\n",
      "  F = -0.89873656478246022     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -9.31750D-01    |proj g|=  6.73583D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      4      7      1     0     0   7.028D-07  -9.326D-01\n",
      "  F = -0.93263209048530071     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -9.63712D-01    |proj g|=  6.54524D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      4      7      1     0     0   6.673D-07  -9.645D-01\n",
      "  F = -0.96449868980795728     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -9.93855D-01    |proj g|=  6.37044D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      4      7      1     0     0   3.566D-07  -9.946D-01\n",
      "  F = -0.99455978673533374     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.02236D+00    |proj g|=  6.20765D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      4      7      1     0     0   2.816D-07  -1.023D+00\n",
      "  F =  -1.0229927341327820     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "Metrics for Basketball (equity) - MSE: 0.006795151147279348, R2: 0.8531345053975548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All zero values for Basque Pelota (equity), skipping.\n",
      "Checking stationarity for Beach Volleyball (equity):\n",
      "ADF Statistic: -340642448495085.44, p-value: 0.0\n",
      "Optimal ARIMA order: (0, 0, 0)\n",
      "Optimal SARIMA order: (0, 0, 0), Seasonal: (0, 0, 0, 0)\n",
      "Constant series detected for Beach Volleyball (equity). Predicting constant value: 0.4285714285714285\n",
      "Metrics for Beach Volleyball (equity) - MSE: 0.0012683480255458322, R2: 0.0\n",
      "Constant series detected for Beach Volleyball (equity). Predicting constant value: 0.4285714285714285\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  6.54633D-01    |proj g|=  4.61160D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     15      1     0     0   4.611D-05   6.546D-01\n",
      "  F =  0.65463324155459945     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  6.79495D-01    |proj g|=  4.38791D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     17      1     0     0   4.387D-05   6.795D-01\n",
      "  F =  0.67949495923081482     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  6.91477D-01    |proj g|=  4.28400D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     17      1     0     0   4.283D-05   6.915D-01\n",
      "  F =  0.69147709945017910     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  6.98531D-01    |proj g|=  4.22399D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     16      1     0     0   4.223D-05   6.985D-01\n",
      "  F =  0.69853093320551873     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  7.03179D-01    |proj g|=  4.18491D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     17      1     0     0   4.183D-05   7.032D-01\n",
      "  F =  0.70317880364225938     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "Metrics for Beach Volleyball (equity) - MSE: 0.20918367346938774, R2: 0.0\n",
      "Checking stationarity for Biathlon (equity):\n",
      "ADF Statistic: nan, p-value: nan\n",
      "Skipping ARIMA fitting for non-stationary series: Biathlon (equity)\n",
      "All zero values for Bobsleigh (equity), skipping.\n",
      "Checking stationarity for Boxing (equity):\n",
      "ADF Statistic: 8.290626166795253, p-value: 1.0\n",
      "Skipping ARIMA fitting for non-stationary series: Boxing (equity)\n",
      "Checking stationarity for Canoeing (equity):\n",
      "ADF Statistic: -1.4301032858815075, p-value: 0.5677621985055048\n",
      "Skipping ARIMA fitting for non-stationary series: Canoeing (equity)\n",
      "All zero values for Cricket (equity), skipping.\n",
      "Insufficient data for Croquet (equity)\n",
      "Checking stationarity for Cross Country Skiing (equity):\n",
      "ADF Statistic: -2.5044304077069905, p-value: 0.11440007682514225\n",
      "Skipping ARIMA fitting for non-stationary series: Cross Country Skiing (equity)\n",
      "All zero values for Curling (equity), skipping.\n",
      "Checking stationarity for Cycling (equity):\n",
      "ADF Statistic: -3.6602899519956096, p-value: 0.004707678422270713\n",
      "Optimal ARIMA order: (0, 2, 1)\n",
      "Optimal SARIMA order: (0, 2, 1), Seasonal: (0, 0, 0, 0)\n",
      "Constant series detected for Cycling (equity). Predicting constant value: 0.0\n",
      "Constant series detected for Cycling (equity). Predicting constant value: 0.0\n",
      "Constant series detected for Cycling (equity). Predicting constant value: 0.0\n",
      "Constant series detected for Cycling (equity). Predicting constant value: 0.0\n",
      "Constant series detected for Cycling (equity). Predicting constant value: 0.0\n",
      "Constant series detected for Cycling (equity). Predicting constant value: 0.0\n",
      "Constant series detected for Cycling (equity). Predicting constant value: 0.0\n",
      "Constant series detected for Cycling (equity). Predicting constant value: 0.0\n",
      "Constant series detected for Cycling (equity). Predicting constant value: 0.0\n",
      "Constant series detected for Cycling (equity). Predicting constant value: 0.0\n",
      "Constant series detected for Cycling (equity). Predicting constant value: 0.0\n",
      "Constant series detected for Cycling (equity). Predicting constant value: 0.0\n",
      "Constant series detected for Cycling (equity). Predicting constant value: 0.0\n",
      "Constant series detected for Cycling (equity). Predicting constant value: 0.0\n",
      "Constant series detected for Cycling (equity). Predicting constant value: 0.0\n",
      "Constant series detected for Cycling (equity). Predicting constant value: 0.0\n",
      "Constant series detected for Cycling (equity). Predicting constant value: 0.0\n",
      "Constant series detected for Cycling (equity). Predicting constant value: 0.0\n",
      "Metrics for Cycling (equity) - MSE: 0.0013971539256983788, R2: 0.9468089490042189\n",
      "Constant series detected for Cycling (equity). Predicting constant value: 0.0\n",
      "Constant series detected for Cycling (equity). Predicting constant value: 0.0\n",
      "Constant series detected for Cycling (equity). Predicting constant value: 0.0\n",
      "Constant series detected for Cycling (equity). Predicting constant value: 0.0\n",
      "Constant series detected for Cycling (equity). Predicting constant value: 0.0\n",
      "Constant series detected for Cycling (equity). Predicting constant value: 0.0\n",
      "Constant series detected for Cycling (equity). Predicting constant value: 0.0\n",
      "Constant series detected for Cycling (equity). Predicting constant value: 0.0\n",
      "Constant series detected for Cycling (equity). Predicting constant value: 0.0\n",
      "Constant series detected for Cycling (equity). Predicting constant value: 0.0\n",
      "Constant series detected for Cycling (equity). Predicting constant value: 0.0\n",
      "Constant series detected for Cycling (equity). Predicting constant value: 0.0\n",
      "Constant series detected for Cycling (equity). Predicting constant value: 0.0\n",
      "Constant series detected for Cycling (equity). Predicting constant value: 0.0\n",
      "Constant series detected for Cycling (equity). Predicting constant value: 0.0\n",
      "Constant series detected for Cycling (equity). Predicting constant value: 0.0\n",
      "Constant series detected for Cycling (equity). Predicting constant value: 0.0\n",
      "Constant series detected for Cycling (equity). Predicting constant value: 0.0\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.16872D+00    |proj g|=  7.80246D+00\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      4     16      1     0     0   7.724D-04  -2.180D+00\n",
      "  F =  -2.1804157721958561     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.18980D+00    |proj g|=  7.68973D+00\n",
      "\n",
      "At iterate    5    f= -2.20032D+00    |proj g|=  4.09987D-02\n",
      "\n",
      "At iterate   10    f= -2.20058D+00    |proj g|=  1.58960D+00\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     14     27      1     0     0   3.482D-02  -2.202D+00\n",
      "  F =  -2.2017505811513338     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.22238D+00    |proj g|=  7.57477D+00\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      4     25      1     0     0   8.704D-03  -2.232D+00\n",
      "  F =  -2.2318867211428524     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.93022D+00    |proj g|=  7.83355D+00\n",
      "\n",
      "At iterate    5    f= -1.95893D+00    |proj g|=  2.62277D+00\n",
      "\n",
      "At iterate   10    f= -1.96896D+00    |proj g|=  1.76906D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     11     22      1     0     0   1.196D-03  -1.969D+00\n",
      "  F =  -1.9689556088407141     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.82279D+00    |proj g|=  1.01158D+01\n",
      "\n",
      "At iterate    5    f= -1.89221D+00    |proj g|=  4.39457D-02\n",
      "\n",
      "At iterate   10    f= -1.89265D+00    |proj g|=  1.15603D+00\n",
      "\n",
      "At iterate   15    f= -1.89457D+00    |proj g|=  2.42879D-02\n",
      "  ys=-4.764E-07  -gs= 2.362E-07 BFGS update SKIPPED\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     19     59      2     1     0   1.116D-02  -1.895D+00\n",
      "  F =  -1.8945738698379189     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.82102D+00    |proj g|=  9.58055D+00\n",
      "\n",
      "At iterate    5    f= -1.88194D+00    |proj g|=  5.52102D-01\n",
      "\n",
      "At iterate   10    f= -1.89676D+00    |proj g|=  5.16161D+00\n",
      "\n",
      "At iterate   15    f= -1.91001D+00    |proj g|=  2.95073D-03\n",
      "  ys=-5.435E-08  -gs= 5.028E-08 BFGS update SKIPPED\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     19     53      1     1     0   1.382D-03  -1.910D+00\n",
      "  F =  -1.9100149924050398     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.88466D+00    |proj g|=  6.64776D+00\n",
      "\n",
      "At iterate    5    f= -1.90198D+00    |proj g|=  1.11393D-01\n",
      "\n",
      "At iterate   10    f= -1.90592D+00    |proj g|=  3.40608D+00\n",
      "\n",
      "At iterate   15    f= -1.91388D+00    |proj g|=  3.22223D-03\n",
      "  ys=-1.242E-06  -gs= 4.896E-07 BFGS update SKIPPED\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     17     34      1     1     0   1.323D-02  -1.914D+00\n",
      "  F =  -1.9138851172799975     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.54087D+00    |proj g|=  1.43314D+01\n",
      "\n",
      "At iterate    5    f= -1.59270D+00    |proj g|=  4.13338D-01\n",
      "\n",
      "At iterate   10    f= -1.69417D+00    |proj g|=  8.27579D+00\n",
      "\n",
      "At iterate   15    f= -1.82341D+00    |proj g|=  8.01731D-02\n",
      "\n",
      "At iterate   20    f= -1.82358D+00    |proj g|=  7.69855D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     21     59      2     0     0   2.477D-04  -1.824D+00\n",
      "  F =  -1.8235803540386846     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.77929D+00    |proj g|=  8.08778D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      4     20      1     0     0   1.928D-03  -1.779D+00\n",
      "  F =  -1.7794946600322121     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.79777D+00    |proj g|=  5.46612D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      3     25      1     0     0   1.954D-03  -1.798D+00\n",
      "  F =  -1.7978561255981915     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "Metrics for Cycling (equity) - MSE: 0.0013971539256983788, R2: 0.9468089490042189\n",
      "Checking stationarity for Diving (equity):\n",
      "ADF Statistic: -3.515806775136415, p-value: 0.0075903020812729035\n",
      "Optimal ARIMA order: (0, 1, 0)\n",
      "Optimal SARIMA order: (0, 1, 0), Seasonal: (0, 0, 0, 0)\n",
      "Constant series detected for Diving (equity). Predicting constant value: 0.0\n",
      "Constant series detected for Diving (equity). Predicting constant value: 0.0\n",
      "Metrics for Diving (equity) - MSE: 0.0034619884303771116, R2: 0.7359066878618289\n",
      "Constant series detected for Diving (equity). Predicting constant value: 0.0\n",
      "Constant series detected for Diving (equity). Predicting constant value: 0.0\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -6.92124D-01    |proj g|=  3.06985D+00\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      4      8      1     0     0   7.105D-08  -7.092D-01\n",
      "  F = -0.70924318120320962     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -7.13515D-01    |proj g|=  2.28370D+00\n",
      "\n",
      "At iterate    5    f= -7.24258D-01    |proj g|=  2.77666D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      6     47      2     0     0   2.777D-04  -7.243D-01\n",
      "  F = -0.72425775157825956     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -8.23258D-01    |proj g|=  2.04293D+00\n",
      "\n",
      "At iterate    5    f= -8.30624D-01    |proj g|=  7.06488D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      6     18      1     0     0   7.065D-05  -8.306D-01\n",
      "  F = -0.83062449102459956     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -8.97150D-01    |proj g|=  1.82559D+00\n",
      "\n",
      "At iterate    5    f= -9.02514D-01    |proj g|=  1.55982D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      5      9      1     0     0   1.560D-03  -9.025D-01\n",
      "  F = -0.90251440955475026     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -9.58054D-01    |proj g|=  1.65650D+00\n",
      "\n",
      "At iterate    5    f= -9.62134D-01    |proj g|=  1.05623D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      5     18      1     0     0   1.056D-03  -9.621D-01\n",
      "  F = -0.96213356650741000     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.03131D+00    |proj g|=  1.55749D+00\n",
      "\n",
      "At iterate    5    f= -1.03451D+00    |proj g|=  6.35590D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      5     17      1     0     0   6.356D-04  -1.035D+00\n",
      "  F =  -1.0345135986261207     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.07307D+00    |proj g|=  1.43713D+00\n",
      "\n",
      "At iterate    5    f= -1.07566D+00    |proj g|=  3.29223D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      5     24      1     0     0   3.292D-04  -1.076D+00\n",
      "  F =  -1.0756550066923745     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.08631D+00    |proj g|=  1.30262D+00\n",
      "\n",
      "At iterate    5    f= -1.08844D+00    |proj g|=  1.47847D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      5     18      1     0     0   1.478D-04  -1.088D+00\n",
      "  F =  -1.0884387656603669     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.01382D+00    |proj g|=  1.08766D+00\n",
      "\n",
      "At iterate    5    f= -1.01561D+00    |proj g|=  3.69946D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      5     17      1     0     0   3.699D-05  -1.016D+00\n",
      "  F =  -1.0156089654568061     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.03517D+00    |proj g|=  1.01549D+00\n",
      "\n",
      "At iterate    5    f= -1.03669D+00    |proj g|=  2.11874D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      5     17      1     0     0   2.119D-05  -1.037D+00\n",
      "  F =  -1.0366915598796822     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.05214D+00    |proj g|=  9.50659D-01\n",
      "\n",
      "At iterate    5    f= -1.05345D+00    |proj g|=  1.17748D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      5     45      2     0     0   1.177D-05  -1.053D+00\n",
      "  F =  -1.0534487804980839     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.09013D+00    |proj g|=  9.16164D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      4      7      1     0     0   8.574D-06  -1.091D+00\n",
      "  F =  -1.0912639370788131     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.11915D+00    |proj g|=  8.79076D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      4      7      1     0     0   5.792D-06  -1.120D+00\n",
      "  F =  -1.1201445133273924     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.14669D+00    |proj g|=  8.46067D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      4      7      1     0     0   4.184D-06  -1.148D+00\n",
      "  F =  -1.1475735872258161     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.17446D+00    |proj g|=  8.17765D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      4      7      1     0     0   2.469D-06  -1.175D+00\n",
      "  F =  -1.1752446691974459     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.20288D+00    |proj g|=  7.93864D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      4      7      1     0     0   2.220D-06  -1.204D+00\n",
      "  F =  -1.2035867106981848     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.23136D+00    |proj g|=  7.72908D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      4      7      1     0     0   1.575D-06  -1.232D+00\n",
      "  F =  -1.2319984818727086     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.22877D+00    |proj g|=  7.30803D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      4      7      1     0     0   1.123D-06  -1.229D+00\n",
      "  F =  -1.2293440513435760     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.23848D+00    |proj g|=  7.01530D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      4      7      1     0     0   1.023D-06  -1.239D+00\n",
      "  F =  -1.2390004134058210     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.25868D+00    |proj g|=  6.82803D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      4      7      1     0     0   6.967D-07  -1.259D+00\n",
      "  F =  -1.2591563723723089     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.27992D+00    |proj g|=  6.66478D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      4      7      1     0     0   8.882D-09  -1.280D+00\n",
      "  F =  -1.2803632155913269     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.30248D+00    |proj g|=  6.52678D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      4      7      1     0     0   5.162D-07  -1.303D+00\n",
      "  F =  -1.3028843104762973     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.32324D+00    |proj g|=  6.39318D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      4      7      1     0     0   5.111D-07  -1.324D+00\n",
      "  F =  -1.3236139827224895     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.34313D+00    |proj g|=  6.26448D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      4      7      1     0     0   1.854D-07  -1.343D+00\n",
      "  F =  -1.3434752528062177     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.36319D+00    |proj g|=  6.15131D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      4      7      1     0     0   1.957D-07  -1.364D+00\n",
      "  F =  -1.3635169151503965     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "Metrics for Diving (equity) - MSE: 0.0034619884303771116, R2: 0.7359066878618289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking stationarity for Equestrianism (equity):\n",
      "ADF Statistic: 1.0842350578661764, p-value: 0.9950798038076288\n",
      "Skipping ARIMA fitting for non-stationary series: Equestrianism (equity)\n",
      "Checking stationarity for Fencing (equity):\n",
      "ADF Statistic: 1.6883701965382443, p-value: 0.9980998961069535\n",
      "Skipping ARIMA fitting for non-stationary series: Fencing (equity)\n",
      "Checking stationarity for Figure Skating (equity):\n",
      "ADF Statistic: 0.676371211705234, p-value: 0.9893543260525283\n",
      "Skipping ARIMA fitting for non-stationary series: Figure Skating (equity)\n",
      "Checking stationarity for Football (equity):\n",
      "ADF Statistic: 0.3426890355520917, p-value: 0.9792204626145311\n",
      "Skipping ARIMA fitting for non-stationary series: Football (equity)\n",
      "Insufficient data for Freestyle Skiing (equity)\n",
      "Checking stationarity for Golf (equity):\n",
      "ADF Statistic: -1.7851239669421481, p-value: 0.38787183980471673\n",
      "Skipping ARIMA fitting for non-stationary series: Golf (equity)\n",
      "Checking stationarity for Gymnastics (equity):\n",
      "ADF Statistic: -1.5629042473617025, p-value: 0.5021962533551372\n",
      "Skipping ARIMA fitting for non-stationary series: Gymnastics (equity)\n",
      "Checking stationarity for Handball (equity):\n",
      "ADF Statistic: -2.7891018602751045, p-value: 0.05984743146424834\n",
      "Skipping ARIMA fitting for non-stationary series: Handball (equity)\n",
      "Checking stationarity for Hockey (equity):\n",
      "ADF Statistic: -0.9498583259450797, p-value: 0.771110502623788\n",
      "Skipping ARIMA fitting for non-stationary series: Hockey (equity)\n",
      "All zero values for Ice Hockey (equity), skipping.\n",
      "All zero values for Jeu De Paume (equity), skipping.\n",
      "Checking stationarity for Judo (equity):\n",
      "ADF Statistic: -0.8734122854736668, p-value: 0.7966020095845043\n",
      "Skipping ARIMA fitting for non-stationary series: Judo (equity)\n",
      "All zero values for Lacrosse (equity), skipping.\n",
      "Checking stationarity for Luge (equity):\n",
      "ADF Statistic: -1.2561506733693109, p-value: 0.6489872321551478\n",
      "Skipping ARIMA fitting for non-stationary series: Luge (equity)\n",
      "All zero values for Military Ski Patrol (equity), skipping.\n",
      "Checking stationarity for Modern Pentathlon (equity):\n",
      "ADF Statistic: -0.5537749241945384, p-value: 0.881088714592801\n",
      "Skipping ARIMA fitting for non-stationary series: Modern Pentathlon (equity)\n",
      "Insufficient data for Motorboating (equity)\n",
      "All zero values for Nordic Combined (equity), skipping.\n",
      "All zero values for Polo (equity), skipping.\n",
      "All zero values for Racquets (equity), skipping.\n",
      "Checking stationarity for Rhythmic Gymnastics (equity):\n",
      "Series is constant, skipping stationarity test.\n",
      "Skipping ARIMA fitting for non-stationary series: Rhythmic Gymnastics (equity)\n",
      "All zero values for Roque (equity), skipping.\n",
      "Checking stationarity for Rowing (equity):\n",
      "ADF Statistic: -0.3155227292190863, p-value: 0.923276895421747\n",
      "Skipping ARIMA fitting for non-stationary series: Rowing (equity)\n",
      "Checking stationarity for Rugby (equity):\n",
      "ADF Statistic: nan, p-value: nan\n",
      "Skipping ARIMA fitting for non-stationary series: Rugby (equity)\n",
      "Insufficient data for Rugby Sevens (equity)\n",
      "Checking stationarity for Sailing (equity):\n",
      "ADF Statistic: 1.9024429139436023, p-value: 0.9985319391026038\n",
      "Skipping ARIMA fitting for non-stationary series: Sailing (equity)\n",
      "Checking stationarity for Shooting (equity):\n",
      "ADF Statistic: 0.7784862759963214, p-value: 0.9912808384991549\n",
      "Skipping ARIMA fitting for non-stationary series: Shooting (equity)\n",
      "Insufficient data for Short Track Speed Skating (equity)\n",
      "All zero values for Skeleton (equity), skipping.\n",
      "All zero values for Ski Jumping (equity), skipping.\n",
      "All zero values for Snowboarding (equity), skipping.\n",
      "Insufficient data for Softball (equity)\n",
      "Checking stationarity for Speed Skating (equity):\n",
      "ADF Statistic: -27.179005996963948, p-value: 0.0\n",
      "Optimal ARIMA order: (0, 1, 0)\n",
      "Optimal SARIMA order: (0, 1, 0), Seasonal: (0, 0, 0, 0)\n",
      "Constant series detected for Speed Skating (equity). Predicting constant value: 0.0\n",
      "Constant series detected for Speed Skating (equity). Predicting constant value: 0.0\n",
      "Constant series detected for Speed Skating (equity). Predicting constant value: 0.0\n",
      "Constant series detected for Speed Skating (equity). Predicting constant value: 0.0\n",
      "Constant series detected for Speed Skating (equity). Predicting constant value: 0.0\n",
      "Constant series detected for Speed Skating (equity). Predicting constant value: 0.0\n",
      "Metrics for Speed Skating (equity) - MSE: 0.009706979182885305, R2: 0.7588615052287947\n",
      "Constant series detected for Speed Skating (equity). Predicting constant value: 0.0\n",
      "Constant series detected for Speed Skating (equity). Predicting constant value: 0.0\n",
      "Constant series detected for Speed Skating (equity). Predicting constant value: 0.0\n",
      "Constant series detected for Speed Skating (equity). Predicting constant value: 0.0\n",
      "Constant series detected for Speed Skating (equity). Predicting constant value: 0.0\n",
      "Constant series detected for Speed Skating (equity). Predicting constant value: 0.0\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -5.15786D-01    |proj g|=  9.99798D-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      "\n",
      " Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate    5    f= -5.19866D-01    |proj g|=  2.74160D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      5     46      2     0     0   2.742D-05  -5.199D-01\n",
      "  F = -0.51986604430303807     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -5.77483D-01    |proj g|=  9.35164D-01\n",
      "\n",
      "At iterate    5    f= -5.80691D-01    |proj g|=  1.55749D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      5     46      2     0     0   1.557D-05  -5.807D-01\n",
      "  F = -0.58069089344556057     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -6.38221D-01    |proj g|=  8.87023D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      4      7      1     0     0   9.643D-06  -6.408D-01\n",
      "  F = -0.64080843935548626     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -6.76889D-01    |proj g|=  8.30741D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      4      7      1     0     0   5.586D-06  -6.790D-01\n",
      "  F = -0.67902118874118966     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -7.20420D-01    |proj g|=  7.89959D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      4      7      1     0     0   3.479D-06  -7.222D-01\n",
      "  F = -0.72220693291259452     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -7.65860D-01    |proj g|=  7.58802D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      4      7      1     0     0   2.367D-06  -7.674D-01\n",
      "  F = -0.76737909901310397     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -8.02495D-01    |proj g|=  7.26953D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      4      7      1     0     0   1.531D-06  -8.038D-01\n",
      "  F = -0.80380175501591977     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -8.37595D-01    |proj g|=  6.99343D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      4      7      1     0     0   9.699D-07  -8.387D-01\n",
      "  F = -0.83873188770217300     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "Metrics for Speed Skating (equity) - MSE: 0.009706979182885305, R2: 0.7588615052287947\n",
      "Checking stationarity for Swimming (equity):\n",
      "ADF Statistic: -3.3767891827098215, p-value: 0.011776038796076664\n",
      "Optimal ARIMA order: (0, 1, 0)\n",
      "Optimal SARIMA order: (0, 1, 0), Seasonal: (0, 0, 0, 0)\n",
      "Constant series detected for Swimming (equity). Predicting constant value: 0.0\n",
      "Constant series detected for Swimming (equity). Predicting constant value: 0.0\n",
      "Constant series detected for Swimming (equity). Predicting constant value: 0.0\n",
      "Constant series detected for Swimming (equity). Predicting constant value: 0.0\n",
      "Metrics for Swimming (equity) - MSE: 0.0030192064071202554, R2: 0.8521825124175009\n",
      "Constant series detected for Swimming (equity). Predicting constant value: 0.0\n",
      "Constant series detected for Swimming (equity). Predicting constant value: 0.0\n",
      "Constant series detected for Swimming (equity). Predicting constant value: 0.0\n",
      "Constant series detected for Swimming (equity). Predicting constant value: 0.0\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -7.65872D-01    |proj g|=  1.90713D+00\n",
      "\n",
      "At iterate    5    f= -7.73238D-01    |proj g|=  3.38086D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      6     48      2     0     0   3.381D-05  -7.732D-01\n",
      "  F = -0.77323767737183502     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -8.66983D-01    |proj g|=  1.76278D+00\n",
      "\n",
      "At iterate    5    f= -8.72347D-01    |proj g|=  1.30808D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      5      9      1     0     0   1.308D-03  -8.723D-01\n",
      "  F = -0.87234664478896684     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -8.81722D-01    |proj g|=  1.51855D+00\n",
      "\n",
      "At iterate    5    f= -8.85803D-01    |proj g|=  5.69895D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      5     19      1     0     0   5.699D-04  -8.858D-01\n",
      "  F = -0.88580251497933693     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -9.14368D-01    |proj g|=  1.36574D+00\n",
      "\n",
      "At iterate    5    f= -9.17575D-01    |proj g|=  2.44741D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      5     19      1     0     0   2.447D-04  -9.176D-01\n",
      "  F = -0.91757515580687610     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -9.79151D-01    |proj g|=  1.29494D+00\n",
      "\n",
      "At iterate    5    f= -9.81739D-01    |proj g|=  1.55456D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      5     15      1     0     0   1.555D-04  -9.817D-01\n",
      "  F = -0.98173884804048694     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.03304D+00    |proj g|=  1.22875D+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      "\n",
      " Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate    5    f= -1.03517D+00    |proj g|=  9.75142D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      5     24      1     0     0   9.751D-05  -1.035D+00\n",
      "  F =  -1.0351678166294052     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.08536D+00    |proj g|=  1.17559D+00\n",
      "\n",
      "At iterate    5    f= -1.08715D+00    |proj g|=  6.53249D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      5     17      1     0     0   6.532D-05  -1.087D+00\n",
      "  F =  -1.0871499309025041     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.13220D+00    |proj g|=  1.12774D+00\n",
      "\n",
      "At iterate    5    f= -1.13371D+00    |proj g|=  4.63339D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      5     17      1     0     0   4.633D-05  -1.134D+00\n",
      "  F =  -1.1337147864334776     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.15060D+00    |proj g|=  1.05684D+00\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      5     47      2     0     0   2.562D-05  -1.152D+00\n",
      "  F =  -1.1519035145824563     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.17959D+00    |proj g|=  1.00821D+00\n",
      "\n",
      "At iterate    5    f= -1.18072D+00    |proj g|=  1.68509D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      5     14      1     0     0   1.685D-05  -1.181D+00\n",
      "  F =  -1.1807243592227556     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.21400D+00    |proj g|=  9.72402D-01\n",
      "\n",
      "At iterate    5    f= -1.21500D+00    |proj g|=  1.22000D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      5     41      2     0     0   1.220D-05  -1.215D+00\n",
      "  F =  -1.2149989976545206     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.22338D+00    |proj g|=  9.17554D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      4      7      1     0     0   7.730D-06  -1.224D+00\n",
      "  F =  -1.2242599571834891     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.25324D+00    |proj g|=  8.88733D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      4      7      1     0     0   5.525D-06  -1.254D+00\n",
      "  F =  -1.2540216906507866     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.28308D+00    |proj g|=  8.63691D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      4      7      1     0     0   4.093D-06  -1.284D+00\n",
      "  F =  -1.2837871843871691     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.30045D+00    |proj g|=  8.31085D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      4      7      1     0     0   3.288D-06  -1.301D+00\n",
      "  F =  -1.3010860201213550     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.30719D+00    |proj g|=  7.93231D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      4      7      1     0     0   2.654D-06  -1.308D+00\n",
      "  F =  -1.3077679769933750     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.32730D+00    |proj g|=  7.69853D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      4      7      1     0     0   1.507D-06  -1.328D+00\n",
      "  F =  -1.3278210537506416     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.35212D+00    |proj g|=  7.52397D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      4      7      1     0     0   7.334D-07  -1.353D+00\n",
      "  F =  -1.3525969807663001     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.33845D+00    |proj g|=  7.08402D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      4      7      1     0     0   7.847D-07  -1.339D+00\n",
      "  F =  -1.3388921956924056     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.34471D+00    |proj g|=  6.81977D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      4      7      1     0     0   2.013D-07  -1.345D+00\n",
      "  F =  -1.3451142877301090     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.36401D+00    |proj g|=  6.66893D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      4      7      1     0     0   2.671D-07  -1.364D+00\n",
      "  F =  -1.3643830653732800     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.38249D+00    |proj g|=  6.52580D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      4      7      1     0     0   3.698D-07  -1.383D+00\n",
      "  F =  -1.3828380871105355     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.39782D+00    |proj g|=  6.37441D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      4      7      1     0     0   1.384D-06  -1.398D+00\n",
      "  F =  -1.3981378474532105     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.41527D+00    |proj g|=  6.25014D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      4      7      1     0     0   4.412D-08  -1.416D+00\n",
      "  F =  -1.4155705420900113     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.43275D+00    |proj g|=  6.13657D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      4      7      1     0     0   6.436D-07  -1.433D+00\n",
      "  F =  -1.4330273528272726     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "Metrics for Swimming (equity) - MSE: 0.0030192064071202554, R2: 0.8521825124175009\n",
      "Checking stationarity for Synchronized Swimming (equity):\n",
      "Series is constant, skipping stationarity test.\n",
      "Skipping ARIMA fitting for non-stationary series: Synchronized Swimming (equity)\n",
      "Checking stationarity for Table Tennis (equity):\n",
      "ADF Statistic: -2.0851132446624825, p-value: 0.25054261923237275\n",
      "Skipping ARIMA fitting for non-stationary series: Table Tennis (equity)\n",
      "Checking stationarity for Taekwondo (equity):\n",
      "ADF Statistic: -3.080450014755737, p-value: 0.028034212798134468\n",
      "Optimal ARIMA order: (1, 0, 0)\n",
      "Optimal SARIMA order: (1, 0, 0), Seasonal: (0, 0, 0, 0)\n",
      "Metrics for Taekwondo (equity) - MSE: 0.0002623956927650653, R2: -25.03621261461379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.57813D+03    |proj g|=  7.75715D+05\n",
      "\n",
      "At iterate    5    f=  1.05605D-01    |proj g|=  7.08447D-01\n",
      "\n",
      "At iterate   10    f= -6.87304D-01    |proj g|=  1.39719D+00\n",
      "\n",
      "At iterate   15    f= -1.03328D+00    |proj g|=  5.94506D+00\n",
      "\n",
      "At iterate   20    f= -1.11155D+00    |proj g|=  3.86725D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     23     49      1     0     0   6.050D-06  -1.112D+00\n",
      "  F =  -1.1115851628762357     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  7.92141D+04    |proj g|=  1.28457D+08\n",
      "\n",
      "At iterate    5    f=  5.74136D-01    |proj g|=  5.31079D-01\n",
      "\n",
      "At iterate   10    f= -6.56985D-01    |proj g|=  1.01901D+00\n",
      "\n",
      "At iterate   15    f= -1.33792D+00    |proj g|=  2.19749D+01\n",
      "\n",
      "At iterate   20    f= -1.62575D+00    |proj g|=  1.17356D+00\n",
      "\n",
      "At iterate   25    f= -1.63188D+00    |proj g|=  3.52172D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     25     60      1     0     0   3.522D-03  -1.632D+00\n",
      "  F =  -1.6318837290173445     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.28422D+03    |proj g|=  6.31967D+05\n",
      "\n",
      "At iterate    5    f= -6.37026D-01    |proj g|=  3.12207D-01\n",
      "\n",
      "At iterate   10    f= -1.24767D+00    |proj g|=  1.33666D+01\n",
      "\n",
      "At iterate   15    f= -2.02630D+00    |proj g|=  1.14761D+01\n",
      "\n",
      "At iterate   20    f= -2.07494D+00    |proj g|=  1.72404D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     23     66      1     0     0   3.474D-03  -2.075D+00\n",
      "  F =  -2.0749379820523464     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  3.03692D+03    |proj g|=  9.60356D+05\n",
      "\n",
      "At iterate    5    f= -6.45071D-01    |proj g|=  1.69784D+00\n",
      "\n",
      "At iterate   10    f= -1.41685D+00    |proj g|=  2.90665D+01\n",
      "\n",
      "At iterate   15    f= -2.21078D+00    |proj g|=  1.19291D+01\n",
      "\n",
      "At iterate   20    f= -2.31882D+00    |proj g|=  6.29215D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     24     63      1     0     0   4.624D-03  -2.319D+00\n",
      "  F =  -2.3191652523389186     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.51609D+03    |proj g|=  3.38657D+05\n",
      "\n",
      "At iterate    5    f=  4.69540D-02    |proj g|=  1.21977D+00\n",
      "\n",
      "At iterate   10    f= -1.60972D+00    |proj g|=  2.28538D+01\n",
      "\n",
      "At iterate   15    f= -2.32894D+00    |proj g|=  5.88067D+01\n",
      "\n",
      "At iterate   20    f= -2.48837D+00    |proj g|=  2.54468D+00\n",
      "\n",
      "At iterate   25    f= -2.49006D+00    |proj g|=  1.74946D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     25     64      1     0     0   1.749D-04  -2.490D+00\n",
      "  F =  -2.4900586971148297     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "Metrics for Taekwondo (equity) - MSE: 7.853396960781068e-05, R2: -6.792533134335071\n",
      "Checking stationarity for Tennis (equity):\n",
      "ADF Statistic: -3.1448211870454306, p-value: 0.023409179668744205\n",
      "Optimal ARIMA order: (1, 1, 0)\n",
      "Optimal SARIMA order: (1, 1, 0), Seasonal: (0, 0, 0, 0)\n",
      "Fitting error for Tennis (equity): too many indices for array: array is 0-dimensional, but 1 were indexed\n",
      "No predictions made for Tennis (equity).\n",
      "Fitting error for Tennis (equity): too many indices for array: array is 0-dimensional, but 1 were indexed\n",
      "No predictions made for Tennis (equity).\n",
      "Checking stationarity for Trampolining (equity):\n",
      "Series is constant, skipping stationarity test.\n",
      "Skipping ARIMA fitting for non-stationary series: Trampolining (equity)\n",
      "Checking stationarity for Triathlon (equity):\n",
      "ADF Statistic: -45.7760643131316, p-value: 0.0\n",
      "Optimal ARIMA order: (0, 0, 0)\n",
      "Optimal SARIMA order: (0, 0, 0), Seasonal: (0, 0, 0, 0)\n",
      "Constant series detected for Triathlon (equity). Predicting constant value: 0.48\n",
      "Metrics for Triathlon (equity) - MSE: 0.00012292617506839604, R2: -33.69822392514562\n",
      "Constant series detected for Triathlon (equity). Predicting constant value: 0.48\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  7.11052D-01    |proj g|=  4.11953D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     15      1     0     0   4.119D-05   7.111D-01\n",
      "  F =  0.71105224293183722     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  7.16014D-01    |proj g|=  4.07885D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     14      1     0     0   4.078D-05   7.160D-01\n",
      "  F =  0.71601371230349320     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  7.18476D-01    |proj g|=  4.05882D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     20      1     0     0   4.058D-05   7.185D-01\n",
      "  F =  0.71847610616076973     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  7.19948D-01    |proj g|=  4.04689D-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     16      1     0     0   4.047D-05   7.199D-01\n",
      "  F =  0.71994774256981342     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  7.20926D-01    |proj g|=  4.03897D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     18      1     0     0   4.038D-05   7.209D-01\n",
      "  F =  0.72092643265595602     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "Metrics for Triathlon (equity) - MSE: 0.20843792130054759, R2: -58834.521919999235\n",
      "All zero values for Tug-Of-War (equity), skipping.\n",
      "Checking stationarity for Volleyball (equity):\n",
      "ADF Statistic: -1.780273559871093, p-value: 0.3902983628540808\n",
      "Skipping ARIMA fitting for non-stationary series: Volleyball (equity)\n",
      "Checking stationarity for Water Polo (equity):\n",
      "ADF Statistic: 0.6542810672319648, p-value: 0.9888798840435545\n",
      "Skipping ARIMA fitting for non-stationary series: Water Polo (equity)\n",
      "Checking stationarity for Weightlifting (equity):\n",
      "ADF Statistic: 0.25258770163732097, p-value: 0.9750615574948117\n",
      "Skipping ARIMA fitting for non-stationary series: Weightlifting (equity)\n",
      "Checking stationarity for Wrestling (equity):\n",
      "ADF Statistic: 7.654652327755364, p-value: 1.0\n",
      "Skipping ARIMA fitting for non-stationary series: Wrestling (equity)\n",
      "All zero values for climbing (equity), skipping.\n",
      "All zero values for Fitness (equity), skipping.\n",
      "All zero values for Headis (equity), skipping.\n",
      "\n",
      "Processing parameter: popularity\n",
      "Checking stationarity for Alpine Skiing (popularity):\n",
      "ADF Statistic: -4.654641741675395, p-value: 0.00010230915252272946\n",
      "Optimal ARIMA order: (0, 0, 0)\n",
      "Optimal SARIMA order: (0, 0, 0), Seasonal: (0, 0, 0, 0)\n",
      "Constant series detected for Alpine Skiing (popularity). Predicting constant value: 0.0139189189189189\n",
      "Metrics for Alpine Skiing (popularity) - MSE: 0.0002023574493679255, R2: -1.781301496797223\n",
      "Constant series detected for Alpine Skiing (popularity). Predicting constant value: 0.0139189189189189\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.92136D+00    |proj g|=  7.96415D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     18      1     0     0   7.964D-03  -1.921D+00\n",
      "  F =  -1.9213566526362462     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.87369D+00    |proj g|=  7.24018D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     18      1     0     0   7.240D-03  -1.874D+00\n",
      "  F =  -1.8736935350165236     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.68432D+00    |proj g|=  4.95789D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     19      1     0     0   4.958D-03  -1.684D+00\n",
      "  F =  -1.6843221578914778     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.72650D+00    |proj g|=  5.39420D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     17      1     0     0   5.394D-03  -1.727D+00\n",
      "  F =  -1.7265019772256918     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.72531D+00    |proj g|=  5.38138D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     15      1     0     0   5.381D-03  -1.725D+00\n",
      "  F =  -1.7253126104054310     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.73446D+00    |proj g|=  5.48075D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     18      1     0     0   5.481D-03  -1.734D+00\n",
      "  F =  -1.7344625392065391     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.77311D+00    |proj g|=  5.92109D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     18      1     0     0   5.921D-03  -1.773D+00\n",
      "  F =  -1.7731099093979359     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.78339D+00    |proj g|=  6.04404D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     15      1     0     0   6.044D-03  -1.783D+00\n",
      "  F =  -1.7833876347301520     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.79300D+00    |proj g|=  6.16139D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     18      1     0     0   6.161D-03  -1.793D+00\n",
      "  F =  -1.7930045003734782     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.80505D+00    |proj g|=  6.31162D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     18      1     0     0   6.312D-03  -1.805D+00\n",
      "  F =  -1.8050518801815463     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.79237D+00    |proj g|=  6.15363D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     16      1     0     0   6.154D-03  -1.792D+00\n",
      "  F =  -1.7923740810708859     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "Metrics for Alpine Skiing (popularity) - MSE: 0.001686743612963051, R2: -22.183443703708228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insufficient data for Alpinism (popularity)\n",
      "Checking stationarity for Archery (popularity):\n",
      "ADF Statistic: -8.78610516657412, p-value: 2.306386173290792e-14\n",
      "Optimal ARIMA order: (0, 0, 0)\n",
      "Optimal SARIMA order: (0, 0, 0), Seasonal: (0, 0, 0, 0)\n",
      "Constant series detected for Archery (popularity). Predicting constant value: 0.0165289256198347\n",
      "Metrics for Archery (popularity) - MSE: 0.0001641980766328963, R2: -0.5194680677085335\n",
      "Constant series detected for Archery (popularity). Predicting constant value: 0.0165289256198347\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.80494D+00    |proj g|=  6.31017D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     20      1     0     0   6.310D-03  -1.805D+00\n",
      "  F =  -1.8049374949917310     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.91876D+00    |proj g|=  7.92289D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     17      1     0     0   7.923D-03  -1.919D+00\n",
      "  F =  -1.9187590547711428     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.01219D+00    |proj g|=  9.55025D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     15      1     0     0   9.550D-03  -2.012D+00\n",
      "  F =  -2.0121878702652363     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.11628D+00    |proj g|=  1.17599D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     18      1     0     0   1.176D-02  -2.116D+00\n",
      "  F =  -2.1162787595059553     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.20309D+00    |proj g|=  1.39889D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     17      1     0     0   1.399D-02  -2.203D+00\n",
      "  F =  -2.2030886718033718     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.27365D+00    |proj g|=  1.61084D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     21      1     0     0   1.611D-02  -2.274D+00\n",
      "  F =  -2.2736506393410223     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.33033D+00    |proj g|=  1.80413D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     18      1     0     0   1.804D-02  -2.330D+00\n",
      "  F =  -2.3303316329857902     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.35577D+00    |proj g|=  1.89824D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     19      1     0     0   1.898D-02  -2.356D+00\n",
      "  F =  -2.3557656038605455     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.38510D+00    |proj g|=  2.01289D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     17      1     0     0   2.013D-02  -2.385D+00\n",
      "  F =  -2.3850987667667560     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.40816D+00    |proj g|=  2.10787D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     19      1     0     0   2.108D-02  -2.408D+00\n",
      "  F =  -2.4081612168367150     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.43081D+00    |proj g|=  2.20550D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     19      1     0     0   2.205D-02  -2.431D+00\n",
      "  F =  -2.4308067054292328     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.44846D+00    |proj g|=  2.28474D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     19      1     0     0   2.285D-02  -2.448D+00\n",
      "  F =  -2.4484632502682953     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.46794D+00    |proj g|=  2.37546D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     19      1     0     0   2.375D-02  -2.468D+00\n",
      "  F =  -2.4679399830368314     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.48249D+00    |proj g|=  2.44559D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     17      1     0     0   2.446D-02  -2.482D+00\n",
      "  F =  -2.4824935851777052     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.49764D+00    |proj g|=  2.52078D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     17      1     0     0   2.521D-02  -2.498D+00\n",
      "  F =  -2.4976413138472586     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.51652D+00    |proj g|=  2.61773D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     18      1     0     0   2.618D-02  -2.517D+00\n",
      "  F =  -2.5165193902623715     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "Metrics for Archery (popularity) - MSE: 0.0002863276692459974, R2: -1.6496397475677886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking stationarity for Art Competitions (popularity):\n",
      "ADF Statistic: -1.5795560652827265, p-value: 0.493854500508376\n",
      "Skipping ARIMA fitting for non-stationary series: Art Competitions (popularity)\n",
      "Checking stationarity for Athletics (popularity):\n",
      "ADF Statistic: -4.0708356076159316, p-value: 0.0010817968907030164\n",
      "Optimal ARIMA order: (0, 0, 1)\n",
      "Optimal SARIMA order: (0, 0, 1), Seasonal: (0, 0, 0, 0)\n",
      "Metrics for Athletics (popularity) - MSE: 0.0017610554341612335, R2: -0.4017217278608911\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  3.72605D+00    |proj g|=  1.56391D+02\n",
      "\n",
      "At iterate    5    f= -2.27920D-01    |proj g|=  7.43520D-01\n",
      "\n",
      "At iterate   10    f= -2.71002D-01    |proj g|=  6.66957D-03\n",
      "\n",
      "At iterate   15    f= -2.73090D-01    |proj g|=  6.57654D-02\n",
      "\n",
      "At iterate   20    f= -2.73297D-01    |proj g|=  1.60495D-02\n",
      "\n",
      "At iterate   25    f= -2.73326D-01    |proj g|=  5.61992D-03\n",
      "\n",
      "At iterate   30    f= -2.73330D-01    |proj g|=  4.34354D-04\n",
      "\n",
      "At iterate   35    f= -2.73330D-01    |proj g|=  3.19154D-04\n",
      "\n",
      "At iterate   40    f= -2.73331D-01    |proj g|=  2.37024D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     42     54      1     0     0   1.430D-04  -2.733D-01\n",
      "  F = -0.27333052528029761     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  3.67653D+00    |proj g|=  1.72827D+02\n",
      "\n",
      "At iterate    5    f= -2.90582D-01    |proj g|=  2.20454D+00\n",
      "\n",
      "At iterate   10    f= -3.18249D-01    |proj g|=  3.59153D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     13     22      1     0     0   1.201D-05  -3.183D-01\n",
      "  F = -0.31825000452771662     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  3.13101D+00    |proj g|=  1.25367D+02\n",
      "\n",
      "At iterate    5    f= -2.89152D-01    |proj g|=  5.50974D-01\n",
      "\n",
      "At iterate   10    f= -3.51304D-01    |proj g|=  1.91670D-01\n",
      "\n",
      "At iterate   15    f= -3.53990D-01    |proj g|=  1.02815D-02\n",
      "\n",
      "At iterate   20    f= -3.54391D-01    |proj g|=  9.35274D-03\n",
      "\n",
      "At iterate   25    f= -3.54424D-01    |proj g|=  1.28757D-04\n",
      "\n",
      "At iterate   30    f= -3.54430D-01    |proj g|=  1.16047D-03\n",
      "\n",
      "At iterate   35    f= -3.54430D-01    |proj g|=  2.91493D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     36     52      1     0     0   1.404D-05  -3.544D-01\n",
      "  F = -0.35443015717633142     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.12505D+00    |proj g|=  4.53754D+02\n",
      "\n",
      "At iterate    5    f= -2.89674D-01    |proj g|=  9.51235D-01\n",
      "\n",
      "At iterate   10    f= -3.94501D-01    |proj g|=  8.85066D-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate   15    f= -3.98818D-01    |proj g|=  1.18260D-02\n",
      "\n",
      "At iterate   20    f= -3.99186D-01    |proj g|=  1.15597D-02\n",
      "\n",
      "At iterate   25    f= -3.99227D-01    |proj g|=  4.23510D-03\n",
      "\n",
      "At iterate   30    f= -3.99231D-01    |proj g|=  1.35689D-03\n",
      "\n",
      "At iterate   35    f= -3.99231D-01    |proj g|=  3.55202D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     37     55      1     0     0   1.557D-05  -3.992D-01\n",
      "  F = -0.39923118060275287     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -5.69419D-02    |proj g|=  8.38734D-01\n",
      "\n",
      "At iterate    5    f= -3.95791D-01    |proj g|=  1.01739D-01\n",
      "\n",
      "At iterate   10    f= -4.35499D-01    |proj g|=  1.00289D-01\n",
      "\n",
      "At iterate   15    f= -4.37860D-01    |proj g|=  2.53589D-02\n",
      "\n",
      "At iterate   20    f= -4.38056D-01    |proj g|=  5.84783D-03\n",
      "\n",
      "At iterate   25    f= -4.38070D-01    |proj g|=  9.65587D-04\n",
      "\n",
      "At iterate   30    f= -4.38072D-01    |proj g|=  5.92735D-04\n",
      "\n",
      "At iterate   35    f= -4.38072D-01    |proj g|=  2.29479D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     35     43      1     0     0   2.295D-05  -4.381D-01\n",
      "  F = -0.43807237234421464     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -7.44073D-02    |proj g|=  9.03408D-01\n",
      "\n",
      "At iterate    5    f= -4.48605D-01    |proj g|=  3.47543D-01\n",
      "\n",
      "At iterate   10    f= -4.93804D-01    |proj g|=  6.68172D-02\n",
      "\n",
      "At iterate   15    f= -4.96467D-01    |proj g|=  9.22828D-03\n",
      "\n",
      "At iterate   20    f= -4.96674D-01    |proj g|=  9.22371D-03\n",
      "\n",
      "At iterate   25    f= -4.96711D-01    |proj g|=  2.34151D-03\n",
      "\n",
      "At iterate   30    f= -4.96714D-01    |proj g|=  5.06059D-04\n",
      "\n",
      "At iterate   35    f= -4.96714D-01    |proj g|=  2.69699D-04\n",
      "\n",
      "At iterate   40    f= -4.96714D-01    |proj g|=  7.12200D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     40     49      1     0     0   7.122D-05  -4.967D-01\n",
      "  F = -0.49671406090993492     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.03313D-01    |proj g|=  8.68940D-01\n",
      "\n",
      "At iterate    5    f= -4.06970D-01    |proj g|=  4.26629D-01\n",
      "\n",
      "At iterate   10    f= -5.31124D-01    |proj g|=  1.74011D-01\n",
      "\n",
      "At iterate   15    f= -5.37656D-01    |proj g|=  1.08696D-01\n",
      "\n",
      "At iterate   20    f= -5.38219D-01    |proj g|=  1.15137D-02\n",
      "\n",
      "At iterate   25    f= -5.38263D-01    |proj g|=  8.38114D-03\n",
      "\n",
      "At iterate   30    f= -5.38269D-01    |proj g|=  4.67711D-04\n",
      "\n",
      "At iterate   35    f= -5.38270D-01    |proj g|=  4.09293D-04\n",
      "\n",
      "At iterate   40    f= -5.38270D-01    |proj g|=  1.17769D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     42     47      1     0     0   8.782D-05  -5.383D-01\n",
      "  F = -0.53826961945101170     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.22857D-01    |proj g|=  8.67953D-01\n",
      "\n",
      "At iterate    5    f= -5.36005D-01    |proj g|=  2.90537D-01\n",
      "\n",
      "At iterate   10    f= -5.74398D-01    |proj g|=  1.08223D-01\n",
      "\n",
      "At iterate   15    f= -5.76475D-01    |proj g|=  9.19505D-04\n",
      "\n",
      "At iterate   20    f= -5.76755D-01    |proj g|=  6.08799D-03\n",
      "\n",
      "At iterate   25    f= -5.76778D-01    |proj g|=  1.63460D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     26     40      1     0     0   1.197D-03  -5.768D-01\n",
      "  F = -0.57677848314142266     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.44256D-01    |proj g|=  9.29799D-01\n",
      "\n",
      "At iterate    5    f= -5.66433D-01    |proj g|=  1.61312D-01\n",
      "\n",
      "At iterate   10    f= -6.14752D-01    |proj g|=  1.50687D-01\n",
      "\n",
      "At iterate   15    f= -6.17598D-01    |proj g|=  1.30034D-03\n",
      "\n",
      "At iterate   20    f= -6.17822D-01    |proj g|=  8.65635D-03\n",
      "\n",
      "At iterate   25    f= -6.17840D-01    |proj g|=  2.96594D-03\n",
      "\n",
      "At iterate   30    f= -6.17842D-01    |proj g|=  1.52893D-03\n",
      "\n",
      "At iterate   35    f= -6.17842D-01    |proj g|=  2.05332D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     38     43      1     0     0   1.893D-04  -6.178D-01\n",
      "  F = -0.61784243786496673     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.69797D-01    |proj g|=  9.64163D-01\n",
      "\n",
      "At iterate    5    f= -5.93874D-01    |proj g|=  1.71218D-01\n",
      "\n",
      "At iterate   10    f= -6.53331D-01    |proj g|=  1.06588D-01\n",
      "\n",
      "At iterate   15    f= -6.56741D-01    |proj g|=  2.13390D-02\n",
      "\n",
      "At iterate   20    f= -6.57000D-01    |proj g|=  1.07411D-02\n",
      "\n",
      "At iterate   25    f= -6.57034D-01    |proj g|=  2.18048D-03\n",
      "\n",
      "At iterate   30    f= -6.57037D-01    |proj g|=  8.35572D-04\n",
      "\n",
      "At iterate   35    f= -6.57037D-01    |proj g|=  2.28701D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     39     47      1     0     0   9.098D-06  -6.570D-01\n",
      "  F = -0.65703736502523935     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.92406D-01    |proj g|=  9.64816D-01\n",
      "\n",
      "At iterate    5    f= -6.20717D-01    |proj g|=  1.54032D-01\n",
      "\n",
      "At iterate   10    f= -6.82578D-01    |proj g|=  1.10976D-01\n",
      "\n",
      "At iterate   15    f= -6.86110D-01    |proj g|=  2.20064D-02\n",
      "\n",
      "At iterate   20    f= -6.86375D-01    |proj g|=  9.13043D-03\n",
      "\n",
      "At iterate   25    f= -6.86412D-01    |proj g|=  2.13987D-03\n",
      "\n",
      "At iterate   30    f= -6.86415D-01    |proj g|=  8.38596D-04\n",
      "\n",
      "At iterate   35    f= -6.86415D-01    |proj g|=  2.25149D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     39     47      1     0     0   1.270D-05  -6.864D-01\n",
      "  F = -0.68641496244316924     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.10466D-01    |proj g|=  9.80324D-01\n",
      "\n",
      "At iterate    5    f= -6.39906D-01    |proj g|=  4.56102D-01\n",
      "\n",
      "At iterate   10    f= -7.11566D-01    |proj g|=  8.36936D-02\n",
      "\n",
      "At iterate   15    f= -7.15407D-01    |proj g|=  3.49963D-02\n",
      "\n",
      "At iterate   20    f= -7.15704D-01    |proj g|=  8.95707D-04\n",
      "\n",
      "At iterate   25    f= -7.15731D-01    |proj g|=  1.91708D-03\n",
      "\n",
      "At iterate   30    f= -7.15733D-01    |proj g|=  7.35271D-04\n",
      "\n",
      "At iterate   35    f= -7.15733D-01    |proj g|=  1.96814D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     39     47      1     0     0   1.117D-04  -7.157D-01\n",
      "  F = -0.71573288228385834     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.23360D-01    |proj g|=  9.79531D-01\n",
      "\n",
      "At iterate    5    f= -6.55306D-01    |proj g|=  3.72574D-01\n",
      "\n",
      "At iterate   10    f= -7.27731D-01    |proj g|=  8.77974D-02\n",
      "\n",
      "At iterate   15    f= -7.31646D-01    |proj g|=  2.39011D-02\n",
      "\n",
      "At iterate   20    f= -7.31951D-01    |proj g|=  1.08820D-03\n",
      "\n",
      "At iterate   25    f= -7.31977D-01    |proj g|=  3.04972D-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate   30    f= -7.31979D-01    |proj g|=  1.56204D-03\n",
      "\n",
      "At iterate   35    f= -7.31979D-01    |proj g|=  2.70252D-04\n",
      "\n",
      "At iterate   40    f= -7.31979D-01    |proj g|=  1.90838D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     40     49      1     0     0   1.908D-04  -7.320D-01\n",
      "  F = -0.73197903888201044     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.37162D-01    |proj g|=  1.01176D+00\n",
      "\n",
      "At iterate    5    f= -6.66507D-01    |proj g|=  9.72930D-01\n",
      "\n",
      "At iterate   10    f= -7.55757D-01    |proj g|=  8.93361D-02\n",
      "\n",
      "At iterate   15    f= -7.60783D-01    |proj g|=  2.84845D-02\n",
      "\n",
      "At iterate   20    f= -7.61167D-01    |proj g|=  5.71867D-03\n",
      "\n",
      "At iterate   25    f= -7.61197D-01    |proj g|=  2.06346D-03\n",
      "\n",
      "At iterate   30    f= -7.61200D-01    |proj g|=  1.18114D-03\n",
      "\n",
      "At iterate   35    f= -7.61200D-01    |proj g|=  2.44873D-04\n",
      "\n",
      "At iterate   40    f= -7.61200D-01    |proj g|=  8.98867D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     40     47      1     0     0   8.989D-05  -7.612D-01\n",
      "  F = -0.76120031886662298     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.51895D-01    |proj g|=  1.01124D+00\n",
      "\n",
      "At iterate    5    f= -6.81459D-01    |proj g|=  9.82477D-01\n",
      "\n",
      "At iterate   10    f= -7.69866D-01    |proj g|=  8.80241D-02\n",
      "\n",
      "At iterate   15    f= -7.74768D-01    |proj g|=  2.45518D-02\n",
      "\n",
      "At iterate   20    f= -7.75140D-01    |proj g|=  7.68581D-03\n",
      "\n",
      "At iterate   25    f= -7.75169D-01    |proj g|=  2.49610D-03\n",
      "\n",
      "At iterate   30    f= -7.75173D-01    |proj g|=  6.82517D-04\n",
      "\n",
      "At iterate   35    f= -7.75173D-01    |proj g|=  2.61275D-04\n",
      "\n",
      "At iterate   40    f= -7.75173D-01    |proj g|=  8.31509D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     41     48      1     0     0   4.931D-05  -7.752D-01\n",
      "  F = -0.77517323025160889     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.66957D-01    |proj g|=  1.02802D+00\n",
      "\n",
      "At iterate    5    f= -6.99967D-01    |proj g|=  9.65981D-01\n",
      "\n",
      "At iterate   10    f= -7.96918D-01    |proj g|=  9.58658D-02\n",
      "\n",
      "At iterate   15    f= -8.02606D-01    |proj g|=  3.31019D-02\n",
      "\n",
      "At iterate   20    f= -8.02994D-01    |proj g|=  3.09278D-02\n",
      "\n",
      "At iterate   25    f= -8.03068D-01    |proj g|=  2.86353D-03\n",
      "\n",
      "At iterate   30    f= -8.03074D-01    |proj g|=  8.42840D-04\n",
      "\n",
      "At iterate   35    f= -8.03074D-01    |proj g|=  3.03633D-04\n",
      "\n",
      "At iterate   40    f= -8.03074D-01    |proj g|=  1.12976D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     41     49      1     0     0   5.883D-05  -8.031D-01\n",
      "  F = -0.80307448531896453     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.79476D-01    |proj g|=  1.01785D+00\n",
      "\n",
      "At iterate    5    f= -7.11766D-01    |proj g|=  1.02711D+00\n",
      "\n",
      "At iterate   10    f= -8.03111D-01    |proj g|=  8.46406D-02\n",
      "\n",
      "At iterate   15    f= -8.08337D-01    |proj g|=  2.82863D-02\n",
      "\n",
      "At iterate   20    f= -8.08708D-01    |proj g|=  1.61930D-02\n",
      "\n",
      "At iterate   25    f= -8.08764D-01    |proj g|=  2.65353D-03\n",
      "\n",
      "At iterate   30    f= -8.08768D-01    |proj g|=  7.45805D-04\n",
      "\n",
      "At iterate   35    f= -8.08769D-01    |proj g|=  2.80776D-04\n",
      "\n",
      "At iterate   40    f= -8.08769D-01    |proj g|=  7.25708D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     41     48      1     0     0   6.291D-05  -8.088D-01\n",
      "  F = -0.80876869042348820     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.92582D-01    |proj g|=  1.04780D+00\n",
      "\n",
      "At iterate    5    f= -7.25854D-01    |proj g|=  8.62940D-01\n",
      "\n",
      "At iterate   10    f= -8.29652D-01    |proj g|=  1.01565D-01\n",
      "\n",
      "At iterate   15    f= -8.35697D-01    |proj g|=  4.70824D-02\n",
      "\n",
      "At iterate   20    f= -8.36142D-01    |proj g|=  1.32897D-02\n",
      "\n",
      "At iterate   25    f= -8.36188D-01    |proj g|=  5.27902D-03\n",
      "\n",
      "At iterate   30    f= -8.36192D-01    |proj g|=  3.05006D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     32     37      1     0     0   8.927D-06  -8.362D-01\n",
      "  F = -0.83619207117177430     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -6.44385D-01    |proj g|=  3.82668D+00\n",
      "\n",
      "At iterate    5    f= -8.28603D-01    |proj g|=  4.33933D-03\n",
      "\n",
      "At iterate   10    f= -8.28631D-01    |proj g|=  9.58090D-02\n",
      "\n",
      "At iterate   15    f= -8.30324D-01    |proj g|=  3.77285D-01\n",
      "\n",
      "At iterate   20    f= -8.31791D-01    |proj g|=  6.27458D-02\n",
      "\n",
      "At iterate   25    f= -8.31899D-01    |proj g|=  1.45387D-02\n",
      "\n",
      "At iterate   30    f= -8.31916D-01    |proj g|=  1.60842D-03\n",
      "\n",
      "At iterate   35    f= -8.31917D-01    |proj g|=  4.70960D-04\n",
      "\n",
      "At iterate   40    f= -8.31917D-01    |proj g|=  1.76039D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     44     52      1     0     0   8.413D-05  -8.319D-01\n",
      "  F = -0.83191735159942726     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -3.11169D-01    |proj g|=  1.03208D+00\n",
      "\n",
      "At iterate    5    f= -7.49874D-01    |proj g|=  9.92038D-01\n",
      "\n",
      "At iterate   10    f= -8.49060D-01    |proj g|=  8.85293D-02\n",
      "\n",
      "At iterate   15    f= -8.54863D-01    |proj g|=  1.51535D-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate   20    f= -8.55277D-01    |proj g|=  9.16388D-03\n",
      "\n",
      "At iterate   25    f= -8.55335D-01    |proj g|=  2.56856D-03\n",
      "\n",
      "At iterate   30    f= -8.55339D-01    |proj g|=  9.94617D-04\n",
      "\n",
      "At iterate   35    f= -8.55340D-01    |proj g|=  2.70801D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     38     46      1     0     0   2.069D-05  -8.553D-01\n",
      "  F = -0.85533979705832863     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -3.19430D-01    |proj g|=  1.03798D+00\n",
      "\n",
      "At iterate    5    f= -7.56292D-01    |proj g|=  9.52040D-01\n",
      "\n",
      "At iterate   10    f= -8.49050D-01    |proj g|=  6.58600D-02\n",
      "\n",
      "At iterate   15    f= -8.53844D-01    |proj g|=  7.84150D-02\n",
      "\n",
      "At iterate   20    f= -8.54210D-01    |proj g|=  1.06028D-02\n",
      "\n",
      "At iterate   25    f= -8.54261D-01    |proj g|=  2.99520D-03\n",
      "\n",
      "At iterate   30    f= -8.54265D-01    |proj g|=  6.33697D-04\n",
      "\n",
      "At iterate   35    f= -8.54265D-01    |proj g|=  3.42984D-04\n",
      "\n",
      "At iterate   40    f= -8.54265D-01    |proj g|=  1.69157D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     40     49      1     0     0   1.692D-05  -8.543D-01\n",
      "  F = -0.85426521506509978     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -3.29754D-01    |proj g|=  1.04894D+00\n",
      "\n",
      "At iterate    5    f= -7.67739D-01    |proj g|=  8.74190D-01\n",
      "\n",
      "At iterate   10    f= -8.71244D-01    |proj g|=  8.48562D-02\n",
      "\n",
      "At iterate   15    f= -8.76712D-01    |proj g|=  1.03095D-01\n",
      "\n",
      "At iterate   20    f= -8.77143D-01    |proj g|=  2.37866D-02\n",
      "\n",
      "At iterate   25    f= -8.77195D-01    |proj g|=  2.79385D-03\n",
      "\n",
      "At iterate   30    f= -8.77199D-01    |proj g|=  1.00994D-04\n",
      "\n",
      "At iterate   35    f= -8.77200D-01    |proj g|=  3.32712D-04\n",
      "\n",
      "At iterate   40    f= -8.77200D-01    |proj g|=  4.36298D-06\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     40     47      1     0     0   4.363D-06  -8.772D-01\n",
      "  F = -0.87719979030071482     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -6.63296D-01    |proj g|=  3.43660D+00\n",
      "\n",
      "At iterate    5    f= -7.94318D-01    |proj g|=  5.65139D-01\n",
      "\n",
      "At iterate   10    f= -8.43515D-01    |proj g|=  3.84778D-01\n",
      "\n",
      "At iterate   15    f= -8.50092D-01    |proj g|=  8.26680D-02\n",
      "\n",
      "At iterate   20    f= -8.50370D-01    |proj g|=  7.17313D-03\n",
      "\n",
      "At iterate   25    f= -8.50385D-01    |proj g|=  5.58548D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     27     48      1     0     0   1.496D-04  -8.504D-01\n",
      "  F = -0.85038515461748931     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -6.71648D-01    |proj g|=  4.00091D+00\n",
      "\n",
      "At iterate    5    f= -8.69744D-01    |proj g|=  4.03997D-03\n",
      "\n",
      "At iterate   10    f= -8.69746D-01    |proj g|=  2.70268D-02\n",
      "\n",
      "At iterate   15    f= -8.69888D-01    |proj g|=  1.12846D-01\n",
      "\n",
      "At iterate   20    f= -8.70013D-01    |proj g|=  9.45517D-03\n",
      "\n",
      "At iterate   25    f= -8.70030D-01    |proj g|=  2.30003D-03\n",
      "\n",
      "At iterate   30    f= -8.70032D-01    |proj g|=  6.29653D-04\n",
      "\n",
      "At iterate   35    f= -8.70032D-01    |proj g|=  3.03289D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     39     50      1     0     0   1.384D-04  -8.700D-01\n",
      "  F = -0.87003209134846160     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -3.31940D-01    |proj g|=  1.03762D+00\n",
      "\n",
      "At iterate    5    f= -7.76676D-01    |proj g|=  1.12755D+00\n",
      "\n",
      "At iterate   10    f= -8.57821D-01    |proj g|=  2.86618D-02\n",
      "\n",
      "At iterate   15    f= -8.58976D-01    |proj g|=  4.73866D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     18     23      1     0     0   7.073D-07  -8.590D-01\n",
      "  F = -0.85897561341665096     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -3.34531D-01    |proj g|=  1.02669D+00\n",
      "\n",
      "At iterate    5    f= -7.86310D-01    |proj g|=  8.24822D-01\n",
      "\n",
      "At iterate   10    f= -8.72763D-01    |proj g|=  3.45234D-02\n",
      "\n",
      "At iterate   15    f= -8.74751D-01    |proj g|=  1.36911D-02\n",
      "\n",
      "At iterate   20    f= -8.74784D-01    |proj g|=  4.06317D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     21     41      1     0     0   4.063D-04  -8.748D-01\n",
      "  F = -0.87478400897769915     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -6.75099D-01    |proj g|=  3.90523D+00\n",
      "\n",
      "At iterate    5    f= -8.62117D-01    |proj g|=  2.14423D-03\n",
      "\n",
      "At iterate   10    f= -8.62145D-01    |proj g|=  9.56002D-02\n",
      "\n",
      "At iterate   15    f= -8.62843D-01    |proj g|=  1.30819D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     18     37      1     0     0   1.629D-04  -8.628D-01\n",
      "  F = -0.86284375450828066     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -6.70018D-01    |proj g|=  3.99819D+00\n",
      "\n",
      "At iterate    5    f= -8.73405D-01    |proj g|=  2.03337D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      7     24      1     0     0   4.459D-04  -8.734D-01\n",
      "  F = -0.87340579858817147     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -3.31141D-01    |proj g|=  1.01963D+00\n",
      "\n",
      "At iterate    5    f= -7.99483D-01    |proj g|=  2.28344D+00\n",
      "\n",
      "At iterate   10    f= -8.66912D-01    |proj g|=  3.41578D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     14     19      1     0     0   8.297D-06  -8.671D-01\n",
      "  F = -0.86711851014335284     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "Metrics for Athletics (popularity) - MSE: 0.010012551028071824, R2: -6.969544884910887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking stationarity for Badminton (popularity):\n",
      "ADF Statistic: -2.2161674603123336, p-value: 0.2004300157100855\n",
      "Skipping ARIMA fitting for non-stationary series: Badminton (popularity)\n",
      "Checking stationarity for Baseball (popularity):\n",
      "ADF Statistic: -2.432832901454846, p-value: 0.13268314888982735\n",
      "Skipping ARIMA fitting for non-stationary series: Baseball (popularity)\n",
      "Checking stationarity for Basketball (popularity):\n",
      "ADF Statistic: 1.9544648827828397, p-value: 0.9986107793776037\n",
      "Skipping ARIMA fitting for non-stationary series: Basketball (popularity)\n",
      "Insufficient data for Basque Pelota (popularity)\n",
      "Checking stationarity for Beach Volleyball (popularity):\n",
      "ADF Statistic: -1.300612741768457, p-value: 0.6288919369701744\n",
      "Skipping ARIMA fitting for non-stationary series: Beach Volleyball (popularity)\n",
      "Checking stationarity for Biathlon (popularity):\n",
      "ADF Statistic: 0.7491070359845161, p-value: 0.9907686205348968\n",
      "Skipping ARIMA fitting for non-stationary series: Biathlon (popularity)\n",
      "Checking stationarity for Bobsleigh (popularity):\n",
      "ADF Statistic: -4.9137002029592916, p-value: 3.279502230700228e-05\n",
      "Optimal ARIMA order: (0, 0, 0)\n",
      "Optimal SARIMA order: (0, 0, 0), Seasonal: (0, 0, 0, 0)\n",
      "Constant series detected for Bobsleigh (popularity). Predicting constant value: 0.0068505181802213\n",
      "Metrics for Bobsleigh (popularity) - MSE: 2.2528955606981378e-05, R2: -1.0242390647842519\n",
      "Constant series detected for Bobsleigh (popularity). Predicting constant value: 0.0068505181802213\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.74847D+00    |proj g|=  4.16198D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     18      1     0     0   4.162D-02  -2.748D+00\n",
      "  F =  -2.7484728240577132     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.74490D+00    |proj g|=  4.13239D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     18      1     0     0   4.132D-02  -2.745D+00\n",
      "  F =  -2.7449030182032992     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.73846D+00    |proj g|=  4.07951D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     18      1     0     0   4.080D-02  -2.738D+00\n",
      "  F =  -2.7384593558188364     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.77822D+00    |proj g|=  4.41697D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     20      1     0     0   4.417D-02  -2.778D+00\n",
      "  F =  -2.7782199617305734     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.82489D+00    |proj g|=  4.84880D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     21      1     0     0   4.849D-02  -2.825D+00\n",
      "  F =  -2.8248853975484400     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.74962D+00    |proj g|=  4.17152D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     18      1     0     0   4.172D-02  -2.750D+00\n",
      "  F =  -2.7496177377932502     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.77290D+00    |proj g|=  4.37021D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     18      1     0     0   4.370D-02  -2.773D+00\n",
      "  F =  -2.7728958109849224     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.79716D+00    |proj g|=  4.58737D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     18      1     0     0   4.587D-02  -2.797D+00\n",
      "  F =  -2.7971569460352916     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.82717D+00    |proj g|=  4.87103D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     17      1     0     0   4.871D-02  -2.827D+00\n",
      "  F =  -2.8271739753520366     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.83718D+00    |proj g|=  4.96940D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     17      1     0     0   4.969D-02  -2.837D+00\n",
      "  F =  -2.8371759790033528     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.84870D+00    |proj g|=  5.08520D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     19      1     0     0   5.085D-02  -2.849D+00\n",
      "  F =  -2.8487006555147247     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.85349D+00    |proj g|=  5.13415D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     21      1     0     0   5.134D-02  -2.853D+00\n",
      "  F =  -2.8534935296508248     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.85976D+00    |proj g|=  5.19885D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     19      1     0     0   5.199D-02  -2.860D+00\n",
      "  F =  -2.8597592869757813     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "Metrics for Bobsleigh (popularity) - MSE: 0.00018412345286101495, R2: -15.543593610204066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking stationarity for Boxing (popularity):\n",
      "ADF Statistic: -3.386793226216832, p-value: 0.011417413689796343\n",
      "Optimal ARIMA order: (1, 0, 0)\n",
      "Optimal SARIMA order: (1, 0, 0), Seasonal: (0, 0, 0, 0)\n",
      "Metrics for Boxing (popularity) - MSE: 3.372973986278663e-05, R2: -1.9092842228374431\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.62598D+00    |proj g|=  4.88299D+03\n",
      "\n",
      "At iterate    5    f= -3.16064D+00    |proj g|=  6.57530D+01\n",
      "\n",
      "At iterate   10    f= -3.30730D+00    |proj g|=  7.17642D+00\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     13     66      2     0     0   2.415D-02  -3.308D+00\n",
      "  F =  -3.3076984342927322     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.50808D+00    |proj g|=  3.49527D+02\n",
      "\n",
      "At iterate    5    f= -2.47151D+00    |proj g|=  4.86773D-01\n",
      "\n",
      "At iterate   10    f= -2.47837D+00    |proj g|=  7.82844D+00\n",
      "\n",
      "At iterate   15    f= -2.87187D+00    |proj g|=  2.86771D+00\n",
      "\n",
      "At iterate   20    f= -2.91936D+00    |proj g|=  4.23355D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     22     39      1     0     0   9.805D-04  -2.919D+00\n",
      "  F =  -2.9193572152414595     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  5.63855D-01    |proj g|=  9.99056D+02\n",
      "  ys=-3.986E+00  -gs= 8.826E-01 BFGS update SKIPPED\n",
      "\n",
      "At iterate    5    f= -2.32121D+00    |proj g|=  6.56680D-01\n",
      "\n",
      "At iterate   10    f= -2.38469D+00    |proj g|=  2.95156D+01\n",
      "\n",
      "At iterate   15    f= -3.03031D+00    |proj g|=  1.79969D+01\n",
      "\n",
      "At iterate   20    f= -3.06260D+00    |proj g|=  1.07412D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     21     35      1     1     0   8.570D-03  -3.063D+00\n",
      "  F =  -3.0625988963691806     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  5.54685D-01    |proj g|=  9.71014D+02\n",
      "\n",
      "At iterate    5    f= -2.30555D+00    |proj g|=  2.01152D+00\n",
      "\n",
      "At iterate   10    f= -2.58322D+00    |proj g|=  1.06392D+02\n",
      "\n",
      "At iterate   15    f= -3.19572D+00    |proj g|=  1.92670D+00\n",
      "\n",
      "At iterate   20    f= -3.20129D+00    |proj g|=  3.37239D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     20     51      1     0     0   3.372D-03  -3.201D+00\n",
      "  F =  -3.2012943021430358     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.65846D+00    |proj g|=  1.41854D+03\n",
      "\n",
      "At iterate    5    f= -2.29472D+00    |proj g|=  8.35093D-01\n",
      "\n",
      "At iterate   10    f= -2.37476D+00    |proj g|=  3.58781D+01\n",
      "\n",
      "At iterate   15    f= -3.26278D+00    |proj g|=  9.43389D+00\n",
      "\n",
      "At iterate   20    f= -3.32699D+00    |proj g|=  3.87627D-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      "\n",
      " Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     24     60      1     0     0   6.559D-03  -3.327D+00\n",
      "  F =  -3.3270116444319999     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -3.29467D+00    |proj g|=  2.06563D+01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      4     18      1     0     0   1.039D-02  -3.300D+00\n",
      "  F =  -3.2997902464162214     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  3.67009D+00    |proj g|=  2.32925D+03\n",
      "  ys=-8.036E+00  -gs= 9.050E-01 BFGS update SKIPPED\n",
      "\n",
      "At iterate    5    f= -2.28310D+00    |proj g|=  8.47187D-01\n",
      "\n",
      "At iterate   10    f= -2.31509D+00    |proj g|=  1.67173D+01\n",
      "\n",
      "At iterate   15    f= -3.30801D+00    |proj g|=  3.03479D+01\n",
      "\n",
      "At iterate   20    f= -3.49105D+00    |proj g|=  4.84698D+00\n",
      "\n",
      "At iterate   25    f= -3.49348D+00    |proj g|=  2.11856D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     25     53      1     1     0   2.119D-03  -3.493D+00\n",
      "  F =  -3.4934814930280003     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  4.82980D+00    |proj g|=  2.89905D+03\n",
      "\n",
      "At iterate    5    f= -2.27502D+00    |proj g|=  1.32659D+00\n",
      "\n",
      "At iterate   10    f= -2.32210D+00    |proj g|=  1.10972D+01\n",
      "\n",
      "At iterate   15    f= -3.53413D+00    |proj g|=  3.76263D+00\n",
      "\n",
      "At iterate   20    f= -3.57120D+00    |proj g|=  4.99027D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     23     61      1     0     0   6.286D-03  -3.571D+00\n",
      "  F =  -3.5712836991315107     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  5.80116D+00    |proj g|=  3.42513D+03\n",
      "  ys=-1.019E+01  -gs= 9.686E-01 BFGS update SKIPPED\n",
      "\n",
      "At iterate    5    f= -2.27503D+00    |proj g|=  9.23920D-01\n",
      "\n",
      "At iterate   10    f= -2.51405D+00    |proj g|=  2.57343D+01\n",
      "\n",
      "At iterate   15    f= -3.63711D+00    |proj g|=  1.21315D+01\n",
      "\n",
      "At iterate   20    f= -3.63858D+00    |proj g|=  1.74604D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     21     40      1     1     0   1.300D-06  -3.639D+00\n",
      "  F =  -3.6385825187902490     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  6.40122D+00    |proj g|=  3.67181D+03\n",
      "  ys=-4.607E+00  -gs= 9.718E-01 BFGS update SKIPPED\n",
      "\n",
      "At iterate    5    f= -2.25473D+00    |proj g|=  8.81616D-01\n",
      "\n",
      "At iterate   10    f= -2.63953D+00    |proj g|=  3.21765D+01\n",
      "\n",
      "At iterate   15    f= -3.63554D+00    |proj g|=  3.22108D+00\n",
      "\n",
      "At iterate   20    f= -3.64184D+00    |proj g|=  5.27357D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     22     54      1     1     0   5.934D-04  -3.642D+00\n",
      "  F =  -3.6418431517574334     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  7.41192D+00    |proj g|=  4.20280D+03\n",
      "\n",
      "At iterate    5    f= -2.24777D+00    |proj g|=  1.41380D+00\n",
      "\n",
      "At iterate   10    f= -3.43900D+00    |proj g|=  6.92764D+00\n",
      "\n",
      "At iterate   15    f= -3.68403D+00    |proj g|=  3.20677D+00\n",
      "\n",
      "At iterate   20    f= -3.69429D+00    |proj g|=  3.90876D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     22     59      1     0     0   3.179D-04  -3.694D+00\n",
      "  F =  -3.6942949472255449     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  8.70526D+00    |proj g|=  4.90881D+03\n",
      "\n",
      "At iterate    5    f= -2.23529D+00    |proj g|=  2.12544D+00\n",
      "\n",
      "At iterate   10    f= -3.49687D+00    |proj g|=  9.20224D+01\n",
      "\n",
      "At iterate   15    f= -3.72233D+00    |proj g|=  5.62575D+00\n",
      "\n",
      "At iterate   20    f= -3.74067D+00    |proj g|=  6.59245D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     23     40      1     0     0   7.840D-06  -3.741D+00\n",
      "  F =  -3.7406754687475181     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.00444D+01    |proj g|=  5.66939D+03\n",
      "  ys=-1.307E+01  -gs= 9.524E-01 BFGS update SKIPPED\n",
      "\n",
      "At iterate    5    f= -2.23130D+00    |proj g|=  9.26962D-01\n",
      "\n",
      "At iterate   10    f= -2.63031D+00    |proj g|=  2.17908D+02\n",
      "\n",
      "At iterate   15    f= -3.73649D+00    |proj g|=  1.22363D+01\n",
      "\n",
      "At iterate   20    f= -3.78526D+00    |proj g|=  5.53840D-01\n",
      "\n",
      "At iterate   25    f= -3.78538D+00    |proj g|=  3.88845D-07\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     25     43      1     1     0   3.888D-07  -3.785D+00\n",
      "  F =  -3.7853786241032359     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -3.74565D+00    |proj g|=  1.34410D+01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      3     47      2     0     0   2.985D-01  -3.747D+00\n",
      "  F =  -3.7467086780396683     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.04542D+01    |proj g|=  5.87683D+03\n",
      "  ys=-9.280E+00  -gs= 9.188E-01 BFGS update SKIPPED\n",
      "\n",
      "At iterate    5    f= -2.21672D+00    |proj g|=  1.56576D+00\n",
      "\n",
      "At iterate   10    f= -3.76874D+00    |proj g|=  2.05007D+01\n",
      "\n",
      "At iterate   15    f= -3.80461D+00    |proj g|=  1.62965D+00\n",
      "\n",
      "At iterate   20    f= -3.80529D+00    |proj g|=  3.35423D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     20     87      2     1     0   3.354D-03  -3.805D+00\n",
      "  F =  -3.8052850572641574     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.17135D+01    |proj g|=  6.61476D+03\n",
      "\n",
      "At iterate    5    f= -2.20550D+00    |proj g|=  9.57382D-01\n",
      "\n",
      "At iterate   10    f= -2.55784D+00    |proj g|=  2.89565D+01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate   15    f= -3.81441D+00    |proj g|=  2.58404D+01\n",
      "\n",
      "At iterate   20    f= -3.84098D+00    |proj g|=  1.83606D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     23     67      2     0     0   6.957D-05  -3.841D+00\n",
      "  F =  -3.8409864310913471     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.27995D+01    |proj g|=  7.28350D+03\n",
      "  ys=-1.164E+01  -gs= 9.395E-01 BFGS update SKIPPED\n",
      "\n",
      "At iterate    5    f= -2.20442D+00    |proj g|=  1.64467D+00\n",
      "\n",
      "At iterate   10    f= -3.46167D+00    |proj g|=  8.67359D+00\n",
      "\n",
      "At iterate   15    f= -3.83856D+00    |proj g|=  2.15623D+01\n",
      "\n",
      "At iterate   20    f= -3.87459D+00    |proj g|=  2.14775D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     24     62      1     1     0   7.230D-03  -3.875D+00\n",
      "  F =  -3.8746438828745529     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -3.81629D+00    |proj g|=  6.98004D+00\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      4     16      1     0     0   5.172D-03  -3.817D+00\n",
      "  F =  -3.8165549966725516     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -3.79614D+00    |proj g|=  8.98966D+00\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      2     22      1     0     0   1.034D-01  -3.797D+00\n",
      "  F =  -3.7966045233814709     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -3.82850D+00    |proj g|=  6.96189D+00\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      4     26      1     0     0   4.716D-03  -3.829D+00\n",
      "  F =  -3.8287639359379129     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -3.85660D+00    |proj g|=  6.20491D+00\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      3     25      1     0     0   8.978D-03  -3.857D+00\n",
      "  F =  -3.8567920621900877     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -3.88204D+00    |proj g|=  6.03081D+00\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      3     22      1     0     0   8.035D-03  -3.882D+00\n",
      "  F =  -3.8822136519096482     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -3.90286D+00    |proj g|=  6.31126D+00\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      4     25      1     0     0   7.209D-03  -3.903D+00\n",
      "  F =  -3.9030403528241990     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -3.92689D+00    |proj g|=  5.67718D+00\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      3     47      2     0     0   6.286D-03  -3.927D+00\n",
      "  F =  -3.9270314107926616     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -3.89098D+00    |proj g|=  7.74983D+00\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      3     21      1     0     0   1.754D-02  -3.891D+00\n",
      "  F =  -3.8912658845339054     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "Metrics for Boxing (popularity) - MSE: 2.1560806350017173e-05, R2: -0.8596797366635867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking stationarity for Canoeing (popularity):\n",
      "ADF Statistic: -1.4954249686235095, p-value: 0.5357733152656656\n",
      "Skipping ARIMA fitting for non-stationary series: Canoeing (popularity)\n",
      "Insufficient data for Cricket (popularity)\n",
      "Insufficient data for Croquet (popularity)\n",
      "Checking stationarity for Cross Country Skiing (popularity):\n",
      "ADF Statistic: -0.4794410169779505, p-value: 0.8959663888730973\n",
      "Skipping ARIMA fitting for non-stationary series: Cross Country Skiing (popularity)\n",
      "Insufficient data for Curling (popularity)\n",
      "Checking stationarity for Cycling (popularity):\n",
      "ADF Statistic: -5.4721455504463785, p-value: 2.385484674143488e-06\n",
      "Optimal ARIMA order: (0, 1, 2)\n",
      "Optimal SARIMA order: (0, 1, 2), Seasonal: (0, 0, 0, 0)\n",
      "Metrics for Cycling (popularity) - MSE: 0.0001109889160294778, R2: 0.18301735823456944\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -5.97101D-01    |proj g|=  9.73000D+01\n",
      "\n",
      "At iterate    5    f= -1.15652D+00    |proj g|=  6.92312D-03\n",
      "\n",
      "At iterate   10    f= -1.15652D+00    |proj g|=  7.75381D-02\n",
      "\n",
      "At iterate   15    f= -1.15659D+00    |proj g|=  1.06172D-02\n",
      "  ys=-4.011E-09  -gs= 1.744E-09 BFGS update SKIPPED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      "\n",
      " Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ys=-2.262E-12  -gs= 6.653E-12 BFGS update SKIPPED\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3     19     95      3     2     0   8.021D-03  -1.157D+00\n",
      "  F =  -1.1565904011614712     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.28241D+00    |proj g|=  1.92501D+01\n",
      "\n",
      "At iterate    5    f= -1.35708D+00    |proj g|=  3.15392D-01\n",
      "\n",
      "At iterate   10    f= -1.38512D+00    |proj g|=  5.17392D+00\n",
      "\n",
      "At iterate   15    f= -1.48120D+00    |proj g|=  9.31289D-01\n",
      "\n",
      "At iterate   20    f= -1.48673D+00    |proj g|=  3.39703D-01\n",
      "\n",
      "At iterate   25    f= -1.48776D+00    |proj g|=  1.41565D-01\n",
      "\n",
      "At iterate   30    f= -1.48776D+00    |proj g|=  8.09581D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3     30     69      1     0     0   8.096D-03  -1.488D+00\n",
      "  F =  -1.4877626418618330     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.51495D+00    |proj g|=  1.53815D+01\n",
      "\n",
      "At iterate    5    f= -1.55813D+00    |proj g|=  3.31153D-01\n",
      "\n",
      "At iterate   10    f= -1.57355D+00    |proj g|=  7.01038D+00\n",
      "\n",
      "At iterate   15    f= -1.70484D+00    |proj g|=  5.68953D-02\n",
      "\n",
      "At iterate   20    f= -1.71350D+00    |proj g|=  1.55532D+00\n",
      "\n",
      "At iterate   25    f= -1.71396D+00    |proj g|=  1.30073D-02\n",
      "  ys=-8.092E-12  -gs= 1.870E-11 BFGS update SKIPPED\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3     27     86      2     1     0   1.892D-02  -1.714D+00\n",
      "  F =  -1.7139592149666505     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.61352D+00    |proj g|=  1.64035D+01\n",
      "\n",
      "At iterate    5    f= -1.65759D+00    |proj g|=  4.35983D-01\n",
      "\n",
      "At iterate   10    f= -1.67909D+00    |proj g|=  8.39006D+00\n",
      "\n",
      "At iterate   15    f= -1.80339D+00    |proj g|=  3.44725D-01\n",
      "\n",
      "At iterate   20    f= -1.80628D+00    |proj g|=  6.07828D-03\n",
      "\n",
      "At iterate   25    f= -1.80674D+00    |proj g|=  9.22267D-02\n",
      "  ys=-3.088E-08  -gs= 7.104E-08 BFGS update SKIPPED\n",
      "\n",
      "At iterate   30    f= -1.80674D+00    |proj g|=  2.61656D-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "\n",
      " Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3     31    125      2     1     0   2.617D-02  -1.807D+00\n",
      "  F =  -1.8067391742136174     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.73553D+00    |proj g|=  1.65493D+01\n",
      "\n",
      "At iterate    5    f= -1.77447D+00    |proj g|=  4.47176D-01\n",
      "\n",
      "At iterate   10    f= -1.79276D+00    |proj g|=  8.60531D+00\n",
      "\n",
      "At iterate   15    f= -1.93866D+00    |proj g|=  1.08456D-01\n",
      "\n",
      "At iterate   20    f= -1.94407D+00    |proj g|=  7.73370D-01\n",
      "\n",
      "At iterate   25    f= -1.94420D+00    |proj g|=  2.46139D-02\n",
      "  ys=-1.526E-11  -gs= 3.545E-11 BFGS update SKIPPED\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3     27    107      3     1     0   3.475D-02  -1.944D+00\n",
      "  F =  -1.9442040960618745     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.87300D+00    |proj g|=  3.78729D+00\n",
      "\n",
      "At iterate    5    f= -1.87801D+00    |proj g|=  2.31493D+00\n",
      "\n",
      "At iterate   10    f= -1.99078D+00    |proj g|=  4.08261D+00\n",
      "\n",
      "At iterate   15    f= -2.00519D+00    |proj g|=  1.00327D-01\n",
      "\n",
      "At iterate   20    f= -2.00526D+00    |proj g|=  4.52090D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3     25     90      2     0     0   1.559D-02  -2.005D+00\n",
      "  F =  -2.0053380725303023     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.96161D+00    |proj g|=  3.90449D+00\n",
      "\n",
      "At iterate    5    f= -1.96619D+00    |proj g|=  2.66503D+00\n",
      "\n",
      "At iterate   10    f= -2.08845D+00    |proj g|=  5.13631D+00\n",
      "\n",
      "At iterate   15    f= -2.10099D+00    |proj g|=  3.33447D-01\n",
      "\n",
      "At iterate   20    f= -2.10127D+00    |proj g|=  1.33089D+00\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3     20     53      1     0     0   1.331D+00  -2.101D+00\n",
      "  F =  -2.1012688316334858     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  5.50305D+03    |proj g|=  3.69187D+07\n",
      "\n",
      "At iterate    5    f= -2.12283D+00    |proj g|=  2.05705D+01\n",
      "\n",
      "At iterate   10    f= -2.21995D+00    |proj g|=  7.75452D-02\n",
      "\n",
      "At iterate   15    f= -2.22087D+00    |proj g|=  7.83238D-01\n",
      "\n",
      "At iterate   20    f= -2.22410D+00    |proj g|=  6.82700D-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate   25    f= -2.22718D+00    |proj g|=  5.18957D+00\n",
      "\n",
      "At iterate   30    f= -2.23335D+00    |proj g|=  5.38377D-02\n",
      "\n",
      "At iterate   35    f= -2.24086D+00    |proj g|=  1.35778D-01\n",
      "\n",
      "At iterate   40    f= -2.24855D+00    |proj g|=  1.23954D+00\n",
      "\n",
      "At iterate   45    f= -2.25059D+00    |proj g|=  1.88432D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3     45    130      2     0     0   1.884D-01  -2.251D+00\n",
      "  F =  -2.2505925494766212     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.75568D+00    |proj g|=  1.98514D+03\n",
      "\n",
      "At iterate    5    f= -2.15794D+00    |proj g|=  9.95584D+00\n",
      "\n",
      "At iterate   10    f= -2.18639D+00    |proj g|=  1.42368D-02\n",
      "\n",
      "At iterate   15    f= -2.21827D+00    |proj g|=  2.00509D+00\n",
      "  ys=-3.162E-05  -gs= 3.295E-05 BFGS update SKIPPED\n",
      "  ys=-2.553E-07  -gs= 1.840E-07 BFGS update SKIPPED\n",
      "\n",
      "At iterate   20    f= -2.21951D+00    |proj g|=  4.22079D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3     21    118      2     2     0   4.221D-02  -2.220D+00\n",
      "  F =  -2.2195129827550097     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  4.88818D+00    |proj g|=  2.88307D+03\n",
      "  ys=-1.099E+01  -gs= 8.630E-01 BFGS update SKIPPED\n",
      "\n",
      "At iterate    5    f= -2.08159D+00    |proj g|=  2.84664D+00\n",
      "\n",
      "At iterate   10    f= -2.09046D+00    |proj g|=  6.38982D+00\n",
      "\n",
      "At iterate   15    f= -2.25756D+00    |proj g|=  1.73994D+00\n",
      "\n",
      "At iterate   20    f= -2.26595D+00    |proj g|=  2.85874D-01\n",
      "\n",
      "At iterate   25    f= -2.28050D+00    |proj g|=  1.31330D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3     27     67      2     1     0   1.448D-02  -2.281D+00\n",
      "  F =  -2.2805029793081233     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  4.60041D+00    |proj g|=  3.12870D+03\n",
      "  ys=-9.583E+00  -gs= 8.546E-01 BFGS update SKIPPED\n",
      "\n",
      "At iterate    5    f= -2.20171D+00    |proj g|=  8.54309D-01\n",
      "\n",
      "At iterate   10    f= -2.32122D+00    |proj g|=  3.73366D-02\n",
      "\n",
      "At iterate   15    f= -2.32395D+00    |proj g|=  8.75594D-01\n",
      "\n",
      "At iterate   20    f= -2.33732D+00    |proj g|=  1.32228D+00\n",
      "\n",
      "At iterate   25    f= -2.33782D+00    |proj g|=  9.63933D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3     30    123      2     1     0   2.740D-02  -2.338D+00\n",
      "  F =  -2.3378184990825002     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  5.09763D+00    |proj g|=  3.43414D+03\n",
      "  ys=-1.257E+01  -gs= 9.017E-01 BFGS update SKIPPED\n",
      "\n",
      "At iterate    5    f= -2.21556D+00    |proj g|=  6.95228D-01\n",
      "\n",
      "At iterate   10    f= -2.22259D+00    |proj g|=  5.38734D+00\n",
      "\n",
      "At iterate   15    f= -2.37280D+00    |proj g|=  3.15177D+00\n",
      "\n",
      "At iterate   20    f= -2.37614D+00    |proj g|=  4.07465D-02\n",
      "\n",
      "At iterate   25    f= -2.37787D+00    |proj g|=  1.38080D+00\n",
      "\n",
      "At iterate   30    f= -2.39032D+00    |proj g|=  1.10920D-02\n",
      "\n",
      "At iterate   35    f= -2.39035D+00    |proj g|=  1.62501D-02\n",
      "  ys=-3.050E-10  -gs= 1.788E-10 BFGS update SKIPPED\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3     37    140      4     2     0   4.379D-02  -2.390D+00\n",
      "  F =  -2.3903459901365198     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  6.01749D+00    |proj g|=  4.16128D+03\n",
      "\n",
      "At iterate    5    f= -2.25839D+00    |proj g|=  5.11869D-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "\n",
      " Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate   10    f= -2.27254D+00    |proj g|=  8.07347D+00\n",
      "\n",
      "At iterate   15    f= -2.42267D+00    |proj g|=  5.24575D-01\n",
      "\n",
      "At iterate   20    f= -2.42978D+00    |proj g|=  3.58892D-01\n",
      "\n",
      "At iterate   25    f= -2.43788D+00    |proj g|=  2.35538D-02\n",
      "\n",
      "At iterate   30    f= -2.43805D+00    |proj g|=  4.83515D-01\n",
      "\n",
      "At iterate   35    f= -2.43816D+00    |proj g|=  4.17745D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3     36     78      1     0     0   4.177D-02  -2.438D+00\n",
      "  F =  -2.4381631862979427     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  6.92799D+00    |proj g|=  4.92168D+03\n",
      "\n",
      "At iterate    5    f= -2.29325D+00    |proj g|=  9.15415D-01\n",
      "\n",
      "At iterate   10    f= -2.42036D+00    |proj g|=  2.34110D+01\n",
      "\n",
      "At iterate   15    f= -2.46662D+00    |proj g|=  1.10412D-01\n",
      "\n",
      "At iterate   20    f= -2.48068D+00    |proj g|=  4.60271D-01\n",
      "  ys=-1.047E-05  -gs= 3.560E-05 BFGS update SKIPPED\n",
      "\n",
      "At iterate   25    f= -2.48071D+00    |proj g|=  3.28089D-02\n",
      "\n",
      "At iterate   30    f= -2.48071D+00    |proj g|=  5.52561D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3     31    136      3     1     0   5.526D-02  -2.481D+00\n",
      "  F =  -2.4807141832080486     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  7.59105D+00    |proj g|=  5.57867D+03\n",
      "  ys=-8.517E+00  -gs= 8.599E-01 BFGS update SKIPPED\n",
      "\n",
      "At iterate    5    f= -2.41888D+00    |proj g|=  5.06603D+00\n",
      "\n",
      "At iterate   10    f= -2.51056D+00    |proj g|=  7.22922D-02\n",
      "\n",
      "At iterate   15    f= -2.51057D+00    |proj g|=  2.88956D-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "\n",
      " Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate   20    f= -2.51088D+00    |proj g|=  8.38442D-02\n",
      "\n",
      "At iterate   25    f= -2.51096D+00    |proj g|=  1.85503D+00\n",
      "\n",
      "At iterate   30    f= -2.51446D+00    |proj g|=  1.67159D+00\n",
      "\n",
      "At iterate   35    f= -2.51709D+00    |proj g|=  2.16289D+00\n",
      "\n",
      "At iterate   40    f= -2.51744D+00    |proj g|=  4.83812D-02\n",
      "\n",
      "At iterate   45    f= -2.51751D+00    |proj g|=  4.60595D-01\n",
      "\n",
      "At iterate   50    f= -2.51810D+00    |proj g|=  1.07471D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3     50    116      1     1     0   1.075D-01  -2.518D+00\n",
      "  F =  -2.5181010715475889     \n",
      "\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT                 \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  7.83022D+00    |proj g|=  5.97071D+03\n",
      "  ys=-5.604E+01  -gs= 9.583E-01 BFGS update SKIPPED\n",
      "\n",
      "At iterate    5    f= -2.36699D+00    |proj g|=  2.32862D+00\n",
      "\n",
      "At iterate   10    f= -2.37178D+00    |proj g|=  4.16755D+00\n",
      "\n",
      "At iterate   15    f= -2.54388D+00    |proj g|=  1.00496D+00\n",
      "  ys=-1.193E-08  -gs= 3.452E-09 BFGS update SKIPPED\n",
      "\n",
      "At iterate   20    f= -2.54750D+00    |proj g|=  7.64492D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3     20     69      1     2     0   7.645D-02  -2.547D+00\n",
      "  F =  -2.5474964594554552     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  5.95196D+00    |proj g|=  4.72875D+03\n",
      "\n",
      "At iterate    5    f= -2.40470D+00    |proj g|=  2.94702D+00\n",
      "\n",
      "At iterate   10    f= -2.56840D+00    |proj g|=  3.79618D+00\n",
      "\n",
      "At iterate   15    f= -2.57325D+00    |proj g|=  3.23391D-01\n",
      "\n",
      "At iterate   20    f= -2.57565D+00    |proj g|=  3.39910D-01\n",
      "\n",
      "At iterate   25    f= -2.57570D+00    |proj g|=  9.43232D-01\n",
      "\n",
      "At iterate   30    f= -2.57601D+00    |proj g|=  4.16562D-01\n",
      "\n",
      "At iterate   35    f= -2.59088D+00    |proj g|=  4.94681D+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate   40    f= -2.59208D+00    |proj g|=  2.47871D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3     43    138      2     0     0   1.307D-01  -2.592D+00\n",
      "  F =  -2.5920838260697128     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  6.36862D+00    |proj g|=  5.18689D+03\n",
      "  ys=-8.427E+00  -gs= 8.657E-01 BFGS update SKIPPED\n",
      "\n",
      "At iterate    5    f= -2.43243D+00    |proj g|=  8.45139D-01\n",
      "\n",
      "At iterate   10    f= -2.58386D+00    |proj g|=  9.89253D+00\n",
      "\n",
      "At iterate   15    f= -2.60648D+00    |proj g|=  2.74948D-01\n",
      "\n",
      "At iterate   20    f= -2.62437D+00    |proj g|=  7.84805D-01\n",
      "\n",
      "At iterate   25    f= -2.62485D+00    |proj g|=  2.91819D-01\n",
      "\n",
      "At iterate   30    f= -2.62486D+00    |proj g|=  1.54246D-02\n",
      "  ys=-6.254E-10  -gs= 3.030E-10 BFGS update SKIPPED\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3     34    112      1     2     0   4.637D-02  -2.625D+00\n",
      "  F =  -2.6248576697566639     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  3.31497D+00    |proj g|=  3.20853D+03\n",
      "\n",
      "At iterate    5    f= -2.48993D+00    |proj g|=  4.21299D-01\n",
      "\n",
      "At iterate   10    f= -2.51949D+00    |proj g|=  1.90373D+01\n",
      "\n",
      "At iterate   15    f= -2.64123D+00    |proj g|=  2.32170D+00\n",
      "\n",
      "At iterate   20    f= -2.64183D+00    |proj g|=  6.48079D-02\n",
      "\n",
      "At iterate   25    f= -2.64251D+00    |proj g|=  8.21752D-01\n",
      "\n",
      "At iterate   30    f= -2.65019D+00    |proj g|=  1.42524D+00\n",
      "\n",
      "At iterate   35    f= -2.65143D+00    |proj g|=  2.42587D+00\n",
      "\n",
      "At iterate   40    f= -2.65246D+00    |proj g|=  3.10685D+00\n",
      "\n",
      "At iterate   45    f= -2.65329D+00    |proj g|=  4.38425D-01\n",
      "\n",
      "At iterate   50    f= -2.65346D+00    |proj g|=  6.98853D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3     50     99      1     0     0   6.989D-01  -2.653D+00\n",
      "  F =  -2.6534601862597444     \n",
      "\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT                 \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.93979D+00    |proj g|=  2.87706D+03\n",
      "\n",
      "At iterate    5    f= -2.47870D+00    |proj g|=  4.73812D-01\n",
      "\n",
      "At iterate   10    f= -2.49995D+00    |proj g|=  2.37061D+00\n",
      "\n",
      "At iterate   15    f= -2.67334D+00    |proj g|=  2.94043D+00\n",
      "\n",
      "At iterate   20    f= -2.67400D+00    |proj g|=  3.74196D-02\n",
      "\n",
      "At iterate   25    f= -2.67456D+00    |proj g|=  3.90293D-01\n",
      "\n",
      "At iterate   30    f= -2.67729D+00    |proj g|=  1.05660D+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate   35    f= -2.67813D+00    |proj g|=  2.68115D-01\n",
      "\n",
      "At iterate   40    f= -2.67814D+00    |proj g|=  4.84434D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3     41    114      2     0     0   4.844D-02  -2.678D+00\n",
      "  F =  -2.6781372307583613     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.88954D+00    |proj g|=  2.97825D+03\n",
      "  ys=-1.148E+01  -gs= 9.938E-01 BFGS update SKIPPED\n",
      "\n",
      "At iterate    5    f= -2.51919D+00    |proj g|=  4.38579D-01\n",
      "\n",
      "At iterate   10    f= -2.59187D+00    |proj g|=  1.84500D+01\n",
      "\n",
      "At iterate   15    f= -2.69923D+00    |proj g|=  1.37113D+00\n",
      "\n",
      "At iterate   20    f= -2.70033D+00    |proj g|=  5.29873D+00\n",
      "\n",
      "At iterate   25    f= -2.70183D+00    |proj g|=  2.11150D-01\n",
      "  ys=-3.437E-04  -gs= 3.739E-04 BFGS update SKIPPED\n",
      "\n",
      "At iterate   30    f= -2.70417D+00    |proj g|=  5.14945D-02\n",
      "\n",
      "At iterate   35    f= -2.70604D+00    |proj g|=  2.68738D+00\n",
      "\n",
      "At iterate   40    f= -2.70693D+00    |proj g|=  7.34724D-03\n",
      "\n",
      "At iterate   45    f= -2.70705D+00    |proj g|=  1.54067D+00\n",
      "  ys=-4.797E-07  -gs= 1.058E-06 BFGS update SKIPPED\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3     49    187      3     3     0   1.936D-02  -2.707D+00\n",
      "  F =  -2.7071611389203420     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.34570D+00    |proj g|=  2.12479D+03\n",
      "  ys=-6.120E+00  -gs= 8.769E-01 BFGS update SKIPPED\n",
      "\n",
      "At iterate    5    f= -2.58256D+00    |proj g|=  4.04488D-01\n",
      "\n",
      "At iterate   10    f= -2.63466D+00    |proj g|=  2.46130D+01\n",
      "\n",
      "At iterate   15    f= -2.72519D+00    |proj g|=  1.24158D+00\n",
      "  ys=-1.677E-05  -gs= 2.049E-05 BFGS update SKIPPED\n",
      "\n",
      "At iterate   20    f= -2.72528D+00    |proj g|=  4.03791D-02\n",
      "\n",
      "At iterate   25    f= -2.72538D+00    |proj g|=  2.44577D-01\n",
      "\n",
      "At iterate   30    f= -2.72540D+00    |proj g|=  1.04384D-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ys=-2.172E-15  -gs= 1.963E-10 BFGS update SKIPPED\n",
      "\n",
      "At iterate   35    f= -2.72541D+00    |proj g|=  2.32167D-01\n",
      "\n",
      "At iterate   40    f= -2.72549D+00    |proj g|=  4.91788D-01\n",
      "\n",
      "At iterate   45    f= -2.72553D+00    |proj g|=  1.29261D-01\n",
      "\n",
      "At iterate   50    f= -2.72562D+00    |proj g|=  9.17008D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3     50    112      1     3     0   9.170D-01  -2.726D+00\n",
      "  F =  -2.7256152226321810     \n",
      "\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT                 \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.41440D+00    |proj g|=  2.23512D+03\n",
      "  ys=-4.246E+00  -gs= 9.025E-01 BFGS update SKIPPED\n",
      "\n",
      "At iterate    5    f= -2.60790D+00    |proj g|=  4.25852D-01\n",
      "\n",
      "At iterate   10    f= -2.74789D+00    |proj g|=  3.60441D+00\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3     13     42      1     1     0   6.028D-02  -2.749D+00\n",
      "  F =  -2.7488166836085979     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.53624D+00    |proj g|=  2.36865D+03\n",
      "  ys=-3.430E+00  -gs= 9.075E-01 BFGS update SKIPPED\n",
      "\n",
      "At iterate    5    f= -2.62641D+00    |proj g|=  4.18775D-01\n",
      "\n",
      "At iterate   10    f= -2.63455D+00    |proj g|=  1.07821D+01\n",
      "\n",
      "At iterate   15    f= -2.77327D+00    |proj g|=  1.11054D+00\n",
      "\n",
      "At iterate   20    f= -2.77384D+00    |proj g|=  3.46952D-01\n",
      "\n",
      "At iterate   25    f= -2.77410D+00    |proj g|=  6.64922D-01\n",
      "\n",
      "At iterate   30    f= -2.77802D+00    |proj g|=  4.56905D+00\n",
      "\n",
      "At iterate   35    f= -2.78085D+00    |proj g|=  1.37434D-02\n",
      "  ys=-5.205E-16  -gs= 1.159E-10 BFGS update SKIPPED\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3     39    160      4     2     0   4.141D-02  -2.781D+00\n",
      "  F =  -2.7808534289839701     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.60121D+00    |proj g|=  2.47469D+03\n",
      "  ys=-6.046E+00  -gs= 8.989E-01 BFGS update SKIPPED\n",
      "\n",
      "At iterate    5    f= -2.64861D+00    |proj g|=  2.72786D+00\n",
      "\n",
      "At iterate   10    f= -2.65591D+00    |proj g|=  1.02524D+01\n",
      "\n",
      "At iterate   15    f= -2.79599D+00    |proj g|=  3.45549D+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "\n",
      " Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "\n",
      " Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate   20    f= -2.79695D+00    |proj g|=  2.44579D-01\n",
      "\n",
      "At iterate   25    f= -2.79705D+00    |proj g|=  9.75098D-01\n",
      "\n",
      "At iterate   30    f= -2.79709D+00    |proj g|=  4.99411D-02\n",
      "\n",
      "At iterate   35    f= -2.79710D+00    |proj g|=  5.09638D-02\n",
      "  ys=-3.872E-11  -gs= 2.865E-10 BFGS update SKIPPED\n",
      "\n",
      "At iterate   40    f= -2.79710D+00    |proj g|=  4.99187D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3     40    157      4     2     0   4.992D-02  -2.797D+00\n",
      "  F =  -2.7970979372819036     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.66829D+00    |proj g|=  2.59083D+03\n",
      "  ys=-6.671E+00  -gs= 8.833E-01 BFGS update SKIPPED\n",
      "\n",
      "At iterate    5    f= -2.66519D+00    |proj g|=  8.72286D+00\n",
      "\n",
      "At iterate   10    f= -2.67152D+00    |proj g|=  1.46663D+00\n",
      "\n",
      "At iterate   15    f= -2.73233D+00    |proj g|=  1.97473D+01\n",
      "\n",
      "At iterate   20    f= -2.81671D+00    |proj g|=  1.69599D+00\n",
      "\n",
      "At iterate   25    f= -2.81691D+00    |proj g|=  2.06062D-02\n",
      "\n",
      "At iterate   30    f= -2.81692D+00    |proj g|=  3.75827D-01\n",
      "\n",
      "At iterate   35    f= -2.81859D+00    |proj g|=  7.49721D+00\n",
      "\n",
      "At iterate   40    f= -2.82107D+00    |proj g|=  2.81863D-01\n",
      "\n",
      "At iterate   45    f= -2.82123D+00    |proj g|=  1.35152D+00\n",
      "\n",
      "At iterate   50    f= -2.82149D+00    |proj g|=  1.96222D+00\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3     50    114      2     1     0   1.962D+00  -2.821D+00\n",
      "  F =  -2.8214923636130780     \n",
      "\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT                 \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.73676D+00    |proj g|=  2.70109D+03\n",
      "\n",
      "At iterate    5    f= -2.69168D+00    |proj g|=  1.25352D+00\n",
      "\n",
      "At iterate   10    f= -2.69312D+00    |proj g|=  4.22025D+00\n",
      "\n",
      "At iterate   15    f= -2.83922D+00    |proj g|=  1.16298D+00\n",
      "\n",
      "At iterate   20    f= -2.83927D+00    |proj g|=  4.45121D-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      "\n",
      " Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate   25    f= -2.83951D+00    |proj g|=  5.58439D-01\n",
      "\n",
      "At iterate   30    f= -2.84041D+00    |proj g|=  4.66908D-02\n",
      "\n",
      "At iterate   35    f= -2.84501D+00    |proj g|=  9.44904D-01\n",
      "\n",
      "At iterate   40    f= -2.84561D+00    |proj g|=  1.36027D+00\n",
      "\n",
      "At iterate   45    f= -2.84575D+00    |proj g|=  5.98340D-01\n",
      "\n",
      "At iterate   50    f= -2.84649D+00    |proj g|=  2.04365D+00\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3     50    145      2     0     0   2.044D+00  -2.846D+00\n",
      "  F =  -2.8464862531458066     \n",
      "\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT                 \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.76366D+00    |proj g|=  2.78282D+03\n",
      "\n",
      "At iterate    5    f= -2.71236D+00    |proj g|=  1.47529D+00\n",
      "\n",
      "At iterate   10    f= -2.71331D+00    |proj g|=  2.37019D+00\n",
      "\n",
      "At iterate   15    f= -2.79439D+00    |proj g|=  2.23083D+01\n",
      "\n",
      "At iterate   20    f= -2.85960D+00    |proj g|=  5.25915D-01\n",
      "\n",
      "At iterate   25    f= -2.85963D+00    |proj g|=  6.36447D-02\n",
      "\n",
      "At iterate   30    f= -2.85992D+00    |proj g|=  3.37725D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3     34     94      2     0     0   4.764D-02  -2.860D+00\n",
      "  F =  -2.8599805774242184     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "Metrics for Cycling (popularity) - MSE: 0.0001109889160294778, R2: 0.18301735823456944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking stationarity for Diving (popularity):\n",
      "ADF Statistic: -3.4754842790498297, p-value: 0.008639489476542696\n",
      "Optimal ARIMA order: (1, 0, 0)\n",
      "Optimal SARIMA order: (1, 0, 0), Seasonal: (0, 0, 0, 0)\n",
      "Metrics for Diving (popularity) - MSE: 1.302504265110699e-05, R2: -0.36392589762502126\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.31554D+00    |proj g|=  6.22694D+02\n",
      "\n",
      "At iterate    5    f= -3.16962D+00    |proj g|=  4.32719D+00\n",
      "\n",
      "At iterate   10    f= -3.18075D+00    |proj g|=  1.57787D+01\n",
      "\n",
      "At iterate   15    f= -3.24726D+00    |proj g|=  2.95811D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     18     29      1     0     0   6.975D-04  -3.247D+00\n",
      "  F =  -3.2472597823322946     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.42182D+00    |proj g|=  3.59503D+02\n",
      "\n",
      "At iterate    5    f= -2.99915D+00    |proj g|=  6.05027D-01\n",
      "\n",
      "At iterate   10    f= -3.00712D+00    |proj g|=  1.19995D+01\n",
      "\n",
      "At iterate   15    f= -3.38162D+00    |proj g|=  3.43710D+01\n",
      "\n",
      "At iterate   20    f= -3.40444D+00    |proj g|=  8.66961D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     23     48      1     0     0   2.577D-02  -3.404D+00\n",
      "  F =  -3.4044451744722295     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -5.16441D-01    |proj g|=  1.20694D+03\n",
      "\n",
      "At iterate    5    f= -2.78725D+00    |proj g|=  6.76923D-01\n",
      "\n",
      "At iterate   10    f= -2.81167D+00    |proj g|=  2.51990D+01\n",
      "\n",
      "At iterate   15    f= -3.35538D+00    |proj g|=  1.47572D+00\n",
      "\n",
      "At iterate   20    f= -3.38780D+00    |proj g|=  2.58742D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     22     54      1     0     0   6.200D-04  -3.388D+00\n",
      "  F =  -3.3877953615792977     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.28610D+00    |proj g|=  7.37015D+02\n",
      "\n",
      "At iterate    5    f= -2.76847D+00    |proj g|=  8.13993D-01\n",
      "\n",
      "At iterate   10    f= -3.04796D+00    |proj g|=  1.75153D+02\n",
      "\n",
      "At iterate   15    f= -3.51845D+00    |proj g|=  2.25420D+00\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     19     44      1     0     0   4.182D-03  -3.519D+00\n",
      "  F =  -3.5193745149557016     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -6.60992D-01    |proj g|=  1.07618D+03\n",
      "  ys=-1.102E-01  -gs= 8.419E-01 BFGS update SKIPPED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate    5    f= -2.76163D+00    |proj g|=  8.51358D-01\n",
      "\n",
      "At iterate   10    f= -2.78585D+00    |proj g|=  1.56545D+01\n",
      "\n",
      "At iterate   15    f= -3.63404D+00    |proj g|=  1.89374D+00\n",
      "\n",
      "At iterate   20    f= -3.63411D+00    |proj g|=  2.47359D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     21     55      1     1     0   2.467D-01  -3.634D+00\n",
      "  F =  -3.6341123334222609     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -3.52753D+00    |proj g|=  2.69552D+01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      4     16      1     0     0   1.866D-02  -3.533D+00\n",
      "  F =  -3.5331325009623700     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -3.74548D+00    |proj g|=  2.45808D+01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      4     49      2     0     0   2.544D-02  -3.750D+00\n",
      "  F =  -3.7495089315895331     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -3.79855D+00    |proj g|=  2.34940D+01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      4     45      2     0     0   1.851D-02  -3.802D+00\n",
      "  F =  -3.8017503603457152     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -3.87985D+00    |proj g|=  2.23274D+01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      4     49      2     0     0   1.809D-02  -3.882D+00\n",
      "  F =  -3.8823851537711227     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -3.95013D+00    |proj g|=  2.12493D+01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      4     21      1     0     0   1.780D-02  -3.952D+00\n",
      "  F =  -3.9521643189193232     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -3.95189D+00    |proj g|=  2.05455D+01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      4     22      1     0     0   1.083D-02  -3.954D+00\n",
      "  F =  -3.9536729081788944     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -4.02564D+00    |proj g|=  1.91554D+01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      4     20      1     0     0   6.810D-01  -4.027D+00\n",
      "  F =  -4.0270753336270273     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -4.06633D+00    |proj g|=  1.86034D+01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      4     30      1     0     0   7.270D-01  -4.068D+00\n",
      "  F =  -4.0675649634289721     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -4.10982D+00    |proj g|=  1.80100D+01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      4     50      2     0     0   7.374D-01  -4.111D+00\n",
      "  F =  -4.1108888065217046     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -4.14785D+00    |proj g|=  1.75222D+01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      3     11      1     0     0   7.540D-01  -4.149D+00\n",
      "  F =  -4.1487774882147868     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -4.18518D+00    |proj g|=  1.70253D+01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      3     47      2     0     0   8.469D-01  -4.186D+00\n",
      "  F =  -4.1859982347552016     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -4.21893D+00    |proj g|=  1.66035D+01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      3     47      2     0     0   5.686D-01  -4.220D+00\n",
      "  F =  -4.2196539925641998     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -4.25230D+00    |proj g|=  1.60340D+01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      3     21      1     0     0   3.006D-01  -4.253D+00\n",
      "  F =  -4.2529326722607657     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -4.28191D+00    |proj g|=  1.54649D+01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      3     24      1     0     0   1.293D-01  -4.282D+00\n",
      "  F =  -4.2824542487665997     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -4.31027D+00    |proj g|=  1.50802D+01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      3     24      1     0     0   5.125D-02  -4.311D+00\n",
      "  F =  -4.3107553362118711     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -4.30023D+00    |proj g|=  1.47077D+01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      3     16      1     0     0   8.258D-03  -4.301D+00\n",
      "  F =  -4.3006954032160518     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.68985D+00    |proj g|=  3.47675D+03\n",
      "\n",
      "At iterate    5    f= -2.98431D+00    |proj g|=  4.98873D+00\n",
      "\n",
      "At iterate   10    f= -2.98932D+00    |proj g|=  8.78265D+00\n",
      "\n",
      "At iterate   15    f= -3.54779D+00    |proj g|=  2.39971D+02\n",
      "\n",
      "At iterate   20    f= -4.19281D+00    |proj g|=  4.29496D-01\n",
      "\n",
      "At iterate   25    f= -4.21544D+00    |proj g|=  2.23498D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     28     47      1     0     0   8.540D-05  -4.215D+00\n",
      "  F =  -4.2154501642984341     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -4.20928D+00    |proj g|=  1.28592D+01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      2      8      1     0     0   8.179D-01  -4.210D+00\n",
      "  F =  -4.2097049012138976     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -4.23819D+00    |proj g|=  1.24897D+01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      3     26      1     0     0   9.090D-01  -4.239D+00\n",
      "  F =  -4.2385729474392910     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -4.25513D+00    |proj g|=  1.23701D+01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      3     26      1     0     0   9.604D-01  -4.255D+00\n",
      "  F =  -4.2554836526728970     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -4.27976D+00    |proj g|=  1.20730D+01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      3     26      1     0     0   1.008D+00  -4.280D+00\n",
      "  F =  -4.2800789985374887     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -4.30017D+00    |proj g|=  1.19043D+01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      3     25      1     0     0   1.045D+00  -4.300D+00\n",
      "  F =  -4.3004714666865906     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "Metrics for Diving (popularity) - MSE: 9.29175500322898e-06, R2: 0.027007770894801997\n",
      "Checking stationarity for Equestrianism (popularity):\n",
      "ADF Statistic: -1.9390094621829814, p-value: 0.31393810251704946\n",
      "Skipping ARIMA fitting for non-stationary series: Equestrianism (popularity)\n",
      "Checking stationarity for Fencing (popularity):\n",
      "ADF Statistic: -2.637488381164988, p-value: 0.08549402827335367\n",
      "Skipping ARIMA fitting for non-stationary series: Fencing (popularity)\n",
      "Checking stationarity for Figure Skating (popularity):\n",
      "ADF Statistic: -8.038350034967799, p-value: 1.8760719496758474e-12\n",
      "Optimal ARIMA order: (0, 0, 0)\n",
      "Optimal SARIMA order: (0, 0, 0), Seasonal: (0, 0, 0, 0)\n",
      "Constant series detected for Figure Skating (popularity). Predicting constant value: 0.0074169622702354\n",
      "Metrics for Figure Skating (popularity) - MSE: 3.985305855298758e-06, R2: -0.2637342071362194\n",
      "Constant series detected for Figure Skating (popularity). Predicting constant value: 0.0074169622702354\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -3.49814D+00    |proj g|=  1.86179D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     12      1     0     0   1.862D-01  -3.498D+00\n",
      "  F =  -3.4981387595093971     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -3.53475D+00    |proj g|=  2.00304D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     13      1     0     0   2.003D-01  -3.535D+00\n",
      "  F =  -3.5347455797579066     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -3.36966D+00    |proj g|=  1.44030D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     21      1     0     0   1.440D-01  -3.370D+00\n",
      "  F =  -3.3696574536479269     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -3.26213D+00    |proj g|=  1.16184D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     19      1     0     0   1.162D-01  -3.262D+00\n",
      "  F =  -3.2621308051452793     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -3.21381D+00    |proj g|=  1.05490D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     21      1     0     0   1.055D-01  -3.214D+00\n",
      "  F =  -3.2138100043035340     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -3.21725D+00    |proj g|=  1.06217D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     21      1     0     0   1.062D-01  -3.217D+00\n",
      "  F =  -3.2172455280663610     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -3.24863D+00    |proj g|=  1.13090D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     19      1     0     0   1.131D-01  -3.249D+00\n",
      "  F =  -3.2486267302110186     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -3.25126D+00    |proj g|=  1.13688D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     21      1     0     0   1.137D-01  -3.251D+00\n",
      "  F =  -3.2512637137005189     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -3.26788D+00    |proj g|=  1.17525D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     20      1     0     0   1.175D-01  -3.268D+00\n",
      "  F =  -3.2678778808127582     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -3.26722D+00    |proj g|=  1.17371D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     21      1     0     0   1.174D-01  -3.267D+00\n",
      "  F =  -3.2672177784756191     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -3.26777D+00    |proj g|=  1.17499D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     21      1     0     0   1.175D-01  -3.268D+00\n",
      "  F =  -3.2677664415362062     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -3.29218D+00    |proj g|=  1.23372D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     18      1     0     0   1.234D-01  -3.292D+00\n",
      "  F =  -3.2921764791564194     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -3.28383D+00    |proj g|=  1.21333D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     21      1     0     0   1.213D-01  -3.284D+00\n",
      "  F =  -3.2838342899289601     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -3.28053D+00    |proj g|=  1.20533D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     18      1     0     0   1.205D-01  -3.281D+00\n",
      "  F =  -3.2805255842285956     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -3.27528D+00    |proj g|=  1.19277D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     21      1     0     0   1.193D-01  -3.275D+00\n",
      "  F =  -3.2752819443601631     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -3.27754D+00    |proj g|=  1.19818D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     21      1     0     0   1.198D-01  -3.278D+00\n",
      "  F =  -3.2775448606414805     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "Metrics for Figure Skating (popularity) - MSE: 8.086807472920871e-05, R2: -24.64313907417478\n",
      "Checking stationarity for Football (popularity):\n",
      "ADF Statistic: -1.2110583147807557, p-value: 0.6688207055101476\n",
      "Skipping ARIMA fitting for non-stationary series: Football (popularity)\n",
      "Insufficient data for Freestyle Skiing (popularity)\n",
      "Checking stationarity for Golf (popularity):\n",
      "ADF Statistic: -2.045279942458185, p-value: 0.2670788758305538\n",
      "Skipping ARIMA fitting for non-stationary series: Golf (popularity)\n",
      "Checking stationarity for Gymnastics (popularity):\n",
      "ADF Statistic: 1.565302891046513, p-value: 0.9977496564553763\n",
      "Skipping ARIMA fitting for non-stationary series: Gymnastics (popularity)\n",
      "Checking stationarity for Handball (popularity):\n",
      "ADF Statistic: 1.2682736647488488, p-value: 0.9964252535405722\n",
      "Skipping ARIMA fitting for non-stationary series: Handball (popularity)\n",
      "Checking stationarity for Hockey (popularity):\n",
      "ADF Statistic: 1.5182356628397211, p-value: 0.9975903103518846\n",
      "Skipping ARIMA fitting for non-stationary series: Hockey (popularity)\n",
      "Checking stationarity for Ice Hockey (popularity):\n",
      "ADF Statistic: -4.557825015543955, p-value: 0.00015437479466543703\n",
      "Optimal ARIMA order: (1, 0, 2)\n",
      "Optimal SARIMA order: (0, 0, 0), Seasonal: (0, 0, 0, 0)\n",
      "Metrics for Ice Hockey (popularity) - MSE: 3.275671573415254e-05, R2: -0.7074613934038418\n",
      "Constant series detected for Ice Hockey (popularity). Predicting constant value: 0.0139794967381174\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.83606D+00    |proj g|=  4.95829D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     17      1     0     0   4.958D-02  -2.836D+00\n",
      "  F =  -2.8360566062396537     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.63816D+00    |proj g|=  3.33835D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     17      1     0     0   3.338D-02  -2.638D+00\n",
      "  F =  -2.6381590086667512     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.67740D+00    |proj g|=  3.61078D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     17      1     0     0   3.611D-02  -2.677D+00\n",
      "  F =  -2.6774015494646597     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.58829D+00    |proj g|=  3.02161D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     19      1     0     0   3.022D-02  -2.588D+00\n",
      "  F =  -2.5882913673551196     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.58461D+00    |proj g|=  2.99943D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     21      1     0     0   2.999D-02  -2.585D+00\n",
      "  F =  -2.5846059433193305     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.60347D+00    |proj g|=  3.11470D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     17      1     0     0   3.115D-02  -2.603D+00\n",
      "  F =  -2.6034714381120025     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.53626D+00    |proj g|=  2.72312D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     20      1     0     0   2.723D-02  -2.536D+00\n",
      "  F =  -2.5362628479758706     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.55101D+00    |proj g|=  2.80462D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     18      1     0     0   2.805D-02  -2.551D+00\n",
      "  F =  -2.5510148950588531     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.49092D+00    |proj g|=  2.48715D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     17      1     0     0   2.487D-02  -2.491D+00\n",
      "  F =  -2.4909235229741444     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.47233D+00    |proj g|=  2.39639D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     21      1     0     0   2.396D-02  -2.472D+00\n",
      "  F =  -2.4723289219847278     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.48390D+00    |proj g|=  2.45246D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     20      1     0     0   2.452D-02  -2.484D+00\n",
      "  F =  -2.4838984498383958     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.48206D+00    |proj g|=  2.44346D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     19      1     0     0   2.443D-02  -2.482D+00\n",
      "  F =  -2.4820579809658025     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.45600D+00    |proj g|=  2.31943D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     16      1     0     0   2.319D-02  -2.456D+00\n",
      "  F =  -2.4560010521456594     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.45642D+00    |proj g|=  2.32137D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     17      1     0     0   2.321D-02  -2.456D+00\n",
      "  F =  -2.4564200555977433     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.46406D+00    |proj g|=  2.35709D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     16      1     0     0   2.357D-02  -2.464D+00\n",
      "  F =  -2.4640568925490518     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "Metrics for Ice Hockey (popularity) - MSE: 0.00041527956251446617, R2: -20.602524637560084\n",
      "Insufficient data for Jeu De Paume (popularity)\n",
      "Checking stationarity for Judo (popularity):\n",
      "ADF Statistic: -1.5743966798767401, p-value: 0.49644084314530434\n",
      "Skipping ARIMA fitting for non-stationary series: Judo (popularity)\n",
      "Insufficient data for Lacrosse (popularity)\n",
      "Checking stationarity for Luge (popularity):\n",
      "ADF Statistic: -0.5818113499290328, p-value: 0.8750391792761201\n",
      "Skipping ARIMA fitting for non-stationary series: Luge (popularity)\n",
      "Insufficient data for Military Ski Patrol (popularity)\n",
      "Checking stationarity for Modern Pentathlon (popularity):\n",
      "ADF Statistic: -4.220676724484758, p-value: 0.0006077642493211968\n",
      "Optimal ARIMA order: (1, 0, 0)\n",
      "Optimal SARIMA order: (1, 0, 0), Seasonal: (0, 0, 0, 0)\n",
      "Metrics for Modern Pentathlon (popularity) - MSE: 4.93987892555407e-06, R2: 0.09819941748150074\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -4.04864D-01    |proj g|=  7.22127D+03\n",
      "\n",
      "At iterate    5    f= -3.91880D+00    |proj g|=  2.47857D-01\n",
      "\n",
      "At iterate   10    f= -3.91922D+00    |proj g|=  8.52338D+00\n",
      "\n",
      "At iterate   15    f= -3.95984D+00    |proj g|=  1.05232D+02\n",
      "\n",
      "At iterate   20    f= -4.07183D+00    |proj g|=  9.14562D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     22     72      2     0     0   3.479D-01  -4.072D+00\n",
      "  F =  -4.0718772525652209     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -3.97590D+00    |proj g|=  7.89706D+02\n",
      "\n",
      "At iterate    5    f= -4.24631D+00    |proj g|=  6.93202D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      5     31      1     0     0   6.932D-01  -4.246D+00\n",
      "  F =  -4.2463072286418031     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -4.34729D+00    |proj g|=  6.61697D+02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      5     51      2     0     0   1.738D+00  -4.507D+00\n",
      "  F =  -4.5068359308452033     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -4.71087D+00    |proj g|=  1.77112D+02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      3     23      1     0     0   1.871D+00  -4.727D+00\n",
      "  F =  -4.7265330239485728     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -4.62273D+00    |proj g|=  4.66815D+02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      "\n",
      " Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate    5    f= -4.70585D+00    |proj g|=  5.43451D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      5     29      1     0     0   5.435D-01  -4.706D+00\n",
      "  F =  -4.7058499463338928     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -4.77080D+00    |proj g|=  3.78736D+02\n",
      "\n",
      "At iterate    5    f= -4.82327D+00    |proj g|=  1.76270D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      5     27      1     0     0   1.763D-01  -4.823D+00\n",
      "  F =  -4.8232661263814141     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.77187D-01    |proj g|=  4.54251D+03\n",
      "\n",
      "At iterate    5    f= -3.51216D+00    |proj g|=  7.48875D-01\n",
      "\n",
      "At iterate   10    f= -3.52570D+00    |proj g|=  3.33150D+01\n",
      "\n",
      "At iterate   15    f= -4.30080D+00    |proj g|=  6.78946D+01\n",
      "\n",
      "At iterate   20    f= -4.52700D+00    |proj g|=  1.71510D+01\n",
      "\n",
      "At iterate   25    f= -4.53412D+00    |proj g|=  3.36877D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     26     51      1     0     0   8.490D-04  -4.534D+00\n",
      "  F =  -4.5341165470416041     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.02433D+00    |proj g|=  6.54467D+03\n",
      "  ys=-8.770E+00  -gs= 9.719E-01 BFGS update SKIPPED\n",
      "\n",
      "At iterate    5    f= -3.42706D+00    |proj g|=  7.86928D-01\n",
      "\n",
      "At iterate   10    f= -3.43128D+00    |proj g|=  1.61464D+01\n",
      "\n",
      "At iterate   15    f= -4.00849D+00    |proj g|=  3.16301D+02\n",
      "\n",
      "At iterate   20    f= -4.54570D+00    |proj g|=  4.07205D+00\n",
      "\n",
      "At iterate   25    f= -4.58376D+00    |proj g|=  9.38343D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     28     43      1     1     0   4.051D-02  -4.584D+00\n",
      "  F =  -4.5837732175037038     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  3.94391D+00    |proj g|=  8.94459D+03\n",
      "\n",
      "At iterate    5    f= -3.36440D+00    |proj g|=  8.74554D-01\n",
      "\n",
      "At iterate   10    f= -3.36767D+00    |proj g|=  1.26947D+01\n",
      "\n",
      "At iterate   15    f= -3.82457D+00    |proj g|=  3.19693D+02\n",
      "\n",
      "At iterate   20    f= -4.62558D+00    |proj g|=  8.99705D+01\n",
      "\n",
      "At iterate   25    f= -4.65122D+00    |proj g|=  7.88013D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     28     49      1     0     0   7.684D-05  -4.651D+00\n",
      "  F =  -4.6512227921063465     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -4.52565D+00    |proj g|=  7.05026D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      1     21      1     0     0   7.050D-01  -4.526D+00\n",
      "  F =  -4.5256513552511546     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -4.55023D+00    |proj g|=  1.40675D+01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      2     45      2     0     0   1.446D+00  -4.550D+00\n",
      "  F =  -4.5504326762323224     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -4.58236D+00    |proj g|=  2.18192D+01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      4     30      1     0     0   1.940D+00  -4.583D+00\n",
      "  F =  -4.5828621611321942     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -4.62806D+00    |proj g|=  1.05178D+01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      2     46      2     0     0   1.642D+00  -4.628D+00\n",
      "  F =  -4.6281382536278244     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -4.66503D+00    |proj g|=  1.32869D+01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      2     24      1     0     0   1.887D+00  -4.665D+00\n",
      "  F =  -4.6651662989991491     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -4.70238D+00    |proj g|=  1.36186D+01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      2     25      1     0     0   1.869D+00  -4.703D+00\n",
      "  F =  -4.7025079060124853     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -4.73854D+00    |proj g|=  9.31210D+00\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      2     24      1     0     0   1.531D+00  -4.739D+00\n",
      "  F =  -4.7385870215940074     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -4.76551D+00    |proj g|=  1.63980D+00\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      1     21      1     0     0   1.640D+00  -4.766D+00\n",
      "  F =  -4.7655120209707240     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -4.65987D+00    |proj g|=  1.01552D+01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      2     22      1     0     0   1.568D+00  -4.660D+00\n",
      "  F =  -4.6600395920797766     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -4.67983D+00    |proj g|=  9.42455D+00\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      2     24      1     0     0   1.687D+00  -4.680D+00\n",
      "  F =  -4.6799746774542488     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -4.69593D+00    |proj g|=  7.33537D+00\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      2     13      1     0     0   2.245D+00  -4.696D+00\n",
      "  F =  -4.6960269454577217     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -4.71909D+00    |proj g|=  6.55066D+00\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      3     26      1     0     0   2.240D+00  -4.719D+00\n",
      "  F =  -4.7191765595200845     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -4.74259D+00    |proj g|=  6.21653D+00\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      3     48      2     0     0   2.423D+00  -4.743D+00\n",
      "  F =  -4.7426694063778845     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -4.76599D+00    |proj g|=  7.45298D+00\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      2     46      2     0     0   2.557D+00  -4.766D+00\n",
      "  F =  -4.7660814347812774     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -4.77281D+00    |proj g|=  2.83999D+00\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      2     21      1     0     0   5.959D-01  -4.773D+00\n",
      "  F =  -4.7728323163692759     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "Metrics for Modern Pentathlon (popularity) - MSE: 3.860500371050066e-06, R2: 0.2952455847821517\n",
      "Insufficient data for Motorboating (popularity)\n",
      "Checking stationarity for Nordic Combined (popularity):\n",
      "ADF Statistic: -2.1004775950750134, p-value: 0.2443226014930085\n",
      "Skipping ARIMA fitting for non-stationary series: Nordic Combined (popularity)\n",
      "Checking stationarity for Polo (popularity):\n",
      "ADF Statistic: -7.854134690273293, p-value: 5.500316574224187e-12\n",
      "Optimal ARIMA order: (0, 0, 0)\n",
      "Optimal SARIMA order: (0, 0, 0), Seasonal: (0, 0, 0, 0)\n",
      "Constant series detected for Polo (popularity). Predicting constant value: 0.0108471074380165\n",
      "Metrics for Polo (popularity) - MSE: 1.8129218094867512e-05, R2: -64.66439842993044\n",
      "Constant series detected for Polo (popularity). Predicting constant value: 0.0108471074380165\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -3.39159D+00    |proj g|=  1.50482D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     18      1     0     0   1.505D-01  -3.392D+00\n",
      "  F =  -3.3915918428889471     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -3.53843D+00    |proj g|=  2.01783D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     13      1     0     0   2.018D-01  -3.538D+00\n",
      "  F =  -3.5384271987448428     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -3.62568D+00    |proj g|=  2.40204D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     17      1     0     0   2.402D-01  -3.626D+00\n",
      "  F =  -3.6256839220604045     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for Polo (popularity) - MSE: 2.2549453542959747e-05, R2: -80.67458155524695\n",
      "Insufficient data for Racquets (popularity)\n",
      "Checking stationarity for Rhythmic Gymnastics (popularity):\n",
      "ADF Statistic: -10.326996934985573, p-value: 2.9082535024634263e-18\n",
      "Optimal ARIMA order: (1, 0, 0)\n",
      "Optimal SARIMA order: (1, 0, 0), Seasonal: (0, 0, 0, 0)\n",
      "Metrics for Rhythmic Gymnastics (popularity) - MSE: 5.212423463501747e-06, R2: -1.2900108985693404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.10885D+01    |proj g|=  5.13709D+05\n",
      "  ys=-9.232E+00  -gs= 9.773E-01 BFGS update SKIPPED\n",
      "\n",
      "At iterate    5    f= -5.30030D+00    |proj g|=  3.87514D+01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      7     37      1     1     0   4.801D+00  -5.300D+00\n",
      "  F =  -5.3003272170767186     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  7.47020D+01    |proj g|=  2.93489D+06\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      5     66      2     0     0   1.093D+01  -5.747D+00\n",
      "  F =  -5.7467275103782178     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -3.25693D+00    |proj g|=  1.54700D+03\n",
      "\n",
      "At iterate    5    f= -4.09961D+00    |proj g|=  4.84177D-01\n",
      "\n",
      "At iterate   10    f= -4.10010D+00    |proj g|=  9.29412D+00\n",
      "\n",
      "At iterate   15    f= -4.14283D+00    |proj g|=  8.19499D+01\n",
      "\n",
      "At iterate   20    f= -4.49272D+00    |proj g|=  6.74333D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     21     47      1     0     0   6.743D-01  -4.493D+00\n",
      "  F =  -4.4927167699357966     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.68244D+00    |proj g|=  2.15498D+03\n",
      "\n",
      "At iterate    5    f= -3.98446D+00    |proj g|=  6.99373D-01\n",
      "\n",
      "At iterate   10    f= -3.98525D+00    |proj g|=  1.18683D+01\n",
      "\n",
      "At iterate   15    f= -4.09818D+00    |proj g|=  2.86193D+02\n",
      "\n",
      "At iterate   20    f= -4.63841D+00    |proj g|=  1.29758D+01\n",
      "\n",
      "At iterate   25    f= -4.64270D+00    |proj g|=  4.47155D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     25     46      1     0     0   4.472D-03  -4.643D+00\n",
      "  F =  -4.6427016487134516     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.65287D+00    |proj g|=  3.67806D+03\n",
      "\n",
      "At iterate    5    f= -3.91339D+00    |proj g|=  6.54643D+00\n",
      "\n",
      "At iterate   10    f= -4.07866D+00    |proj g|=  4.02677D+02\n",
      "\n",
      "At iterate   15    f= -4.73355D+00    |proj g|=  4.21177D+01\n",
      "\n",
      "At iterate   20    f= -4.75383D+00    |proj g|=  5.15528D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     24     38      1     0     0   2.968D-05  -4.754D+00\n",
      "  F =  -4.7538296911352882     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -3.05542D-01    |proj g|=  5.78575D+03\n",
      "  ys=-6.655E+00  -gs= 9.266E-01 BFGS update SKIPPED\n",
      "\n",
      "At iterate    5    f= -3.83735D+00    |proj g|=  2.05020D+01\n",
      "\n",
      "At iterate   10    f= -3.84088D+00    |proj g|=  2.65045D+00\n",
      "\n",
      "At iterate   15    f= -3.85693D+00    |proj g|=  4.08658D+01\n",
      "\n",
      "At iterate   20    f= -4.80963D+00    |proj g|=  3.20297D+01\n",
      "\n",
      "At iterate   25    f= -4.82465D+00    |proj g|=  1.58306D+00\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     27     52      1     1     0   3.470D-02  -4.825D+00\n",
      "  F =  -4.8246966258159976     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.22919D+00    |proj g|=  8.37223D+03\n",
      "\n",
      "At iterate    5    f= -3.78175D+00    |proj g|=  8.32721D-01\n",
      "\n",
      "At iterate   10    f= -3.78294D+00    |proj g|=  1.07557D+01\n",
      "\n",
      "At iterate   15    f= -3.93787D+00    |proj g|=  3.38755D+02\n",
      "\n",
      "At iterate   20    f= -4.86842D+00    |proj g|=  2.14686D+01\n",
      "\n",
      "At iterate   25    f= -4.90134D+00    |proj g|=  4.24427D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     28     49      1     0     0   6.702D-05  -4.901D+00\n",
      "  F =  -4.9013485678078750     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "Metrics for Rhythmic Gymnastics (popularity) - MSE: 2.7713448590270786e-06, R2: -0.21755455505576937\n",
      "Insufficient data for Roque (popularity)\n",
      "Checking stationarity for Rowing (popularity):\n",
      "ADF Statistic: -3.1126651007050183, p-value: 0.025630001585137056\n",
      "Optimal ARIMA order: (1, 0, 0)\n",
      "Optimal SARIMA order: (1, 0, 0), Seasonal: (0, 0, 0, 0)\n",
      "Metrics for Rowing (popularity) - MSE: 0.0002849388148692326, R2: -0.2926376885908164\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.27179D-02    |proj g|=  3.14125D+02\n",
      "\n",
      "At iterate    5    f= -1.68859D+00    |proj g|=  1.84121D+00\n",
      "\n",
      "At iterate   10    f= -1.75907D+00    |proj g|=  1.28390D+00\n",
      "\n",
      "At iterate   15    f= -1.75953D+00    |proj g|=  1.50660D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     16     38      1     0     0   1.507D-03  -1.760D+00\n",
      "  F =  -1.7595339440269684     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.01540D+00    |proj g|=  1.17954D+01\n",
      "\n",
      "At iterate    5    f= -1.11217D+00    |proj g|=  1.57941D+00\n",
      "\n",
      "At iterate   10    f= -1.28225D+00    |proj g|=  8.01444D-01\n",
      "\n",
      "At iterate   15    f= -1.28410D+00    |proj g|=  1.26863D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     15     33      1     0     0   1.269D-03  -1.284D+00\n",
      "  F =  -1.2840974147206590     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.37368D+00    |proj g|=  4.28267D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      2     16      1     0     0   8.958D-04  -1.374D+00\n",
      "  F =  -1.3736851951303533     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.45381D+00    |proj g|=  4.81542D-01\n",
      "\n",
      "At iterate    5    f= -1.45398D+00    |proj g|=  3.72241D-02\n",
      "\n",
      "At iterate   10    f= -1.45406D+00    |proj g|=  2.14117D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     13     16      1     0     0   6.394D-06  -1.454D+00\n",
      "  F =  -1.4540642808370150     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.54960D+00    |proj g|=  1.29552D+00\n",
      "\n",
      "At iterate    5    f= -1.55065D+00    |proj g|=  3.16706D-01\n",
      "\n",
      "At iterate   10    f= -1.55106D+00    |proj g|=  1.59418D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     12     28      1     0     0   3.820D-04  -1.551D+00\n",
      "  F =  -1.5510624262673194     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.62447D+00    |proj g|=  1.79283D+00\n",
      "\n",
      "At iterate    5    f= -1.62606D+00    |proj g|=  2.89949D-01\n",
      "\n",
      "At iterate   10    f= -1.62696D+00    |proj g|=  2.69407D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     13     27      1     0     0   3.127D-04  -1.627D+00\n",
      "  F =  -1.6269594742521556     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.67924D+00    |proj g|=  1.86749D+00\n",
      "\n",
      "At iterate    5    f= -1.68077D+00    |proj g|=  2.65765D-01\n",
      "\n",
      "At iterate   10    f= -1.68190D+00    |proj g|=  2.26165D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     14     32      1     0     0   7.425D-04  -1.682D+00\n",
      "  F =  -1.6819279920496468     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.72949D+00    |proj g|=  1.81319D+00\n",
      "\n",
      "At iterate    5    f= -1.73080D+00    |proj g|=  2.51127D-01\n",
      "\n",
      "At iterate   10    f= -1.73202D+00    |proj g|=  3.69118D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     14     18      1     0     0   2.062D-04  -1.732D+00\n",
      "  F =  -1.7320771447740015     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.78150D+00    |proj g|=  1.91820D+00\n",
      "\n",
      "At iterate    5    f= -1.78281D+00    |proj g|=  2.22583D-01\n",
      "\n",
      "At iterate   10    f= -1.78411D+00    |proj g|=  6.55771D-01\n",
      "\n",
      "At iterate   15    f= -1.78429D+00    |proj g|=  8.25122D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     15     34      1     0     0   8.251D-04  -1.784D+00\n",
      "  F =  -1.7842902132679057     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.83013D+00    |proj g|=  2.08363D+00\n",
      "\n",
      "At iterate    5    f= -1.83152D+00    |proj g|=  1.96986D-01\n",
      "\n",
      "At iterate   10    f= -1.83282D+00    |proj g|=  9.69356D-01\n",
      "\n",
      "At iterate   15    f= -1.83323D+00    |proj g|=  3.24795D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     15     19      1     0     0   3.248D-04  -1.833D+00\n",
      "  F =  -1.8332316085205667     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.87225D+00    |proj g|=  2.13346D+00\n",
      "\n",
      "At iterate    5    f= -1.87360D+00    |proj g|=  1.83235D-01\n",
      "\n",
      "At iterate   10    f= -1.87483D+00    |proj g|=  1.15162D+00\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     14     53      2     0     0   4.536D-03  -1.875D+00\n",
      "  F =  -1.8754524270030484     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.91323D+00    |proj g|=  2.26304D+00\n",
      "\n",
      "At iterate    5    f= -1.91462D+00    |proj g|=  1.72023D-01\n",
      "\n",
      "At iterate   10    f= -1.91579D+00    |proj g|=  1.31145D+00\n",
      "\n",
      "At iterate   15    f= -1.91666D+00    |proj g|=  1.52134D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     16     32      1     0     0   1.521D-03  -1.917D+00\n",
      "  F =  -1.9166605221449122     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.94528D+00    |proj g|=  2.14841D+00\n",
      "\n",
      "At iterate    5    f= -1.94647D+00    |proj g|=  1.64317D-01\n",
      "\n",
      "At iterate   10    f= -1.94752D+00    |proj g|=  1.35756D+00\n",
      "\n",
      "At iterate   15    f= -1.94849D+00    |proj g|=  2.05103D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     16     33      1     0     0   2.024D-03  -1.948D+00\n",
      "  F =  -1.9484893110436776     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.98156D+00    |proj g|=  2.30234D+00\n",
      "\n",
      "At iterate    5    f= -1.98282D+00    |proj g|=  1.58720D-01\n",
      "\n",
      "At iterate   10    f= -1.98385D+00    |proj g|=  1.45941D+00\n",
      "\n",
      "At iterate   15    f= -1.98501D+00    |proj g|=  2.59464D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     16     20      1     0     0   5.228D-04  -1.985D+00\n",
      "  F =  -1.9850145319748014     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.01544D+00    |proj g|=  2.46862D+00\n",
      "\n",
      "At iterate    5    f= -2.01679D+00    |proj g|=  1.57843D-01\n",
      "\n",
      "At iterate   10    f= -2.01782D+00    |proj g|=  1.55836D+00\n",
      "\n",
      "At iterate   15    f= -2.01918D+00    |proj g|=  2.72390D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     17     38      1     0     0   8.335D-04  -2.019D+00\n",
      "  F =  -2.0191752877649805     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.04468D+00    |proj g|=  2.48989D+00\n",
      "\n",
      "At iterate    5    f= -2.04598D+00    |proj g|=  1.54234D-01\n",
      "\n",
      "At iterate   10    f= -2.04696D+00    |proj g|=  1.60841D+00\n",
      "\n",
      "At iterate   15    f= -2.04845D+00    |proj g|=  2.15903D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     17     33      1     0     0   1.220D-03  -2.048D+00\n",
      "  F =  -2.0484520161140840     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.05345D+00    |proj g|=  1.98044D+00\n",
      "\n",
      "At iterate    5    f= -2.05428D+00    |proj g|=  1.37125D-01\n",
      "\n",
      "At iterate   10    f= -2.05499D+00    |proj g|=  1.43524D+00\n",
      "\n",
      "At iterate   15    f= -2.05630D+00    |proj g|=  5.65057D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     16     20      1     0     0   5.187D-05  -2.056D+00\n",
      "  F =  -2.0562971710183757     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.08075D+00    |proj g|=  1.92391D+00\n",
      "\n",
      "At iterate    5    f= -2.08150D+00    |proj g|=  1.29242D-01\n",
      "\n",
      "At iterate   10    f= -2.08211D+00    |proj g|=  1.40868D+00\n",
      "\n",
      "At iterate   15    f= -2.08344D+00    |proj g|=  9.97573D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     17     31      1     0     0   1.758D-03  -2.083D+00\n",
      "  F =  -2.0834381568747404     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.10675D+00    |proj g|=  2.14915D+00\n",
      "\n",
      "At iterate    5    f= -2.10763D+00    |proj g|=  1.32393D-01\n",
      "\n",
      "At iterate   10    f= -2.10828D+00    |proj g|=  1.49363D+00\n",
      "\n",
      "At iterate   15    f= -2.10973D+00    |proj g|=  2.08452D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     17     33      1     0     0   2.062D-03  -2.110D+00\n",
      "  F =  -2.1097332621331764     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.13020D+00    |proj g|=  2.11783D+00\n",
      "\n",
      "At iterate    5    f= -2.13102D+00    |proj g|=  1.27306D-01\n",
      "\n",
      "At iterate   10    f= -2.13161D+00    |proj g|=  1.48416D+00\n",
      "\n",
      "At iterate   15    f= -2.13312D+00    |proj g|=  5.61254D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     17     34      1     0     0   2.587D-03  -2.133D+00\n",
      "  F =  -2.1331205570464080     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.15417D+00    |proj g|=  2.15974D+00\n",
      "\n",
      "At iterate    5    f= -2.15498D+00    |proj g|=  1.25342D-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate   10    f= -2.15554D+00    |proj g|=  1.50324D+00\n",
      "\n",
      "At iterate   15    f= -2.15713D+00    |proj g|=  8.97976D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     17     22      1     0     0   2.488D-03  -2.157D+00\n",
      "  F =  -2.1571285279643106     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.17421D+00    |proj g|=  2.07164D+00\n",
      "\n",
      "At iterate    5    f= -2.17493D+00    |proj g|=  1.18544D-01\n",
      "\n",
      "At iterate   10    f= -2.17543D+00    |proj g|=  1.45657D+00\n",
      "\n",
      "At iterate   15    f= -2.17702D+00    |proj g|=  1.43370D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     17     21      1     0     0   7.161D-04  -2.177D+00\n",
      "  F =  -2.1770197839772734     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.19649D+00    |proj g|=  2.13621D+00\n",
      "\n",
      "At iterate    5    f= -2.19722D+00    |proj g|=  1.18324D-01\n",
      "\n",
      "At iterate   10    f= -2.19771D+00    |proj g|=  1.48352D+00\n",
      "\n",
      "At iterate   15    f= -2.19936D+00    |proj g|=  1.75769D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     18     32      1     0     0   8.957D-04  -2.199D+00\n",
      "  F =  -2.1993623740878721     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.21668D+00    |proj g|=  2.12105D+00\n",
      "\n",
      "At iterate    5    f= -2.21738D+00    |proj g|=  1.14936D-01\n",
      "\n",
      "At iterate   10    f= -2.21783D+00    |proj g|=  1.46931D+00\n",
      "\n",
      "At iterate   15    f= -2.21952D+00    |proj g|=  2.27845D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     18     33      1     0     0   1.185D-03  -2.220D+00\n",
      "  F =  -2.2195162201952776     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.23646D+00    |proj g|=  2.12082D+00\n",
      "\n",
      "At iterate    5    f= -2.23713D+00    |proj g|=  1.12417D-01\n",
      "\n",
      "At iterate   10    f= -2.23755D+00    |proj g|=  1.46171D+00\n",
      "\n",
      "At iterate   15    f= -2.23927D+00    |proj g|=  2.78251D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     18     61      2     0     0   1.466D-03  -2.239D+00\n",
      "  F =  -2.2392711169318149     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.25505D+00    |proj g|=  2.09490D+00\n",
      "\n",
      "At iterate    5    f= -2.25568D+00    |proj g|=  1.08902D-01\n",
      "\n",
      "At iterate   10    f= -2.25607D+00    |proj g|=  1.43809D+00\n",
      "\n",
      "At iterate   15    f= -2.25780D+00    |proj g|=  3.35023D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     18     36      1     0     0   1.764D-03  -2.258D+00\n",
      "  F =  -2.2578054104789533     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.27388D+00    |proj g|=  2.12603D+00\n",
      "\n",
      "At iterate    5    f= -2.27451D+00    |proj g|=  1.08248D-01\n",
      "\n",
      "At iterate   10    f= -2.27488D+00    |proj g|=  1.44792D+00\n",
      "\n",
      "At iterate   15    f= -2.27665D+00    |proj g|=  3.70099D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     18     29      1     0     0   1.948D-03  -2.277D+00\n",
      "  F =  -2.2766530451698945     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.28624D+00    |proj g|=  1.93638D+00\n",
      "\n",
      "At iterate    5    f= -2.28675D+00    |proj g|=  9.76220D-02\n",
      "\n",
      "At iterate   10    f= -2.28705D+00    |proj g|=  1.32246D+00\n",
      "\n",
      "At iterate   15    f= -2.28873D+00    |proj g|=  6.43279D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     17     22      1     0     0   2.660D-05  -2.289D+00\n",
      "  F =  -2.2887271658974879     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "Metrics for Rowing (popularity) - MSE: 0.0005487176828675417, R2: -1.489282331002621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking stationarity for Rugby (popularity):\n",
      "ADF Statistic: -1.534890176273394, p-value: 0.5161865254566824\n",
      "Skipping ARIMA fitting for non-stationary series: Rugby (popularity)\n",
      "Insufficient data for Rugby Sevens (popularity)\n",
      "Checking stationarity for Sailing (popularity):\n",
      "ADF Statistic: -1.8089880791038262, p-value: 0.37600858068374476\n",
      "Skipping ARIMA fitting for non-stationary series: Sailing (popularity)\n",
      "Checking stationarity for Shooting (popularity):\n",
      "ADF Statistic: -2.7501605120860946, p-value: 0.06575317914177882\n",
      "Skipping ARIMA fitting for non-stationary series: Shooting (popularity)\n",
      "Insufficient data for Short Track Speed Skating (popularity)\n",
      "Insufficient data for Skeleton (popularity)\n",
      "Checking stationarity for Ski Jumping (popularity):\n",
      "ADF Statistic: -2.7082002360703794, p-value: 0.07262998769180708\n",
      "Skipping ARIMA fitting for non-stationary series: Ski Jumping (popularity)\n",
      "All zero values for Snowboarding (popularity), skipping.\n",
      "Insufficient data for Softball (popularity)\n",
      "Checking stationarity for Speed Skating (popularity):\n",
      "ADF Statistic: -1.8947803195828383, p-value: 0.3345205833897141\n",
      "Skipping ARIMA fitting for non-stationary series: Speed Skating (popularity)\n",
      "Checking stationarity for Swimming (popularity):\n",
      "ADF Statistic: -1.4941568287038627, p-value: 0.5363998664245984\n",
      "Skipping ARIMA fitting for non-stationary series: Swimming (popularity)\n",
      "Checking stationarity for Synchronized Swimming (popularity):\n",
      "ADF Statistic: -0.8377078312645199, p-value: 0.8077940329155665\n",
      "Skipping ARIMA fitting for non-stationary series: Synchronized Swimming (popularity)\n",
      "Checking stationarity for Table Tennis (popularity):\n",
      "ADF Statistic: -2.2700403504342628, p-value: 0.18181265148931613\n",
      "Skipping ARIMA fitting for non-stationary series: Table Tennis (popularity)\n",
      "Checking stationarity for Taekwondo (popularity):\n",
      "ADF Statistic: 0.47807878243494595, p-value: 0.9841913670141567\n",
      "Skipping ARIMA fitting for non-stationary series: Taekwondo (popularity)\n",
      "Checking stationarity for Tennis (popularity):\n",
      "ADF Statistic: -85.42595697049681, p-value: 0.0\n",
      "Optimal ARIMA order: (0, 1, 1)\n",
      "Optimal SARIMA order: (0, 1, 1), Seasonal: (0, 0, 0, 0)\n",
      "Fitting error for Tennis (popularity): too many indices for array: array is 0-dimensional, but 1 were indexed\n",
      "No predictions made for Tennis (popularity).\n",
      "Fitting error for Tennis (popularity): too many indices for array: array is 0-dimensional, but 1 were indexed\n",
      "No predictions made for Tennis (popularity).\n",
      "Checking stationarity for Trampolining (popularity):\n",
      "ADF Statistic: -7.720502192802472, p-value: 1.1961807769309694e-11\n",
      "Optimal ARIMA order: (0, 0, 0)\n",
      "Optimal SARIMA order: (0, 0, 0), Seasonal: (0, 0, 0, 0)\n",
      "Constant series detected for Trampolining (popularity). Predicting constant value: 0.0017364879531148\n",
      "Metrics for Trampolining (popularity) - MSE: 1.5493890797384764e-07, R2: -51.94040953543624\n",
      "Constant series detected for Trampolining (popularity). Predicting constant value: 0.0017364879531148\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -4.75478D+00    |proj g|=  2.28536D+00\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     21      1     0     0   2.285D+00  -4.755D+00\n",
      "  F =  -4.7547761996563054     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -4.71092D+00    |proj g|=  2.09417D+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     20      1     0     0   2.094D+00  -4.711D+00\n",
      "  F =  -4.7109212967862035     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -4.67540D+00    |proj g|=  1.95107D+00\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     19      1     0     0   1.951D+00  -4.675D+00\n",
      "  F =  -4.6754003992008411     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "Metrics for Trampolining (popularity) - MSE: 4.387292270486045e-06, R2: -1498.0750392431414\n",
      "Checking stationarity for Triathlon (popularity):\n",
      "ADF Statistic: -0.27032651552237325, p-value: 0.9296031111033893\n",
      "Skipping ARIMA fitting for non-stationary series: Triathlon (popularity)\n",
      "Checking stationarity for Tug-Of-War (popularity):\n",
      "ADF Statistic: -1.7185754562051825, p-value: 0.4215681481534028\n",
      "Skipping ARIMA fitting for non-stationary series: Tug-Of-War (popularity)\n",
      "Checking stationarity for Volleyball (popularity):\n",
      "ADF Statistic: -0.18538451728275782, p-value: 0.9402414686983294\n",
      "Skipping ARIMA fitting for non-stationary series: Volleyball (popularity)\n",
      "Checking stationarity for Water Polo (popularity):\n",
      "ADF Statistic: -3.7512660315409643, p-value: 0.0034471899282735715\n",
      "Optimal ARIMA order: (1, 0, 0)\n",
      "Optimal SARIMA order: (2, 0, 2), Seasonal: (0, 0, 0, 0)\n",
      "Metrics for Water Polo (popularity) - MSE: 2.7281030616548134e-05, R2: -0.5170978830173381\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            5     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.09286D+00    |proj g|=  1.64161D+03\n",
      "\n",
      "At iterate    5    f= -2.54240D+00    |proj g|=  5.32747D-01\n",
      "\n",
      "At iterate   10    f= -2.57948D+00    |proj g|=  2.33496D+01\n",
      "\n",
      "At iterate   15    f= -3.11195D+00    |proj g|=  1.68541D+00\n",
      "\n",
      "At iterate   20    f= -3.12322D+00    |proj g|=  1.94848D+00\n",
      "\n",
      "At iterate   25    f= -3.16230D+00    |proj g|=  6.07346D+00\n",
      "\n",
      "At iterate   30    f= -3.17096D+00    |proj g|=  5.51088D+00\n",
      "\n",
      "At iterate   35    f= -3.17139D+00    |proj g|=  3.15382D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    5     37     66      1     0     0   3.161D-04  -3.171D+00\n",
      "  F =  -3.1713879891426084     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            5     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.90085D-01    |proj g|=  1.38358D+03\n",
      "\n",
      "At iterate    5    f= -3.03970D+00    |proj g|=  7.56961D+00\n",
      "\n",
      "At iterate   10    f= -3.28502D+00    |proj g|=  1.41521D+00\n",
      "\n",
      "At iterate   15    f= -3.29069D+00    |proj g|=  1.05278D+01\n",
      "\n",
      "At iterate   20    f= -3.39445D+00    |proj g|=  3.73775D+01\n",
      "\n",
      "At iterate   25    f= -3.40829D+00    |proj g|=  4.63031D+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    5     28     67      1     0     0   2.849D-01  -3.409D+00\n",
      "  F =  -3.4086367688702794     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            5     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  7.89594D-01    |proj g|=  1.50628D+03\n",
      "\n",
      "At iterate    5    f= -2.55696D+00    |proj g|=  5.31889D-01\n",
      "\n",
      "At iterate   10    f= -2.60862D+00    |proj g|=  2.82224D+01\n",
      "\n",
      "At iterate   15    f= -3.18597D+00    |proj g|=  1.79695D+01\n",
      "\n",
      "At iterate   20    f= -3.20017D+00    |proj g|=  1.02844D+00\n",
      "\n",
      "At iterate   25    f= -3.20816D+00    |proj g|=  1.23403D+01\n",
      "\n",
      "At iterate   30    f= -3.25802D+00    |proj g|=  4.29449D+00\n",
      "\n",
      "At iterate   35    f= -3.26090D+00    |proj g|=  3.94408D-01\n",
      "\n",
      "At iterate   40    f= -3.26095D+00    |proj g|=  5.08096D-01\n",
      "\n",
      "At iterate   45    f= -3.26234D+00    |proj g|=  3.71992D+00\n",
      "\n",
      "At iterate   50    f= -3.34937D+00    |proj g|=  2.71358D+00\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    5     50     71      1     0     0   2.714D+00  -3.349D+00\n",
      "  F =  -3.3493729895344848     \n",
      "\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT                 \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            5     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.32965D+00    |proj g|=  1.82706D+03\n",
      "\n",
      "At iterate    5    f= -2.56692D+00    |proj g|=  8.76066D-01\n",
      "\n",
      "At iterate   10    f= -2.63304D+00    |proj g|=  3.64520D+01\n",
      "\n",
      "At iterate   15    f= -3.19993D+00    |proj g|=  6.88806D+00\n",
      "\n",
      "At iterate   20    f= -3.20427D+00    |proj g|=  5.64223D-01\n",
      "\n",
      "At iterate   25    f= -3.21053D+00    |proj g|=  5.09257D-01\n",
      "\n",
      "At iterate   30    f= -3.22227D+00    |proj g|=  2.96664D-02\n",
      "\n",
      "At iterate   35    f= -3.22262D+00    |proj g|=  5.05960D-01\n",
      "\n",
      "At iterate   40    f= -3.23438D+00    |proj g|=  1.45008D+01\n",
      "\n",
      "At iterate   45    f= -3.24976D+00    |proj g|=  1.68461D-02\n",
      "\n",
      "At iterate   50    f= -3.25266D+00    |proj g|=  6.17584D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    5     50     67      1     0     0   6.176D-02  -3.253D+00\n",
      "  F =  -3.2526592680606172     \n",
      "\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT                 \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            5     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -3.01974D+00    |proj g|=  1.66764D+02\n",
      "\n",
      "At iterate    5    f= -3.17540D+00    |proj g|=  5.00173D-01\n",
      "\n",
      "At iterate   10    f= -3.21591D+00    |proj g|=  3.11557D+01\n",
      "\n",
      "At iterate   15    f= -3.29491D+00    |proj g|=  1.76794D-01\n",
      "\n",
      "At iterate   20    f= -3.30311D+00    |proj g|=  3.92049D-01\n",
      "\n",
      "At iterate   25    f= -3.30313D+00    |proj g|=  3.96094D-01\n",
      "\n",
      "At iterate   30    f= -3.30497D+00    |proj g|=  4.42856D+00\n",
      "\n",
      "At iterate   35    f= -3.32594D+00    |proj g|=  6.72693D+00\n",
      "\n",
      "At iterate   40    f= -3.33204D+00    |proj g|=  6.46815D-01\n",
      "\n",
      "At iterate   45    f= -3.33284D+00    |proj g|=  4.74487D-01\n",
      "\n",
      "At iterate   50    f= -3.33295D+00    |proj g|=  4.22849D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    5     50     60      1     0     0   4.228D-01  -3.333D+00\n",
      "  F =  -3.3329461313038733     \n",
      "\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT                 \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            5     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  4.96213D-01    |proj g|=  1.41693D+03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ys=-7.663E-01  -gs= 1.048E+00 BFGS update SKIPPED\n",
      "\n",
      "At iterate    5    f= -2.59478D+00    |proj g|=  7.53890D-01\n",
      "\n",
      "At iterate   10    f= -2.72502D+00    |proj g|=  5.87400D+01\n",
      "\n",
      "At iterate   15    f= -3.33840D+00    |proj g|=  3.25735D+00\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    5     19     46      1     1     0   3.788D-02  -3.340D+00\n",
      "  F =  -3.3395885841972675     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            5     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  8.50199D+05    |proj g|=  6.37657D+10\n",
      "\n",
      "At iterate    5    f= -2.90693D+00    |proj g|=  1.05264D+00\n",
      "\n",
      "At iterate   10    f= -2.93688D+00    |proj g|=  2.05263D+01\n",
      "\n",
      "At iterate   15    f= -3.38515D+00    |proj g|=  5.47345D+00\n",
      "\n",
      "At iterate   20    f= -3.39568D+00    |proj g|=  7.71446D-01\n",
      "\n",
      "At iterate   25    f= -3.39617D+00    |proj g|=  1.39015D-01\n",
      "\n",
      "At iterate   30    f= -3.39661D+00    |proj g|=  5.75802D-01\n",
      "\n",
      "At iterate   35    f= -3.40441D+00    |proj g|=  3.29213D-01\n",
      "\n",
      "At iterate   40    f= -3.40454D+00    |proj g|=  6.76366D-02\n",
      "\n",
      "At iterate   45    f= -3.40465D+00    |proj g|=  3.88118D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    5     47     73      1     0     0   1.443D-03  -3.405D+00\n",
      "  F =  -3.4046544543201041     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            5     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.72171D+06    |proj g|=  1.29129D+11\n",
      "\n",
      "At iterate    5    f= -2.56768D+00    |proj g|=  3.69671D+00\n",
      "\n",
      "At iterate   10    f= -2.58019D+00    |proj g|=  8.37757D+00\n",
      "\n",
      "At iterate   15    f= -3.38692D+00    |proj g|=  3.22031D+01\n",
      "\n",
      "At iterate   20    f= -3.42266D+00    |proj g|=  2.50296D-02\n",
      "\n",
      "At iterate   25    f= -3.42311D+00    |proj g|=  6.47258D-01\n",
      "\n",
      "At iterate   30    f= -3.42332D+00    |proj g|=  1.24458D-01\n",
      "\n",
      "At iterate   35    f= -3.42368D+00    |proj g|=  2.82569D+00\n",
      "\n",
      "At iterate   40    f= -3.42473D+00    |proj g|=  1.90544D-02\n",
      "\n",
      "At iterate   45    f= -3.42476D+00    |proj g|=  7.79840D-02\n",
      "\n",
      "At iterate   50    f= -3.42816D+00    |proj g|=  1.41140D+00\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    5     50     75      1     0     0   1.411D+00  -3.428D+00\n",
      "  F =  -3.4281638892051767     \n",
      "\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT                 \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            5     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.54740D+02    |proj g|=  3.02233D+05\n",
      "  ys=-2.795E+00  -gs= 9.320E-01 BFGS update SKIPPED\n",
      "\n",
      "At iterate    5    f= -2.56111D+00    |proj g|=  1.06249D+00\n",
      "\n",
      "At iterate   10    f= -2.60029D+00    |proj g|=  2.40867D+01\n",
      "\n",
      "At iterate   15    f= -3.42286D+00    |proj g|=  3.60669D+01\n",
      "\n",
      "At iterate   20    f= -3.47003D+00    |proj g|=  1.90207D-02\n",
      "\n",
      "At iterate   25    f= -3.47007D+00    |proj g|=  1.10352D+00\n",
      "\n",
      "At iterate   30    f= -3.47137D+00    |proj g|=  6.71908D+00\n",
      "\n",
      "At iterate   35    f= -3.47207D+00    |proj g|=  2.80897D-02\n",
      "\n",
      "At iterate   40    f= -3.47221D+00    |proj g|=  1.12596D+00\n",
      "\n",
      "At iterate   45    f= -3.47317D+00    |proj g|=  5.87179D-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate   50    f= -3.47323D+00    |proj g|=  2.52913D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    5     50     73      1     1     0   2.529D-03  -3.473D+00\n",
      "  F =  -3.4732261174153836     \n",
      "\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT                 \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            5     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.67989D+01    |proj g|=  2.70836D+04\n",
      "  ys=-5.290E+00  -gs= 9.150E-01 BFGS update SKIPPED\n",
      "\n",
      "At iterate    5    f= -2.57846D+00    |proj g|=  9.37693D-01\n",
      "\n",
      "At iterate   10    f= -2.87089D+00    |proj g|=  7.60235D+01\n",
      "\n",
      "At iterate   15    f= -3.52070D+00    |proj g|=  3.55141D+00\n",
      "\n",
      "At iterate   20    f= -3.52088D+00    |proj g|=  1.45067D-01\n",
      "\n",
      "At iterate   25    f= -3.52094D+00    |proj g|=  2.11313D+00\n",
      "\n",
      "At iterate   30    f= -3.52170D+00    |proj g|=  8.63235D-01\n",
      "\n",
      "At iterate   35    f= -3.52172D+00    |proj g|=  2.66797D-01\n",
      "\n",
      "At iterate   40    f= -3.52173D+00    |proj g|=  1.25270D-01\n",
      "\n",
      "At iterate   45    f= -3.52236D+00    |proj g|=  2.28784D+00\n",
      "\n",
      "At iterate   50    f= -3.52313D+00    |proj g|=  1.07970D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    5     50     74      1     1     0   1.080D-02  -3.523D+00\n",
      "  F =  -3.5231338123268148     \n",
      "\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT                 \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            5     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -3.10083D+00    |proj g|=  4.75092D+02\n",
      "\n",
      "At iterate    5    f= -3.50664D+00    |proj g|=  4.17671D-01\n",
      "\n",
      "At iterate   10    f= -3.51365D+00    |proj g|=  2.43367D+01\n",
      "\n",
      "At iterate   15    f= -3.56292D+00    |proj g|=  1.09752D+00\n",
      "\n",
      "At iterate   20    f= -3.56295D+00    |proj g|=  7.41028D-01\n",
      "\n",
      "At iterate   25    f= -3.56401D+00    |proj g|=  9.28470D+00\n",
      "\n",
      "At iterate   30    f= -3.57565D+00    |proj g|=  9.18040D+00\n",
      "\n",
      "At iterate   35    f= -3.57674D+00    |proj g|=  2.47285D-01\n",
      "\n",
      "At iterate   40    f= -3.57701D+00    |proj g|=  4.64294D+00\n",
      "\n",
      "At iterate   45    f= -3.60041D+00    |proj g|=  3.64215D+01\n",
      "\n",
      "At iterate   50    f= -3.66019D+00    |proj g|=  2.29500D+00\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    5     50     63      1     0     0   2.295D+00  -3.660D+00\n",
      "  F =  -3.6601872363646626     \n",
      "\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT                 \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            5     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.79165D+00    |proj g|=  7.28356D+02\n",
      "\n",
      "At iterate    5    f= -3.48444D+00    |proj g|=  3.01991D+00\n",
      "\n",
      "At iterate   10    f= -3.48471D+00    |proj g|=  2.94371D+00\n",
      "\n",
      "At iterate   15    f= -3.50400D+00    |proj g|=  4.20237D+01\n",
      "\n",
      "At iterate   20    f= -3.60168D+00    |proj g|=  3.16768D-01\n",
      "\n",
      "At iterate   25    f= -3.60170D+00    |proj g|=  1.00763D+00\n",
      "\n",
      "At iterate   30    f= -3.60330D+00    |proj g|=  1.09039D+01\n",
      "\n",
      "At iterate   35    f= -3.60925D+00    |proj g|=  2.81873D-01\n",
      "\n",
      "At iterate   40    f= -3.60930D+00    |proj g|=  1.39638D+00\n",
      "\n",
      "At iterate   45    f= -3.61368D+00    |proj g|=  1.60583D+01\n",
      "\n",
      "At iterate   50    f= -3.67811D+00    |proj g|=  2.10247D+01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    5     50     64      1     0     0   2.102D+01  -3.678D+00\n",
      "  F =  -3.6781121298262982     \n",
      "\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT                 \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            5     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.81844D+00    |proj g|=  8.14282D+02\n",
      "\n",
      "At iterate    5    f= -3.54489D+00    |proj g|=  1.68956D+00\n",
      "\n",
      "At iterate   10    f= -3.54501D+00    |proj g|=  2.53996D+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate   15    f= -3.55747D+00    |proj g|=  3.59590D+01\n",
      "\n",
      "At iterate   20    f= -3.59979D+00    |proj g|=  2.47035D-01\n",
      "\n",
      "At iterate   25    f= -3.60004D+00    |proj g|=  4.12225D+00\n",
      "\n",
      "At iterate   30    f= -3.61822D+00    |proj g|=  2.85471D+01\n",
      "\n",
      "At iterate   35    f= -3.64472D+00    |proj g|=  5.42880D-02\n",
      "\n",
      "At iterate   40    f= -3.65868D+00    |proj g|=  1.38413D+01\n",
      "\n",
      "At iterate   45    f= -3.72473D+00    |proj g|=  4.73817D+00\n",
      "\n",
      "At iterate   50    f= -3.73764D+00    |proj g|=  7.63386D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    5     50     66      1     0     0   7.634D-01  -3.738D+00\n",
      "  F =  -3.7376396785756651     \n",
      "\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT                 \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            5     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.70247D+00    |proj g|=  9.80834D+02\n",
      "\n",
      "At iterate    5    f= -3.56372D+00    |proj g|=  3.77199D-01\n",
      "\n",
      "At iterate   10    f= -3.56705D+00    |proj g|=  1.71258D+01\n",
      "\n",
      "At iterate   15    f= -3.62371D+00    |proj g|=  5.45636D+00\n",
      "\n",
      "At iterate   20    f= -3.62413D+00    |proj g|=  2.01453D+00\n",
      "\n",
      "At iterate   25    f= -3.63110D+00    |proj g|=  2.20711D+01\n",
      "\n",
      "At iterate   30    f= -3.67456D+00    |proj g|=  9.09068D-01\n",
      "\n",
      "At iterate   35    f= -3.67559D+00    |proj g|=  8.60987D-01\n",
      "\n",
      "At iterate   40    f= -3.70083D+00    |proj g|=  9.92142D+00\n",
      "\n",
      "At iterate   45    f= -3.75942D+00    |proj g|=  2.06869D+00\n",
      "\n",
      "At iterate   50    f= -3.77177D+00    |proj g|=  6.21709D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    5     50     66      1     0     0   6.217D-01  -3.772D+00\n",
      "  F =  -3.7717712485445429     \n",
      "\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT                 \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            5     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.58237D+00    |proj g|=  1.11924D+03\n",
      "\n",
      "At iterate    5    f= -3.56330D+00    |proj g|=  4.82347D-01\n",
      "\n",
      "At iterate   10    f= -3.63418D+00    |proj g|=  3.12160D+01\n",
      "\n",
      "At iterate   15    f= -3.64758D+00    |proj g|=  6.61439D-01\n",
      "\n",
      "At iterate   20    f= -3.65391D+00    |proj g|=  1.23029D+01\n",
      "\n",
      "At iterate   25    f= -3.70040D+00    |proj g|=  4.49988D+00\n",
      "\n",
      "At iterate   30    f= -3.70264D+00    |proj g|=  2.82690D-01\n",
      "\n",
      "At iterate   35    f= -3.72492D+00    |proj g|=  4.71682D+00\n",
      "\n",
      "At iterate   40    f= -3.78123D+00    |proj g|=  1.93358D+00\n",
      "\n",
      "At iterate   45    f= -3.78434D+00    |proj g|=  2.68217D+00\n",
      "\n",
      "At iterate   50    f= -3.78539D+00    |proj g|=  5.60237D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    5     50     71      1     0     0   5.602D-01  -3.785D+00\n",
      "  F =  -3.7853945925360031     \n",
      "\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT                 \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            5     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.56944D+00    |proj g|=  1.21697D+03\n",
      "\n",
      "At iterate    5    f= -3.60139D+00    |proj g|=  1.02960D+00\n",
      "\n",
      "At iterate   10    f= -3.64199D+00    |proj g|=  5.09588D+01\n",
      "\n",
      "At iterate   15    f= -3.66684D+00    |proj g|=  2.60886D-01\n",
      "\n",
      "At iterate   20    f= -3.66777D+00    |proj g|=  8.76318D+00\n",
      "\n",
      "At iterate   25    f= -3.70875D+00    |proj g|=  3.28671D+01\n",
      "\n",
      "At iterate   30    f= -3.73223D+00    |proj g|=  7.32794D-02\n",
      "\n",
      "At iterate   35    f= -3.73397D+00    |proj g|=  6.56480D+00\n",
      "\n",
      "At iterate   40    f= -3.79156D+00    |proj g|=  2.63232D+01\n",
      "\n",
      "At iterate   45    f= -3.81958D+00    |proj g|=  1.12304D+00\n",
      "\n",
      "At iterate   50    f= -3.82036D+00    |proj g|=  7.27648D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    5     50     66      1     0     0   7.276D-01  -3.820D+00\n",
      "  F =  -3.8203565462211273     \n",
      "\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT                 \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            5     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.62219D+00    |proj g|=  1.27792D+03\n",
      "\n",
      "At iterate    5    f= -3.65360D+00    |proj g|=  3.80737D-01\n",
      "\n",
      "At iterate   10    f= -3.65431D+00    |proj g|=  7.57142D+00\n",
      "\n",
      "At iterate   15    f= -3.69241D+00    |proj g|=  3.76416D+01\n",
      "\n",
      "At iterate   20    f= -3.71331D+00    |proj g|=  6.64455D-01\n",
      "\n",
      "At iterate   25    f= -3.72136D+00    |proj g|=  2.37861D+01\n",
      "\n",
      "At iterate   30    f= -3.76638D+00    |proj g|=  2.91089D+00\n",
      "\n",
      "At iterate   35    f= -3.76715D+00    |proj g|=  1.91057D-01\n",
      "\n",
      "At iterate   40    f= -3.77164D+00    |proj g|=  3.76592D+00\n",
      "\n",
      "At iterate   45    f= -3.82809D+00    |proj g|=  5.19840D+00\n",
      "\n",
      "At iterate   50    f= -3.83650D+00    |proj g|=  4.59869D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    5     50     65      1     0     0   4.599D-01  -3.836D+00\n",
      "  F =  -3.8364959391438052     \n",
      "\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT                 \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            5     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.72174D+00    |proj g|=  1.20489D+03\n",
      "\n",
      "At iterate    5    f= -3.67775D+00    |proj g|=  3.38425D-01\n",
      "\n",
      "At iterate   10    f= -3.68022D+00    |proj g|=  1.38310D+01\n",
      "\n",
      "At iterate   15    f= -3.72856D+00    |proj g|=  1.63882D+01\n",
      "\n",
      "At iterate   20    f= -3.76601D+00    |proj g|=  2.00420D+01\n",
      "\n",
      "At iterate   25    f= -3.78689D+00    |proj g|=  6.79574D-02\n",
      "\n",
      "At iterate   30    f= -3.78700D+00    |proj g|=  2.48862D+00\n",
      "\n",
      "At iterate   35    f= -3.79675D+00    |proj g|=  1.91274D+01\n",
      "\n",
      "At iterate   40    f= -3.84280D+00    |proj g|=  5.89973D+00\n",
      "\n",
      "At iterate   45    f= -3.84545D+00    |proj g|=  1.94510D+00\n",
      "\n",
      "At iterate   50    f= -3.85052D+00    |proj g|=  1.97272D+00\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    5     50     67      1     0     0   1.973D+00  -3.851D+00\n",
      "  F =  -3.8505203741908218     \n",
      "\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT                 \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            5     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.64115D+00    |proj g|=  1.28675D+03\n",
      "\n",
      "At iterate    5    f= -3.66704D+00    |proj g|=  5.26085D-01\n",
      "\n",
      "At iterate   10    f= -3.66850D+00    |proj g|=  1.09213D+01\n",
      "\n",
      "At iterate   15    f= -3.73829D+00    |proj g|=  4.75505D+01\n",
      "\n",
      "At iterate   20    f= -3.77054D+00    |proj g|=  4.03989D+00\n",
      "\n",
      "At iterate   25    f= -3.79643D+00    |proj g|=  2.16382D+01\n",
      "\n",
      "At iterate   30    f= -3.80593D+00    |proj g|=  3.72994D-01\n",
      "\n",
      "At iterate   35    f= -3.80656D+00    |proj g|=  1.40666D+00\n",
      "\n",
      "At iterate   40    f= -3.83175D+00    |proj g|=  1.70238D+01\n",
      "\n",
      "At iterate   45    f= -3.85384D+00    |proj g|=  7.85774D-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate   50    f= -3.85439D+00    |proj g|=  1.06953D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    5     50     65      1     0     0   1.070D-02  -3.854D+00\n",
      "  F =  -3.8543936103902663     \n",
      "\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT                 \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            5     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.81614D+00    |proj g|=  1.20438D+03\n",
      "\n",
      "At iterate    5    f= -3.72738D+00    |proj g|=  4.22521D-01\n",
      "\n",
      "At iterate   10    f= -3.79336D+00    |proj g|=  1.88629D-01\n",
      "\n",
      "At iterate   15    f= -3.79391D+00    |proj g|=  5.66764D+00\n",
      "\n",
      "At iterate   20    f= -3.82793D+00    |proj g|=  2.19318D+01\n",
      "\n",
      "At iterate   25    f= -3.83169D+00    |proj g|=  8.56395D-02\n",
      "\n",
      "At iterate   30    f= -3.83535D+00    |proj g|=  8.17071D+00\n",
      "\n",
      "At iterate   35    f= -3.87675D+00    |proj g|=  3.10889D+00\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    5     39     76      1     0     0   8.678D-02  -3.880D+00\n",
      "  F =  -3.8796583063302759     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            5     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -3.28945D+00    |proj g|=  6.59629D+02\n",
      "\n",
      "At iterate    5    f= -3.75885D+00    |proj g|=  3.76667D-01\n",
      "\n",
      "At iterate   10    f= -3.75934D+00    |proj g|=  7.62097D+00\n",
      "\n",
      "At iterate   15    f= -3.79575D+00    |proj g|=  4.67813D+01\n",
      "\n",
      "At iterate   20    f= -3.80972D+00    |proj g|=  1.51388D-01\n",
      "\n",
      "At iterate   25    f= -3.81001D+00    |proj g|=  5.76188D+00\n",
      "\n",
      "At iterate   30    f= -3.82609D+00    |proj g|=  2.84880D+01\n",
      "\n",
      "At iterate   35    f= -3.83720D+00    |proj g|=  9.43649D-02\n",
      "\n",
      "At iterate   40    f= -3.83739D+00    |proj g|=  3.34162D+00\n",
      "\n",
      "At iterate   45    f= -3.86056D+00    |proj g|=  7.53332D+00\n",
      "\n",
      "At iterate   50    f= -3.88383D+00    |proj g|=  1.15762D+00\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    5     50     58      1     0     0   1.158D+00  -3.884D+00\n",
      "  F =  -3.8838293193009972     \n",
      "\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT                 \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            5     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -3.29328D+00    |proj g|=  6.17395D+02\n",
      "\n",
      "At iterate    5    f= -3.72932D+00    |proj g|=  5.40126D-01\n",
      "\n",
      "At iterate   10    f= -3.74479D+00    |proj g|=  4.63954D+01\n",
      "\n",
      "At iterate   15    f= -3.83788D+00    |proj g|=  1.32568D+00\n",
      "\n",
      "At iterate   20    f= -3.83793D+00    |proj g|=  1.54084D+00\n",
      "\n",
      "At iterate   25    f= -3.84049D+00    |proj g|=  1.81806D+01\n",
      "\n",
      "At iterate   30    f= -3.86885D+00    |proj g|=  2.56550D+01\n",
      "\n",
      "At iterate   35    f= -3.87515D+00    |proj g|=  4.90028D-02\n",
      "\n",
      "At iterate   40    f= -3.87658D+00    |proj g|=  2.13428D+00\n",
      "\n",
      "At iterate   45    f= -3.87837D+00    |proj g|=  2.50797D-01\n",
      "\n",
      "At iterate   50    f= -3.87840D+00    |proj g|=  1.11977D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    5     50     63      1     0     0   1.120D-01  -3.878D+00\n",
      "  F =  -3.8783986769652969     \n",
      "\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT                 \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            5     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -3.31550D+00    |proj g|=  6.50688D+02\n",
      "\n",
      "At iterate    5    f= -3.76133D+00    |proj g|=  4.84733D-01\n",
      "\n",
      "At iterate   10    f= -3.76193D+00    |proj g|=  8.72698D+00\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At iterate   15    f= -3.81604D+00    |proj g|=  7.28119D+01\n",
      "\n",
      "At iterate   20    f= -3.84771D+00    |proj g|=  1.08697D-01\n",
      "\n",
      "At iterate   25    f= -3.84782D+00    |proj g|=  3.53682D+00\n",
      "\n",
      "At iterate   30    f= -3.85673D+00    |proj g|=  3.24282D+01\n",
      "\n",
      "At iterate   35    f= -3.88413D+00    |proj g|=  2.44285D+00\n",
      "\n",
      "At iterate   40    f= -3.88743D+00    |proj g|=  2.05796D-01\n",
      "\n",
      "At iterate   45    f= -3.88743D+00    |proj g|=  9.23626D-02\n",
      "\n",
      "At iterate   50    f= -3.88746D+00    |proj g|=  1.43323D+00\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    5     50     59      1     0     0   1.433D+00  -3.887D+00\n",
      "  F =  -3.8874581429435087     \n",
      "\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT                 \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            5     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -3.34574D+00    |proj g|=  6.69887D+02\n",
      "\n",
      "At iterate    5    f= -3.79048D+00    |proj g|=  6.13496D-01\n",
      "\n",
      "At iterate   10    f= -3.79071D+00    |proj g|=  5.50765D+00\n",
      "\n",
      "At iterate   15    f= -3.81802D+00    |proj g|=  6.65153D+01\n",
      "\n",
      "At iterate   20    f= -3.86543D+00    |proj g|=  1.99286D-01\n",
      "\n",
      "At iterate   25    f= -3.86560D+00    |proj g|=  4.59981D+00\n",
      "\n",
      "At iterate   30    f= -3.87801D+00    |proj g|=  3.49825D+01\n",
      "\n",
      "At iterate   35    f= -3.90356D+00    |proj g|=  8.27004D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    5     38     56      1     0     0   4.070D-01  -3.904D+00\n",
      "  F =  -3.9035632793136910     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            5     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -3.36030D+00    |proj g|=  6.94366D+02\n",
      "\n",
      "At iterate    5    f= -3.81450D+00    |proj g|=  8.94181D-01\n",
      "\n",
      "At iterate   10    f= -3.81471D+00    |proj g|=  5.20791D+00\n",
      "\n",
      "At iterate   15    f= -3.83975D+00    |proj g|=  6.60695D+01\n",
      "\n",
      "At iterate   20    f= -3.89071D+00    |proj g|=  1.05342D-01\n",
      "\n",
      "At iterate   25    f= -3.89076D+00    |proj g|=  2.40650D+00\n",
      "\n",
      "At iterate   30    f= -3.89523D+00    |proj g|=  2.49497D+01\n",
      "\n",
      "At iterate   35    f= -3.91839D+00    |proj g|=  2.31876D+00\n",
      "\n",
      "At iterate   40    f= -3.92070D+00    |proj g|=  1.02491D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    5     40     80      2     0     0   1.025D-01  -3.921D+00\n",
      "  F =  -3.9207025284994024     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            5     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -3.32065D+00    |proj g|=  6.89777D+02\n",
      "\n",
      "At iterate    5    f= -3.77756D+00    |proj g|=  7.23427D-01\n",
      "\n",
      "At iterate   10    f= -3.77785D+00    |proj g|=  6.03464D+00\n",
      "\n",
      "At iterate   15    f= -3.81136D+00    |proj g|=  7.75846D+01\n",
      "\n",
      "At iterate   20    f= -3.87572D+00    |proj g|=  1.08937D+00\n",
      "\n",
      "At iterate   25    f= -3.87696D+00    |proj g|=  1.32548D+01\n",
      "\n",
      "At iterate   30    f= -3.91480D+00    |proj g|=  3.98450D+01\n",
      "\n",
      "At iterate   35    f= -3.92623D+00    |proj g|=  4.21651D-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate   40    f= -3.93366D+00    |proj g|=  1.00787D+00\n",
      "\n",
      "At iterate   45    f= -3.94492D+00    |proj g|=  1.25842D-02\n",
      "\n",
      "At iterate   50    f= -3.95456D+00    |proj g|=  3.13483D+00\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    5     50     69      1     0     0   3.135D+00  -3.955D+00\n",
      "  F =  -3.9545596857679217     \n",
      "\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT                 \n",
      "Metrics for Water Polo (popularity) - MSE: 3.1791421611239405e-05, R2: -0.9228363832010769\n",
      "Checking stationarity for Weightlifting (popularity):\n",
      "ADF Statistic: -5.829063239884678, p-value: 4.0148811610240874e-07\n",
      "Optimal ARIMA order: (0, 0, 0)\n",
      "Optimal SARIMA order: (0, 0, 0), Seasonal: (0, 0, 0, 0)\n",
      "Constant series detected for Weightlifting (popularity). Predicting constant value: 0.0263157894736842\n",
      "Metrics for Weightlifting (popularity) - MSE: 2.439686795226554e-05, R2: -1.162060002026954\n",
      "Constant series detected for Weightlifting (popularity). Predicting constant value: 0.0263157894736842\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.54474D+00    |proj g|=  2.76969D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     18      1     0     0   2.770D-02  -2.545D+00\n",
      "  F =  -2.5447447270009924     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.64667D+00    |proj g|=  3.39564D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     21      1     0     0   3.396D-02  -2.647D+00\n",
      "  F =  -2.6466715714068125     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.71083D+00    |proj g|=  3.86031D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     21      1     0     0   3.860D-02  -2.711D+00\n",
      "  F =  -2.7108306116422085     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.67559D+00    |proj g|=  3.59776D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     21      1     0     0   3.598D-02  -2.676D+00\n",
      "  F =  -2.6755942211041850     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.67358D+00    |proj g|=  3.58331D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     21      1     0     0   3.583D-02  -2.674D+00\n",
      "  F =  -2.6735810292815763     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.72837D+00    |proj g|=  3.99804D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     20      1     0     0   3.998D-02  -2.728D+00\n",
      "  F =  -2.7283679819793796     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.76279D+00    |proj g|=  4.28283D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     18      1     0     0   4.283D-02  -2.763D+00\n",
      "  F =  -2.7627913442044543     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.75708D+00    |proj g|=  4.23417D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     21      1     0     0   4.234D-02  -2.757D+00\n",
      "  F =  -2.7570753583560990     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.75828D+00    |proj g|=  4.24435D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     21      1     0     0   4.244D-02  -2.758D+00\n",
      "  F =  -2.7582767591802870     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.75233D+00    |proj g|=  4.19420D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     18      1     0     0   4.194D-02  -2.752D+00\n",
      "  F =  -2.7523296621564439     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.73366D+00    |proj g|=  4.04058D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     17      1     0     0   4.041D-02  -2.734D+00\n",
      "  F =  -2.7336630288869550     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.73369D+00    |proj g|=  4.04082D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     20      1     0     0   4.041D-02  -2.734D+00\n",
      "  F =  -2.7336931508559497     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.73573D+00    |proj g|=  4.05732D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     16      1     0     0   4.057D-02  -2.736D+00\n",
      "  F =  -2.7357315688644412     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.73561D+00    |proj g|=  4.05631D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     16      1     0     0   4.056D-02  -2.736D+00\n",
      "  F =  -2.7356065068968145     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.73243D+00    |proj g|=  4.03065D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     16      1     0     0   4.031D-02  -2.732D+00\n",
      "  F =  -2.7324323894829190     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.71809D+00    |proj g|=  3.91677D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     18      1     0     0   3.917D-02  -2.718D+00\n",
      "  F =  -2.7180945664060419     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.71781D+00    |proj g|=  3.91456D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     20      1     0     0   3.915D-02  -2.718D+00\n",
      "  F =  -2.7178124211468702     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.71968D+00    |proj g|=  3.92918D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     20      1     0     0   3.929D-02  -2.720D+00\n",
      "  F =  -2.7196774485510944     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.72296D+00    |proj g|=  3.95502D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     21      1     0     0   3.955D-02  -2.723D+00\n",
      "  F =  -2.7229561654096890     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.71748D+00    |proj g|=  3.91198D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     20      1     0     0   3.912D-02  -2.717D+00\n",
      "  F =  -2.7174821843463066     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.71204D+00    |proj g|=  3.86968D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     20      1     0     0   3.870D-02  -2.712D+00\n",
      "  F =  -2.7120431164908196     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.70494D+00    |proj g|=  3.81513D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     16      1     0     0   3.815D-02  -2.705D+00\n",
      "  F =  -2.7049411946536672     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.69829D+00    |proj g|=  3.76476D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     16      1     0     0   3.765D-02  -2.698D+00\n",
      "  F =  -2.6982924500753085     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.68969D+00    |proj g|=  3.70059D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     21      1     0     0   3.701D-02  -2.690D+00\n",
      "  F =  -2.6896928837131551     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.68423D+00    |proj g|=  3.66040D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     20      1     0     0   3.660D-02  -2.684D+00\n",
      "  F =  -2.6842301614740438     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.67943D+00    |proj g|=  3.62546D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     21      1     0     0   3.625D-02  -2.679D+00\n",
      "  F =  -2.6794318333002654     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "Metrics for Weightlifting (popularity) - MSE: 0.000270192197717318, R2: -22.944538482863923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking stationarity for Wrestling (popularity):\n",
      "ADF Statistic: -1.4067120431268416, p-value: 0.5790540840445961\n",
      "Skipping ARIMA fitting for non-stationary series: Wrestling (popularity)\n",
      "All zero values for climbing (popularity), skipping.\n",
      "All zero values for Fitness (popularity), skipping.\n",
      "All zero values for Headis (popularity), skipping.\n",
      "\n",
      "Processing parameter: normalizedcountry\n",
      "Checking stationarity for Alpine Skiing (normalizedcountry):\n",
      "ADF Statistic: 1.636353424623943, p-value: 0.997962643029658\n",
      "Skipping ARIMA fitting for non-stationary series: Alpine Skiing (normalizedcountry)\n",
      "Insufficient data for Alpinism (normalizedcountry)\n",
      "Checking stationarity for Archery (normalizedcountry):\n",
      "ADF Statistic: -2.4719242157737966, p-value: 0.12245574958880001\n",
      "Skipping ARIMA fitting for non-stationary series: Archery (normalizedcountry)\n",
      "Checking stationarity for Art Competitions (normalizedcountry):\n",
      "ADF Statistic: -2.1279322432007812, p-value: 0.23343222320471696\n",
      "Skipping ARIMA fitting for non-stationary series: Art Competitions (normalizedcountry)\n",
      "Checking stationarity for Athletics (normalizedcountry):\n",
      "ADF Statistic: 3.318395165964572, p-value: 1.0\n",
      "Skipping ARIMA fitting for non-stationary series: Athletics (normalizedcountry)\n",
      "Checking stationarity for Badminton (normalizedcountry):\n",
      "ADF Statistic: -1.04780389223747, p-value: 0.7354323233678514\n",
      "Skipping ARIMA fitting for non-stationary series: Badminton (normalizedcountry)\n",
      "Checking stationarity for Baseball (normalizedcountry):\n",
      "Series is constant, skipping stationarity test.\n",
      "Skipping ARIMA fitting for non-stationary series: Baseball (normalizedcountry)\n",
      "Checking stationarity for Basketball (normalizedcountry):\n",
      "ADF Statistic: -2.2940447548265515, p-value: 0.17389585093334087\n",
      "Skipping ARIMA fitting for non-stationary series: Basketball (normalizedcountry)\n",
      "Insufficient data for Basque Pelota (normalizedcountry)\n",
      "Checking stationarity for Beach Volleyball (normalizedcountry):\n",
      "ADF Statistic: -2.9068883707497157, p-value: 0.04455281743165646\n",
      "Optimal ARIMA order: (0, 0, 0)\n",
      "Optimal SARIMA order: (0, 0, 0), Seasonal: (0, 0, 0, 0)\n",
      "Constant series detected for Beach Volleyball (normalizedcountry). Predicting constant value: 0.105\n",
      "Metrics for Beach Volleyball (normalizedcountry) - MSE: 4.810247618532923e-05, R2: -7.017079364221569\n",
      "Constant series detected for Beach Volleyball (normalizedcountry). Predicting constant value: 0.105\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -7.87304D-01    |proj g|=  8.24617D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     17      1     0     0   8.246D-04  -7.873D-01\n",
      "  F = -0.78730438787462265     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -7.56972D-01    |proj g|=  7.76083D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     15      1     0     0   7.761D-04  -7.570D-01\n",
      "  F = -0.75697186310373554     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -7.53668D-01    |proj g|=  7.70971D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     16      1     0     0   7.709D-04  -7.537D-01\n",
      "  F = -0.75366779757091018     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -7.51696D-01    |proj g|=  7.67937D-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     15      1     0     0   7.679D-04  -7.517D-01\n",
      "  F = -0.75169578789618441     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "Metrics for Beach Volleyball (normalizedcountry) - MSE: 0.01107, R2: -1844.0000000000068\n",
      "Checking stationarity for Biathlon (normalizedcountry):\n",
      "ADF Statistic: -0.12001753231556761, p-value: 0.9474078481751632\n",
      "Skipping ARIMA fitting for non-stationary series: Biathlon (normalizedcountry)\n",
      "Checking stationarity for Bobsleigh (normalizedcountry):\n",
      "ADF Statistic: -1.1908507530763008, p-value: 0.6775190516429757\n",
      "Skipping ARIMA fitting for non-stationary series: Bobsleigh (normalizedcountry)\n",
      "Checking stationarity for Boxing (normalizedcountry):\n",
      "ADF Statistic: -1.8896553221544787, p-value: 0.3369431130467822\n",
      "Skipping ARIMA fitting for non-stationary series: Boxing (normalizedcountry)\n",
      "Checking stationarity for Canoeing (normalizedcountry):\n",
      "ADF Statistic: 1.7990747278932826, p-value: 0.9983471801507229\n",
      "Skipping ARIMA fitting for non-stationary series: Canoeing (normalizedcountry)\n",
      "Insufficient data for Cricket (normalizedcountry)\n",
      "Insufficient data for Croquet (normalizedcountry)\n",
      "Checking stationarity for Cross Country Skiing (normalizedcountry):\n",
      "ADF Statistic: 2.5164208394545886, p-value: 0.9990549549677178\n",
      "Skipping ARIMA fitting for non-stationary series: Cross Country Skiing (normalizedcountry)\n",
      "Insufficient data for Curling (normalizedcountry)\n",
      "Checking stationarity for Cycling (normalizedcountry):\n",
      "ADF Statistic: -0.7085049832921759, p-value: 0.8445342387452741\n",
      "Skipping ARIMA fitting for non-stationary series: Cycling (normalizedcountry)\n",
      "Checking stationarity for Diving (normalizedcountry):\n",
      "ADF Statistic: -0.1242991629986959, p-value: 0.9469638114337058\n",
      "Skipping ARIMA fitting for non-stationary series: Diving (normalizedcountry)\n",
      "Checking stationarity for Equestrianism (normalizedcountry):\n",
      "ADF Statistic: -1.7155964514519066, p-value: 0.4230951599742992\n",
      "Skipping ARIMA fitting for non-stationary series: Equestrianism (normalizedcountry)\n",
      "Checking stationarity for Fencing (normalizedcountry):\n",
      "ADF Statistic: -1.2589190254357856, p-value: 0.6477512139654324\n",
      "Skipping ARIMA fitting for non-stationary series: Fencing (normalizedcountry)\n",
      "Checking stationarity for Figure Skating (normalizedcountry):\n",
      "ADF Statistic: 0.9840646904250264, p-value: 0.9940949343264974\n",
      "Skipping ARIMA fitting for non-stationary series: Figure Skating (normalizedcountry)\n",
      "Checking stationarity for Football (normalizedcountry):\n",
      "ADF Statistic: 0.02699536021056542, p-value: 0.9607084543466355\n",
      "Skipping ARIMA fitting for non-stationary series: Football (normalizedcountry)\n",
      "Insufficient data for Freestyle Skiing (normalizedcountry)\n",
      "Insufficient data for Golf (normalizedcountry)\n",
      "Checking stationarity for Gymnastics (normalizedcountry):\n",
      "ADF Statistic: 0.25386647203996826, p-value: 0.9751260378544709\n",
      "Skipping ARIMA fitting for non-stationary series: Gymnastics (normalizedcountry)\n",
      "Checking stationarity for Handball (normalizedcountry):\n",
      "ADF Statistic: -4.1946585574118025, p-value: 0.0006727531314537219\n",
      "Optimal ARIMA order: (0, 1, 1)\n",
      "Optimal SARIMA order: (0, 1, 1), Seasonal: (0, 0, 0, 0)\n",
      "Fitting error for Handball (normalizedcountry): too many indices for array: array is 0-dimensional, but 1 were indexed\n",
      "No predictions made for Handball (normalizedcountry).\n",
      "Fitting error for Handball (normalizedcountry): too many indices for array: array is 0-dimensional, but 1 were indexed\n",
      "No predictions made for Handball (normalizedcountry).\n",
      "Checking stationarity for Hockey (normalizedcountry):\n",
      "ADF Statistic: -2.6700784766448398, p-value: 0.07936065057943453\n",
      "Skipping ARIMA fitting for non-stationary series: Hockey (normalizedcountry)\n",
      "Checking stationarity for Ice Hockey (normalizedcountry):\n",
      "ADF Statistic: -4.139498443113051, p-value: 0.0008327399705275574\n",
      "Optimal ARIMA order: (0, 1, 2)\n",
      "Optimal SARIMA order: (0, 1, 2), Seasonal: (0, 0, 0, 0)\n",
      "Metrics for Ice Hockey (normalizedcountry) - MSE: 0.0003557915175548377, R2: -0.7123422330447684\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.82731D-01    |proj g|=  1.69420D+03\n",
      "\n",
      "At iterate    5    f= -2.04982D+00    |proj g|=  2.00165D-01\n",
      "\n",
      "At iterate   10    f= -2.05129D+00    |proj g|=  4.82311D+00\n",
      "\n",
      "At iterate   15    f= -2.09671D+00    |proj g|=  5.58967D+00\n",
      "\n",
      "At iterate   20    f= -2.12054D+00    |proj g|=  3.54513D+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      "\n",
      " Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "\n",
      " Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "\n",
      " Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate   25    f= -2.12085D+00    |proj g|=  2.21424D-02\n",
      "  ys=-7.563E-09  -gs= 4.850E-08 BFGS update SKIPPED\n",
      "  ys=-5.925E-11  -gs= 5.353E-10 BFGS update SKIPPED\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3     28    111      2     2     0   4.460D-02  -2.121D+00\n",
      "  F =  -2.1208492403854646     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.72008D+00    |proj g|=  3.37754D+01\n",
      "\n",
      "At iterate    5    f= -1.79262D+00    |proj g|=  3.22826D-01\n",
      "\n",
      "At iterate   10    f= -1.80663D+00    |proj g|=  6.98963D+00\n",
      "\n",
      "At iterate   15    f= -1.88090D+00    |proj g|=  1.97920D+00\n",
      "\n",
      "At iterate   20    f= -2.01775D+00    |proj g|=  4.19582D-01\n",
      "\n",
      "At iterate   25    f= -2.01855D+00    |proj g|=  1.25234D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3     29    148      4     0     0   1.895D-02  -2.019D+00\n",
      "  F =  -2.0185559469383501     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.52172D+00    |proj g|=  1.97519D+01\n",
      "\n",
      "At iterate    5    f= -1.58168D+00    |proj g|=  4.25226D-01\n",
      "\n",
      "At iterate   10    f= -1.61732D+00    |proj g|=  7.37841D+00\n",
      "\n",
      "At iterate   15    f= -1.90069D+00    |proj g|=  3.02603D+00\n",
      "\n",
      "At iterate   20    f= -1.91176D+00    |proj g|=  2.92276D+00\n",
      "\n",
      "At iterate   25    f= -1.91384D+00    |proj g|=  1.63524D+00\n",
      "\n",
      "At iterate   30    f= -1.95074D+00    |proj g|=  4.13772D-02\n",
      "\n",
      "At iterate   35    f= -1.95533D+00    |proj g|=  9.75606D-01\n",
      "\n",
      "At iterate   40    f= -1.96114D+00    |proj g|=  3.70510D-02\n",
      "\n",
      "At iterate   45    f= -1.96196D+00    |proj g|=  9.94647D-01\n",
      "\n",
      "At iterate   50    f= -1.96291D+00    |proj g|=  3.58920D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3     50     97      2     0     0   3.589D-01  -1.963D+00\n",
      "  F =  -1.9629129464156556     \n",
      "\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT                 \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.63662D+00    |proj g|=  1.21684D+01\n",
      "\n",
      "At iterate    5    f= -1.66589D+00    |proj g|=  6.09946D-01\n",
      "\n",
      "At iterate   10    f= -1.81047D+00    |proj g|=  1.36190D+01\n",
      "\n",
      "At iterate   15    f= -2.08656D+00    |proj g|=  7.80592D-01\n",
      "\n",
      "At iterate   20    f= -2.10873D+00    |proj g|=  4.31627D+00\n",
      "\n",
      "At iterate   25    f= -2.13772D+00    |proj g|=  2.34831D+00\n",
      "\n",
      "At iterate   30    f= -2.13925D+00    |proj g|=  5.04609D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3     30    104      3     0     0   5.046D-03  -2.139D+00\n",
      "  F =  -2.1392529018432183     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.76938D+00    |proj g|=  1.11339D+01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "\n",
      " Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate    5    f= -1.79238D+00    |proj g|=  9.92183D-01\n",
      "\n",
      "At iterate   10    f= -1.98152D+00    |proj g|=  1.62958D+01\n",
      "\n",
      "At iterate   15    f= -2.24367D+00    |proj g|=  2.09499D-01\n",
      "\n",
      "At iterate   20    f= -2.25142D+00    |proj g|=  1.14439D+01\n",
      "\n",
      "At iterate   25    f= -2.28200D+00    |proj g|=  3.76136D-01\n",
      "\n",
      "At iterate   30    f= -2.28411D+00    |proj g|=  4.69831D-01\n",
      "\n",
      "At iterate   35    f= -2.28422D+00    |proj g|=  6.06042D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3     36     94      2     0     0   6.060D-02  -2.284D+00\n",
      "  F =  -2.2842205941114746     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.89208D+00    |proj g|=  6.53070D-01\n",
      "\n",
      "At iterate    5    f= -2.33802D+00    |proj g|=  2.25695D+01\n",
      "\n",
      "At iterate   10    f= -2.37161D+00    |proj g|=  5.95219D-02\n",
      "\n",
      "At iterate   15    f= -2.37445D+00    |proj g|=  3.90080D+00\n",
      "\n",
      "At iterate   20    f= -2.39097D+00    |proj g|=  6.71522D-01\n",
      "\n",
      "At iterate   25    f= -2.39125D+00    |proj g|=  1.20618D-01\n",
      "  ys=-6.900E-11  -gs= 4.582E-10 BFGS update SKIPPED\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3     28     80      2     1     0   1.312D-02  -2.391D+00\n",
      "  F =  -2.3912493610051224     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.97942D+00    |proj g|=  6.62076D-01\n",
      "\n",
      "At iterate    5    f= -2.45829D+00    |proj g|=  3.02273D+00\n",
      "\n",
      "At iterate   10    f= -2.47473D+00    |proj g|=  1.71695D-02\n",
      "\n",
      "At iterate   15    f= -2.47548D+00    |proj g|=  6.11483D-01\n",
      "\n",
      "At iterate   20    f= -2.47569D+00    |proj g|=  1.08748D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3     24     91      2     0     0   3.459D-04  -2.476D+00\n",
      "  F =  -2.4756912415894043     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  8.42388D+01    |proj g|=  9.12740D+04\n",
      "  ys=-1.073E-01  -gs= 9.637E-01 BFGS update SKIPPED\n",
      "\n",
      "At iterate    5    f= -1.96699D+00    |proj g|=  5.64431D-01\n",
      "\n",
      "At iterate   10    f= -2.00808D+00    |proj g|=  1.03814D+01\n",
      "\n",
      "At iterate   15    f= -2.36817D+00    |proj g|=  9.07468D-01\n",
      "\n",
      "At iterate   20    f= -2.39198D+00    |proj g|=  9.51449D+00\n",
      "\n",
      "At iterate   25    f= -2.42317D+00    |proj g|=  1.41610D-01\n",
      "\n",
      "At iterate   30    f= -2.42398D+00    |proj g|=  1.32273D-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "\n",
      " Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3     31    107      3     1     0   1.323D-02  -2.424D+00\n",
      "  F =  -2.4239800338048414     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.98178D+00    |proj g|=  2.20740D+01\n",
      "\n",
      "At iterate    5    f= -2.03164D+00    |proj g|=  4.26043D+00\n",
      "\n",
      "At iterate   10    f= -2.30321D+00    |proj g|=  8.36922D+00\n",
      "\n",
      "At iterate   15    f= -2.33786D+00    |proj g|=  3.76556D-02\n",
      "\n",
      "At iterate   20    f= -2.33787D+00    |proj g|=  1.57898D-01\n",
      "\n",
      "At iterate   25    f= -2.33792D+00    |proj g|=  3.42825D-02\n",
      "  ys=-7.307E-07  -gs= 5.876E-07 BFGS update SKIPPED\n",
      "\n",
      "At iterate   30    f= -2.33792D+00    |proj g|=  5.52282D-03\n",
      "\n",
      "At iterate   35    f= -2.33793D+00    |proj g|=  1.72364D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3     36     99      2     1     0   1.724D-02  -2.338D+00\n",
      "  F =  -2.3379251358187676     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.90372D+00    |proj g|=  5.91457D+01\n",
      "\n",
      "At iterate    5    f= -2.07704D+00    |proj g|=  2.21754D+00\n",
      "\n",
      "At iterate   10    f= -2.38325D+00    |proj g|=  1.01794D+01\n",
      "\n",
      "At iterate   15    f= -2.39764D+00    |proj g|=  1.00491D-01\n",
      "\n",
      "At iterate   20    f= -2.40429D+00    |proj g|=  1.98365D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3     22     51      1     0     0   1.967D-02  -2.404D+00\n",
      "  F =  -2.4042887303659342     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.00124D+00    |proj g|=  4.87593D+01\n",
      "\n",
      "At iterate    5    f= -2.14835D+00    |proj g|=  5.46052D+00\n",
      "\n",
      "At iterate   10    f= -2.45233D+00    |proj g|=  2.70315D+00\n",
      "\n",
      "At iterate   15    f= -2.45580D+00    |proj g|=  8.80936D-02\n",
      "\n",
      "At iterate   20    f= -2.45781D+00    |proj g|=  1.38973D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3     24     61      2     0     0   1.231D-03  -2.458D+00\n",
      "  F =  -2.4578065759825050     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.34925D+00    |proj g|=  1.25645D+02\n",
      "\n",
      "At iterate    5    f= -1.86208D+00    |proj g|=  1.42464D-01\n",
      "\n",
      "At iterate   10    f= -1.86439D+00    |proj g|=  2.80586D+00\n",
      "\n",
      "At iterate   15    f= -1.93051D+00    |proj g|=  1.91839D+00\n",
      "\n",
      "At iterate   20    f= -1.94011D+00    |proj g|=  1.31404D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3     22     45      1     0     0   2.687D-02  -1.940D+00\n",
      "  F =  -1.9401121709698828     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.41767D+00    |proj g|=  1.47267D+02\n",
      "\n",
      "At iterate    5    f= -1.97120D+00    |proj g|=  2.07265D-01\n",
      "\n",
      "At iterate   10    f= -1.97679D+00    |proj g|=  5.36791D+00\n",
      "\n",
      "At iterate   15    f= -2.18696D+00    |proj g|=  6.87520D+00\n",
      "\n",
      "At iterate   20    f= -2.21587D+00    |proj g|=  3.38123D-01\n",
      "\n",
      "At iterate   25    f= -2.46401D+00    |proj g|=  5.36712D-01\n",
      "\n",
      "At iterate   30    f= -2.46404D+00    |proj g|=  8.68745D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3     32     75      1     0     0   9.528D-02  -2.464D+00\n",
      "  F =  -2.4640432077333299     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.71123D+00    |proj g|=  1.29845D+02\n",
      "\n",
      "At iterate    5    f= -2.12666D+00    |proj g|=  3.31630D-01\n",
      "\n",
      "At iterate   10    f= -2.14361D+00    |proj g|=  8.05649D+00\n",
      "\n",
      "At iterate   15    f= -2.51824D+00    |proj g|=  1.64869D+01\n",
      "\n",
      "At iterate   20    f= -2.58156D+00    |proj g|=  1.21038D-01\n",
      "\n",
      "At iterate   25    f= -2.58557D+00    |proj g|=  5.37638D+00\n",
      "\n",
      "At iterate   30    f= -2.60330D+00    |proj g|=  6.56424D-01\n",
      "\n",
      "At iterate   35    f= -2.60340D+00    |proj g|=  1.31578D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3     38     53      1     0     0   2.041D-02  -2.603D+00\n",
      "  F =  -2.6033971766985684     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "Metrics for Ice Hockey (normalizedcountry) - MSE: 0.0003557915175548377, R2: -0.7123422330447684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insufficient data for Jeu De Paume (normalizedcountry)\n",
      "Checking stationarity for Judo (normalizedcountry):\n",
      "ADF Statistic: -0.6493242785590182, p-value: 0.8594428424344474\n",
      "Skipping ARIMA fitting for non-stationary series: Judo (normalizedcountry)\n",
      "Insufficient data for Lacrosse (normalizedcountry)\n",
      "Checking stationarity for Luge (normalizedcountry):\n",
      "ADF Statistic: 0.9703241352508281, p-value: 0.9939427526083812\n",
      "Skipping ARIMA fitting for non-stationary series: Luge (normalizedcountry)\n",
      "Insufficient data for Military Ski Patrol (normalizedcountry)\n",
      "Checking stationarity for Modern Pentathlon (normalizedcountry):\n",
      "ADF Statistic: -1.6636064473131407, p-value: 0.44995428461930126\n",
      "Skipping ARIMA fitting for non-stationary series: Modern Pentathlon (normalizedcountry)\n",
      "Insufficient data for Motorboating (normalizedcountry)\n",
      "Checking stationarity for Nordic Combined (normalizedcountry):\n",
      "ADF Statistic: -2.394826919482925, p-value: 0.1432017989444469\n",
      "Skipping ARIMA fitting for non-stationary series: Nordic Combined (normalizedcountry)\n",
      "Checking stationarity for Polo (normalizedcountry):\n",
      "ADF Statistic: -1.2236867762727808, p-value: 0.6633241731738458\n",
      "Skipping ARIMA fitting for non-stationary series: Polo (normalizedcountry)\n",
      "Insufficient data for Racquets (normalizedcountry)\n",
      "Checking stationarity for Rhythmic Gymnastics (normalizedcountry):\n",
      "ADF Statistic: -2.378081732672938, p-value: 0.14801847275169017\n",
      "Skipping ARIMA fitting for non-stationary series: Rhythmic Gymnastics (normalizedcountry)\n",
      "Insufficient data for Roque (normalizedcountry)\n",
      "Checking stationarity for Rowing (normalizedcountry):\n",
      "ADF Statistic: 0.30692819724413567, p-value: 0.9776601245618964\n",
      "Skipping ARIMA fitting for non-stationary series: Rowing (normalizedcountry)\n",
      "Insufficient data for Rugby (normalizedcountry)\n",
      "Insufficient data for Rugby Sevens (normalizedcountry)\n",
      "Checking stationarity for Sailing (normalizedcountry):\n",
      "ADF Statistic: -0.226856204414252, p-value: 0.9352437970159851\n",
      "Skipping ARIMA fitting for non-stationary series: Sailing (normalizedcountry)\n",
      "Checking stationarity for Shooting (normalizedcountry):\n",
      "ADF Statistic: 1.1549100893961, p-value: 0.9956590573330488\n",
      "Skipping ARIMA fitting for non-stationary series: Shooting (normalizedcountry)\n",
      "Insufficient data for Short Track Speed Skating (normalizedcountry)\n",
      "Insufficient data for Skeleton (normalizedcountry)\n",
      "Checking stationarity for Ski Jumping (normalizedcountry):\n",
      "ADF Statistic: -4.717173076669073, p-value: 7.811907362472959e-05\n",
      "Optimal ARIMA order: (2, 1, 0)\n",
      "Optimal SARIMA order: (2, 1, 0), Seasonal: (0, 0, 0, 0)\n",
      "Metrics for Ski Jumping (normalizedcountry) - MSE: 7.093365706509485e-05, R2: -0.19877880440010287\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.74427D+00    |proj g|=  7.55452D-01\n",
      "\n",
      "At iterate    5    f= -1.80471D+00    |proj g|=  4.55792D+01\n",
      "\n",
      "At iterate   10    f= -2.15197D+00    |proj g|=  1.33641D+01\n",
      "\n",
      "At iterate   15    f= -2.16863D+00    |proj g|=  8.72184D-01\n",
      "  ys=-9.022E-10  -gs= 2.754E-08 BFGS update SKIPPED\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3     19     94      2     1     0   2.045D-01  -2.169D+00\n",
      "  F =  -2.1686345805959668     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.91847D+00    |proj g|=  1.15519D+01\n",
      "\n",
      "At iterate    5    f= -1.93658D+00    |proj g|=  7.75964D+00\n",
      "\n",
      "At iterate   10    f= -2.56688D+00    |proj g|=  4.49923D+01\n",
      "\n",
      "At iterate   15    f= -2.70657D+00    |proj g|=  1.89026D+01\n",
      "\n",
      "At iterate   20    f= -3.06136D+00    |proj g|=  2.75440D+01\n",
      "  ys=-3.803E-08  -gs= 5.267E-06 BFGS update SKIPPED\n",
      "  ys=-3.218E-05  -gs= 4.097E-06 BFGS update SKIPPED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      "\n",
      " Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "\n",
      " Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3     25    118      3     2     0   9.488D-01  -3.062D+00\n",
      "  F =  -3.0617980133648466     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  4.24994D+05    |proj g|=  2.50073D+10\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3      2     22      1     0     0   4.567D+01  -2.105D+00\n",
      "  F =  -2.1048952793668367     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.52201D+00    |proj g|=  2.88776D+01\n",
      "\n",
      "At iterate    5    f= -2.54141D+00    |proj g|=  2.04354D-01\n",
      "\n",
      "At iterate   10    f= -2.54344D+00    |proj g|=  6.41381D+00\n",
      "\n",
      "At iterate   15    f= -2.58366D+00    |proj g|=  1.41169D+00\n",
      "\n",
      "At iterate   20    f= -2.58488D+00    |proj g|=  1.89664D+00\n",
      "\n",
      "At iterate   25    f= -2.58701D+00    |proj g|=  3.22322D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3     28     53      1     0     0   2.674D-02  -2.587D+00\n",
      "  F =  -2.5870090157948584     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.63781D+00    |proj g|=  5.46850D+00\n",
      "\n",
      "At iterate    5    f= -2.63876D+00    |proj g|=  4.79772D-01\n",
      "\n",
      "At iterate   10    f= -2.64343D+00    |proj g|=  1.05777D+01\n",
      "\n",
      "At iterate   15    f= -2.65783D+00    |proj g|=  1.91708D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3     16     28      1     0     0   1.917D-02  -2.658D+00\n",
      "  F =  -2.6578312498299259     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.72728D+00    |proj g|=  1.97709D+01\n",
      "\n",
      "At iterate    5    f= -2.73620D+00    |proj g|=  1.18833D+00\n",
      "\n",
      "At iterate   10    f= -2.75003D+00    |proj g|=  1.58692D+01\n",
      "\n",
      "At iterate   15    f= -2.76071D+00    |proj g|=  9.05507D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3     16     37      1     0     0   9.071D-02  -2.761D+00\n",
      "  F =  -2.7607136416659412     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.82574D+00    |proj g|=  2.75856D+01\n",
      "\n",
      "At iterate    5    f= -2.83945D+00    |proj g|=  1.77918D-01\n",
      "\n",
      "At iterate   10    f= -2.84462D+00    |proj g|=  9.63839D+00\n",
      "\n",
      "At iterate   15    f= -2.86503D+00    |proj g|=  2.78077D-02\n",
      "\n",
      "At iterate   20    f= -2.86548D+00    |proj g|=  5.21749D-02\n",
      "\n",
      "At iterate   25    f= -2.86552D+00    |proj g|=  2.39378D-03\n",
      "  ys=-2.504E-06  -gs= 3.778E-06 BFGS update SKIPPED\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3     27     61      1     1     0   5.477D-03  -2.866D+00\n",
      "  F =  -2.8655156920433331     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.87736D+00    |proj g|=  2.07423D+01\n",
      "\n",
      "At iterate    5    f= -2.88770D+00    |proj g|=  8.16756D+00\n",
      "\n",
      "At iterate   10    f= -2.90557D+00    |proj g|=  1.64399D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3     15     67      2     0     0   1.199D-02  -2.906D+00\n",
      "  F =  -2.9055679321675631     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.94814D+00    |proj g|=  2.75075D+01\n",
      "\n",
      "At iterate    5    f= -2.96031D+00    |proj g|=  1.52802D-01\n",
      "\n",
      "At iterate   10    f= -2.96118D+00    |proj g|=  4.97347D+00\n",
      "\n",
      "At iterate   15    f= -2.98045D+00    |proj g|=  1.89062D+00\n",
      "\n",
      "At iterate   20    f= -2.98073D+00    |proj g|=  3.86931D-02\n",
      "  ys=-7.402E-11  -gs= 9.207E-11 BFGS update SKIPPED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "\n",
      " Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3     25    101      3     1     0   1.973D-02  -2.981D+00\n",
      "  F =  -2.9807335140655833     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.99316D+00    |proj g|=  2.85591D+01\n",
      "\n",
      "At iterate    5    f= -3.00560D+00    |proj g|=  2.42899D-01\n",
      "\n",
      "At iterate   10    f= -3.02411D+00    |proj g|=  1.87695D-01\n",
      "\n",
      "At iterate   15    f= -3.02429D+00    |proj g|=  8.05341D-03\n",
      "\n",
      "At iterate   20    f= -3.02430D+00    |proj g|=  3.31423D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3     22     73      1     0     0   1.124D-01  -3.024D+00\n",
      "  F =  -3.0243015255912908     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -3.05542D+00    |proj g|=  3.22019D+01\n",
      "\n",
      "At iterate    5    f= -3.07436D+00    |proj g|=  3.64604D+00\n",
      "\n",
      "At iterate   10    f= -3.08778D+00    |proj g|=  1.33170D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3     14    146      3     0     0   1.314D-01  -3.088D+00\n",
      "  F =  -3.0877827925606787     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -3.08064D+00    |proj g|=  3.29409D+01\n",
      "\n",
      "At iterate    5    f= -3.09500D+00    |proj g|=  1.28726D-01\n",
      "\n",
      "At iterate   10    f= -3.11145D+00    |proj g|=  2.09192D+00\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3     13     64      2     0     0   1.291D-01  -3.113D+00\n",
      "  F =  -3.1126913063811910     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -3.03316D+00    |proj g|=  2.92184D+01\n",
      "\n",
      "At iterate    5    f= -3.04649D+00    |proj g|=  3.48923D-01\n",
      "\n",
      "At iterate   10    f= -3.05048D+00    |proj g|=  9.29757D+00\n",
      "\n",
      "At iterate   15    f= -3.06515D+00    |proj g|=  2.48094D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3     18     61      1     0     0   8.090D-02  -3.065D+00\n",
      "  F =  -3.0652123015375525     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "Metrics for Ski Jumping (normalizedcountry) - MSE: 7.093365706509485e-05, R2: -0.19877880440010287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All zero values for Snowboarding (normalizedcountry), skipping.\n",
      "Insufficient data for Softball (normalizedcountry)\n",
      "Checking stationarity for Speed Skating (normalizedcountry):\n",
      "ADF Statistic: -0.3214194931301347, p-value: 0.9224154296998591\n",
      "Skipping ARIMA fitting for non-stationary series: Speed Skating (normalizedcountry)\n",
      "Checking stationarity for Swimming (normalizedcountry):\n",
      "ADF Statistic: 1.2979327778050356, p-value: 0.9965973363111306\n",
      "Skipping ARIMA fitting for non-stationary series: Swimming (normalizedcountry)\n",
      "Checking stationarity for Synchronized Swimming (normalizedcountry):\n",
      "ADF Statistic: -2.6159951412830176, p-value: 0.08973625367688565\n",
      "Skipping ARIMA fitting for non-stationary series: Synchronized Swimming (normalizedcountry)\n",
      "Checking stationarity for Table Tennis (normalizedcountry):\n",
      "ADF Statistic: 30.553298497976797, p-value: 1.0\n",
      "Skipping ARIMA fitting for non-stationary series: Table Tennis (normalizedcountry)\n",
      "Checking stationarity for Taekwondo (normalizedcountry):\n",
      "ADF Statistic: -13.905375835416407, p-value: 5.63557985623791e-26\n",
      "Optimal ARIMA order: (0, 0, 0)\n",
      "Optimal SARIMA order: (0, 0, 0), Seasonal: (0, 0, 0, 0)\n",
      "Constant series detected for Taekwondo (normalizedcountry). Predicting constant value: 0.25\n",
      "Metrics for Taekwondo (normalizedcountry) - MSE: 0.0011981575267195625, R2: -39.35899037371151\n",
      "Constant series detected for Taekwondo (normalizedcountry). Predicting constant value: 0.25\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.32070D-01    |proj g|=  1.31140D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     17      1     0     0   1.311D-04   1.321D-01\n",
      "  F =  0.13206960145736452     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.73677D-01    |proj g|=  1.20669D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     18      1     0     0   1.207D-04   1.737D-01\n",
      "  F =  0.17367733891785453     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.97763D-01    |proj g|=  1.14994D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     18      1     0     0   1.150D-04   1.978D-01\n",
      "  F =  0.19776345301762890     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "Metrics for Taekwondo (normalizedcountry) - MSE: 0.07348125000000001, R2: -2474.157894736838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking stationarity for Tennis (normalizedcountry):\n",
      "ADF Statistic: -0.1479946530126656, p-value: 0.944443250228271\n",
      "Skipping ARIMA fitting for non-stationary series: Tennis (normalizedcountry)\n",
      "Checking stationarity for Trampolining (normalizedcountry):\n",
      "ADF Statistic: -5.135290850693083, p-value: 1.1900373979667732e-05\n",
      "Optimal ARIMA order: (1, 0, 0)\n",
      "Optimal SARIMA order: (1, 0, 0), Seasonal: (0, 0, 0, 0)\n",
      "Metrics for Trampolining (normalizedcountry) - MSE: 3.175300585359878e-05, R2: -4.715541053647803\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  3.73138D+01    |proj g|=  8.08777D+03\n",
      "\n",
      "At iterate    5    f= -1.04593D+00    |proj g|=  2.28361D+00\n",
      "\n",
      "At iterate   10    f= -1.71455D+00    |proj g|=  1.64009D+00\n",
      "\n",
      "At iterate   15    f= -1.74105D+00    |proj g|=  3.33700D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     17     43      1     0     0   1.048D-06  -1.741D+00\n",
      "  F =  -1.7410456508744057     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.49530D+00    |proj g|=  1.36982D+03\n",
      "  ys=-2.725E+00  -gs= 8.712E-01 BFGS update SKIPPED\n",
      "\n",
      "At iterate    5    f= -1.02225D+00    |proj g|=  9.56755D-01\n",
      "  ys=-4.446E-01  -gs= 9.327E-01 BFGS update SKIPPED\n",
      "\n",
      "At iterate   10    f= -1.90956D+00    |proj g|=  9.11676D+00\n",
      "\n",
      "At iterate   15    f= -2.09808D+00    |proj g|=  2.46202D+00\n",
      "\n",
      "At iterate   20    f= -2.10581D+00    |proj g|=  8.52986D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     21     78      2     2     0   8.530D-05  -2.106D+00\n",
      "  F =  -2.1058132192856203     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.53287D+01    |proj g|=  2.48420D+03\n",
      "  ys=-7.209E-01  -gs= 8.978E-01 BFGS update SKIPPED\n",
      "\n",
      "At iterate    5    f= -1.03210D+00    |proj g|=  7.62771D-01\n",
      "\n",
      "At iterate   10    f= -2.20025D+00    |proj g|=  1.65999D+01\n",
      "\n",
      "At iterate   15    f= -2.36224D+00    |proj g|=  1.84315D+00\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     19     48      1     1     0   1.133D-03  -2.363D+00\n",
      "  F =  -2.3632976236870462     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "Metrics for Trampolining (normalizedcountry) - MSE: 7.304057023652195e-05, R2: -12.147302642574001\n",
      "Checking stationarity for Triathlon (normalizedcountry):\n",
      "ADF Statistic: 0.24116036131744548, p-value: 0.974477934958228\n",
      "Skipping ARIMA fitting for non-stationary series: Triathlon (normalizedcountry)\n",
      "Checking stationarity for Tug-Of-War (normalizedcountry):\n",
      "ADF Statistic: -3.9999999999999982, p-value: 0.0014105112530392726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal ARIMA order: (0, 0, 0)\n",
      "Optimal SARIMA order: (0, 0, 0), Seasonal: (0, 0, 0, 0)\n",
      "Constant series detected for Tug-Of-War (normalizedcountry). Predicting constant value: 0.02\n",
      "Constant series detected for Tug-Of-War (normalizedcountry). Predicting constant value: 0.02\n",
      "Constant series detected for Tug-Of-War (normalizedcountry). Predicting constant value: 0.02\n",
      "Metrics for Tug-Of-War (normalizedcountry) - MSE: 3.311147026997294e-05, R2: -0.2735180873066516\n",
      "Constant series detected for Tug-Of-War (normalizedcountry). Predicting constant value: 0.02\n",
      "Constant series detected for Tug-Of-War (normalizedcountry). Predicting constant value: 0.02\n",
      "Constant series detected for Tug-Of-War (normalizedcountry). Predicting constant value: 0.02\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.55100D+00    |proj g|=  2.80454D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     19      1     0     0   2.805D-02  -2.551D+00\n",
      "  F =  -2.5510003799860348     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.62866D+00    |proj g|=  3.27556D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     16      1     0     0   3.276D-02  -2.629D+00\n",
      "  F =  -2.6286608574737587     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "Metrics for Tug-Of-War (normalizedcountry) - MSE: 0.00015000000000000001, R2: -4.769230769230769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking stationarity for Volleyball (normalizedcountry):\n",
      "ADF Statistic: -0.7094534388119139, p-value: 0.8442856648181634\n",
      "Skipping ARIMA fitting for non-stationary series: Volleyball (normalizedcountry)\n",
      "Checking stationarity for Water Polo (normalizedcountry):\n",
      "ADF Statistic: -4.097041343559405, p-value: 0.000979488398502853\n",
      "Optimal ARIMA order: (1, 0, 0)\n",
      "Optimal SARIMA order: (1, 0, 0), Seasonal: (0, 0, 0, 0)\n",
      "Metrics for Water Polo (normalizedcountry) - MSE: 0.0005109616157113387, R2: -0.5364494097646704\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.17603D+00    |proj g|=  1.99601D+02\n",
      "\n",
      "At iterate    5    f= -2.62671D+00    |proj g|=  4.68970D-01\n",
      "\n",
      "At iterate   10    f= -2.62681D+00    |proj g|=  8.79213D-01\n",
      "\n",
      "At iterate   15    f= -2.63335D+00    |proj g|=  6.21001D+00\n",
      "\n",
      "At iterate   20    f= -2.63693D+00    |proj g|=  2.07923D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     21     43      1     0     0   2.079D-03  -2.637D+00\n",
      "  F =  -2.6369254109279501     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.52769D+00    |proj g|=  5.47758D+01\n",
      "\n",
      "At iterate    5    f= -2.61720D+00    |proj g|=  9.09270D-02\n",
      "\n",
      "At iterate   10    f= -2.61743D+00    |proj g|=  1.62265D+00\n",
      "\n",
      "At iterate   15    f= -2.62819D+00    |proj g|=  4.40768D+00\n",
      "\n",
      "At iterate   20    f= -2.62953D+00    |proj g|=  5.02082D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     20     40      1     0     0   5.021D-03  -2.630D+00\n",
      "  F =  -2.6295276666675527     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.65185D+00    |proj g|=  9.55411D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      2      7      1     0     0   4.052D-02  -2.652D+00\n",
      "  F =  -2.6519080659760235     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -1.46737D+00    |proj g|=  1.17363D+02\n",
      "\n",
      "At iterate    5    f= -1.99796D+00    |proj g|=  3.56830D+00\n",
      "\n",
      "At iterate   10    f= -2.35146D+00    |proj g|=  3.17021D+00\n",
      "\n",
      "At iterate   15    f= -2.35538D+00    |proj g|=  4.52072D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     15     33      1     0     0   4.521D-04  -2.355D+00\n",
      "  F =  -2.3553802346271047     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -3.89711D-01    |proj g|=  2.61915D+02\n",
      "\n",
      "At iterate    5    f= -2.03012D+00    |proj g|=  2.99675D+00\n",
      "\n",
      "At iterate   10    f= -2.43976D+00    |proj g|=  3.74498D+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate   15    f= -2.44403D+00    |proj g|=  5.30243D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     15     43      1     0     0   5.302D-04  -2.444D+00\n",
      "  F =  -2.4440321716132396     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.59584D-01    |proj g|=  4.65560D+02\n",
      "\n",
      "At iterate    5    f= -2.14779D+00    |proj g|=  2.27096D+01\n",
      "\n",
      "At iterate   10    f= -2.52269D+00    |proj g|=  9.74094D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     14     33      1     0     0   1.471D-03  -2.524D+00\n",
      "  F =  -2.5235309626534539     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.33997D+00    |proj g|=  3.95987D+00\n",
      "\n",
      "At iterate    5    f= -2.34202D+00    |proj g|=  1.00634D-01\n",
      "\n",
      "At iterate   10    f= -2.34245D+00    |proj g|=  1.78595D+00\n",
      "\n",
      "At iterate   15    f= -2.34892D+00    |proj g|=  3.37402D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     18     35      1     0     0   1.080D-03  -2.349D+00\n",
      "  F =  -2.3489592897524805     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.02060D+00    |proj g|=  3.67176D+00\n",
      "\n",
      "At iterate    5    f= -2.02363D+00    |proj g|=  9.22166D-02\n",
      "\n",
      "At iterate   10    f= -2.02476D+00    |proj g|=  2.24103D+00\n",
      "\n",
      "At iterate   15    f= -2.06681D+00    |proj g|=  7.15028D+00\n",
      "\n",
      "At iterate   20    f= -2.08228D+00    |proj g|=  2.10129D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     22     33      1     0     0   1.180D-03  -2.082D+00\n",
      "  F =  -2.0822819909340060     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -7.07374D-01    |proj g|=  1.06456D+02\n",
      "\n",
      "At iterate    5    f= -1.64482D+00    |proj g|=  3.03312D+01\n",
      "\n",
      "At iterate   10    f= -2.10569D+00    |proj g|=  5.91792D+00\n",
      "\n",
      "At iterate   15    f= -2.11454D+00    |proj g|=  7.18693D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     18     30      1     0     0   7.045D-06  -2.115D+00\n",
      "  F =  -2.1145436507156399     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -4.86404D-02    |proj g|=  1.64282D+02\n",
      "\n",
      "At iterate    5    f= -1.44409D+00    |proj g|=  1.21764D+01\n",
      "\n",
      "At iterate   10    f= -2.11874D+00    |proj g|=  1.77209D+00\n",
      "\n",
      "At iterate   15    f= -2.13455D+00    |proj g|=  3.13623D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     17     41      1     0     0   1.754D-05  -2.135D+00\n",
      "  F =  -2.1345455911350704     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.06671D+00    |proj g|=  2.44014D+00\n",
      "\n",
      "At iterate    5    f= -2.07098D+00    |proj g|=  2.34511D+00\n",
      "\n",
      "At iterate   10    f= -2.07585D+00    |proj g|=  3.80478D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     11     29      1     0     0   3.805D-04  -2.076D+00\n",
      "  F =  -2.0758461900782832     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.03939D+00    |proj g|=  2.36500D+00\n",
      "\n",
      "At iterate    5    f= -2.04072D+00    |proj g|=  2.01348D-01\n",
      "\n",
      "At iterate   10    f= -2.04300D+00    |proj g|=  2.97823D+00\n",
      "\n",
      "At iterate   15    f= -2.05595D+00    |proj g|=  1.58234D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     19     37      1     0     0   1.893D-04  -2.056D+00\n",
      "  F =  -2.0559797290789321     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.08592D+00    |proj g|=  2.20652D+00\n",
      "\n",
      "At iterate    5    f= -2.08700D+00    |proj g|=  2.20548D-01\n",
      "\n",
      "At iterate   10    f= -2.08937D+00    |proj g|=  3.02045D+00\n",
      "\n",
      "At iterate   15    f= -2.09588D+00    |proj g|=  1.44254D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     16     35      1     0     0   1.443D-03  -2.096D+00\n",
      "  F =  -2.0958828053904637     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.10806D+00    |proj g|=  2.16622D+00\n",
      "\n",
      "At iterate    5    f= -2.10903D+00    |proj g|=  1.88796D-01\n",
      "\n",
      "At iterate   10    f= -2.11080D+00    |proj g|=  2.78437D+00\n",
      "\n",
      "At iterate   15    f= -2.12025D+00    |proj g|=  9.19536D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     19     38      1     0     0   1.179D-03  -2.120D+00\n",
      "  F =  -2.1202557282876344     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.13516D+00    |proj g|=  2.12562D+00\n",
      "\n",
      "At iterate    5    f= -2.13604D+00    |proj g|=  1.74649D-01\n",
      "\n",
      "At iterate   10    f= -2.13751D+00    |proj g|=  2.65153D+00\n",
      "\n",
      "At iterate   15    f= -2.14876D+00    |proj g|=  1.98052D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     19     26      1     0     0   4.925D-03  -2.149D+00\n",
      "  F =  -2.1488918424036845     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.16860D+00    |proj g|=  1.96651D+00\n",
      "\n",
      "At iterate    5    f= -2.16933D+00    |proj g|=  2.03405D-01\n",
      "\n",
      "At iterate   10    f= -2.17108D+00    |proj g|=  2.82042D+00\n",
      "\n",
      "At iterate   15    f= -2.17606D+00    |proj g|=  9.44748D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     16     41      1     0     0   9.447D-04  -2.176D+00\n",
      "  F =  -2.1760629241850804     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.19871D+00    |proj g|=  1.91245D+00\n",
      "\n",
      "At iterate    5    f= -2.19936D+00    |proj g|=  2.26781D-01\n",
      "\n",
      "At iterate   10    f= -2.20137D+00    |proj g|=  3.05407D+00\n",
      "\n",
      "At iterate   15    f= -2.20572D+00    |proj g|=  1.77786D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     16     31      1     0     0   1.778D-03  -2.206D+00\n",
      "  F =  -2.2057209499541881     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.22718D+00    |proj g|=  1.86274D+00\n",
      "\n",
      "At iterate    5    f= -2.22777D+00    |proj g|=  3.06392D-01\n",
      "\n",
      "At iterate   10    f= -2.23058D+00    |proj g|=  3.49274D+00\n",
      "\n",
      "At iterate   15    f= -2.23378D+00    |proj g|=  2.42711D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     16     38      1     0     0   2.427D-03  -2.234D+00\n",
      "  F =  -2.2337830553143063     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.25416D+00    |proj g|=  1.81684D+00\n",
      "\n",
      "At iterate    5    f= -2.25470D+00    |proj g|=  3.52233D-01\n",
      "\n",
      "At iterate   10    f= -2.25785D+00    |proj g|=  3.59612D+00\n",
      "\n",
      "At iterate   15    f= -2.26041D+00    |proj g|=  9.48193D-06\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     15     22      1     0     0   9.482D-06  -2.260D+00\n",
      "  F =  -2.2604099889931648     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.27981D+00    |proj g|=  1.77430D+00\n",
      "\n",
      "At iterate    5    f= -2.28035D+00    |proj g|=  5.27943D-01\n",
      "\n",
      "At iterate   10    f= -2.28424D+00    |proj g|=  3.08896D+00\n",
      "\n",
      "At iterate   15    f= -2.28574D+00    |proj g|=  9.35332D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     15     42      1     0     0   9.353D-04  -2.286D+00\n",
      "  F =  -2.2857395486437602     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.30425D+00    |proj g|=  1.73474D+00\n",
      "\n",
      "At iterate    5    f= -2.30480D+00    |proj g|=  6.95931D-01\n",
      "\n",
      "At iterate   10    f= -2.30918D+00    |proj g|=  2.22163D+00\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     14     23      1     0     0   6.831D-03  -2.310D+00\n",
      "  F =  -2.3098906956055507     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.32393D+00    |proj g|=  1.70954D+00\n",
      "\n",
      "At iterate    5    f= -2.32466D+00    |proj g|=  1.14314D+00\n",
      "\n",
      "At iterate   10    f= -2.32984D+00    |proj g|=  5.30954D-01\n",
      "\n",
      "At iterate   15    f= -2.32991D+00    |proj g|=  1.90470D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     15     38      1     0     0   1.905D-04  -2.330D+00\n",
      "  F =  -2.3299094877307440     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.34619D+00    |proj g|=  1.67618D+00\n",
      "\n",
      "At iterate    5    f= -2.35039D+00    |proj g|=  3.20377D+00\n",
      "\n",
      "At iterate   10    f= -2.35194D+00    |proj g|=  6.28480D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     11     24      1     0     0   4.684D-03  -2.352D+00\n",
      "  F =  -2.3519375949411736     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.36387D+00    |proj g|=  1.65720D+00\n",
      "\n",
      "At iterate    5    f= -2.36720D+00    |proj g|=  3.73376D+00\n",
      "\n",
      "At iterate   10    f= -2.37011D+00    |proj g|=  4.82040D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     11     22      1     0     0   1.296D-05  -2.370D+00\n",
      "  F =  -2.3701094459135059     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -2.38434D+00    |proj g|=  1.62854D+00\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      4     12      1     0     0   1.434D-02  -2.385D+00\n",
      "  F =  -2.3846445415414146     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "Metrics for Water Polo (normalizedcountry) - MSE: 0.0005325288231836981, R2: -0.6013014890055877\n",
      "Checking stationarity for Weightlifting (normalizedcountry):\n",
      "ADF Statistic: -0.39040799087856065, p-value: 0.9116880228553013\n",
      "Skipping ARIMA fitting for non-stationary series: Weightlifting (normalizedcountry)\n",
      "Checking stationarity for Wrestling (normalizedcountry):\n",
      "ADF Statistic: -0.08506987285440631, p-value: 0.9509054760323499\n",
      "Skipping ARIMA fitting for non-stationary series: Wrestling (normalizedcountry)\n",
      "All zero values for climbing (normalizedcountry), skipping.\n",
      "All zero values for Fitness (normalizedcountry), skipping.\n",
      "All zero values for Headis (normalizedcountry), skipping.\n",
      "\n",
      "Processing parameter: CV\n",
      "Checking stationarity for Alpine Skiing (CV):\n",
      "ADF Statistic: -5.597947135717146, p-value: 1.2841875516310806e-06\n",
      "Optimal ARIMA order: (1, 0, 0)\n",
      "Optimal SARIMA order: (1, 0, 0), Seasonal: (0, 0, 0, 0)\n",
      "Metrics for Alpine Skiing (CV) - MSE: 0.01449806899220767, R2: 0.17146214873212284\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.04945D+03    |proj g|=  2.97070D+05\n",
      "  ys=-2.276E-01  -gs= 5.570E-01 BFGS update SKIPPED\n",
      "\n",
      "At iterate    5    f=  5.00332D-01    |proj g|=  3.33317D-01\n",
      "\n",
      "At iterate   10    f=  1.23637D-01    |proj g|=  7.80010D-01\n",
      "\n",
      "At iterate   15    f= -2.92878D-01    |proj g|=  4.88063D+00\n",
      "\n",
      "At iterate   20    f= -4.36931D-01    |proj g|=  7.38141D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     25     87      2     1     0   2.627D-04  -4.375D-01\n",
      "  F = -0.43746095696815934     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.45793D+00    |proj g|=  9.36557D+01\n",
      "\n",
      "At iterate    5    f= -1.49289D-01    |proj g|=  1.32596D-01\n",
      "\n",
      "At iterate   10    f= -4.57550D-01    |proj g|=  4.58309D+00\n",
      "\n",
      "At iterate   15    f= -5.14825D-01    |proj g|=  1.34595D-01\n",
      "\n",
      "At iterate   20    f= -5.15078D-01    |proj g|=  1.06191D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     20     37      1     0     0   1.062D-04  -5.151D-01\n",
      "  F = -0.51507785102113390     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  4.83508D+01    |proj g|=  1.11195D+03\n",
      "\n",
      "At iterate    5    f=  1.50344D-01    |proj g|=  9.23427D-01\n",
      "\n",
      "At iterate   10    f= -3.61213D-01    |proj g|=  7.23644D-01\n",
      "\n",
      "At iterate   15    f= -3.94460D-01    |proj g|=  2.10876D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     17     35      1     0     0   7.370D-04  -3.945D-01\n",
      "  F = -0.39446112797381949     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  6.14274D-02    |proj g|=  4.21469D+00\n",
      "\n",
      "At iterate    5    f= -1.28265D-02    |proj g|=  1.01028D-01\n",
      "\n",
      "At iterate   10    f= -7.90765D-02    |proj g|=  6.12099D-01\n",
      "\n",
      "At iterate   15    f= -8.60341D-02    |proj g|=  1.07557D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     17     20      1     0     0   1.282D-05  -8.603D-02\n",
      "  F =  -8.6034839024561396E-002\n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  7.61931D+00    |proj g|=  7.12635D+01\n",
      "\n",
      "At iterate    5    f=  3.30693D-01    |proj g|=  2.92427D-01\n",
      "\n",
      "At iterate   10    f=  1.34023D-01    |proj g|=  2.74105D-02\n",
      "\n",
      "At iterate   15    f=  1.31239D-01    |proj g|=  8.98825D-07\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     15     28      1     0     0   8.988D-07   1.312D-01\n",
      "  F =  0.13123938597188664     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  8.77591D-02    |proj g|=  2.59400D-01\n",
      "\n",
      "At iterate    5    f=  8.68354D-02    |proj g|=  8.97688D-02\n",
      "\n",
      "At iterate   10    f=  8.42803D-02    |proj g|=  2.51023D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     14     17      1     0     0   8.851D-06   8.427D-02\n",
      "  F =   8.4272775122851681E-002\n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  4.24652D-02    |proj g|=  2.63555D-01\n",
      "\n",
      "At iterate    5    f=  4.14201D-02    |proj g|=  1.11156D-01\n",
      "\n",
      "At iterate   10    f=  3.52237D-02    |proj g|=  1.97996D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     14     18      1     0     0   3.381D-05   3.472D-02\n",
      "  F =   3.4720290611634591E-002\n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  6.98070D-02    |proj g|=  4.59087D-01\n",
      "\n",
      "At iterate    5    f=  6.69512D-02    |proj g|=  1.37859D-01\n",
      "\n",
      "At iterate   10    f=  5.99497D-02    |proj g|=  3.15152D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     14     17      1     0     0   1.191D-05   5.992D-02\n",
      "  F =   5.9924491343680213E-002\n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.07969D-01    |proj g|=  9.68042D-02\n",
      "\n",
      "At iterate    5    f=  1.07814D-01    |proj g|=  2.99026D-02\n",
      "\n",
      "At iterate   10    f=  1.06895D-01    |proj g|=  1.02564D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     13     16      1     0     0   2.968D-06   1.068D-01\n",
      "  F =  0.10675347769936354     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  5.61841D-02    |proj g|=  8.69481D-02\n",
      "\n",
      "At iterate    5    f=  5.57343D-02    |proj g|=  8.92699D-02\n",
      "\n",
      "At iterate   10    f=  5.55193D-02    |proj g|=  4.70439D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     11     51      2     0     0   4.704D-05   5.552D-02\n",
      "  F =   5.5519324438590908E-002\n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  3.59856D-02    |proj g|=  1.25562D-01\n",
      "\n",
      "At iterate    5    f=  3.57565D-02    |proj g|=  3.60302D-02\n",
      "\n",
      "At iterate   10    f=  3.41027D-02    |proj g|=  2.10843D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     14     17      1     0     0   3.456D-07   3.356D-02\n",
      "  F =   3.3563442573767768E-002\n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "Metrics for Alpine Skiing (CV) - MSE: 0.05179065254204405, R2: -1.9597400864908057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      "\n",
      " Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insufficient data for Alpinism (CV)\n",
      "Checking stationarity for Archery (CV):\n",
      "ADF Statistic: -1.5973846671741356, p-value: 0.4849071184866433\n",
      "Skipping ARIMA fitting for non-stationary series: Archery (CV)\n",
      "Checking stationarity for Art Competitions (CV):\n",
      "ADF Statistic: -1.7417773714114226, p-value: 0.40972614113637257\n",
      "Skipping ARIMA fitting for non-stationary series: Art Competitions (CV)\n",
      "Checking stationarity for Athletics (CV):\n",
      "ADF Statistic: -3.083079911960942, p-value: 0.02783095537448894\n",
      "Optimal ARIMA order: (1, 0, 0)\n",
      "Optimal SARIMA order: (1, 0, 0), Seasonal: (0, 0, 0, 0)\n",
      "Metrics for Athletics (CV) - MSE: 0.007543717677937682, R2: -0.11573568515338661\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  7.51787D+01    |proj g|=  1.21796D+04\n",
      "\n",
      "At iterate    5    f=  2.32724D-01    |proj g|=  3.19304D+00\n",
      "\n",
      "At iterate   10    f= -3.34784D-01    |proj g|=  5.51472D+00\n",
      "\n",
      "At iterate   15    f= -4.22888D-01    |proj g|=  8.41934D-01\n",
      "\n",
      "At iterate   20    f= -4.23769D-01    |proj g|=  1.65825D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     20     47      1     0     0   1.658D-02  -4.238D-01\n",
      "  F = -0.42376920719197608     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.82649D+01    |proj g|=  2.97726D+03\n",
      "\n",
      "At iterate    5    f= -3.68066D-01    |proj g|=  2.56003D-01\n",
      "\n",
      "At iterate   10    f= -3.86088D-01    |proj g|=  2.12597D+00\n",
      "\n",
      "At iterate   15    f= -1.14167D+00    |proj g|=  2.00038D+00\n",
      "\n",
      "At iterate   20    f= -1.25308D+00    |proj g|=  4.55005D-01\n",
      "\n",
      "At iterate   25    f= -1.26169D+00    |proj g|=  5.21513D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     26     65      1     0     0   5.215D-04  -1.262D+00\n",
      "  F =  -1.2616927591646292     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  5.02426D+00    |proj g|=  3.59679D+02\n",
      "\n",
      "At iterate    5    f= -3.75435D-01    |proj g|=  9.40243D-01\n",
      "\n",
      "At iterate   10    f= -7.94051D-01    |proj g|=  2.19464D+00\n",
      "\n",
      "At iterate   15    f= -8.21809D-01    |proj g|=  4.61225D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     17     28      1     0     0   2.373D-03  -8.218D-01\n",
      "  F = -0.82180862381793673     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  6.85795D+01    |proj g|=  1.68855D+03\n",
      "\n",
      "At iterate    5    f= -1.33071D-01    |proj g|=  2.05649D-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate   10    f= -3.31580D-01    |proj g|=  2.62495D+00\n",
      "\n",
      "At iterate   15    f= -5.63673D-01    |proj g|=  2.70958D-01\n",
      "\n",
      "At iterate   20    f= -5.73246D-01    |proj g|=  7.62956D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     21     37      1     0     0   2.639D-06  -5.732D-01\n",
      "  F = -0.57324590788080432     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  5.84477D+01    |proj g|=  1.28292D+03\n",
      "\n",
      "At iterate    5    f= -2.32849D-01    |proj g|=  4.15179D-01\n",
      "\n",
      "At iterate   10    f= -4.66954D-01    |proj g|=  8.67666D-01\n",
      "\n",
      "At iterate   15    f= -4.95084D-01    |proj g|=  3.26207D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     18     36      1     0     0   3.090D-05  -4.951D-01\n",
      "  F = -0.49509749005362708     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -4.40835D-01    |proj g|=  8.67884D-01\n",
      "\n",
      "At iterate    5    f= -4.43274D-01    |proj g|=  1.74746D-02\n",
      "\n",
      "At iterate   10    f= -4.43607D-01    |proj g|=  3.26127D-01\n",
      "\n",
      "At iterate   15    f= -4.59867D-01    |proj g|=  1.62252D+00\n",
      "\n",
      "At iterate   20    f= -4.71367D-01    |proj g|=  2.10264D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     22     27      1     0     0   3.284D-06  -4.714D-01\n",
      "  F = -0.47136688758509365     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  4.39358D+01    |proj g|=  8.26369D+02\n",
      "\n",
      "At iterate    5    f= -1.76221D-01    |proj g|=  4.01744D-01\n",
      "\n",
      "At iterate   10    f= -4.81492D-01    |proj g|=  5.17698D-02\n",
      "\n",
      "At iterate   15    f= -5.13323D-01    |proj g|=  4.70586D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     18     42      1     0     0   4.503D-05  -5.133D-01\n",
      "  F = -0.51332530216652772     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  5.17152D+01    |proj g|=  1.03765D+03\n",
      "\n",
      "At iterate    5    f= -3.32259D-01    |proj g|=  3.96183D-01\n",
      "\n",
      "At iterate   10    f= -5.87190D-01    |proj g|=  5.42406D-01\n",
      "\n",
      "At iterate   15    f= -5.99255D-01    |proj g|=  7.74975D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     18     35      1     0     0   2.677D-05  -5.993D-01\n",
      "  F = -0.59925464032680864     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  5.68300D+01    |proj g|=  1.16780D+03\n",
      "\n",
      "At iterate    5    f= -5.27864D-01    |proj g|=  5.82362D-02\n",
      "\n",
      "At iterate   10    f= -5.36313D-01    |proj g|=  1.03587D+00\n",
      "\n",
      "At iterate   15    f= -6.21114D-01    |proj g|=  9.23491D-02\n",
      "\n",
      "At iterate   20    f= -6.24565D-01    |proj g|=  4.26785D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     21     37      1     0     0   4.472D-06  -6.246D-01\n",
      "  F = -0.62456533764563971     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  5.86830D+01    |proj g|=  1.21216D+03\n",
      "\n",
      "At iterate    5    f= -5.48951D-01    |proj g|=  2.87751D-01\n",
      "\n",
      "At iterate   10    f= -5.93532D-01    |proj g|=  2.67201D+00\n",
      "\n",
      "At iterate   15    f= -6.73520D-01    |proj g|=  4.22567D-02\n",
      "\n",
      "At iterate   20    f= -6.73936D-01    |proj g|=  1.29985D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     21     56      1     0     0   1.300D-05  -6.739D-01\n",
      "  F = -0.67393588881561550     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  5.55256D+01    |proj g|=  1.11773D+03\n",
      "\n",
      "At iterate    5    f= -6.17926D-01    |proj g|=  5.63393D-01\n",
      "\n",
      "At iterate   10    f= -6.55974D-01    |proj g|=  1.40835D+00\n",
      "\n",
      "At iterate   15    f= -6.81755D-01    |proj g|=  8.82758D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     18     42      1     0     0   1.823D-04  -6.818D-01\n",
      "  F = -0.68175972063790002     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  6.05488D+01    |proj g|=  1.27230D+03\n",
      "\n",
      "At iterate    5    f= -6.28495D-01    |proj g|=  2.26000D-01\n",
      "\n",
      "At iterate   10    f= -6.50227D-01    |proj g|=  2.41471D+00\n",
      "\n",
      "At iterate   15    f= -7.35508D-01    |proj g|=  7.20134D-03\n",
      "\n",
      "At iterate   20    f= -7.36751D-01    |proj g|=  5.08930D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     21     40      1     0     0   5.425D-07  -7.368D-01\n",
      "  F = -0.73675055612194218     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  6.55152D+01    |proj g|=  1.43191D+03\n",
      "\n",
      "At iterate    5    f= -6.88829D-01    |proj g|=  2.83836D-01\n",
      "\n",
      "At iterate   10    f= -7.81956D-01    |proj g|=  1.72317D-01\n",
      "\n",
      "At iterate   15    f= -7.86945D-01    |proj g|=  7.82999D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     16     31      1     0     0   3.117D-05  -7.869D-01\n",
      "  F = -0.78694533517583132     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  7.05309D+01    |proj g|=  1.59874D+03\n",
      "\n",
      "At iterate    5    f= -7.77351D-01    |proj g|=  1.51653D+00\n",
      "\n",
      "At iterate   10    f= -7.99971D-01    |proj g|=  1.47378D+00\n",
      "\n",
      "At iterate   15    f= -8.32603D-01    |proj g|=  6.26242D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     18     39      1     0     0   4.594D-04  -8.326D-01\n",
      "  F = -0.83264426633518673     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -8.64000D-01    |proj g|=  3.55556D-01\n",
      "\n",
      "At iterate    5    f= -8.64244D-01    |proj g|=  2.00324D-02\n",
      "\n",
      "At iterate   10    f= -8.64424D-01    |proj g|=  3.10704D-01\n",
      "\n",
      "At iterate   15    f= -8.69404D-01    |proj g|=  3.23522D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     18     23      1     0     0   1.327D-06  -8.696D-01\n",
      "  F = -0.86959795842632126     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -8.97704D-01    |proj g|=  2.19470D-01\n",
      "\n",
      "At iterate    5    f= -8.97792D-01    |proj g|=  1.54708D-02\n",
      "\n",
      "At iterate   10    f= -8.97897D-01    |proj g|=  2.24599D-01\n",
      "\n",
      "At iterate   15    f= -8.98854D-01    |proj g|=  2.43025D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     19     62      2     0     0   1.259D-04  -8.989D-01\n",
      "  F = -0.89885587613411577     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  7.56530D+01    |proj g|=  1.78919D+03\n",
      "\n",
      "At iterate    5    f= -8.02586D-01    |proj g|=  2.50252D-01\n",
      "\n",
      "At iterate   10    f= -8.07397D-01    |proj g|=  1.33860D+00\n",
      "\n",
      "At iterate   15    f= -8.90532D-01    |proj g|=  2.18281D-01\n",
      "\n",
      "At iterate   20    f= -9.00329D-01    |proj g|=  1.04179D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     23     39      1     0     0   5.356D-08  -9.003D-01\n",
      "  F = -0.90034208160869733     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  7.00668D+01    |proj g|=  1.58434D+03\n",
      "  ys=-1.914E-02  -gs= 9.964E-01 BFGS update SKIPPED\n",
      "\n",
      "At iterate    5    f= -7.64643D-01    |proj g|=  7.21182D-01\n",
      "\n",
      "At iterate   10    f= -7.73838D-01    |proj g|=  1.71655D+00\n",
      "\n",
      "At iterate   15    f= -8.52949D-01    |proj g|=  4.27144D-01\n",
      "\n",
      "At iterate   20    f= -8.57124D-01    |proj g|=  1.79708D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     22     43      1     1     0   6.960D-05  -8.571D-01\n",
      "  F = -0.85712384274807774     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -7.83818D-01    |proj g|=  1.23447D-01\n",
      "\n",
      "At iterate    5    f= -7.83863D-01    |proj g|=  4.09528D-02\n",
      "\n",
      "At iterate   10    f= -7.84385D-01    |proj g|=  2.85106D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     14     20      1     0     0   1.733D-06  -7.846D-01\n",
      "  F = -0.78461543937364475     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -8.01079D-01    |proj g|=  3.13089D-01\n",
      "\n",
      "At iterate    5    f= -8.01310D-01    |proj g|=  5.42057D-03\n",
      "\n",
      "At iterate   10    f= -8.01337D-01    |proj g|=  1.05873D-01\n",
      "\n",
      "At iterate   15    f= -8.04243D-01    |proj g|=  1.18894D+00\n",
      "\n",
      "At iterate   20    f= -8.09341D-01    |proj g|=  2.56633D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     22     25      1     0     0   2.705D-06  -8.093D-01\n",
      "  F = -0.80934072816026814     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -8.34369D-01    |proj g|=  2.05031D-01\n",
      "\n",
      "At iterate    5    f= -8.34513D-01    |proj g|=  1.09136D-01\n",
      "\n",
      "At iterate   10    f= -8.36583D-01    |proj g|=  4.39032D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     14     21      1     0     0   8.015D-06  -8.370D-01\n",
      "  F = -0.83704331463412529     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -8.59655D-01    |proj g|=  4.92259D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      2     15      1     0     0   2.232D-04  -8.597D-01\n",
      "  F = -0.85965508823246228     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -8.81632D-01    |proj g|=  1.20129D-01\n",
      "\n",
      "At iterate    5    f= -8.81663D-01    |proj g|=  2.14100D-02\n",
      "\n",
      "At iterate   10    f= -8.81877D-01    |proj g|=  2.78647D-01\n",
      "\n",
      "At iterate   15    f= -8.82411D-01    |proj g|=  2.51926D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     16     31      1     0     0   2.519D-05  -8.824D-01\n",
      "  F = -0.88241062553947858     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -9.04568D-01    |proj g|=  2.64298D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      2     44      2     0     0   3.232D-04  -9.046D-01\n",
      "  F = -0.90456962162320698     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -9.27835D-01    |proj g|=  1.91419D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      2     42      2     0     0   3.069D-04  -9.278D-01\n",
      "  F = -0.92783549970389223     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -9.28325D-01    |proj g|=  2.77234D-01\n",
      "\n",
      "At iterate    5    f= -9.28470D-01    |proj g|=  3.39567D-03\n",
      "\n",
      "At iterate   10    f= -9.28478D-01    |proj g|=  6.33691D-02\n",
      "\n",
      "At iterate   15    f= -9.29443D-01    |proj g|=  7.51651D-01\n",
      "\n",
      "At iterate   20    f= -9.35213D-01    |proj g|=  1.75926D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     23     26      1     0     0   3.742D-07  -9.352D-01\n",
      "  F = -0.93521412792670844     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -9.36750D-01    |proj g|=  8.64382D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      2      6      1     0     0   1.131D-03  -9.368D-01\n",
      "  F = -0.93676491065729661     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "Metrics for Athletics (CV) - MSE: 0.007558810529830851, R2: -0.1179679576438053\n",
      "Checking stationarity for Badminton (CV):\n",
      "ADF Statistic: -4.006150124809719, p-value: 0.0013786475733219958\n",
      "Optimal ARIMA order: (0, 0, 0)\n",
      "Optimal SARIMA order: (0, 0, 0), Seasonal: (0, 0, 0, 0)\n",
      "Constant series detected for Badminton (CV). Predicting constant value: 0.6121206057579025\n",
      "Metrics for Badminton (CV) - MSE: 0.010422325654476823, R2: -6.7989834118192665\n",
      "Constant series detected for Badminton (CV). Predicting constant value: 0.6121206057579025\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.07232D+00    |proj g|=  2.00014D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     14      1     0     0   1.998D-05   1.072D+00\n",
      "  F =   1.0723168393662541     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.11654D+00    |proj g|=  1.83084D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     12      1     0     0   1.828D-05   1.117D+00\n",
      "  F =   1.1165389339255070     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.15041D+00    |proj g|=  1.71093D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     12      1     0     0   1.711D-05   1.150D+00\n",
      "  F =   1.1504088782196831     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.16990D+00    |proj g|=  1.64550D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     11      1     0     0   1.643D-05   1.170D+00\n",
      "  F =   1.1699047641642129     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.17832D+00    |proj g|=  1.61803D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     10      1     0     0   1.616D-05   1.178D+00\n",
      "  F =   1.1783226952677472     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "Metrics for Badminton (CV) - MSE: 0.5454500765735578, R2: -407.15804842419936\n",
      "Checking stationarity for Baseball (CV):\n",
      "ADF Statistic: -1.4502249456964236, p-value: 0.5579751367316419\n",
      "Skipping ARIMA fitting for non-stationary series: Baseball (CV)\n",
      "Checking stationarity for Basketball (CV):\n",
      "ADF Statistic: 1.358515137985797, p-value: 0.9969172874717482\n",
      "Skipping ARIMA fitting for non-stationary series: Basketball (CV)\n",
      "Insufficient data for Basque Pelota (CV)\n",
      "Checking stationarity for Beach Volleyball (CV):\n",
      "ADF Statistic: -0.25317838833101197, p-value: 0.9318788734704906\n",
      "Skipping ARIMA fitting for non-stationary series: Beach Volleyball (CV)\n",
      "Checking stationarity for Biathlon (CV):\n",
      "ADF Statistic: -2.726525506313059, p-value: 0.06955959318420835\n",
      "Skipping ARIMA fitting for non-stationary series: Biathlon (CV)\n",
      "Checking stationarity for Bobsleigh (CV):\n",
      "ADF Statistic: 1.032110548541878, p-value: 0.9945934591348056\n",
      "Skipping ARIMA fitting for non-stationary series: Bobsleigh (CV)\n",
      "Checking stationarity for Boxing (CV):\n",
      "ADF Statistic: 1.9566580877741069, p-value: 0.9986139153014687\n",
      "Skipping ARIMA fitting for non-stationary series: Boxing (CV)\n",
      "Checking stationarity for Canoeing (CV):\n",
      "ADF Statistic: -0.6394226835187193, p-value: 0.8618230287485356\n",
      "Skipping ARIMA fitting for non-stationary series: Canoeing (CV)\n",
      "Insufficient data for Cricket (CV)\n",
      "Insufficient data for Croquet (CV)\n",
      "Checking stationarity for Cross Country Skiing (CV):\n",
      "ADF Statistic: -3.8827086746536605, p-value: 0.002165851966092137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal ARIMA order: (3, 0, 1)\n",
      "Optimal SARIMA order: (0, 0, 0), Seasonal: (0, 0, 0, 0)\n",
      "Metrics for Cross Country Skiing (CV) - MSE: 0.019146231449906757, R2: -2.230377499078027\n",
      "Constant series detected for Cross Country Skiing (CV). Predicting constant value: 0.6321810341670748\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.03525D+00    |proj g|=  2.15406D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     10      1     0     0   2.151D-05   1.035D+00\n",
      "  F =   1.0352498344148260     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.00350D+00    |proj g|=  2.29527D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     12      1     0     0   2.295D-05   1.004D+00\n",
      "  F =   1.0035004863519690     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.07918D+00    |proj g|=  1.97287D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     14      1     0     0   1.971D-05   1.079D+00\n",
      "  F =   1.0791820978806679     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.11133D+00    |proj g|=  1.85002D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     12      1     0     0   1.849D-05   1.111D+00\n",
      "  F =   1.1113273221488467     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.16317D+00    |proj g|=  1.66782D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     11      1     0     0   1.665D-05   1.163D+00\n",
      "  F =   1.1631699695438842     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.17036D+00    |proj g|=  1.64400D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     12      1     0     0   1.642D-05   1.170D+00\n",
      "  F =   1.1703602573509764     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.18614D+00    |proj g|=  1.59295D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     12      1     0     0   1.591D-05   1.186D+00\n",
      "  F =   1.1861351369329105     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.19197D+00    |proj g|=  1.57446D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     10      1     0     0   1.573D-05   1.192D+00\n",
      "  F =   1.1919726215363080     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.18949D+00    |proj g|=  1.58228D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     11      1     0     0   1.580D-05   1.189D+00\n",
      "  F =   1.1894934329434321     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.18095D+00    |proj g|=  1.60956D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     10      1     0     0   1.607D-05   1.181D+00\n",
      "  F =   1.1809478668834819     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.18149D+00    |proj g|=  1.60780D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1      9      1     0     0   1.606D-05   1.181D+00\n",
      "  F =   1.1814936479351623     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.17220D+00    |proj g|=  1.63798D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     14      1     0     0   1.638D-05   1.172D+00\n",
      "  F =   1.1721979458786043     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.17241D+00    |proj g|=  1.63727D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1      9      1     0     0   1.636D-05   1.172D+00\n",
      "  F =   1.1724131060242660     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.18717D+00    |proj g|=  1.58964D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     11      1     0     0   1.588D-05   1.187D+00\n",
      "  F =   1.1871739093855860     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "Metrics for Cross Country Skiing (CV) - MSE: 0.6212025526655924, R2: -77.15317010148303\n",
      "Insufficient data for Curling (CV)\n",
      "Checking stationarity for Cycling (CV):\n",
      "ADF Statistic: -2.573356180469268, p-value: 0.09862998095065129\n",
      "Skipping ARIMA fitting for non-stationary series: Cycling (CV)\n",
      "Checking stationarity for Diving (CV):\n",
      "ADF Statistic: -3.8615829014825724, p-value: 0.0023364893375055536\n",
      "Optimal ARIMA order: (0, 0, 1)\n",
      "Optimal SARIMA order: (0, 0, 1), Seasonal: (0, 0, 0, 0)\n",
      "Metrics for Diving (CV) - MSE: 0.016803444895975933, R2: -1.323815866701041\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  8.09093D+00    |proj g|=  1.40461D+02\n",
      "\n",
      "At iterate    5    f=  6.19677D-01    |proj g|=  6.46935D-02\n",
      "\n",
      "At iterate   10    f=  5.98047D-01    |proj g|=  3.34739D-02\n",
      "\n",
      "At iterate   15    f=  5.96332D-01    |proj g|=  1.22442D-02\n",
      "\n",
      "At iterate   20    f=  5.96176D-01    |proj g|=  2.41405D-05\n",
      "\n",
      "At iterate   25    f=  5.96160D-01    |proj g|=  2.91959D-03\n",
      "\n",
      "At iterate   30    f=  5.96157D-01    |proj g|=  4.27688D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     34     45      1     0     0   1.120D-04   5.962D-01\n",
      "  F =  0.59615724517301982     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.09148D+01    |proj g|=  2.16616D+02\n",
      "\n",
      "At iterate    5    f=  6.62581D-01    |proj g|=  1.31449D-01\n",
      "\n",
      "At iterate   10    f=  6.58947D-01    |proj g|=  1.21766D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     12     28      1     0     0   2.633D-05   6.589D-01\n",
      "  F =  0.65894717024111593     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  5.41882D+00    |proj g|=  6.44537D+01\n",
      "\n",
      "At iterate    5    f=  6.97438D-01    |proj g|=  1.71348D-01\n",
      "\n",
      "At iterate   10    f=  6.65748D-01    |proj g|=  1.67238D-02\n",
      "\n",
      "At iterate   15    f=  6.63492D-01    |proj g|=  1.22069D-02\n",
      "\n",
      "At iterate   20    f=  6.63306D-01    |proj g|=  4.94163D-03\n",
      "\n",
      "At iterate   25    f=  6.63291D-01    |proj g|=  6.58318D-05\n",
      "\n",
      "At iterate   30    f=  6.63289D-01    |proj g|=  2.74609D-04\n",
      "\n",
      "At iterate   35    f=  6.63289D-01    |proj g|=  7.16386D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     36     47      1     0     0   1.072D-05   6.633D-01\n",
      "  F =  0.66328867592739904     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  7.43855D+01    |proj g|=  2.82616D+03\n",
      "\n",
      "At iterate    5    f=  6.80342D-01    |proj g|=  2.14166D-01\n",
      "\n",
      "At iterate   10    f=  6.45860D-01    |proj g|=  2.49743D-02\n",
      "\n",
      "At iterate   15    f=  6.43318D-01    |proj g|=  6.83628D-03\n",
      "\n",
      "At iterate   20    f=  6.43117D-01    |proj g|=  3.12745D-03\n",
      "\n",
      "At iterate   25    f=  6.43088D-01    |proj g|=  8.24474D-04\n",
      "\n",
      "At iterate   30    f=  6.43086D-01    |proj g|=  3.84331D-04\n",
      "\n",
      "At iterate   35    f=  6.43085D-01    |proj g|=  9.66648D-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     38     53      1     0     0   9.292D-06   6.431D-01\n",
      "  F =  0.64308520395265589     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.04872D+00    |proj g|=  1.24820D+00\n",
      "\n",
      "At iterate    5    f=  6.17014D-01    |proj g|=  1.92701D-01\n",
      "\n",
      "At iterate   10    f=  5.67235D-01    |proj g|=  2.51930D-02\n",
      "\n",
      "At iterate   15    f=  5.63809D-01    |proj g|=  2.40504D-02\n",
      "\n",
      "At iterate   20    f=  5.63484D-01    |proj g|=  6.62569D-03\n",
      "\n",
      "At iterate   25    f=  5.63450D-01    |proj g|=  9.65665D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     27     32      1     0     0   4.617D-06   5.634D-01\n",
      "  F =  0.56344849281032272     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.14810D-01    |proj g|=  5.57297D-01\n",
      "\n",
      "At iterate    5    f=  6.62089D-01    |proj g|=  8.17695D-02\n",
      "\n",
      "At iterate   10    f=  6.49481D-01    |proj g|=  1.15146D-02\n",
      "\n",
      "At iterate   15    f=  6.48526D-01    |proj g|=  1.18346D-02\n",
      "\n",
      "At iterate   20    f=  6.48433D-01    |proj g|=  4.30521D-03\n",
      "\n",
      "At iterate   25    f=  6.48422D-01    |proj g|=  8.29019D-04\n",
      "\n",
      "At iterate   30    f=  6.48421D-01    |proj g|=  3.11432D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     31     35      1     0     0   6.103D-06   6.484D-01\n",
      "  F =  0.64842069819442749     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  8.49497D-01    |proj g|=  9.14544D-01\n",
      "\n",
      "At iterate    5    f=  6.16158D-01    |proj g|=  5.52330D-02\n",
      "\n",
      "At iterate   10    f=  5.99942D-01    |proj g|=  7.38623D-02\n",
      "\n",
      "At iterate   15    f=  5.97797D-01    |proj g|=  1.44803D-02\n",
      "\n",
      "At iterate   20    f=  5.97482D-01    |proj g|=  2.30936D-03\n",
      "\n",
      "At iterate   25    f=  5.97456D-01    |proj g|=  6.44351D-04\n",
      "\n",
      "At iterate   30    f=  5.97454D-01    |proj g|=  2.52918D-04\n",
      "\n",
      "At iterate   35    f=  5.97453D-01    |proj g|=  6.77474D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     37     46      1     0     0   7.508D-06   5.975D-01\n",
      "  F =  0.59745342435188853     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.05061D+00    |proj g|=  7.99695D-01\n",
      "\n",
      "At iterate    5    f=  6.09367D-01    |proj g|=  1.89753D-02\n",
      "\n",
      "At iterate   10    f=  6.01896D-01    |proj g|=  1.11003D-02\n",
      "\n",
      "At iterate   15    f=  6.01283D-01    |proj g|=  8.94274D-03\n",
      "\n",
      "At iterate   20    f=  6.01224D-01    |proj g|=  1.60805D-03\n",
      "\n",
      "At iterate   25    f=  6.01215D-01    |proj g|=  4.78168D-04\n",
      "\n",
      "At iterate   30    f=  6.01214D-01    |proj g|=  4.95787D-04\n",
      "\n",
      "At iterate   35    f=  6.01214D-01    |proj g|=  4.87955D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     37     43      1     0     0   3.418D-05   6.012D-01\n",
      "  F =  0.60121421192908953     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  8.24655D-01    |proj g|=  9.11747D-01\n",
      "\n",
      "At iterate    5    f=  6.02934D-01    |proj g|=  6.23339D-02\n",
      "\n",
      "At iterate   10    f=  5.80114D-01    |proj g|=  4.61019D-02\n",
      "\n",
      "At iterate   15    f=  5.74917D-01    |proj g|=  1.51375D-02\n",
      "\n",
      "At iterate   20    f=  5.74474D-01    |proj g|=  5.07819D-03\n",
      "\n",
      "At iterate   25    f=  5.74439D-01    |proj g|=  1.03087D-03\n",
      "\n",
      "At iterate   30    f=  5.74434D-01    |proj g|=  2.63988D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     34     41      1     0     0   1.781D-05   5.744D-01\n",
      "  F =  0.57443372116254454     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  8.32754D-01    |proj g|=  9.82294D-01\n",
      "\n",
      "At iterate    5    f=  5.66546D-01    |proj g|=  3.15125D-02\n",
      "\n",
      "At iterate   10    f=  5.65774D-01    |proj g|=  6.61622D-04\n",
      "\n",
      "At iterate   15    f=  5.65694D-01    |proj g|=  7.58731D-04\n",
      "\n",
      "At iterate   20    f=  5.65682D-01    |proj g|=  4.68081D-04\n",
      "\n",
      "At iterate   25    f=  5.65681D-01    |proj g|=  1.18471D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     25     39      1     0     0   1.185D-04   5.657D-01\n",
      "  F =  0.56568097539508699     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.04399D+00    |proj g|=  8.47109D-01\n",
      "\n",
      "At iterate    5    f=  5.47984D-01    |proj g|=  1.10182D-01\n",
      "\n",
      "At iterate   10    f=  5.34031D-01    |proj g|=  1.09383D-02\n",
      "\n",
      "At iterate   15    f=  5.32999D-01    |proj g|=  2.22136D-02\n",
      "\n",
      "At iterate   20    f=  5.32915D-01    |proj g|=  4.71563D-04\n",
      "\n",
      "At iterate   25    f=  5.32902D-01    |proj g|=  3.99085D-04\n",
      "\n",
      "At iterate   30    f=  5.32901D-01    |proj g|=  2.14816D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     30     37      1     0     0   2.148D-05   5.329D-01\n",
      "  F =  0.53290148462399312     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  8.98164D-01    |proj g|=  5.62879D-01\n",
      "\n",
      "At iterate    5    f=  5.92914D-01    |proj g|=  2.17668D-01\n",
      "\n",
      "At iterate   10    f=  5.74283D-01    |proj g|=  1.05995D-02\n",
      "\n",
      "At iterate   15    f=  5.73096D-01    |proj g|=  3.67514D-03\n",
      "\n",
      "At iterate   20    f=  5.72992D-01    |proj g|=  3.08784D-03\n",
      "\n",
      "At iterate   25    f=  5.72977D-01    |proj g|=  6.00931D-04\n",
      "\n",
      "At iterate   30    f=  5.72976D-01    |proj g|=  2.67464D-04\n",
      "\n",
      "At iterate   35    f=  5.72976D-01    |proj g|=  6.81950D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     39     47      1     0     0   8.644D-06   5.730D-01\n",
      "  F =  0.57297553714498628     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  8.04333D-01    |proj g|=  8.88048D-01\n",
      "\n",
      "At iterate    5    f=  5.57495D-01    |proj g|=  2.21985D-02\n",
      "\n",
      "At iterate   10    f=  5.46384D-01    |proj g|=  1.33810D-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate   15    f=  5.45606D-01    |proj g|=  4.18242D-03\n",
      "\n",
      "At iterate   20    f=  5.45498D-01    |proj g|=  1.13089D-03\n",
      "\n",
      "At iterate   25    f=  5.45490D-01    |proj g|=  2.37046D-04\n",
      "\n",
      "At iterate   30    f=  5.45488D-01    |proj g|=  1.26609D-04\n",
      "\n",
      "At iterate   35    f=  5.45488D-01    |proj g|=  7.04591D-06\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     35     45      1     0     0   7.046D-06   5.455D-01\n",
      "  F =  0.54548839596852250     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  8.39082D-01    |proj g|=  7.97359D-01\n",
      "\n",
      "At iterate    5    f=  6.02735D-01    |proj g|=  6.62733D-02\n",
      "\n",
      "At iterate   10    f=  5.91039D-01    |proj g|=  2.46699D-03\n",
      "\n",
      "At iterate   15    f=  5.90569D-01    |proj g|=  7.39297D-04\n",
      "\n",
      "At iterate   20    f=  5.90513D-01    |proj g|=  1.99413D-03\n",
      "\n",
      "At iterate   25    f=  5.90506D-01    |proj g|=  8.01719D-04\n",
      "\n",
      "At iterate   30    f=  5.90505D-01    |proj g|=  5.98044D-04\n",
      "\n",
      "At iterate   35    f=  5.90505D-01    |proj g|=  9.46199D-05\n",
      "\n",
      "At iterate   40    f=  5.90505D-01    |proj g|=  1.04432D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     40     46      1     0     0   1.044D-04   5.905D-01\n",
      "  F =  0.59050469043017861     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.08253D+00    |proj g|=  8.75022D-01\n",
      "\n",
      "At iterate    5    f=  5.68101D-01    |proj g|=  4.54235D-02\n",
      "\n",
      "At iterate   10    f=  5.58541D-01    |proj g|=  6.88445D-03\n",
      "\n",
      "At iterate   15    f=  5.57825D-01    |proj g|=  1.20085D-02\n",
      "\n",
      "At iterate   20    f=  5.57744D-01    |proj g|=  1.46168D-03\n",
      "\n",
      "At iterate   25    f=  5.57737D-01    |proj g|=  5.71389D-04\n",
      "\n",
      "At iterate   30    f=  5.57736D-01    |proj g|=  1.41765D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     34     39      1     0     0   9.246D-06   5.577D-01\n",
      "  F =  0.55773634321813947     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  8.17413D-01    |proj g|=  9.39127D-01\n",
      "\n",
      "At iterate    5    f=  5.80484D-01    |proj g|=  1.96507D-03\n",
      "\n",
      "At iterate   10    f=  5.80474D-01    |proj g|=  1.27726D-02\n",
      "\n",
      "At iterate   15    f=  5.80312D-01    |proj g|=  1.75016D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     17     23      1     0     0   1.640D-06   5.803D-01\n",
      "  F =  0.58031192191249936     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  8.18300D-01    |proj g|=  8.38481D-01\n",
      "\n",
      "At iterate    5    f=  5.71750D-01    |proj g|=  3.77937D-02\n",
      "\n",
      "At iterate   10    f=  5.58942D-01    |proj g|=  6.24150D-03\n",
      "\n",
      "At iterate   15    f=  5.58421D-01    |proj g|=  3.52955D-03\n",
      "\n",
      "At iterate   20    f=  5.58353D-01    |proj g|=  1.80786D-03\n",
      "\n",
      "At iterate   25    f=  5.58347D-01    |proj g|=  5.78154D-04\n",
      "\n",
      "At iterate   30    f=  5.58346D-01    |proj g|=  2.31903D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     32     39      1     0     0   7.163D-07   5.583D-01\n",
      "  F =  0.55834546305897881     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  8.01789D-01    |proj g|=  9.01999D-01\n",
      "\n",
      "At iterate    5    f=  5.85903D-01    |proj g|=  1.15495D-01\n",
      "\n",
      "At iterate   10    f=  5.69849D-01    |proj g|=  3.98467D-03\n",
      "\n",
      "At iterate   15    f=  5.69723D-01    |proj g|=  3.11401D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     15     35      1     0     0   3.114D-05   5.697D-01\n",
      "  F =  0.56972262911951932     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.07525D+00    |proj g|=  9.06833D-01\n",
      "\n",
      "At iterate    5    f=  5.50379D-01    |proj g|=  5.33287D-02\n",
      "\n",
      "At iterate   10    f=  5.45539D-01    |proj g|=  7.65474D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     14     18      1     0     0   5.379D-06   5.455D-01\n",
      "  F =  0.54553003378904530     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  7.97070D-01    |proj g|=  8.60850D-01\n",
      "\n",
      "At iterate    5    f=  5.63341D-01    |proj g|=  3.00413D-02\n",
      "\n",
      "At iterate   10    f=  5.58648D-01    |proj g|=  6.80365D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     12     31      1     0     0   5.409D-05   5.586D-01\n",
      "  F =  0.55864803135012919     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  8.05463D-01    |proj g|=  8.29592D-01\n",
      "\n",
      "At iterate    5    f=  5.52519D-01    |proj g|=  7.99788D-02\n",
      "\n",
      "At iterate   10    f=  5.43650D-01    |proj g|=  2.50746D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     13     19      1     0     0   5.456D-05   5.436D-01\n",
      "  F =  0.54364742147293299     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  7.79151D-01    |proj g|=  9.21641D-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate    5    f=  5.48523D-01    |proj g|=  9.05604D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      9     15      1     0     0   2.282D-07   5.482D-01\n",
      "  F =  0.54824630279008946     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  7.89251D-01    |proj g|=  8.76915D-01\n",
      "\n",
      "At iterate    5    f=  5.46559D-01    |proj g|=  6.93531D-02\n",
      "\n",
      "At iterate   10    f=  5.38965D-01    |proj g|=  2.59794D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     13     28      1     0     0   2.803D-05   5.390D-01\n",
      "  F =  0.53896369140045985     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  7.71759D-01    |proj g|=  9.45263D-01\n",
      "\n",
      "At iterate    5    f=  5.36954D-01    |proj g|=  4.88431D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      9     16      1     0     0   1.399D-07   5.368D-01\n",
      "  F =  0.53680825319327696     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  7.79289D-01    |proj g|=  8.97653D-01\n",
      "\n",
      "At iterate    5    f=  5.37670D-01    |proj g|=  1.03649D-01\n",
      "\n",
      "At iterate   10    f=  5.30259D-01    |proj g|=  3.69364D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     13     18      1     0     0   7.524D-06   5.303D-01\n",
      "  F =  0.53025781171785902     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "Metrics for Diving (CV) - MSE: 0.17231950532945953, R2: -22.83075631845998\n",
      "Checking stationarity for Equestrianism (CV):\n",
      "ADF Statistic: -1.908169220571186, p-value: 0.32822786473799387\n",
      "Skipping ARIMA fitting for non-stationary series: Equestrianism (CV)\n",
      "Checking stationarity for Fencing (CV):\n",
      "ADF Statistic: -5.0530779765080265, p-value: 1.740691598905394e-05\n",
      "Optimal ARIMA order: (0, 0, 0)\n",
      "Optimal SARIMA order: (0, 0, 0), Seasonal: (0, 0, 0, 0)\n",
      "Constant series detected for Fencing (CV). Predicting constant value: 0.6666666666666666\n",
      "Metrics for Fencing (CV) - MSE: 0.00887886106634869, R2: -0.21108159024694118\n",
      "Constant series detected for Fencing (CV). Predicting constant value: 0.6666666666666666\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.10796D+00    |proj g|=  1.86252D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     13      1     0     0   1.861D-05   1.108D+00\n",
      "  F =   1.1079622837206005     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.07547D+00    |proj g|=  1.98757D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     10      1     0     0   1.986D-05   1.075D+00\n",
      "  F =   1.0754705475688893     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.08760D+00    |proj g|=  1.93993D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     12      1     0     0   1.940D-05   1.088D+00\n",
      "  F =   1.0876016751267492     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.13787D+00    |proj g|=  1.75437D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     11      1     0     0   1.753D-05   1.138D+00\n",
      "  F =   1.1378721340160207     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.14022D+00    |proj g|=  1.74617D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     10      1     0     0   1.746D-05   1.140D+00\n",
      "  F =   1.1402156635369933     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.10910D+00    |proj g|=  1.85829D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     16      1     0     0   1.856D-05   1.109D+00\n",
      "  F =   1.1090992762770642     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.09659D+00    |proj g|=  1.90535D-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     13      1     0     0   1.903D-05   1.097D+00\n",
      "  F =   1.0965931691438318     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.09689D+00    |proj g|=  1.90422D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     13      1     0     0   1.902D-05   1.097D+00\n",
      "  F =   1.0968918281003850     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.11057D+00    |proj g|=  1.85281D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     11      1     0     0   1.850D-05   1.111D+00\n",
      "  F =   1.1105736188999809     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.12590D+00    |proj g|=  1.79686D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     13      1     0     0   1.795D-05   1.126D+00\n",
      "  F =   1.1259047064248031     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.12769D+00    |proj g|=  1.79047D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     11      1     0     0   1.788D-05   1.128D+00\n",
      "  F =   1.1276888939051766     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.12801D+00    |proj g|=  1.78932D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     10      1     0     0   1.789D-05   1.128D+00\n",
      "  F =   1.1280103187962505     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.13320D+00    |proj g|=  1.77085D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     12      1     0     0   1.769D-05   1.133D+00\n",
      "  F =   1.1331962384113392     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.15489D+00    |proj g|=  1.69567D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1      9      1     0     0   1.694D-05   1.155D+00\n",
      "  F =   1.1548872307896454     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.15659D+00    |proj g|=  1.68990D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1      9      1     0     0   1.688D-05   1.157D+00\n",
      "  F =   1.1565937063140201     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.16174D+00    |proj g|=  1.67261D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1      9      1     0     0   1.671D-05   1.162D+00\n",
      "  F =   1.1617366550850921     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.15992D+00    |proj g|=  1.67870D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1      9      1     0     0   1.677D-05   1.160D+00\n",
      "  F =   1.1599182726569539     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.16668D+00    |proj g|=  1.65616D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     11      1     0     0   1.654D-05   1.167D+00\n",
      "  F =   1.1666756656615467     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.16263D+00    |proj g|=  1.66962D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1      9      1     0     0   1.668D-05   1.163D+00\n",
      "  F =   1.1626285827167915     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.16651D+00    |proj g|=  1.65673D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     12      1     0     0   1.656D-05   1.167D+00\n",
      "  F =   1.1665066015487955     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.17520D+00    |proj g|=  1.62816D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     12      1     0     0   1.627D-05   1.175D+00\n",
      "  F =   1.1752040757915989     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.17425D+00    |proj g|=  1.63126D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     21      1     0     0   1.631D-05   1.174D+00\n",
      "  F =   1.1742535232026703     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.17511D+00    |proj g|=  1.62845D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     12      1     0     0   1.626D-05   1.175D+00\n",
      "  F =   1.1751139368015837     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.17579D+00    |proj g|=  1.62625D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     12      1     0     0   1.624D-05   1.176D+00\n",
      "  F =   1.1757904827192658     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.16863D+00    |proj g|=  1.64971D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     13      1     0     0   1.648D-05   1.169D+00\n",
      "  F =   1.1686289469994138     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.17389D+00    |proj g|=  1.63244D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1      9      1     0     0   1.631D-05   1.174D+00\n",
      "  F =   1.1738903540759651     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.17377D+00    |proj g|=  1.63283D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     11      1     0     0   1.631D-05   1.174D+00\n",
      "  F =   1.1737692318745230     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "Metrics for Fencing (CV) - MSE: 0.5959829663322835, R2: -80.29240825283179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking stationarity for Figure Skating (CV):\n",
      "ADF Statistic: -0.8339218555630238, p-value: 0.8089541805517151\n",
      "Skipping ARIMA fitting for non-stationary series: Figure Skating (CV)\n",
      "Checking stationarity for Football (CV):\n",
      "ADF Statistic: 1.2718636341884608, p-value: 0.996446656937501\n",
      "Skipping ARIMA fitting for non-stationary series: Football (CV)\n",
      "Insufficient data for Freestyle Skiing (CV)\n",
      "Insufficient data for Golf (CV)\n",
      "Checking stationarity for Gymnastics (CV):\n",
      "ADF Statistic: -2.468496483519824, p-value: 0.12332881421042458\n",
      "Skipping ARIMA fitting for non-stationary series: Gymnastics (CV)\n",
      "Checking stationarity for Handball (CV):\n",
      "ADF Statistic: -2.838515380332971, p-value: 0.05297924330837049\n",
      "Skipping ARIMA fitting for non-stationary series: Handball (CV)\n",
      "Checking stationarity for Hockey (CV):\n",
      "ADF Statistic: -3.7089818576007545, p-value: 0.0039885754675961635\n",
      "Optimal ARIMA order: (0, 0, 0)\n",
      "Optimal SARIMA order: (0, 0, 0), Seasonal: (0, 0, 0, 0)\n",
      "Constant series detected for Hockey (CV). Predicting constant value: 0.6830499730847663\n",
      "Metrics for Hockey (CV) - MSE: 0.009361372877656305, R2: -0.2251162162167748\n",
      "Constant series detected for Hockey (CV). Predicting constant value: 0.6830499730847663\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.40068D-01    |proj g|=  2.60574D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     15      1     0     0   2.605D-05   9.401D-01\n",
      "  F =  0.94006756209525411     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.00183D+00    |proj g|=  2.30294D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     15      1     0     0   2.301D-05   1.002D+00\n",
      "  F =   1.0018334641330027     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.88253D-01    |proj g|=  2.36634D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     12      1     0     0   2.365D-05   9.883D-01\n",
      "  F =  0.98825335620099009     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.02737D+00    |proj g|=  2.18827D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     13      1     0     0   2.187D-05   1.027D+00\n",
      "  F =   1.0273706844086494     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.02749D+00    |proj g|=  2.18776D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     12      1     0     0   2.188D-05   1.027D+00\n",
      "  F =   1.0274871065653739     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.04797D+00    |proj g|=  2.09995D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     14      1     0     0   2.099D-05   1.048D+00\n",
      "  F =   1.0479678902576544     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.07987D+00    |proj g|=  1.97017D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     12      1     0     0   1.966D-05   1.080D+00\n",
      "  F =   1.0798656678640322     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.09578D+00    |proj g|=  1.90846D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     10      1     0     0   1.907D-05   1.096D+00\n",
      "  F =   1.0957793930472768     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.10684D+00    |proj g|=  1.86671D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     12      1     0     0   1.867D-05   1.107D+00\n",
      "  F =   1.1068399182301634     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.12164D+00    |proj g|=  1.81225D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     11      1     0     0   1.812D-05   1.122D+00\n",
      "  F =   1.1216428800069924     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.15437D+00    |proj g|=  1.69744D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     13      1     0     0   1.697D-05   1.154D+00\n",
      "  F =   1.1543688471298204     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.14981D+00    |proj g|=  1.71300D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1      9      1     0     0   1.710D-05   1.150D+00\n",
      "  F =   1.1498055143675423     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.14461D+00    |proj g|=  1.73090D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     12      1     0     0   1.731D-05   1.145D+00\n",
      "  F =   1.1446088453881795     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.14865D+00    |proj g|=  1.71696D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     10      1     0     0   1.716D-05   1.149D+00\n",
      "  F =   1.1486486456429104     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.14496D+00    |proj g|=  1.72968D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     12      1     0     0   1.728D-05   1.145D+00\n",
      "  F =   1.1449581351474185     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.14679D+00    |proj g|=  1.72337D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     12      1     0     0   1.721D-05   1.147D+00\n",
      "  F =   1.1467868050670322     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.14669D+00    |proj g|=  1.72369D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     14      1     0     0   1.722D-05   1.147D+00\n",
      "  F =   1.1466936281682436     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.14442D+00    |proj g|=  1.73154D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     12      1     0     0   1.729D-05   1.144D+00\n",
      "  F =   1.1444224508311560     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.14887D+00    |proj g|=  1.71619D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     11      1     0     0   1.716D-05   1.149D+00\n",
      "  F =   1.1488739495732878     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.14651D+00    |proj g|=  1.72432D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     11      1     0     0   1.722D-05   1.147D+00\n",
      "  F =   1.1465098963069402     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.15035D+00    |proj g|=  1.71114D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     12      1     0     0   1.711D-05   1.150D+00\n",
      "  F =   1.1503478192194283     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "Metrics for Hockey (CV) - MSE: 0.5771283523491987, R2: -74.52837735895073\n",
      "Checking stationarity for Ice Hockey (CV):\n",
      "ADF Statistic: -3.1334914071340445, p-value: 0.024171924545197152\n",
      "Optimal ARIMA order: (2, 0, 1)\n",
      "Optimal SARIMA order: (0, 0, 1), Seasonal: (0, 0, 0, 0)\n",
      "Metrics for Ice Hockey (CV) - MSE: 0.017219124016770934, R2: -1.0841399384138786\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.97174D+02    |proj g|=  2.09934D+04\n",
      "\n",
      "At iterate    5    f=  8.00142D-01    |proj g|=  1.97369D-01\n",
      "\n",
      "At iterate   10    f=  7.93065D-01    |proj g|=  1.32297D-01\n",
      "\n",
      "At iterate   15    f=  7.87589D-01    |proj g|=  8.96215D-03\n",
      "\n",
      "At iterate   20    f=  7.87129D-01    |proj g|=  5.81814D-03\n",
      "\n",
      "At iterate   25    f=  7.87085D-01    |proj g|=  2.87169D-03\n",
      "\n",
      "At iterate   30    f=  7.87080D-01    |proj g|=  5.55539D-04\n",
      "\n",
      "At iterate   35    f=  7.87079D-01    |proj g|=  1.47146D-04\n",
      "\n",
      "At iterate   40    f=  7.87079D-01    |proj g|=  6.48073D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     43     58      1     0     0   2.090D-05   7.871D-01\n",
      "  F =  0.78707922861883217     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  3.84435D+02    |proj g|=  3.06462D+04\n",
      "\n",
      "At iterate    5    f=  8.01290D-01    |proj g|=  7.95181D-02\n",
      "\n",
      "At iterate   10    f=  7.78482D-01    |proj g|=  2.12357D-02\n",
      "\n",
      "At iterate   15    f=  7.76990D-01    |proj g|=  4.83936D-03\n",
      "\n",
      "At iterate   20    f=  7.76762D-01    |proj g|=  2.71388D-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate   25    f=  7.76741D-01    |proj g|=  2.69636D-03\n",
      "\n",
      "At iterate   30    f=  7.76738D-01    |proj g|=  4.82689D-04\n",
      "\n",
      "At iterate   35    f=  7.76738D-01    |proj g|=  8.96345D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     39     52      1     0     0   1.018D-04   7.767D-01\n",
      "  F =  0.77673768172938396     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  4.18681D+01    |proj g|=  1.06872D+03\n",
      "\n",
      "At iterate    5    f=  7.93002D-01    |proj g|=  3.24889D-01\n",
      "\n",
      "At iterate   10    f=  7.65458D-01    |proj g|=  1.56126D-02\n",
      "\n",
      "At iterate   15    f=  7.61592D-01    |proj g|=  8.46870D-03\n",
      "\n",
      "At iterate   20    f=  7.61260D-01    |proj g|=  5.99070D-03\n",
      "\n",
      "At iterate   25    f=  7.61227D-01    |proj g|=  9.19733D-04\n",
      "\n",
      "At iterate   30    f=  7.61224D-01    |proj g|=  1.36133D-03\n",
      "\n",
      "At iterate   35    f=  7.61224D-01    |proj g|=  9.37709D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     38     48      1     0     0   5.790D-05   7.612D-01\n",
      "  F =  0.76122363531593162     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.51756D+00    |proj g|=  3.49262D+00\n",
      "\n",
      "At iterate    5    f=  7.96749D-01    |proj g|=  1.07865D-01\n",
      "\n",
      "At iterate   10    f=  7.60313D-01    |proj g|=  2.41089D-02\n",
      "\n",
      "At iterate   15    f=  7.57962D-01    |proj g|=  4.49395D-03\n",
      "\n",
      "At iterate   20    f=  7.57637D-01    |proj g|=  2.46839D-03\n",
      "\n",
      "At iterate   25    f=  7.57609D-01    |proj g|=  6.40619D-04\n",
      "\n",
      "At iterate   30    f=  7.57606D-01    |proj g|=  2.80112D-04\n",
      "\n",
      "At iterate   35    f=  7.57606D-01    |proj g|=  7.38561D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     37     44      1     0     0   7.993D-06   7.576D-01\n",
      "  F =  0.75760588912691640     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.36323D+00    |proj g|=  2.26062D+00\n",
      "\n",
      "At iterate    5    f=  7.14795D-01    |proj g|=  6.46338D-02\n",
      "\n",
      "At iterate   10    f=  6.92641D-01    |proj g|=  1.62199D-02\n",
      "\n",
      "At iterate   15    f=  6.91239D-01    |proj g|=  2.07209D-03\n",
      "\n",
      "At iterate   20    f=  6.91059D-01    |proj g|=  1.75327D-03\n",
      "\n",
      "At iterate   25    f=  6.91044D-01    |proj g|=  2.70876D-06\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     25     32      1     0     0   2.709D-06   6.910D-01\n",
      "  F =  0.69104421932159044     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.20874D+00    |proj g|=  8.32042D-01\n",
      "\n",
      "At iterate    5    f=  7.42118D-01    |proj g|=  2.06744D-02\n",
      "\n",
      "At iterate   10    f=  7.32815D-01    |proj g|=  1.12981D-02\n",
      "\n",
      "At iterate   15    f=  7.32087D-01    |proj g|=  1.85189D-02\n",
      "\n",
      "At iterate   20    f=  7.32016D-01    |proj g|=  1.47276D-03\n",
      "\n",
      "At iterate   25    f=  7.32010D-01    |proj g|=  3.27715D-04\n",
      "\n",
      "At iterate   30    f=  7.32010D-01    |proj g|=  1.27833D-04\n",
      "\n",
      "At iterate   35    f=  7.32010D-01    |proj g|=  3.45363D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     37     42      1     0     0   3.480D-06   7.320D-01\n",
      "  F =  0.73200952294952581     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.64460D-01    |proj g|=  8.86188D-01\n",
      "\n",
      "At iterate    5    f=  6.83611D-01    |proj g|=  8.86365D-03\n",
      "\n",
      "At iterate   10    f=  6.82072D-01    |proj g|=  4.56754D-02\n",
      "\n",
      "At iterate   15    f=  6.81450D-01    |proj g|=  7.65232D-03\n",
      "\n",
      "At iterate   20    f=  6.81383D-01    |proj g|=  4.89667D-04\n",
      "\n",
      "At iterate   25    f=  6.81374D-01    |proj g|=  1.42170D-04\n",
      "\n",
      "At iterate   30    f=  6.81373D-01    |proj g|=  1.33328D-04\n",
      "\n",
      "At iterate   35    f=  6.81373D-01    |proj g|=  2.12093D-06\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     35     45      1     0     0   2.121D-06   6.814D-01\n",
      "  F =  0.68137284941239296     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.15873D+00    |proj g|=  9.80863D-01\n",
      "\n",
      "At iterate    5    f=  6.55485D-01    |proj g|=  3.49429D-02\n",
      "\n",
      "At iterate   10    f=  6.51336D-01    |proj g|=  7.62149D-03\n",
      "\n",
      "At iterate   15    f=  6.50808D-01    |proj g|=  1.21980D-03\n",
      "\n",
      "At iterate   20    f=  6.50766D-01    |proj g|=  2.82922D-03\n",
      "\n",
      "At iterate   25    f=  6.50760D-01    |proj g|=  3.39784D-04\n",
      "\n",
      "At iterate   30    f=  6.50760D-01    |proj g|=  4.64438D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     32     33      1     0     0   6.909D-06   6.508D-01\n",
      "  F =  0.65075951104765339     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.64640D-01    |proj g|=  5.23231D-01\n",
      "\n",
      "At iterate    5    f=  6.59263D-01    |proj g|=  2.34673D-01\n",
      "\n",
      "At iterate   10    f=  6.36327D-01    |proj g|=  1.43114D-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate   15    f=  6.34814D-01    |proj g|=  1.07372D-02\n",
      "\n",
      "At iterate   20    f=  6.34692D-01    |proj g|=  1.64789D-03\n",
      "\n",
      "At iterate   25    f=  6.34674D-01    |proj g|=  4.24685D-04\n",
      "\n",
      "At iterate   30    f=  6.34673D-01    |proj g|=  1.73085D-04\n",
      "\n",
      "At iterate   35    f=  6.34673D-01    |proj g|=  4.65138D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     39     47      1     0     0   8.485D-06   6.347D-01\n",
      "  F =  0.63467259446976554     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.43178D+00    |proj g|=  3.41773D+00\n",
      "\n",
      "At iterate    5    f=  7.38193D-01    |proj g|=  1.30147D-01\n",
      "\n",
      "At iterate   10    f=  6.86053D-01    |proj g|=  5.23839D-02\n",
      "\n",
      "At iterate   15    f=  6.81924D-01    |proj g|=  5.63384D-03\n",
      "\n",
      "At iterate   20    f=  6.81399D-01    |proj g|=  2.60348D-03\n",
      "\n",
      "At iterate   25    f=  6.81358D-01    |proj g|=  2.07616D-05\n",
      "\n",
      "At iterate   30    f=  6.81352D-01    |proj g|=  2.73388D-04\n",
      "\n",
      "At iterate   35    f=  6.81351D-01    |proj g|=  7.33549D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     36     46      1     0     0   6.525D-05   6.814D-01\n",
      "  F =  0.68135128293410174     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.18746D+00    |proj g|=  8.87138D-01\n",
      "\n",
      "At iterate    5    f=  6.75191D-01    |proj g|=  7.31814D-02\n",
      "\n",
      "At iterate   10    f=  6.51968D-01    |proj g|=  3.77519D-02\n",
      "\n",
      "At iterate   15    f=  6.49947D-01    |proj g|=  6.96956D-03\n",
      "\n",
      "At iterate   20    f=  6.49696D-01    |proj g|=  1.57134D-03\n",
      "\n",
      "At iterate   25    f=  6.49677D-01    |proj g|=  7.45175D-05\n",
      "\n",
      "At iterate   30    f=  6.49674D-01    |proj g|=  1.61076D-04\n",
      "\n",
      "At iterate   35    f=  6.49674D-01    |proj g|=  4.33805D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     36     43      1     0     0   4.947D-06   6.497D-01\n",
      "  F =  0.64967371145853026     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.18688D+00    |proj g|=  9.06693D-01\n",
      "\n",
      "At iterate    5    f=  6.82367D-01    |proj g|=  1.12439D-01\n",
      "\n",
      "At iterate   10    f=  6.64187D-01    |proj g|=  1.36516D-02\n",
      "\n",
      "At iterate   15    f=  6.62969D-01    |proj g|=  6.51211D-03\n",
      "\n",
      "At iterate   20    f=  6.62859D-01    |proj g|=  1.10039D-03\n",
      "\n",
      "At iterate   25    f=  6.62849D-01    |proj g|=  5.22730D-04\n",
      "\n",
      "At iterate   30    f=  6.62847D-01    |proj g|=  1.34144D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     34     40      1     0     0   9.476D-06   6.628D-01\n",
      "  F =  0.66284721748676234     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.01060D-01    |proj g|=  8.78579D-01\n",
      "\n",
      "At iterate    5    f=  6.46026D-01    |proj g|=  1.68721D-02\n",
      "\n",
      "At iterate   10    f=  6.38203D-01    |proj g|=  3.36972D-02\n",
      "\n",
      "At iterate   15    f=  6.36294D-01    |proj g|=  1.14272D-02\n",
      "\n",
      "At iterate   20    f=  6.36129D-01    |proj g|=  1.71643D-04\n",
      "\n",
      "At iterate   25    f=  6.36110D-01    |proj g|=  4.55059D-04\n",
      "\n",
      "At iterate   30    f=  6.36108D-01    |proj g|=  1.62691D-04\n",
      "\n",
      "At iterate   35    f=  6.36108D-01    |proj g|=  4.28648D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     38     49      1     0     0   3.939D-06   6.361D-01\n",
      "  F =  0.63610812926945914     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.11167D-01    |proj g|=  7.67419D-01\n",
      "\n",
      "At iterate    5    f=  6.68714D-01    |proj g|=  3.38805D-02\n",
      "\n",
      "At iterate   10    f=  6.54724D-01    |proj g|=  1.17532D-02\n",
      "\n",
      "At iterate   15    f=  6.53788D-01    |proj g|=  6.77508D-03\n",
      "\n",
      "At iterate   20    f=  6.53674D-01    |proj g|=  1.44596D-03\n",
      "\n",
      "At iterate   25    f=  6.53664D-01    |proj g|=  2.37397D-04\n",
      "\n",
      "At iterate   30    f=  6.53663D-01    |proj g|=  1.47127D-04\n",
      "\n",
      "At iterate   35    f=  6.53663D-01    |proj g|=  4.87700D-06\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     35     43      1     0     0   4.877D-06   6.537D-01\n",
      "  F =  0.65366278634386765     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  8.94719D-01    |proj g|=  8.86923D-01\n",
      "\n",
      "At iterate    5    f=  6.34253D-01    |proj g|=  9.82029D-03\n",
      "\n",
      "At iterate   10    f=  6.32911D-01    |proj g|=  1.24710D-01\n",
      "\n",
      "At iterate   15    f=  6.28449D-01    |proj g|=  1.09376D-02\n",
      "\n",
      "At iterate   20    f=  6.28033D-01    |proj g|=  6.17647D-03\n",
      "\n",
      "At iterate   25    f=  6.27999D-01    |proj g|=  2.00563D-03\n",
      "\n",
      "At iterate   30    f=  6.27995D-01    |proj g|=  1.27836D-04\n",
      "\n",
      "At iterate   35    f=  6.27994D-01    |proj g|=  1.82694D-04\n",
      "\n",
      "At iterate   40    f=  6.27994D-01    |proj g|=  1.40981D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     41     49      1     0     0   1.399D-05   6.280D-01\n",
      "  F =  0.62799436949103637     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "Metrics for Ice Hockey (CV) - MSE: 0.202957471337635, R2: -23.648017166073984\n",
      "Insufficient data for Jeu De Paume (CV)\n",
      "Checking stationarity for Judo (CV):\n",
      "ADF Statistic: -3.5941799014483164, p-value: 0.005873275351397979\n",
      "Optimal ARIMA order: (2, 0, 1)\n",
      "Optimal SARIMA order: (1, 0, 0), Seasonal: (0, 0, 0, 0)\n",
      "Metrics for Judo (CV) - MSE: 0.19788237977374606, R2: -37.87309455938403\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  4.23442D+00    |proj g|=  1.63789D+01\n",
      "\n",
      "At iterate    5    f=  1.44749D+00    |proj g|=  2.64832D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      9     13      1     0     0   3.727D-07   1.447D+00\n",
      "  F =   1.4472219962877033     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.31069D+00    |proj g|=  2.12480D-01\n",
      "\n",
      "At iterate    5    f=  1.29433D+00    |proj g|=  5.25506D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      7     10      1     0     0   7.883D-07   1.294D+00\n",
      "  F =   1.2943319365150561     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.24547D+00    |proj g|=  1.78131D-01\n",
      "\n",
      "At iterate    5    f=  1.23242D+00    |proj g|=  2.67724D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      7     10      1     0     0   4.562D-06   1.232D+00\n",
      "  F =   1.2324159171407150     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.11439D+00    |proj g|=  1.31068D-01\n",
      "\n",
      "At iterate    5    f=  1.10921D+00    |proj g|=  1.29810D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      7     10      1     0     0   6.024D-08   1.109D+00\n",
      "  F =   1.1092136861083139     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.01909D+00    |proj g|=  1.03680D-01\n",
      "\n",
      "At iterate    5    f=  1.01620D+00    |proj g|=  5.06218D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      6      9      1     0     0   8.275D-06   1.016D+00\n",
      "  F =   1.0162017869431790     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.54877D-01    |proj g|=  9.73773D-02\n",
      "\n",
      "At iterate    5    f=  9.52151D-01    |proj g|=  1.06771D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      7     10      1     0     0   4.741D-07   9.522D-01\n",
      "  F =  0.95215023399915599     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  8.85935D-01    |proj g|=  8.54616D-02\n",
      "\n",
      "At iterate    5    f=  8.84007D-01    |proj g|=  3.24932D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      8     10      1     0     0   5.426D-07   8.839D-01\n",
      "  F =  0.88392266574824840     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  8.28567D-01    |proj g|=  8.06145D-02\n",
      "\n",
      "At iterate    5    f=  8.26743D-01    |proj g|=  1.38329D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      7     11      1     0     0   3.925D-08   8.267D-01\n",
      "  F =  0.82674276614400721     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  7.72331D-01    |proj g|=  7.11763D-02\n",
      "\n",
      "At iterate    5    f=  7.71013D-01    |proj g|=  2.39510D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      8     11      1     0     0   1.311D-07   7.710D-01\n",
      "  F =  0.77097830943691403     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  7.24613D-01    |proj g|=  6.78039D-02\n",
      "\n",
      "At iterate    5    f=  7.23378D-01    |proj g|=  1.05976D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      7     12      1     0     0   1.749D-06   7.234D-01\n",
      "  F =  0.72337108502817093     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  6.75912D-01    |proj g|=  5.35770D-02\n",
      "\n",
      "At iterate    5    f=  6.75225D-01    |proj g|=  3.59781D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      7     12      1     0     0   2.897D-07   6.752D-01\n",
      "  F =  0.67522423295585732     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "Metrics for Judo (CV) - MSE: 0.12857616717351902, R2: -8.171136872961581\n",
      "Insufficient data for Lacrosse (CV)\n",
      "Checking stationarity for Luge (CV):\n",
      "ADF Statistic: -1.426888747824354, p-value: 0.5693196072478203\n",
      "Skipping ARIMA fitting for non-stationary series: Luge (CV)\n",
      "Insufficient data for Military Ski Patrol (CV)\n",
      "Checking stationarity for Modern Pentathlon (CV):\n",
      "ADF Statistic: -4.7365450484703695, p-value: 7.181009591807637e-05\n",
      "Optimal ARIMA order: (0, 0, 0)\n",
      "Optimal SARIMA order: (0, 0, 0), Seasonal: (0, 0, 0, 0)\n",
      "Constant series detected for Modern Pentathlon (CV). Predicting constant value: 0.6457370702589753\n",
      "Metrics for Modern Pentathlon (CV) - MSE: 0.08603571690456108, R2: -0.10818031762956792\n",
      "Constant series detected for Modern Pentathlon (CV). Predicting constant value: 0.6457370702589753\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.39620D-01    |proj g|=  2.60807D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     17      1     0     0   2.607D-05   9.396D-01\n",
      "  F =  0.93962025600796006     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.07256D+00    |proj g|=  1.99919D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     12      1     0     0   1.997D-05   1.073D+00\n",
      "  F =   1.0725557310820670     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.04359D+00    |proj g|=  2.11841D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     12      1     0     0   2.118D-05   1.044D+00\n",
      "  F =   1.0435940991821138     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.08321D+00    |proj g|=  1.95703D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     13      1     0     0   1.957D-05   1.083D+00\n",
      "  F =   1.0832127587576303     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.05900D+00    |proj g|=  2.05412D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     10      1     0     0   2.052D-05   1.059D+00\n",
      "  F =   1.0590018999600357     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.03800D+00    |proj g|=  2.14224D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     11      1     0     0   2.140D-05   1.038D+00\n",
      "  F =   1.0379994606855381     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.05659D+00    |proj g|=  2.06406D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     11      1     0     0   2.064D-05   1.057D+00\n",
      "  F =   1.0565891017989650     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.08812D+00    |proj g|=  1.93792D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     10      1     0     0   1.937D-05   1.088D+00\n",
      "  F =   1.0881205461052044     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.10881D+00    |proj g|=  1.85937D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     12      1     0     0   1.858D-05   1.109D+00\n",
      "  F =   1.1088081535864682     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.09741D+00    |proj g|=  1.90223D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     11      1     0     0   1.901D-05   1.097D+00\n",
      "  F =   1.0974142089396117     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.31402D+00    |proj g|=  1.23344D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     12      1     0     0   1.231D-05   1.314D+00\n",
      "  F =   1.3140241796076573     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.30329D+00    |proj g|=  1.26020D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     10      1     0     0   1.258D-05   1.303D+00\n",
      "  F =   1.3032926342846793     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.29610D+00    |proj g|=  1.27846D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     11      1     0     0   1.278D-05   1.296D+00\n",
      "  F =   1.2961039431139074     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.28606D+00    |proj g|=  1.30438D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     10      1     0     0   1.301D-05   1.286D+00\n",
      "  F =   1.2860623580006307     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.27197D+00    |proj g|=  1.34168D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     13      1     0     0   1.340D-05   1.272D+00\n",
      "  F =   1.2719659622412229     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.26104D+00    |proj g|=  1.37133D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1      8      1     0     0   1.370D-05   1.261D+00\n",
      "  F =   1.2610391646060037     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.24485D+00    |proj g|=  1.41646D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1      8      1     0     0   1.414D-05   1.245D+00\n",
      "  F =   1.2448484398968438     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.23204D+00    |proj g|=  1.45322D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     11      1     0     0   1.453D-05   1.232D+00\n",
      "  F =   1.2320377918255290     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.22651D+00    |proj g|=  1.46938D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1      9      1     0     0   1.469D-05   1.227D+00\n",
      "  F =   1.2265093504727125     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.21902D+00    |proj g|=  1.49155D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     10      1     0     0   1.489D-05   1.219D+00\n",
      "  F =   1.2190205846575775     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.21227D+00    |proj g|=  1.51181D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     11      1     0     0   1.511D-05   1.212D+00\n",
      "  F =   1.2122737701556714     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.20177D+00    |proj g|=  1.54391D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     10      1     0     0   1.542D-05   1.202D+00\n",
      "  F =   1.2017687585216985     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "Metrics for Modern Pentathlon (CV) - MSE: 0.6352428963802658, R2: -7.182225940692891\n",
      "Insufficient data for Motorboating (CV)\n",
      "Checking stationarity for Nordic Combined (CV):\n",
      "ADF Statistic: -11.795557022530083, p-value: 9.598123291705723e-22\n",
      "Optimal ARIMA order: (0, 0, 0)\n",
      "Optimal SARIMA order: (0, 0, 0), Seasonal: (0, 0, 0, 0)\n",
      "Constant series detected for Nordic Combined (CV). Predicting constant value: 0.5508946018462734\n",
      "Metrics for Nordic Combined (CV) - MSE: 0.01894535294713205, R2: -0.35334520009022397\n",
      "Constant series detected for Nordic Combined (CV). Predicting constant value: 0.5508946018462734\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  8.76564D-01    |proj g|=  2.95861D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     13      1     0     0   2.957D-05   8.766D-01\n",
      "  F =  0.87656438961896210     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.05591D+00    |proj g|=  2.06687D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     10      1     0     0   2.065D-05   1.056D+00\n",
      "  F =   1.0559102715917004     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.09565D+00    |proj g|=  1.90894D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     10      1     0     0   1.908D-05   1.096D+00\n",
      "  F =   1.0956536643917090     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.07581D+00    |proj g|=  1.98622D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     13      1     0     0   1.984D-05   1.076D+00\n",
      "  F =   1.0758100045282677     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.09932D+00    |proj g|=  1.89499D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     12      1     0     0   1.893D-05   1.099D+00\n",
      "  F =   1.0993207068180704     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.13255D+00    |proj g|=  1.77314D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     11      1     0     0   1.773D-05   1.133D+00\n",
      "  F =   1.1325515613476735     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.12371D+00    |proj g|=  1.80479D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     10      1     0     0   1.804D-05   1.124D+00\n",
      "  F =   1.1237064801618295     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.13048D+00    |proj g|=  1.78050D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     10      1     0     0   1.780D-05   1.130D+00\n",
      "  F =   1.1304786644517553     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.11125D+00    |proj g|=  1.85030D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     12      1     0     0   1.850D-05   1.111D+00\n",
      "  F =   1.1112548074742228     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.11470D+00    |proj g|=  1.83759D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     14      1     0     0   1.835D-05   1.115D+00\n",
      "  F =   1.1146993595044767     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.08915D+00    |proj g|=  1.93394D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     12      1     0     0   1.934D-05   1.089D+00\n",
      "  F =   1.0891483580551014     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.07576D+00    |proj g|=  1.98644D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     10      1     0     0   1.985D-05   1.076D+00\n",
      "  F =   1.0757563753566619     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.06440D+00    |proj g|=  2.03208D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     11      1     0     0   2.032D-05   1.064D+00\n",
      "  F =   1.0643962046989226     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.06975D+00    |proj g|=  2.01046D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     12      1     0     0   2.010D-05   1.070D+00\n",
      "  F =   1.0697453694789234     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "Metrics for Nordic Combined (CV) - MSE: 0.4794611307671681, R2: -33.24989873581665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking stationarity for Polo (CV):\n",
      "ADF Statistic: -2.1281166595313556, p-value: 0.23336005290449374\n",
      "Skipping ARIMA fitting for non-stationary series: Polo (CV)\n",
      "Insufficient data for Racquets (CV)\n",
      "Checking stationarity for Rhythmic Gymnastics (CV):\n",
      "ADF Statistic: -2.13825009365773, p-value: 0.22941468779215723\n",
      "Skipping ARIMA fitting for non-stationary series: Rhythmic Gymnastics (CV)\n",
      "Insufficient data for Roque (CV)\n",
      "Checking stationarity for Rowing (CV):\n",
      "ADF Statistic: -2.821954917130607, p-value: 0.0552054544997533\n",
      "Skipping ARIMA fitting for non-stationary series: Rowing (CV)\n",
      "Insufficient data for Rugby (CV)\n",
      "Insufficient data for Rugby Sevens (CV)\n",
      "Checking stationarity for Sailing (CV):\n",
      "ADF Statistic: -2.3996629950755093, p-value: 0.14183154842955692\n",
      "Skipping ARIMA fitting for non-stationary series: Sailing (CV)\n",
      "Checking stationarity for Shooting (CV):\n",
      "ADF Statistic: -3.3807853905929592, p-value: 0.011631598796200687\n",
      "Optimal ARIMA order: (0, 0, 0)\n",
      "Optimal SARIMA order: (0, 0, 0), Seasonal: (0, 0, 0, 0)\n",
      "Constant series detected for Shooting (CV). Predicting constant value: 0.4618402309153749\n",
      "Metrics for Shooting (CV) - MSE: 0.016530851034421725, R2: -0.5971031069229653\n",
      "Constant series detected for Shooting (CV). Predicting constant value: 0.4618402309153749\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  8.71801D-01    |proj g|=  2.98693D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     12      1     0     0   2.986D-05   8.718D-01\n",
      "  F =  0.87180090881355587     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  8.01982D-01    |proj g|=  3.43454D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     16      1     0     0   3.434D-05   8.020D-01\n",
      "  F =  0.80198160503688387     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.08347D-01    |proj g|=  2.77640D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     12      1     0     0   2.776D-05   9.083D-01\n",
      "  F =  0.90834654801111214     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.98927D-01    |proj g|=  2.31636D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     11      1     0     0   2.315D-05   9.989D-01\n",
      "  F =  0.99892696164738659     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.05610D+00    |proj g|=  2.06606D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     10      1     0     0   2.064D-05   1.056D+00\n",
      "  F =   1.0561043235530725     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.10347D+00    |proj g|=  1.87933D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     13      1     0     0   1.877D-05   1.103D+00\n",
      "  F =   1.1034677466997624     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.07169D+00    |proj g|=  2.00267D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     12      1     0     0   2.001D-05   1.072D+00\n",
      "  F =   1.0716861501289259     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.07958D+00    |proj g|=  1.97129D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     12      1     0     0   1.970D-05   1.080D+00\n",
      "  F =   1.0795814207194772     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.08786D+00    |proj g|=  1.93891D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     13      1     0     0   1.937D-05   1.088D+00\n",
      "  F =   1.0878641101399418     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.09944D+00    |proj g|=  1.89455D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     11      1     0     0   1.893D-05   1.099D+00\n",
      "  F =   1.0994368971409720     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.09113D+00    |proj g|=  1.92629D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     15      1     0     0   1.924D-05   1.091D+00\n",
      "  F =   1.0911272111448631     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.09022D+00    |proj g|=  1.92981D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     13      1     0     0   1.926D-05   1.090D+00\n",
      "  F =   1.0902154252329075     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.10851D+00    |proj g|=  1.86048D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     11      1     0     0   1.860D-05   1.109D+00\n",
      "  F =   1.1085093288473564     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.11851D+00    |proj g|=  1.82365D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     10      1     0     0   1.823D-05   1.119D+00\n",
      "  F =   1.1185054596141328     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.11896D+00    |proj g|=  1.82202D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     13      1     0     0   1.820D-05   1.119D+00\n",
      "  F =   1.1189553773677725     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.12205D+00    |proj g|=  1.81077D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     11      1     0     0   1.810D-05   1.122D+00\n",
      "  F =   1.1220522747390387     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.12272D+00    |proj g|=  1.80835D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1      9      1     0     0   1.804D-05   1.123D+00\n",
      "  F =   1.1227188829572712     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.11989D+00    |proj g|=  1.81861D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     13      1     0     0   1.816D-05   1.120D+00\n",
      "  F =   1.1198926083462595     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.12129D+00    |proj g|=  1.81351D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     13      1     0     0   1.813D-05   1.121D+00\n",
      "  F =   1.1212947973081302     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.12840D+00    |proj g|=  1.78792D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     10      1     0     0   1.787D-05   1.128D+00\n",
      "  F =   1.1284008768070914     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.13546D+00    |proj g|=  1.76285D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     14      1     0     0   1.761D-05   1.135D+00\n",
      "  F =   1.1354639126360426     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.13159D+00    |proj g|=  1.77656D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     10      1     0     0   1.774D-05   1.132D+00\n",
      "  F =   1.1315876833023359     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.12920D+00    |proj g|=  1.78508D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     15      1     0     0   1.785D-05   1.129D+00\n",
      "  F =   1.1291951777083415     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.12694D+00    |proj g|=  1.79317D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     11      1     0     0   1.793D-05   1.127D+00\n",
      "  F =   1.1269360643441557     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.12560D+00    |proj g|=  1.79798D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     10      1     0     0   1.795D-05   1.126D+00\n",
      "  F =   1.1255954963084784     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "Metrics for Shooting (CV) - MSE: 0.5543225830996363, R2: -52.55503584555546\n",
      "Insufficient data for Short Track Speed Skating (CV)\n",
      "Insufficient data for Skeleton (CV)\n",
      "Checking stationarity for Ski Jumping (CV):\n",
      "ADF Statistic: -0.9087728566134734, p-value: 0.7850696628345755\n",
      "Skipping ARIMA fitting for non-stationary series: Ski Jumping (CV)\n",
      "All zero values for Snowboarding (CV), skipping.\n",
      "Insufficient data for Softball (CV)\n",
      "Checking stationarity for Speed Skating (CV):\n",
      "ADF Statistic: -0.8681379881156163, p-value: 0.7982839102208574\n",
      "Skipping ARIMA fitting for non-stationary series: Speed Skating (CV)\n",
      "Checking stationarity for Swimming (CV):\n",
      "ADF Statistic: -5.563438796996418, p-value: 1.52345796120743e-06\n",
      "Optimal ARIMA order: (0, 0, 0)\n",
      "Optimal SARIMA order: (0, 0, 0), Seasonal: (0, 0, 0, 0)\n",
      "Constant series detected for Swimming (CV). Predicting constant value: 0.6546536707079771\n",
      "Metrics for Swimming (CV) - MSE: 0.01760852479532316, R2: -0.7962657156123059\n",
      "Constant series detected for Swimming (CV). Predicting constant value: 0.6546536707079771\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.33440D+00    |proj g|=  1.18418D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     14      1     0     0   1.182D-05   1.334D+00\n",
      "  F =   1.3344042518437553     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.27541D+00    |proj g|=  1.33248D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     11      1     0     0   1.331D-05   1.275D+00\n",
      "  F =   1.2754089570809801     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.23482D+00    |proj g|=  1.44515D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     21      1     0     0   1.445D-05   1.235D+00\n",
      "  F =   1.2348221946917324     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.23118D+00    |proj g|=  1.45573D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     12      1     0     0   1.454D-05   1.231D+00\n",
      "  F =   1.2311754619751156     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.24912D+00    |proj g|=  1.40440D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     10      1     0     0   1.402D-05   1.249D+00\n",
      "  F =   1.2491228125236737     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.27774D+00    |proj g|=  1.32627D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     14      1     0     0   1.324D-05   1.278D+00\n",
      "  F =   1.2777439659146752     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.30414D+00    |proj g|=  1.25807D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1      8      1     0     0   1.258D-05   1.304D+00\n",
      "  F =   1.3041387013533268     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.32458D+00    |proj g|=  1.20769D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1      7      1     0     0   1.207D-05   1.325D+00\n",
      "  F =   1.3245757903136213     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.31195D+00    |proj g|=  1.23858D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1      7      1     0     0   1.237D-05   1.312D+00\n",
      "  F =   1.3119483531420932     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.31102D+00    |proj g|=  1.24087D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1      8      1     0     0   1.240D-05   1.311D+00\n",
      "  F =   1.3110230370654803     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.31683D+00    |proj g|=  1.22655D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     16      1     0     0   1.224D-05   1.317D+00\n",
      "  F =   1.3168252512592160     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.33130D+00    |proj g|=  1.19156D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1      7      1     0     0   1.191D-05   1.331D+00\n",
      "  F =   1.3312971063333010     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.33228D+00    |proj g|=  1.18921D-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     12      1     0     0   1.187D-05   1.332D+00\n",
      "  F =   1.3322827697336559     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.34875D+00    |proj g|=  1.15068D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     12      1     0     0   1.149D-05   1.349D+00\n",
      "  F =   1.3487518075124401     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.34669D+00    |proj g|=  1.15545D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     21      1     0     0   1.155D-05   1.347D+00\n",
      "  F =   1.3466865478079049     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.34656D+00    |proj g|=  1.15575D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1      8      1     0     0   1.155D-05   1.347D+00\n",
      "  F =   1.3465567945056776     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.34618D+00    |proj g|=  1.15661D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     13      1     0     0   1.156D-05   1.346D+00\n",
      "  F =   1.3461815277658700     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.34750D+00    |proj g|=  1.15356D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     11      1     0     0   1.154D-05   1.348D+00\n",
      "  F =   1.3475045023122536     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.34851D+00    |proj g|=  1.15125D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     12      1     0     0   1.149D-05   1.349D+00\n",
      "  F =   1.3485051862090383     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.34929D+00    |proj g|=  1.14945D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     12      1     0     0   1.147D-05   1.349D+00\n",
      "  F =   1.3492866731521351     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.34828D+00    |proj g|=  1.15177D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     12      1     0     0   1.151D-05   1.348D+00\n",
      "  F =   1.3482781349104735     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.34576D+00    |proj g|=  1.15759D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     14      1     0     0   1.157D-05   1.346D+00\n",
      "  F =   1.3457585456988015     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.34253D+00    |proj g|=  1.16508D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1      8      1     0     0   1.165D-05   1.343D+00\n",
      "  F =   1.3425340628163378     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.33980D+00    |proj g|=  1.17148D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     14      1     0     0   1.169D-05   1.340D+00\n",
      "  F =   1.3397953118253469     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.33874D+00    |proj g|=  1.17396D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     10      1     0     0   1.174D-05   1.339D+00\n",
      "  F =   1.3387377562306422     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.34273D+00    |proj g|=  1.16462D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     12      1     0     0   1.162D-05   1.343D+00\n",
      "  F =   1.3427320231174404     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.34679D+00    |proj g|=  1.15520D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     14      1     0     0   1.153D-05   1.347D+00\n",
      "  F =   1.3467937767985223     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "Metrics for Swimming (CV) - MSE: 0.8495538449402101, R2: -85.66395754163494\n",
      "Checking stationarity for Synchronized Swimming (CV):\n",
      "ADF Statistic: -2.107770091106611, p-value: 0.24140170937079186\n",
      "Skipping ARIMA fitting for non-stationary series: Synchronized Swimming (CV)\n",
      "Checking stationarity for Table Tennis (CV):\n",
      "ADF Statistic: -3.3524012157428587, p-value: 0.012692569793164462\n",
      "Optimal ARIMA order: (0, 0, 0)\n",
      "Optimal SARIMA order: (0, 0, 0), Seasonal: (0, 0, 0, 0)\n",
      "Constant series detected for Table Tennis (CV). Predicting constant value: 0.7634239536385686\n",
      "Metrics for Table Tennis (CV) - MSE: 0.012705254216239246, R2: -0.41700881772567033\n",
      "Constant series detected for Table Tennis (CV). Predicting constant value: 0.7634239536385686\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.23946D+00    |proj g|=  1.43181D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     10      1     0     0   1.430D-05   1.239D+00\n",
      "  F =   1.2394568955209442     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.22978D+00    |proj g|=  1.45978D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1      9      1     0     0   1.459D-05   1.230D+00\n",
      "  F =   1.2297836405526792     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.17167D+00    |proj g|=  1.63972D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     13      1     0     0   1.638D-05   1.172D+00\n",
      "  F =   1.1716665040359746     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.13460D+00    |proj g|=  1.76587D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     14      1     0     0   1.766D-05   1.135D+00\n",
      "  F =   1.1346044440787761     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.14029D+00    |proj g|=  1.74591D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     10      1     0     0   1.744D-05   1.140D+00\n",
      "  F =   1.1402894292725534     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.12967D+00    |proj g|=  1.78339D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     13      1     0     0   1.781D-05   1.130D+00\n",
      "  F =   1.1296704172723098     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "Metrics for Table Tennis (CV) - MSE: 0.4354904335739486, R2: -47.569967503737224\n",
      "Checking stationarity for Taekwondo (CV):\n",
      "ADF Statistic: -18.906379214773715, p-value: 0.0\n",
      "Optimal ARIMA order: (1, 0, 1)\n",
      "Optimal SARIMA order: (0, 0, 0), Seasonal: (0, 0, 0, 0)\n",
      "Metrics for Taekwondo (CV) - MSE: 0.011365158346690349, R2: -362.3632530519274\n",
      "Constant series detected for Taekwondo (CV). Predicting constant value: 0.4842312992259073\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  8.45836D-01    |proj g|=  3.14614D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     13      1     0     0   3.145D-05   8.458D-01\n",
      "  F =  0.84583612853096546     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  8.93092D-01    |proj g|=  2.86241D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     16      1     0     0   2.861D-05   8.931D-01\n",
      "  F =  0.89309182281947741     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.09253D-01    |proj g|=  2.77138D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     12      1     0     0   2.771D-05   9.093D-01\n",
      "  F =  0.90925268119388747     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "Metrics for Taekwondo (CV) - MSE: 0.3077044708661075, R2: -12946.740943851055\n",
      "Checking stationarity for Tennis (CV):\n",
      "ADF Statistic: -8.553355360782074, p-value: 9.096839810775546e-14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal ARIMA order: (1, 0, 0)\n",
      "Optimal SARIMA order: (1, 0, 0), Seasonal: (0, 0, 0, 0)\n",
      "Metrics for Tennis (CV) - MSE: 0.01292489606374461, R2: -0.9976636568398176\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  3.93877D+01    |proj g|=  1.39044D+03\n",
      "\n",
      "At iterate    5    f=  3.23774D-01    |proj g|=  9.96613D-01\n",
      "\n",
      "At iterate   10    f=  3.85673D-02    |proj g|=  4.29652D-02\n",
      "\n",
      "At iterate   15    f=  3.03044D-02    |proj g|=  8.96528D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     16     31      1     0     0   1.450D-06   3.030D-02\n",
      "  F =   3.0304442914357799E-002\n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  3.52264D+01    |proj g|=  1.13804D+03\n",
      "\n",
      "At iterate    5    f=  2.10535D-01    |proj g|=  6.41865D-01\n",
      "\n",
      "At iterate   10    f= -4.06695D-01    |proj g|=  7.94919D-01\n",
      "\n",
      "At iterate   15    f= -4.51349D-01    |proj g|=  1.20157D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     16     32      1     0     0   8.294D-06  -4.513D-01\n",
      "  F = -0.45134896293409849     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  4.93570D+01    |proj g|=  1.72781D+03\n",
      "\n",
      "At iterate    5    f=  2.86762D-01    |proj g|=  3.34253D+00\n",
      "\n",
      "At iterate   10    f= -3.98426D-01    |proj g|=  1.80197D+00\n",
      "\n",
      "At iterate   15    f= -4.72843D-01    |proj g|=  2.19751D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     18     30      1     0     0   4.033D-06  -4.729D-01\n",
      "  F = -0.47287426490432510     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.44498D+01    |proj g|=  2.90627D+02\n",
      "\n",
      "At iterate    5    f= -2.49927D-02    |proj g|=  2.56629D+00\n",
      "\n",
      "At iterate   10    f= -4.96296D-01    |proj g|=  6.56699D-01\n",
      "\n",
      "At iterate   15    f= -5.08360D-01    |proj g|=  7.91234D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     16     34      1     0     0   4.072D-07  -5.084D-01\n",
      "  F = -0.50835979290008626     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.34148D+01    |proj g|=  2.47444D+02\n",
      "\n",
      "At iterate    5    f=  3.24688D-01    |proj g|=  3.23371D+00\n",
      "\n",
      "At iterate   10    f= -3.91707D-01    |proj g|=  1.40717D+00\n",
      "\n",
      "At iterate   15    f= -4.11208D-01    |proj g|=  2.29328D-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     17     30      1     0     0   1.912D-05  -4.112D-01\n",
      "  F = -0.41120784399961918     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.44792D+01    |proj g|=  2.71519D+02\n",
      "\n",
      "At iterate    5    f= -3.68975D-02    |proj g|=  2.18857D+00\n",
      "\n",
      "At iterate   10    f= -4.81284D-01    |proj g|=  5.34321D-02\n",
      "\n",
      "At iterate   15    f= -5.15982D-01    |proj g|=  2.14740D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     18     30      1     0     0   2.132D-05  -5.160D-01\n",
      "  F = -0.51598447307747874     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.54035D+01    |proj g|=  2.81183D+02\n",
      "\n",
      "At iterate    5    f=  2.10105D-02    |proj g|=  5.82164D-01\n",
      "\n",
      "At iterate   10    f= -4.45130D-01    |proj g|=  1.29328D-01\n",
      "\n",
      "At iterate   15    f= -4.60017D-01    |proj g|=  3.04071D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     16     31      1     0     0   6.961D-06  -4.600D-01\n",
      "  F = -0.46001732057182843     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.79107D+01    |proj g|=  3.38490D+02\n",
      "\n",
      "At iterate    5    f= -2.04128D-01    |proj g|=  1.23438D+00\n",
      "\n",
      "At iterate   10    f= -5.18681D-01    |proj g|=  3.15505D-01\n",
      "\n",
      "At iterate   15    f= -5.43008D-01    |proj g|=  4.04963D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     17     33      1     0     0   4.155D-06  -5.430D-01\n",
      "  F = -0.54301029891708374     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.62774D+01    |proj g|=  2.92957D+02\n",
      "\n",
      "At iterate    5    f= -2.46841D-01    |proj g|=  2.39149D+00\n",
      "\n",
      "At iterate   10    f= -5.47117D-01    |proj g|=  4.43131D-01\n",
      "\n",
      "At iterate   15    f= -5.66360D-01    |proj g|=  2.93190D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     17     26      1     0     0   4.134D-05  -5.664D-01\n",
      "  F = -0.56636063860023111     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.79050D+01    |proj g|=  3.30530D+02\n",
      "\n",
      "At iterate    5    f= -3.35703D-01    |proj g|=  1.73945D+00\n",
      "\n",
      "At iterate   10    f= -5.34697D-01    |proj g|=  1.03564D+00\n",
      "\n",
      "At iterate   15    f= -5.87253D-01    |proj g|=  5.56158D-02\n",
      "\n",
      "At iterate   20    f= -5.87371D-01    |proj g|=  2.50460D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     20     46      1     0     0   2.505D-05  -5.874D-01\n",
      "  F = -0.58737057940669968     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.85806D+01    |proj g|=  3.47360D+02\n",
      "\n",
      "At iterate    5    f= -6.27572D-01    |proj g|=  2.28202D-01\n",
      "\n",
      "At iterate   10    f= -6.30473D-01    |proj g|=  8.30956D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     13     30      1     0     0   2.847D-05  -6.305D-01\n",
      "  F = -0.63047496953995319     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.92158D+01    |proj g|=  3.66571D+02\n",
      "\n",
      "At iterate    5    f= -2.61742D-01    |proj g|=  5.60866D+00\n",
      "\n",
      "At iterate   10    f= -6.56697D-01    |proj g|=  2.96967D-01\n",
      "\n",
      "At iterate   15    f= -6.69607D-01    |proj g|=  1.17130D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     17     31      1     0     0   2.617D-06  -6.696D-01\n",
      "  F = -0.66960725204747429     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.07732D+01    |proj g|=  4.11638D+02\n",
      "\n",
      "At iterate    5    f= -3.00653D-01    |proj g|=  2.96641D+00\n",
      "\n",
      "At iterate   10    f= -6.34590D-01    |proj g|=  2.10224D-01\n",
      "\n",
      "At iterate   15    f= -7.12410D-01    |proj g|=  1.10195D-01\n",
      "\n",
      "At iterate   20    f= -7.13164D-01    |proj g|=  1.65627D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     20     43      1     0     0   1.656D-05  -7.132D-01\n",
      "  F = -0.71316395049804160     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.20750D+01    |proj g|=  4.47415D+02\n",
      "\n",
      "At iterate    5    f= -4.32730D-01    |proj g|=  4.08623D+00\n",
      "\n",
      "At iterate   10    f= -7.20560D-01    |proj g|=  5.75760D-02\n",
      "\n",
      "At iterate   15    f= -7.36102D-01    |proj g|=  3.22823D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     18     75      2     0     0   5.886D-05  -7.361D-01\n",
      "  F = -0.73610287336223301     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "Metrics for Tennis (CV) - MSE: 0.01010407480182483, R2: -0.561679329415711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      "\n",
      " Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking stationarity for Trampolining (CV):\n",
      "ADF Statistic: -2.6984199461935394, p-value: 0.07431208667566631\n",
      "Skipping ARIMA fitting for non-stationary series: Trampolining (CV)\n",
      "Checking stationarity for Triathlon (CV):\n",
      "ADF Statistic: -1.5111098125819777, p-value: 0.5280084896267089\n",
      "Skipping ARIMA fitting for non-stationary series: Triathlon (CV)\n",
      "Checking stationarity for Tug-Of-War (CV):\n",
      "ADF Statistic: -4.338357031302064, p-value: 0.000380965668290575\n",
      "Optimal ARIMA order: (0, 0, 0)\n",
      "Optimal SARIMA order: (0, 0, 0), Seasonal: (0, 0, 0, 0)\n",
      "Constant series detected for Tug-Of-War (CV). Predicting constant value: 0.4472135954999579\n",
      "Metrics for Tug-Of-War (CV) - MSE: 0.019434435406721396, R2: -2.8815665038520013\n",
      "Constant series detected for Tug-Of-War (CV). Predicting constant value: 0.4472135954999579\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  8.88716D-01    |proj g|=  2.88757D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     15      1     0     0   2.887D-05   8.887D-01\n",
      "  F =  0.88871618243162298     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  8.82436D-01    |proj g|=  2.92407D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     15      1     0     0   2.923D-05   8.824D-01\n",
      "  F =  0.88243550283347816     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.47252D-01    |proj g|=  2.56856D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     11      1     0     0   2.567D-05   9.473D-01\n",
      "  F =  0.94725225457951212     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.60901D-01    |proj g|=  2.49939D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     11      1     0     0   2.498D-05   9.609D-01\n",
      "  F =  0.96090124978359059     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "Metrics for Tug-Of-War (CV) - MSE: 0.334203664842338, R2: -65.74923782287763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking stationarity for Volleyball (CV):\n",
      "ADF Statistic: -2.3815793318846854, p-value: 0.14700314278948806\n",
      "Skipping ARIMA fitting for non-stationary series: Volleyball (CV)\n",
      "Checking stationarity for Water Polo (CV):\n",
      "ADF Statistic: -5.406648871933246, p-value: 3.2799725633978845e-06\n",
      "Optimal ARIMA order: (0, 0, 0)\n",
      "Optimal SARIMA order: (0, 0, 0), Seasonal: (0, 0, 0, 0)\n",
      "Constant series detected for Water Polo (CV). Predicting constant value: 0.8293791789556856\n",
      "Metrics for Water Polo (CV) - MSE: 0.009089546864361425, R2: -0.24431403628999648\n",
      "Constant series detected for Water Polo (CV). Predicting constant value: 0.8293791789556856\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.14502D+00    |proj g|=  1.72949D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     12      1     0     0   1.727D-05   1.145D+00\n",
      "  F =   1.1450157674051729     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.18119D+00    |proj g|=  1.60878D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     10      1     0     0   1.607D-05   1.181D+00\n",
      "  F =   1.1811882917098877     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.13731D+00    |proj g|=  1.75633D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     10      1     0     0   1.756D-05   1.137D+00\n",
      "  F =   1.1373129834031401     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.10187D+00    |proj g|=  1.88534D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     12      1     0     0   1.884D-05   1.102D+00\n",
      "  F =   1.1018740655265780     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.10028D+00    |proj g|=  1.89135D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     21      1     0     0   1.891D-05   1.100D+00\n",
      "  F =   1.1002811662441858     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.08127D+00    |proj g|=  1.96463D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     21      1     0     0   1.965D-05   1.081D+00\n",
      "  F =   1.0812746033143339     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.08378D+00    |proj g|=  1.95482D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     11      1     0     0   1.953D-05   1.084D+00\n",
      "  F =   1.0837790388324811     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.11519D+00    |proj g|=  1.83578D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     10      1     0     0   1.835D-05   1.115D+00\n",
      "  F =   1.1151916980594785     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.11379D+00    |proj g|=  1.84093D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     10      1     0     0   1.840D-05   1.114D+00\n",
      "  F =   1.1137907074800131     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.11401D+00    |proj g|=  1.84014D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     11      1     0     0   1.839D-05   1.114D+00\n",
      "  F =   1.1140063203183270     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.12389D+00    |proj g|=  1.80413D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     13      1     0     0   1.802D-05   1.124D+00\n",
      "  F =   1.1238874131338483     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.12200D+00    |proj g|=  1.81095D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     13      1     0     0   1.809D-05   1.122D+00\n",
      "  F =   1.1220003969052958     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.13580D+00    |proj g|=  1.76165D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     10      1     0     0   1.761D-05   1.136D+00\n",
      "  F =   1.1358015896212155     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.12654D+00    |proj g|=  1.79458D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     10      1     0     0   1.792D-05   1.127D+00\n",
      "  F =   1.1265425640410562     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.12751D+00    |proj g|=  1.79110D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     13      1     0     0   1.790D-05   1.128D+00\n",
      "  F =   1.1275118521021661     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.11704D+00    |proj g|=  1.82901D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     13      1     0     0   1.827D-05   1.117D+00\n",
      "  F =   1.1170392121615760     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.11191D+00    |proj g|=  1.84788D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     10      1     0     0   1.847D-05   1.112D+00\n",
      "  F =   1.1119094268933962     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.11151D+00    |proj g|=  1.84936D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     10      1     0     0   1.848D-05   1.112D+00\n",
      "  F =   1.1115066948292462     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.10640D+00    |proj g|=  1.86837D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     21      1     0     0   1.868D-05   1.106D+00\n",
      "  F =   1.1063957156785580     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.10158D+00    |proj g|=  1.88643D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     15      1     0     0   1.886D-05   1.102D+00\n",
      "  F =   1.1015849949396308     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.09989D+00    |proj g|=  1.89285D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     13      1     0     0   1.891D-05   1.100D+00\n",
      "  F =   1.0998862008124080     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.10832D+00    |proj g|=  1.86119D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     11      1     0     0   1.860D-05   1.108D+00\n",
      "  F =   1.1083181567217051     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.10305D+00    |proj g|=  1.88092D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     12      1     0     0   1.879D-05   1.103D+00\n",
      "  F =   1.1030462039545452     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.09616D+00    |proj g|=  1.90699D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     13      1     0     0   1.905D-05   1.096D+00\n",
      "  F =   1.0961640140956741     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.09449D+00    |proj g|=  1.91338D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     13      1     0     0   1.911D-05   1.094D+00\n",
      "  F =   1.0944914017794312     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "Metrics for Water Polo (CV) - MSE: 0.5021721795183876, R2: -67.74488914942937\n",
      "Checking stationarity for Weightlifting (CV):\n",
      "ADF Statistic: -4.620264457177015, p-value: 0.0001185048898471389\n",
      "Optimal ARIMA order: (0, 0, 0)\n",
      "Optimal SARIMA order: (0, 0, 0), Seasonal: (0, 0, 0, 0)\n",
      "Constant series detected for Weightlifting (CV). Predicting constant value: 0.8660254037844386\n",
      "Metrics for Weightlifting (CV) - MSE: 0.026601765430143313, R2: -0.3957869445197517\n",
      "Constant series detected for Weightlifting (CV). Predicting constant value: 0.8660254037844386\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.27510D+00    |proj g|=  1.33331D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     11      1     0     0   1.332D-05   1.275D+00\n",
      "  F =   1.2750974969787823     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.08263D+00    |proj g|=  1.95931D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     11      1     0     0   1.957D-05   1.083D+00\n",
      "  F =   1.0826292329952645     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.05246D+00    |proj g|=  2.08119D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     10      1     0     0   2.079D-05   1.052D+00\n",
      "  F =   1.0524558745475545     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.06284D+00    |proj g|=  2.03842D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     12      1     0     0   2.035D-05   1.063D+00\n",
      "  F =   1.0628377007483321     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.05500D+00    |proj g|=  2.07065D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     10      1     0     0   2.068D-05   1.055D+00\n",
      "  F =   1.0549952239917053     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.05660D+00    |proj g|=  2.06399D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     12      1     0     0   2.061D-05   1.057D+00\n",
      "  F =   1.0566046170025303     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.06802D+00    |proj g|=  2.01742D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     12      1     0     0   2.017D-05   1.068D+00\n",
      "  F =   1.0680156616016929     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.05574D+00    |proj g|=  2.06759D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     11      1     0     0   2.067D-05   1.056D+00\n",
      "  F =   1.0557362481961858     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.06154D+00    |proj g|=  2.04372D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     10      1     0     0   2.042D-05   1.062D+00\n",
      "  F =   1.0615412785128711     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.08075D+00    |proj g|=  1.96671D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     10      1     0     0   1.965D-05   1.081D+00\n",
      "  F =   1.0807466427428560     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.08804D+00    |proj g|=  1.93822D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     12      1     0     0   1.936D-05   1.088D+00\n",
      "  F =   1.0880416626642460     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.10898D+00    |proj g|=  1.85872D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     10      1     0     0   1.858D-05   1.109D+00\n",
      "  F =   1.1089849606979252     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.11080D+00    |proj g|=  1.85199D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     10      1     0     0   1.851D-05   1.111D+00\n",
      "  F =   1.1107951501990563     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.10501D+00    |proj g|=  1.87354D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     13      1     0     0   1.872D-05   1.105D+00\n",
      "  F =   1.1050103427830107     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.10930D+00    |proj g|=  1.85755D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     14      1     0     0   1.857D-05   1.109D+00\n",
      "  F =   1.1092976887805268     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.12092D+00    |proj g|=  1.81485D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     14      1     0     0   1.813D-05   1.121D+00\n",
      "  F =   1.1209237441978250     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.11821D+00    |proj g|=  1.82475D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     10      1     0     0   1.824D-05   1.118D+00\n",
      "  F =   1.1182066415476226     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.12768D+00    |proj g|=  1.79049D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     10      1     0     0   1.790D-05   1.128D+00\n",
      "  F =   1.1276824612796001     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.13600D+00    |proj g|=  1.76096D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     10      1     0     0   1.759D-05   1.136D+00\n",
      "  F =   1.1359990587477196     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.13579D+00    |proj g|=  1.76170D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     21      1     0     0   1.762D-05   1.136D+00\n",
      "  F =   1.1357885587769523     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.14054D+00    |proj g|=  1.74502D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     12      1     0     0   1.745D-05   1.141D+00\n",
      "  F =   1.1405437055810888     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.13858D+00    |proj g|=  1.75188D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     12      1     0     0   1.752D-05   1.139D+00\n",
      "  F =   1.1385826127625354     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.14174D+00    |proj g|=  1.74085D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     11      1     0     0   1.739D-05   1.142D+00\n",
      "  F =   1.1417406241678183     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.13885D+00    |proj g|=  1.75095D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     12      1     0     0   1.749D-05   1.139D+00\n",
      "  F =   1.1388477453519998     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "Metrics for Weightlifting (CV) - MSE: 0.5368423871205272, R2: -27.1679649110271\n",
      "Checking stationarity for Wrestling (CV):\n",
      "ADF Statistic: -4.14308053006964, p-value: 0.0008213517917481831\n",
      "Optimal ARIMA order: (0, 0, 0)\n",
      "Optimal SARIMA order: (0, 0, 0), Seasonal: (0, 0, 0, 0)\n",
      "Constant series detected for Wrestling (CV). Predicting constant value: 2.442316990216822\n",
      "Metrics for Wrestling (CV) - MSE: 0.1727749182823548, R2: -22.95198549784807\n",
      "Constant series detected for Wrestling (CV). Predicting constant value: 2.442316990216822\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.01154D+00    |proj g|=  3.05680D-06\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      0      1      0     0     0   3.057D-06   2.012D+00\n",
      "  F =   2.0115413591151619     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.84863D+00    |proj g|=  4.23421D-06\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      0      1      0     0     0   4.234D-06   1.849D+00\n",
      "  F =   1.8486294741654987     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.74064D+00    |proj g|=  5.25495D-06\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      0      1      0     0     0   5.255D-06   1.741D+00\n",
      "  F =   1.7406393736360282     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.67743D+00    |proj g|=  5.96305D-06\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      0      1      0     0     0   5.963D-06   1.677D+00\n",
      "  F =   1.6774335513644598     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.62115D+00    |proj g|=  6.67353D-06\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      0      1      0     0     0   6.674D-06   1.621D+00\n",
      "  F =   1.6211472786883219     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.57345D+00    |proj g|=  7.34153D-06\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      0      1      0     0     0   7.342D-06   1.573D+00\n",
      "  F =   1.5734486409605082     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.55544D+00    |proj g|=  7.61082D-06\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      0      1      0     0     0   7.611D-06   1.555D+00\n",
      "  F =   1.5554380518317323     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.53253D+00    |proj g|=  7.96763D-06\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      0      1      0     0     0   7.968D-06   1.533D+00\n",
      "  F =   1.5325312298337108     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.50059D+00    |proj g|=  8.49318D-06\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      0      1      0     0     0   8.493D-06   1.501D+00\n",
      "  F =   1.5005888228533864     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.47178D+00    |proj g|=  8.99705D-06\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      0      1      0     0     0   8.997D-06   1.472D+00\n",
      "  F =   1.4717756214061730     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.44881D+00    |proj g|=  9.41980D-06\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      0      1      0     0     0   9.420D-06   1.449D+00\n",
      "  F =   1.4488146513238263     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.43901D+00    |proj g|=  9.60632D-06\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      0      1      0     0     0   9.606D-06   1.439D+00\n",
      "  F =   1.4390121635486013     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.42918D+00    |proj g|=  9.79699D-06\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      0      1      0     0     0   9.797D-06   1.429D+00\n",
      "  F =   1.4291849171007431     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.41364D+00    |proj g|=  1.01063D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     21      1     0     0   1.010D-05   1.414D+00\n",
      "  F =   1.4136402746534882     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.39789D+00    |proj g|=  1.04297D-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Line search cannot locate an adequate point after MAXLS\n",
      "  function and gradient evaluations.\n",
      "  Previous x, f and g restored.\n",
      " Possible causes: 1 error in function or gradient evaluation;\n",
      "                  2 rounding error dominate computation.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     12      1     0     0   1.041D-05   1.398D+00\n",
      "  F =   1.3978938770449676     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.39300D+00    |proj g|=  1.05323D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     14      1     0     0   1.052D-05   1.393D+00\n",
      "  F =   1.3929998370639667     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.38286D+00    |proj g|=  1.07481D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     15      1     0     0   1.075D-05   1.383D+00\n",
      "  F =   1.3828567585524232     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.37656D+00    |proj g|=  1.08844D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     21      1     0     0   1.088D-05   1.377D+00\n",
      "  F =   1.3765583823640213     \n",
      "\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH                              \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.36682D+00    |proj g|=  1.10984D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     14      1     0     0   1.109D-05   1.367D+00\n",
      "  F =   1.3668212500728489     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.36144D+00    |proj g|=  1.12184D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     13      1     0     0   1.119D-05   1.361D+00\n",
      "  F =   1.3614433462867928     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.35901D+00    |proj g|=  1.12732D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     15      1     0     0   1.127D-05   1.359D+00\n",
      "  F =   1.3590093348719667     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.35708D+00    |proj g|=  1.13168D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     12      1     0     0   1.130D-05   1.357D+00\n",
      "  F =   1.3570766508094154     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.34998D+00    |proj g|=  1.14786D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1      8      1     0     0   1.148D-05   1.350D+00\n",
      "  F =   1.3499800351983948     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.33943D+00    |proj g|=  1.17233D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     13      1     0     0   1.171D-05   1.339D+00\n",
      "  F =   1.3394305949311152     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.33190D+00    |proj g|=  1.19012D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1      8      1     0     0   1.190D-05   1.332D+00\n",
      "  F =   1.3319017664377379     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.32634D+00    |proj g|=  1.20343D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      1     11      1     0     0   1.202D-05   1.326D+00\n",
      "  F =   1.3263408705324264     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "Metrics for Wrestling (CV) - MSE: 0.7120699731203108, R2: -97.71507878104201\n",
      "All zero values for climbing (CV), skipping.\n",
      "All zero values for Fitness (CV), skipping.\n",
      "All zero values for Headis (CV), skipping.\n",
      "\n",
      "Metrics saved to 'model_metrics.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from pmdarima.arima import auto_arima\n",
    "import warnings\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "import logging\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Setup unified logging\n",
    "log_file = \"model_processing.log\"\n",
    "logging.basicConfig(filename=log_file, level=logging.INFO, format='%(asctime)s - %(message)s')\n",
    "\n",
    "# Ensure output directory for plots\n",
    "output_dir = \"model_plots\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "MIN_DATA_POINTS = 5  # Minimum data points to fit the model\n",
    "\n",
    "# Data tracking\n",
    "metrics = []\n",
    "\n",
    "def log_message(message):\n",
    "    print(message)  # For console viewing (optional)\n",
    "    logging.info(message)  # For saving into the log file\n",
    "\n",
    "def incremental_backtest(ts_data, model_func, order, seasonal_order=None, sport_name=\"\", parameter=\"\"):\n",
    "    predictions, actuals, indices = [], [], []\n",
    "\n",
    "    for t in range(len(ts_data) - 1):\n",
    "        train = ts_data.iloc[:t + 1]\n",
    "\n",
    "        if len(train) <= max(order):\n",
    "            continue\n",
    "\n",
    "        if np.all(train == train.iloc[0]):  # Constant series detected\n",
    "            constant_value = train.iloc[0]\n",
    "            log_message(f\"Constant series detected for {sport_name} ({parameter}). Predicting constant value: {constant_value}\")\n",
    "            predictions.append(constant_value)\n",
    "            actuals.append(ts_data.iloc[t + 1])\n",
    "            indices.append(ts_data.index[t + 1])\n",
    "            continue\n",
    "\n",
    "        if model_func == ARIMA:\n",
    "            model = model_func(train, order=order)\n",
    "        elif model_func == SARIMAX:\n",
    "            model = model_func(train, order=order, seasonal_order=seasonal_order)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported model function\")\n",
    "\n",
    "        try:\n",
    "            model_fit = model.fit()\n",
    "            forecast = model_fit.forecast(steps=1)\n",
    "            forecast_value = forecast.iloc[0] if isinstance(forecast, pd.Series) else forecast[0]\n",
    "            predictions.append(forecast_value)\n",
    "            actuals.append(ts_data.iloc[t + 1])\n",
    "            indices.append(ts_data.index[t + 1])\n",
    "        except Exception as e:\n",
    "            log_message(f\"Fitting error for {sport_name} ({parameter}): {e}\")\n",
    "            break\n",
    "\n",
    "    if predictions:\n",
    "        mse = mean_squared_error(actuals, predictions)\n",
    "        r2 = r2_score(actuals, predictions)\n",
    "        metrics.append({\n",
    "            'Sport': sport_name,\n",
    "            'Parameter': parameter,\n",
    "            'Model': model_func.__name__,\n",
    "            'MSE': mse,\n",
    "            'R2': r2\n",
    "        })\n",
    "        log_message(f\"Metrics for {sport_name} ({parameter}) - MSE: {mse}, R2: {r2}\")\n",
    "\n",
    "        # Save plot\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(indices, actuals, label='Actual', marker='o', linestyle='-')\n",
    "        plt.plot(indices, predictions, label=f'{model_func.__name__} Predicted', marker='x', linestyle='--')\n",
    "        plt.title(f'Actual vs Predicted for {sport_name} ({parameter})')\n",
    "        plt.xlabel('Year')\n",
    "        plt.ylabel('Value')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{output_dir}/{sport_name}_{parameter}_{model_func.__name__}.png\")\n",
    "        plt.close()\n",
    "    else:\n",
    "        log_message(f\"No predictions made for {sport_name} ({parameter}).\")\n",
    "\n",
    "def check_stationarity(ts_data):\n",
    "    if np.all(ts_data == ts_data.iloc[0]):\n",
    "        log_message(\"Series is constant, skipping stationarity test.\")\n",
    "        return False\n",
    "    result = adfuller(ts_data)\n",
    "    log_message(f\"ADF Statistic: {result[0]}, p-value: {result[1]}\")\n",
    "    return result[1] <= 0.05  # True if stationary\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"not_final3.csv\")\n",
    "df = df.rename(columns={'Sport_-1': 'Sport'})\n",
    "\n",
    "parameters = ['drug', 'equity', 'popularity', 'normalizedcountry', 'CV']\n",
    "\n",
    "for parameter in parameters:\n",
    "    log_message(f\"\\nProcessing parameter: {parameter}\")\n",
    "\n",
    "    param_columns = [col for col in df.columns if col.startswith(f\"{parameter}_\")]\n",
    "    melted_data = df[['Sport'] + param_columns].melt(id_vars='Sport', var_name='Year', value_name='Value')\n",
    "    melted_data['Year'] = melted_data['Year'].str.extract(r'(\\d+)').astype(int)\n",
    "\n",
    "    for sport_name in melted_data['Sport'].unique():\n",
    "        sport_data = melted_data[melted_data['Sport'] == sport_name].sort_values('Year')\n",
    "\n",
    "        if parameter == 'drug':\n",
    "            sport_data['Value'] = sport_data['Value'].fillna(0)\n",
    "        elif parameter in ['CV', 'popularity']:\n",
    "            sport_data = sport_data[sport_data['Value'] != 0].dropna(subset=['Value'])\n",
    "        else:\n",
    "            sport_data = sport_data.dropna(subset=['Value'])\n",
    "\n",
    "        if sport_data['Value'].sum() == 0:\n",
    "            log_message(f\"All zero values for {sport_name} ({parameter}), skipping.\")\n",
    "            continue\n",
    "\n",
    "        ts_data = sport_data.set_index('Year')['Value']\n",
    "\n",
    "        if len(ts_data) < MIN_DATA_POINTS:\n",
    "            log_message(f\"Insufficient data for {sport_name} ({parameter})\")\n",
    "            continue\n",
    "\n",
    "        log_message(f\"Checking stationarity for {sport_name} ({parameter}):\")\n",
    "        is_stationary = check_stationarity(ts_data)\n",
    "\n",
    "        if not is_stationary:\n",
    "            log_message(f\"Skipping ARIMA fitting for non-stationary series: {sport_name} ({parameter})\")\n",
    "            continue\n",
    "\n",
    "        auto_arima_model = auto_arima(ts_data, seasonal=False, trace=False)\n",
    "        arima_order = auto_arima_model.order\n",
    "\n",
    "        auto_sarima_model = auto_arima(ts_data, seasonal=True, m=1, trace=False)\n",
    "        sarima_order = auto_sarima_model.order\n",
    "        sarima_seasonal_order = auto_sarima_model.seasonal_order\n",
    "\n",
    "        log_message(f\"Optimal ARIMA order: {arima_order}\")\n",
    "        log_message(f\"Optimal SARIMA order: {sarima_order}, Seasonal: {sarima_seasonal_order}\")\n",
    "\n",
    "        incremental_backtest(ts_data, ARIMA, arima_order, sport_name=sport_name, parameter=parameter)\n",
    "        incremental_backtest(ts_data, SARIMAX, sarima_order, seasonal_order=sarima_seasonal_order, sport_name=sport_name, parameter=parameter)\n",
    "\n",
    "# Save metrics to CSV\n",
    "metrics_df = pd.DataFrame(metrics)\n",
    "metrics_df.to_csv('model_metrics.csv', index=False)\n",
    "log_message(\"\\nMetrics saved to 'model_metrics.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load metrics data\n",
    "metrics_df = pd.read_csv('model_metrics.csv')\n",
    "\n",
    "# Function to create a pivot table\n",
    "def create_model_matrix(metrics_df, metric, model_type):\n",
    "    pivot_df = metrics_df[metrics_df['Model'] == model_type].pivot(\n",
    "        index='Sport', columns='Parameter', values=metric\n",
    "    )\n",
    "    return pivot_df\n",
    "\n",
    "# Handle empty matrix scenario in plotting\n",
    "def plot_model_quality(matrix, title):\n",
    "    if matrix.empty:\n",
    "        print(f\"No data available to plot for {title}.\")\n",
    "        return\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.heatmap(matrix, annot=True, cmap='coolwarm', fmt='.2f', cbar_kws={'label': title})\n",
    "    plt.title(f'{title} Heatmap')\n",
    "    plt.xlabel('Parameter')\n",
    "    plt.ylabel('Sport')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Generate and plot for ARIMA R and MSE\n",
    "arima_r2_matrix = create_model_matrix(metrics_df, 'R2', 'ARIMA')\n",
    "plot_model_quality(arima_r2_matrix, 'ARIMA R')\n",
    "\n",
    "arima_mse_matrix = create_model_matrix(metrics_df, 'MSE', 'ARIMA')\n",
    "plot_model_quality(arima_mse_matrix, 'ARIMA MSE')\n",
    "\n",
    "# Generate and plot for SARIMA R and MSE\n",
    "sarima_r2_matrix = create_model_matrix(metrics_df, 'R2', 'SARIMAX')\n",
    "plot_model_quality(sarima_r2_matrix, 'SARIMA R')\n",
    "\n",
    "sarima_mse_matrix = create_model_matrix(metrics_df, 'MSE', 'SARIMAX')\n",
    "plot_model_quality(sarima_mse_matrix, 'SARIMA MSE')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
